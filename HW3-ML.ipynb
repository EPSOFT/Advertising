{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08685b08",
   "metadata": {},
   "source": [
    "<font size=\"1\">  \n",
    "<h1>Subject: Home Work 3<h1>\n",
    "    <p>Shahrood University of Technology (SUT)<p>\n",
    "    <p> Artificial Intelligence</p>\n",
    "    <p> Student Number: 40103834 </p>\n",
    "    <p style=\"color:yellow;\">Author: Ehsan Paydar</p> \n",
    "    </font>  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7777b2cf",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#a21441;\">Import Library</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "41180759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import csv \n",
    "from re import X\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68574200",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#a21441;\">Phase one - Part 1 / Load Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "538240bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  Radio  Newspaper  Sales\n",
       "0           1  230.1   37.8       69.2   22.1\n",
       "1           2   44.5   39.3       45.1   10.4\n",
       "2           3   17.2   45.9       69.3    9.3\n",
       "3           4  151.5   41.3       58.5   18.5\n",
       "4           5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Advertising.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be26c430",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#a21441;\">Phase one - Part 2 / Delete the first column</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e83fb3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(dataset.columns[[0]],axis = 1, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6560a8a4",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#a21441;\">Phase one - Part  3 / Split Data Into Features And Target</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "66dec87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset[['TV', 'Radio', 'Newspaper']]\n",
    "target = dataset['Sales']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02fa2f3a",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#a21441;\">Phase one - Part  4 / Split Training And Test Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b8b30a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98dd6469",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#a21441;\">Phase one - Part  5 / Data Normalization Feature Engineering Methods</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "dcd7f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# fit the scaler to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# transform the training and test data using the scaler\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "631d97c3",
   "metadata": {},
   "source": [
    "<h1 style=\"color:yellow;\">Phase Two - Part  1 / Build And Train The Model (Linear Regeression)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "efe4022b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression model object\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be1bee56",
   "metadata": {},
   "source": [
    "<h1 style=\"color:yellow;\">Phase Two - Part  2 / Model evaluation using MSE and R2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f4ab13d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.1740973539761064\n",
      "R2: 0.8994380241009119\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the mean squared error\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# calculate the r2 score\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "# print the results\n",
    "print('MSE:', mse)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b99ac444",
   "metadata": {},
   "source": [
    "<h1 style=\"color:yellow;\">Phase Two - Part 4 / Convergence trend diagram</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "eb3217b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epsoft/opt/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a scatter plot of the predicted values against the target values\n",
    "sns.scatterplot(y_test, y_pred)\n",
    "\n",
    "\n",
    "# add labels and titles\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Linear Regression Predictions')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ea746e4",
   "metadata": {},
   "source": [
    "<h1 style=\"color:yellow;\">Phase Two - Part 5 / The amount of prediction error according to the formula : Error = Ypred - Ytest </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "86aedfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted     Error\n",
      "95     16.9  16.408024  0.491976\n",
      "15     22.4  20.889882  1.510118\n",
      "30     21.4  21.553843 -0.153843\n",
      "158     7.3  10.608503 -3.308503\n",
      "128    24.7  22.112373  2.587627\n",
      "115    12.6  13.105592 -0.505592\n",
      "69     22.3  21.057192  1.242808\n",
      "170     8.4   7.461010  0.938990\n",
      "174    11.5  13.606346 -2.106346\n",
      "45     14.9  15.155070 -0.255070\n",
      "66      9.5   9.048320  0.451680\n",
      "182     8.7   6.653283  2.046717\n",
      "165    11.9  14.345545 -2.445545\n",
      "78      5.3   8.903493 -3.603493\n",
      "186    10.3   9.689590  0.610410\n",
      "177    11.7  12.164944 -0.464944\n",
      "56      5.5   8.736284 -3.236284\n",
      "152    16.6  16.265073  0.334927\n",
      "82     11.3  10.277596  1.022404\n",
      "68     18.9  18.831091  0.068909\n",
      "124    19.7  19.560367  0.139633\n",
      "16     12.5  13.251035 -0.751035\n",
      "148    10.9  12.336207 -1.436207\n",
      "93     22.2  21.306951  0.893049\n",
      "65      9.3   7.827403  1.472597\n",
      "60      8.1   5.809574  2.290426\n",
      "84     21.7  20.757532  0.942468\n",
      "67     13.4  11.981381  1.418619\n",
      "125    10.6   9.183496  1.416504\n",
      "132     5.7   8.506699 -2.806699\n",
      "9      10.6  12.466468 -1.866468\n",
      "18     11.3  10.003377  1.296623\n",
      "55     23.7  21.387671  2.312329\n",
      "75      8.7  12.249664 -3.549664\n",
      "150    16.1  18.266615 -2.166615\n",
      "104    20.7  20.137663  0.562337\n",
      "135    11.6  14.055140 -2.455140\n",
      "137    20.8  20.854112 -0.054112\n",
      "164    11.9  11.017444  0.882556\n",
      "76      6.9   4.568996  2.331004\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe of actual, predicted and error values\n",
    "error = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Error': y_test - y_pred})\n",
    "\n",
    "# print the dataframe\n",
    "print(error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90776b2e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:yellow;\">Phase Two - Part 6 (+) /Drawing the graph of the data and fitting the prediction line of the model to them</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b1e907a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epsoft/opt/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# create a scatterplot of the data points\n",
    "sns.scatterplot(X_test[:,0], y_test) \n",
    "\n",
    "# get the linearly fitted line\n",
    "line_coeffs = np.polyfit(X_test[:,0], y_pred, 1) \n",
    "line = np.poly1d(line_coeffs) \n",
    "\n",
    "# add the line to the plot\n",
    "x_line = np.linspace(min(X_test[:,0]), max(X_test[:,0]), 100) \n",
    "plt.plot(x_line, line(x_line), color='red', linewidth=3) \n",
    "\n",
    "# add labels and titles\n",
    "plt.xlabel('TV Advertising ($)') \n",
    "plt.ylabel('Sales ($)') \n",
    "plt.title('Linear Regression Model Fit') \n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cdc7ef3",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Phase Three - Part 1 / Again, we use the initial data of the dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b65c31cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  Radio  Newspaper  Sales\n",
       "0           1  230.1   37.8       69.2   22.1\n",
       "1           2   44.5   39.3       45.1   10.4\n",
       "2           3   17.2   45.9       69.3    9.3\n",
       "3           4  151.5   41.3       58.5   18.5\n",
       "4           5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Advertising.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cea2bfd",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Phase Three - Part 2-1 / The correlation matrix</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "515445f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.drop(dataset.columns[[0]],axis = 1, inplace=True)\n",
    "\n",
    "# create correlation matrix\n",
    "corr_matrix = dataset.corr()\n",
    "\n",
    "# visualize the correlation matrix\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True)\n",
    "\n",
    "# add labels and titles\n",
    "plt.title('Advertising Correlation Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78d24ad7",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Phase Three - Part 2-2 / Create polynomial features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8a3be703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create polynomial features\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07851fab",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Phase Three - Part 3 / Correlation matrix analysis produces features based on other features (combine and interactions techniques) or delete features that do not have a significant effect.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b52eb5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the features with low correlation to the target \n",
    "data = dataset.drop([\"Newspaper\"], axis=1) \n",
    "X = data[[\"TV\", \"Radio\"]]\n",
    "y = data[\"Sales\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a764bb8",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Phase Three - Part 4 / Split data into train and test set</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b042a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be506596",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Phase Three - Part 5 / Normalization technique on the data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b314ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec4b0157",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Phase Three - Part 6 / Train the model based on new data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b904f8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the new data\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "# Train the model on the new data\n",
    "model.fit(X_test_poly, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7624b058",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Phase Three - Part 7 / Train the model based on new data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "254cb540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted      Error\n",
      "88     12.9  17.254436  -4.354436\n",
      "68     18.9  22.719332  -3.819332\n",
      "91      7.3  20.427994 -13.127994\n",
      "99     17.2   7.542709   9.657291\n",
      "9      10.6  24.371030 -13.771030\n",
      "126     6.6  12.559272  -5.959272\n",
      "190    10.8  22.807850 -12.007850\n",
      "45     14.9   8.343714   6.556286\n",
      "104    20.7  12.058602   8.641398\n",
      "30     21.4  15.690246   5.709754\n",
      "199    13.4   7.891664   5.508336\n",
      "95     16.9   8.270827   8.629173\n",
      "132     5.7  11.860560  -6.160560\n",
      "51     10.7   6.165911   4.534089\n",
      "156    15.3  10.576644   4.723356\n",
      "180    10.5  12.362895  -1.862895\n",
      "6      11.8   6.743910   5.056090\n",
      "46     10.6  16.650821  -6.050821\n",
      "37     14.7  10.686617   4.013383\n",
      "16     12.5  19.038882  -6.538882\n",
      "177    11.7  20.152239  -8.452239\n",
      "178    11.8  13.113781  -1.313781\n",
      "120    15.5   9.562739   5.937261\n",
      "137    20.8  22.106752  -1.306752\n",
      "135    11.6   8.967252   2.632748\n",
      "119     6.6   7.779444  -1.179444\n",
      "61     24.2  22.407452   1.792548\n",
      "108     5.3  12.720660  -7.420660\n",
      "20     18.0  10.255300   7.744700\n",
      "38     10.1   6.223686   3.876314\n",
      "87     16.0  11.646777   4.353223\n",
      "171    14.5  10.224319   4.275681\n",
      "13      9.7  23.397639 -13.697639\n",
      "93     22.2   9.174032  13.025968\n",
      "89     16.7  15.361434   1.338566\n",
      "26     15.0  21.056758  -6.056758\n",
      "41     17.1  10.979529   6.120471\n",
      "84     21.7  20.233708   1.466292\n",
      "117     9.4  11.851533  -2.451533\n",
      "150    16.1   6.587799   9.512201\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict on the test set\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Calculate the error\n",
    "error = y_test - y_pred\n",
    "\n",
    "# Create a dataframe to visualize the errors\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Error': error})\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f7dd3ef",
   "metadata": {},
   "source": [
    "<h1 style=\"color:green;\">Phase Three - Part 8(+) / Drawing the graph of the data and fitting the prediction line of the model to them.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e946397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data and fit line\n",
    "plt.scatter(X_test, y_test, color='red')\n",
    "predicted_line = poly_features.fit_transform(X_test)\n",
    "plt.plot(X_test, model.predict(predicted_line), color='blue')\n",
    "plt.xlabel('Input Features')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Polynomial Model Fit')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2594c3aa",
   "metadata": {},
   "source": [
    "<h1 style=\"color:orange;\">Phase Four - Part 1/ Load Dataset </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c1ffcc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Advertising.csv')\n",
    "\n",
    "dataset.drop(dataset.columns[[0]],axis = 1, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c36b9602",
   "metadata": {},
   "source": [
    "<h1 style=\"color:orange;\">Phase Four - Part 2 / Split the data again into training and test data. </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "43264ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b3787b8",
   "metadata": {},
   "source": [
    "<h1 style=\"color:orange;\">Phase Four - Part 3/ Linear Regeression with SGDRegressor </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7200dbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 235157292833.16, NNZs: 2, Bias: 30645028560.386078, T: 128, Avg. loss: 22630602602928801678815657984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1502797966345.07, NNZs: 2, Bias: 90645028560.386078, T: 256, Avg. loss: 23652526788711555282566643712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1889447220316.67, NNZs: 2, Bias: 50645028560.386078, T: 384, Avg. loss: 24100661986994215371252170752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2073235132376.31, NNZs: 2, Bias: 93465239964.038025, T: 512, Avg. loss: 25355904029751506795795316736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2498594416725.36, NNZs: 2, Bias: 33465239964.038025, T: 640, Avg. loss: 22557110103052152511213338624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2557456389947.46, NNZs: 2, Bias: -26534760035.961975, T: 768, Avg. loss: 23125743901521541152687259648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1092661890745.66, NNZs: 2, Bias: -4755073408.765129, T: 896, Avg. loss: 24290859420482183579742240768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1120876257892.17, NNZs: 2, Bias: -3457185403.938053, T: 1024, Avg. loss: 23880588158480113095558561792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1179240051986.99, NNZs: 2, Bias: 16542814596.061951, T: 1152, Avg. loss: 24387541529493595695538503680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1127976485041.18, NNZs: 2, Bias: -72823633916.081863, T: 1280, Avg. loss: 24259701899594798583001382912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 272392946749.53, NNZs: 2, Bias: -58713567294.245522, T: 1408, Avg. loss: 1179175264829224816299999232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 373254256193.54, NNZs: 2, Bias: -48520473239.089569, T: 1536, Avg. loss: 1064654705550914270198235136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 303120242136.16, NNZs: 2, Bias: -43121863117.946312, T: 1664, Avg. loss: 1007946267419252250938179584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 226508113112.99, NNZs: 2, Bias: -22797766266.621063, T: 1792, Avg. loss: 1027297354679193579856855040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 192640007579.43, NNZs: 2, Bias: -14713848289.527954, T: 1920, Avg. loss: 868718881663414601414344704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 453917655781.31, NNZs: 2, Bias: -4098612919.883453, T: 2048, Avg. loss: 985229249075023189794357248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 472794624995.87, NNZs: 2, Bias: 20594093095.916748, T: 2176, Avg. loss: 1004287239341718175370706944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 49143887249.91, NNZs: 2, Bias: 13071845192.919250, T: 2304, Avg. loss: 979152157135698939640545280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 182460674093.92, NNZs: 2, Bias: 3296726336.117602, T: 2432, Avg. loss: 1002988982903042628938366976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 323241733938.86, NNZs: 2, Bias: -4531533234.140135, T: 2560, Avg. loss: 901545112867875933353148416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 36626363902.90, NNZs: 2, Bias: -329115657.206728, T: 2688, Avg. loss: 52858634881313418980098048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 99044324094.76, NNZs: 2, Bias: -676248696.437993, T: 2816, Avg. loss: 34709363909110447722201088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 75207439016.53, NNZs: 2, Bias: -495937922.835919, T: 2944, Avg. loss: 32871930792074301025550336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10885461418.87, NNZs: 2, Bias: -4722693573.432331, T: 3072, Avg. loss: 37303996152259176122286080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 56824609366.76, NNZs: 2, Bias: -2141842096.363656, T: 3200, Avg. loss: 37245741327628202013622272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 40578538403.55, NNZs: 2, Bias: -467066297.821338, T: 3328, Avg. loss: 35436203716199497959735296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 88431071742.45, NNZs: 2, Bias: -526858266.368366, T: 3456, Avg. loss: 33746808393876466332336128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 65727207274.39, NNZs: 2, Bias: 1898313140.152071, T: 3584, Avg. loss: 33874685866163775201083392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4154483362.45, NNZs: 2, Bias: 1679405944.493045, T: 3712, Avg. loss: 2027364197104745732636672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10691092357.83, NNZs: 2, Bias: 1654362216.297438, T: 3840, Avg. loss: 504872258484920737857536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 9820407487.79, NNZs: 2, Bias: 2136653637.205719, T: 3968, Avg. loss: 785387761186472063926272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5638266516.03, NNZs: 2, Bias: 2221910149.071309, T: 4096, Avg. loss: 790356688573300987658240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8900902738.19, NNZs: 2, Bias: 2072852482.866235, T: 4224, Avg. loss: 501087064271500590710784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2676062566.70, NNZs: 2, Bias: 1841618060.956759, T: 4352, Avg. loss: 607821368407902868471808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 5361158306.78, NNZs: 2, Bias: 1397814545.309712, T: 4480, Avg. loss: 683478739308329752854528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 14537436256.58, NNZs: 2, Bias: 1112819246.036471, T: 4608, Avg. loss: 727049808541816482430976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 13471578989.21, NNZs: 2, Bias: 949736631.121031, T: 4736, Avg. loss: 680648876750610137874432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6904156614.93, NNZs: 2, Bias: 1034761808.969923, T: 4864, Avg. loss: 784061205459675723595776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 897300926.27, NNZs: 2, Bias: 1069348561.378296, T: 4992, Avg. loss: 7077179933264101507072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 471933567.82, NNZs: 2, Bias: 1063008776.136974, T: 5120, Avg. loss: 99416502274001190912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 249877262.61, NNZs: 2, Bias: 1059511078.453615, T: 5248, Avg. loss: 27948399933476995072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 131076901.34, NNZs: 2, Bias: 1057399864.547860, T: 5376, Avg. loss: 8090340468359220224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 65970547.01, NNZs: 2, Bias: 1056108731.540720, T: 5504, Avg. loss: 2563291634943162368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 25505828.13, NNZs: 2, Bias: 1055356944.771218, T: 5632, Avg. loss: 831924134539072384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 8173142.15, NNZs: 2, Bias: 1054752002.270294, T: 5760, Avg. loss: 272162813840127936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 7035892.10, NNZs: 2, Bias: 1054310186.103484, T: 5888, Avg. loss: 135017463808931760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9737154.53, NNZs: 2, Bias: 1053948096.348086, T: 6016, Avg. loss: 105174470524826416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 13461524.67, NNZs: 2, Bias: 1053602630.007143, T: 6144, Avg. loss: 92128539515276480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 15100729.64, NNZs: 2, Bias: 1053267067.165178, T: 6272, Avg. loss: 100683101116565344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 14368751.64, NNZs: 2, Bias: 1052971003.170307, T: 6400, Avg. loss: 99265143113927024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 15685460.72, NNZs: 2, Bias: 1052644236.911626, T: 6528, Avg. loss: 96530849323979088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 15326877.84, NNZs: 2, Bias: 1052350300.822634, T: 6656, Avg. loss: 93825867276030800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 15152661.78, NNZs: 2, Bias: 1052049054.880662, T: 6784, Avg. loss: 98418960408139056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 14999271.38, NNZs: 2, Bias: 1051989541.218344, T: 6912, Avg. loss: 81802027325602896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 15368577.51, NNZs: 2, Bias: 1051923644.949607, T: 7040, Avg. loss: 80190678463285536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 15179903.30, NNZs: 2, Bias: 1051864202.294702, T: 7168, Avg. loss: 82513360621998304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 15409329.17, NNZs: 2, Bias: 1051799351.649962, T: 7296, Avg. loss: 81424409468183632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 15309102.73, NNZs: 2, Bias: 1051739604.952112, T: 7424, Avg. loss: 81167989054080880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 15286264.26, NNZs: 2, Bias: 1051679637.496289, T: 7552, Avg. loss: 79874704705948832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 15420775.59, NNZs: 2, Bias: 1051616454.114012, T: 7680, Avg. loss: 81083544302252864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 15262220.02, NNZs: 2, Bias: 1051557179.032712, T: 7808, Avg. loss: 81758838333481536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 15193780.99, NNZs: 2, Bias: 1051496689.136020, T: 7936, Avg. loss: 81516442510715008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 15558709.38, NNZs: 2, Bias: 1051430668.884943, T: 8064, Avg. loss: 80272342846322832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 15455784.32, NNZs: 2, Bias: 1051370754.895186, T: 8192, Avg. loss: 81454362210351872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 15420741.26, NNZs: 2, Bias: 1051359026.612735, T: 8320, Avg. loss: 79048465877557936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 15422903.82, NNZs: 2, Bias: 1051346779.244210, T: 8448, Avg. loss: 78861790742961440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 15422523.76, NNZs: 2, Bias: 1051334563.529112, T: 8576, Avg. loss: 78895685178381424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 15456424.66, NNZs: 2, Bias: 1051321875.803921, T: 8704, Avg. loss: 78679064412114192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 15449044.01, NNZs: 2, Bias: 1051309750.523193, T: 8832, Avg. loss: 78975046047552256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 15440503.73, NNZs: 2, Bias: 1051297639.081524, T: 8960, Avg. loss: 78994540996850192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 15486950.96, NNZs: 2, Bias: 1051284765.156447, T: 9088, Avg. loss: 78679841224929904.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 15385027.16, NNZs: 2, Bias: 1051274095.481950, T: 9216, Avg. loss: 78565509928932128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 15438875.31, NNZs: 2, Bias: 1051261071.771472, T: 9344, Avg. loss: 78962785879231488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 15424321.12, NNZs: 2, Bias: 1051249064.507292, T: 9472, Avg. loss: 78888862295054720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 15488774.29, NNZs: 2, Bias: 1051235891.539255, T: 9600, Avg. loss: 78900683434908880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 15434303.58, NNZs: 2, Bias: 1051224504.876707, T: 9728, Avg. loss: 78678199366851360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 15496384.69, NNZs: 2, Bias: 1051211386.869834, T: 9856, Avg. loss: 78756399313619344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 77 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 517659759761.29, NNZs: 2, Bias: 8908417592.888947, T: 128, Avg. loss: 18939422784586932211253510144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1210218480248.54, NNZs: 2, Bias: 65318235575.129776, T: 256, Avg. loss: 20350063560140229152365084672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2863128111421.48, NNZs: 2, Bias: 18217649124.977463, T: 384, Avg. loss: 19889498393686563165092970496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1237442801707.65, NNZs: 2, Bias: 24463137615.838478, T: 512, Avg. loss: 23049496370973927626164404224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 339575620262.20, NNZs: 2, Bias: -35536862384.161530, T: 640, Avg. loss: 21089508269111711443672104960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 822890309692.97, NNZs: 2, Bias: -21753285944.688286, T: 768, Avg. loss: 19931362659674613079699619840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 227745839580.83, NNZs: 2, Bias: -18746072253.489838, T: 896, Avg. loss: 851191482999588627528286208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 106744471933.01, NNZs: 2, Bias: -21762928068.873894, T: 1024, Avg. loss: 791595530234156869128028160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 484806626836.20, NNZs: 2, Bias: -8741963712.358337, T: 1152, Avg. loss: 838222295717113741589872640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 339669303055.88, NNZs: 2, Bias: -3711161460.903202, T: 1280, Avg. loss: 871198215468177778249039872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 216487806001.50, NNZs: 2, Bias: 5315383675.264982, T: 1408, Avg. loss: 787900307818355121373315072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 544602775845.94, NNZs: 2, Bias: 13381985017.726585, T: 1536, Avg. loss: 750593837698587457342144512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42125713632.44, NNZs: 2, Bias: 34977001122.739578, T: 1664, Avg. loss: 869415370829912410240843776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 317070992072.80, NNZs: 2, Bias: 31223149589.001724, T: 1792, Avg. loss: 841242085926888882296586240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 90680231385.00, NNZs: 2, Bias: 16118073189.833372, T: 1920, Avg. loss: 868020499819467139039887360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 191461560853.40, NNZs: 2, Bias: 25796467837.084297, T: 2048, Avg. loss: 849735772498448401261658112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 142282225639.01, NNZs: 2, Bias: 19981743357.780193, T: 2176, Avg. loss: 873042423683935358999855104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 71648237406.00, NNZs: 2, Bias: 17597389510.847927, T: 2304, Avg. loss: 31352782543621226493902848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 82471826363.31, NNZs: 2, Bias: 19427877525.167534, T: 2432, Avg. loss: 28789005958014759069548544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 118143663206.35, NNZs: 2, Bias: 22360767462.111507, T: 2560, Avg. loss: 31303390428091386223919104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 48723335373.78, NNZs: 2, Bias: 22562118627.524475, T: 2688, Avg. loss: 27414346418454105633587200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 39108724667.31, NNZs: 2, Bias: 23227792538.652115, T: 2816, Avg. loss: 33093111855998002081562624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 36563497885.54, NNZs: 2, Bias: 21486678328.711975, T: 2944, Avg. loss: 33229882475658953864773632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 58701284392.80, NNZs: 2, Bias: 20717138646.377644, T: 3072, Avg. loss: 28778479921920436447739904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 48527742096.08, NNZs: 2, Bias: 21741983489.628998, T: 3200, Avg. loss: 33138428881122210382610432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 35654777443.00, NNZs: 2, Bias: 21467915706.290436, T: 3328, Avg. loss: 29217685801699734288596992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2789139815.79, NNZs: 2, Bias: 21885894042.432751, T: 3456, Avg. loss: 662013528131174018318336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4089171341.56, NNZs: 2, Bias: 22087162613.496056, T: 3584, Avg. loss: 599601976598440695562240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 14075662739.96, NNZs: 2, Bias: 21533723831.282833, T: 3712, Avg. loss: 430286663717574605275136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 17984091587.35, NNZs: 2, Bias: 21858284825.219563, T: 3840, Avg. loss: 760808412305655808917504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 9614023565.44, NNZs: 2, Bias: 21826115774.570877, T: 3968, Avg. loss: 614754961238233423282176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6163189896.28, NNZs: 2, Bias: 21800606040.939480, T: 4096, Avg. loss: 494937619912418461220864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4489015625.12, NNZs: 2, Bias: 22049783096.441093, T: 4224, Avg. loss: 686122499237239945428992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 319994346.50, NNZs: 2, Bias: 21842206107.345791, T: 4352, Avg. loss: 622328117500861510320128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 210327622.31, NNZs: 2, Bias: 21832858349.493946, T: 4480, Avg. loss: 66462290065639702528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 258528507.91, NNZs: 2, Bias: 21824154536.344521, T: 4608, Avg. loss: 50666522401741094912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 318012717.05, NNZs: 2, Bias: 21815444824.973743, T: 4736, Avg. loss: 51352818849541472256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 317571184.13, NNZs: 2, Bias: 21807713313.393253, T: 4864, Avg. loss: 50275373276055707648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 329602198.89, NNZs: 2, Bias: 21799490928.125324, T: 4992, Avg. loss: 53057706591440322560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 335464918.10, NNZs: 2, Bias: 21791329695.627640, T: 5120, Avg. loss: 53662164052394582016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 350438785.42, NNZs: 2, Bias: 21783340122.442860, T: 5248, Avg. loss: 50597911892294721536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 340136001.07, NNZs: 2, Bias: 21775650409.573689, T: 5376, Avg. loss: 52863590853863145472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 344884605.88, NNZs: 2, Bias: 21767608361.037563, T: 5504, Avg. loss: 53795589994531979264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 347342050.34, NNZs: 2, Bias: 21766033014.318180, T: 5632, Avg. loss: 42029983827776004096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 347254348.29, NNZs: 2, Bias: 21764506909.998455, T: 5760, Avg. loss: 41855717919201394688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 345659748.73, NNZs: 2, Bias: 21762993370.988338, T: 5888, Avg. loss: 42203393479920041984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 344122777.47, NNZs: 2, Bias: 21761476264.444065, T: 6016, Avg. loss: 42313667912241037312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 344607804.59, NNZs: 2, Bias: 21759947668.477943, T: 6144, Avg. loss: 41677455982703067136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 346077291.00, NNZs: 2, Bias: 21758376736.402210, T: 6272, Avg. loss: 42396198256612163584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 349254720.81, NNZs: 2, Bias: 21756796216.815960, T: 6400, Avg. loss: 41914875906405924864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 345193668.80, NNZs: 2, Bias: 21755344697.081654, T: 6528, Avg. loss: 41547728207422758912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 347884840.47, NNZs: 2, Bias: 21753783804.505486, T: 6656, Avg. loss: 41516067953416364032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 350282013.33, NNZs: 2, Bias: 21752197790.398350, T: 6784, Avg. loss: 42358787755707637760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 350472195.62, NNZs: 2, Bias: 21750661874.565350, T: 6912, Avg. loss: 42086404737306550272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 349112335.51, NNZs: 2, Bias: 21749132431.530277, T: 7040, Avg. loss: 42531006037520015360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 343893073.68, NNZs: 2, Bias: 21747704407.326065, T: 7168, Avg. loss: 41447877569336811520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 345745281.97, NNZs: 2, Bias: 21746134778.739830, T: 7296, Avg. loss: 42234929588183187456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 347370265.57, NNZs: 2, Bias: 21744580215.182144, T: 7424, Avg. loss: 41848976833586552832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 351438693.16, NNZs: 2, Bias: 21742984063.337189, T: 7552, Avg. loss: 41880936277206024192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 351376142.27, NNZs: 2, Bias: 21741450808.063023, T: 7680, Avg. loss: 42003387202753413120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 349281613.01, NNZs: 2, Bias: 21739937392.729641, T: 7808, Avg. loss: 42436625902393761792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 348780595.35, NNZs: 2, Bias: 21739639836.852177, T: 7936, Avg. loss: 40795793115553210368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 348364368.88, NNZs: 2, Bias: 21739340857.818821, T: 8064, Avg. loss: 40800701169050116096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 346813777.69, NNZs: 2, Bias: 21739061647.424335, T: 8192, Avg. loss: 40590771876244496384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 346413705.29, NNZs: 2, Bias: 21738763096.203789, T: 8320, Avg. loss: 40700129071177490432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 347670207.50, NNZs: 2, Bias: 21738438693.216961, T: 8448, Avg. loss: 40608430611615088640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 348118249.66, NNZs: 2, Bias: 21738126808.119091, T: 8576, Avg. loss: 40661447953774190592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 349279359.40, NNZs: 2, Bias: 21737804437.363029, T: 8704, Avg. loss: 40527699660344934400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 349584973.20, NNZs: 2, Bias: 21737495249.502655, T: 8832, Avg. loss: 40604224125469089792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 348983344.30, NNZs: 2, Bias: 21737199642.343639, T: 8960, Avg. loss: 40747138900103225344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 348790227.24, NNZs: 2, Bias: 21736897389.154366, T: 9088, Avg. loss: 40755122942467227648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 348049122.84, NNZs: 2, Bias: 21736603900.038681, T: 9216, Avg. loss: 40762296602061144064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 347064498.40, NNZs: 2, Bias: 21736315890.968513, T: 9344, Avg. loss: 40547592943508258816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 73 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2201076337527.79, NNZs: 2, Bias: 71022113541.807587, T: 128, Avg. loss: 18500464663656245367075241984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1089199163856.00, NNZs: 2, Bias: 68645926403.891876, T: 256, Avg. loss: 19575282788514123698654937088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1350331441651.14, NNZs: 2, Bias: -13681584038.995010, T: 384, Avg. loss: 19407183150701176129704689664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 225476916133.61, NNZs: 2, Bias: 66318415961.004990, T: 512, Avg. loss: 18876144665055477618895224832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 674677368060.40, NNZs: 2, Bias: 96441684805.945679, T: 640, Avg. loss: 20926329539904911422559092736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 323342790542.91, NNZs: 2, Bias: 76441684805.945679, T: 768, Avg. loss: 19914262095530437278626217984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 278257607727.51, NNZs: 2, Bias: 77481140109.506546, T: 896, Avg. loss: 791163447290424681411117056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 131707954267.42, NNZs: 2, Bias: 87692064025.034088, T: 1024, Avg. loss: 769821117824306070245343232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 360737807662.97, NNZs: 2, Bias: 69329077848.251617, T: 1152, Avg. loss: 763591736743732148948697088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 171102081909.89, NNZs: 2, Bias: 79427125616.581741, T: 1280, Avg. loss: 821601254562663955578224640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 503874606307.54, NNZs: 2, Bias: 70425731246.014587, T: 1408, Avg. loss: 843464506904455801699565568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 423985089116.05, NNZs: 2, Bias: 66154284166.954651, T: 1536, Avg. loss: 703967526266570430929174528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 301820134495.20, NNZs: 2, Bias: 68270020396.941528, T: 1664, Avg. loss: 838292921153472838756204544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 201350013900.14, NNZs: 2, Bias: 61469134991.077881, T: 1792, Avg. loss: 844743537623698443048321024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 292756460810.07, NNZs: 2, Bias: 48105004811.878555, T: 1920, Avg. loss: 690856288387543520568672256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 29349769224.50, NNZs: 2, Bias: 58552186860.513176, T: 2048, Avg. loss: 890857460911517435552595968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 248373796726.42, NNZs: 2, Bias: 63547170119.638275, T: 2176, Avg. loss: 809496098310986868667187200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 103288553924.92, NNZs: 2, Bias: 58510847668.729111, T: 2304, Avg. loss: 803707112564822769303289856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 265725909255.42, NNZs: 2, Bias: 44780746268.551056, T: 2432, Avg. loss: 788988944397123310422327296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 335836802157.29, NNZs: 2, Bias: 28582145354.273129, T: 2560, Avg. loss: 752699891223798619358363648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 56520647328.24, NNZs: 2, Bias: 30774555273.175823, T: 2688, Avg. loss: 51801865181530043006844928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 6632269875.65, NNZs: 2, Bias: 33817480676.841503, T: 2816, Avg. loss: 31978896317324253286367232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 45614254081.88, NNZs: 2, Bias: 34226023215.946697, T: 2944, Avg. loss: 31191014491090603265228800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 27785840081.03, NNZs: 2, Bias: 34187419344.403297, T: 3072, Avg. loss: 31183114305006925661601792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 34836759686.27, NNZs: 2, Bias: 35130583390.155609, T: 3200, Avg. loss: 31308782075588449423851520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 55636393548.64, NNZs: 2, Bias: 34169530527.585365, T: 3328, Avg. loss: 31669580522281485673168896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 98695738333.79, NNZs: 2, Bias: 34767360017.813034, T: 3456, Avg. loss: 27486055001824430884126720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 52795570242.59, NNZs: 2, Bias: 35992668825.196342, T: 3584, Avg. loss: 29692004900401781625847808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 67122149328.16, NNZs: 2, Bias: 37038119702.142815, T: 3712, Avg. loss: 29596865094173097327591424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 46559193487.70, NNZs: 2, Bias: 37027138227.000877, T: 3840, Avg. loss: 27973530828998375345487872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 22955711518.88, NNZs: 2, Bias: 37359117120.605431, T: 3968, Avg. loss: 29922954025748849370333184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 38322580390.93, NNZs: 2, Bias: 36281451827.439552, T: 4096, Avg. loss: 30494086573862199607951360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1195623648.29, NNZs: 2, Bias: 36197860283.848137, T: 4224, Avg. loss: 700884939359940021059584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1097937930.72, NNZs: 2, Bias: 35811631890.117058, T: 4352, Avg. loss: 436109421418484223442944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4573812638.22, NNZs: 2, Bias: 35824741511.553017, T: 4480, Avg. loss: 484009967673224265203712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 960410791.88, NNZs: 2, Bias: 35851717225.299446, T: 4608, Avg. loss: 438296789795814202408960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3981642969.09, NNZs: 2, Bias: 35893544244.570946, T: 4736, Avg. loss: 530247298898023306756096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5377544669.84, NNZs: 2, Bias: 36019392966.156784, T: 4864, Avg. loss: 316806671495014398296064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6108242053.20, NNZs: 2, Bias: 36042494644.371017, T: 4992, Avg. loss: 517015850107620420485120.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7327205921.86, NNZs: 2, Bias: 36395719758.552826, T: 5120, Avg. loss: 339640291144766209392640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4216470584.17, NNZs: 2, Bias: 36363364080.446030, T: 5248, Avg. loss: 371502144472752223944704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3744736822.69, NNZs: 2, Bias: 36423429701.244797, T: 5376, Avg. loss: 446927410362817567522816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 5147727177.74, NNZs: 2, Bias: 36249526025.452553, T: 5504, Avg. loss: 427565669222963642105856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2646290587.94, NNZs: 2, Bias: 36274078283.651192, T: 5632, Avg. loss: 3005010619145912320000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1585463844.72, NNZs: 2, Bias: 36279628669.426712, T: 5760, Avg. loss: 723342259256988401664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1097586404.68, NNZs: 2, Bias: 36276659869.434517, T: 5888, Avg. loss: 255238421390366670848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 846319696.97, NNZs: 2, Bias: 36268636781.942551, T: 6016, Avg. loss: 175570993859553198080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 721006362.66, NNZs: 2, Bias: 36258391780.693001, T: 6144, Avg. loss: 159378880473207111680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 655337341.77, NNZs: 2, Bias: 36246811508.047310, T: 6272, Avg. loss: 147242565294508867584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 589382623.63, NNZs: 2, Bias: 36235252232.333351, T: 6400, Avg. loss: 139660237648765517824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 565084106.44, NNZs: 2, Bias: 36223130393.144257, T: 6528, Avg. loss: 138721753488734273536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 601936115.47, NNZs: 2, Bias: 36210863667.621834, T: 6656, Avg. loss: 131845772973730709504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 612154744.15, NNZs: 2, Bias: 36198829920.046852, T: 6784, Avg. loss: 127485366919085359104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 557975723.58, NNZs: 2, Bias: 36187777461.055542, T: 6912, Avg. loss: 136675828312492670976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 575863842.32, NNZs: 2, Bias: 36175873891.812019, T: 7040, Avg. loss: 130758912155980038144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 572423159.58, NNZs: 2, Bias: 36164229412.624184, T: 7168, Avg. loss: 127234024497345101824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 589395546.68, NNZs: 2, Bias: 36151478521.704453, T: 7296, Avg. loss: 145739335510274523136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 586275912.40, NNZs: 2, Bias: 36138464858.086853, T: 7424, Avg. loss: 151504201024172457984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 579761712.79, NNZs: 2, Bias: 36125646745.635757, T: 7552, Avg. loss: 142217080652268339200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 595254702.95, NNZs: 2, Bias: 36113096943.220345, T: 7680, Avg. loss: 137659592771830136832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 569312757.47, NNZs: 2, Bias: 36100578452.552414, T: 7808, Avg. loss: 146735480120462884864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 586723607.26, NNZs: 2, Bias: 36097762339.541885, T: 7936, Avg. loss: 115713124457413214208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 580338698.71, NNZs: 2, Bias: 36095441478.612396, T: 8064, Avg. loss: 110626136872387084288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 587499644.77, NNZs: 2, Bias: 36092870969.498581, T: 8192, Avg. loss: 111785024701616357376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 581114168.91, NNZs: 2, Bias: 36090573144.148010, T: 8320, Avg. loss: 109280701852857532416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 585800300.14, NNZs: 2, Bias: 36088022058.100075, T: 8448, Avg. loss: 113075528219923300352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 580697731.97, NNZs: 2, Bias: 36085650310.049904, T: 8576, Avg. loss: 111834693777072013312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 590305715.83, NNZs: 2, Bias: 36083031341.011368, T: 8704, Avg. loss: 112293872099288743936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 582334390.17, NNZs: 2, Bias: 36080711329.217514, T: 8832, Avg. loss: 111795259109727993856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 582958844.76, NNZs: 2, Bias: 36078310346.302177, T: 8960, Avg. loss: 108776839437847478272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 587799165.41, NNZs: 2, Bias: 36075821089.566124, T: 9088, Avg. loss: 109765967502038171648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 575544095.23, NNZs: 2, Bias: 36073611710.111511, T: 9216, Avg. loss: 110137641111877812224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 582327252.24, NNZs: 2, Bias: 36071107521.459122, T: 9344, Avg. loss: 109132568987832385536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 585505288.88, NNZs: 2, Bias: 36068597013.707779, T: 9472, Avg. loss: 112020235501066584064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 577071708.58, NNZs: 2, Bias: 36066330810.762085, T: 9600, Avg. loss: 109661219220788117504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 583222834.38, NNZs: 2, Bias: 36065738129.863831, T: 9728, Avg. loss: 109300419883085824000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 582052227.87, NNZs: 2, Bias: 36065272197.532433, T: 9856, Avg. loss: 107439643209499918336.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 582832751.19, NNZs: 2, Bias: 36064772803.387482, T: 9984, Avg. loss: 107844631272092811264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 584083289.59, NNZs: 2, Bias: 36064266600.331177, T: 10112, Avg. loss: 107662840416678903808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 584181933.45, NNZs: 2, Bias: 36063778757.786957, T: 10240, Avg. loss: 107723454414343864320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 585205908.35, NNZs: 2, Bias: 36063277623.048210, T: 10368, Avg. loss: 107331284284426518528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 583799845.64, NNZs: 2, Bias: 36062815237.170441, T: 10496, Avg. loss: 107502554183639760896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 584234664.28, NNZs: 2, Bias: 36062322010.815964, T: 10624, Avg. loss: 107713893235379552256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 583966444.24, NNZs: 2, Bias: 36061840832.485703, T: 10752, Avg. loss: 107561063185696800768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 582701054.85, NNZs: 2, Bias: 36061375355.096008, T: 10880, Avg. loss: 107681918308799037440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 583350997.93, NNZs: 2, Bias: 36060879673.019325, T: 11008, Avg. loss: 107474162060365709312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 86 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 591193861826.09, NNZs: 2, Bias: 10216161468.527130, T: 128, Avg. loss: 21653183507450503580597878784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1196766386831.46, NNZs: 2, Bias: -9783838531.472870, T: 256, Avg. loss: 20592516013154586684848865280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 946235364030.32, NNZs: 2, Bias: -69783838531.472870, T: 384, Avg. loss: 20508199865333738998088073216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1097797685874.49, NNZs: 2, Bias: 70216161468.527130, T: 512, Avg. loss: 20574881115378379092039565312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 501224521694.63, NNZs: 2, Bias: -24009385579.514496, T: 640, Avg. loss: 20720590461382290699156717568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 506431986354.81, NNZs: 2, Bias: -99657932904.199020, T: 768, Avg. loss: 22236660644542597583423406080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 945689347632.72, NNZs: 2, Bias: -39657932904.199020, T: 896, Avg. loss: 21195016871872590444750700544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 598120022475.95, NNZs: 2, Bias: 342067095.800980, T: 1024, Avg. loss: 21495142640907355077411340288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 228232678040.96, NNZs: 2, Bias: 6417347449.029240, T: 1152, Avg. loss: 858581295042932468405501952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 99323158457.32, NNZs: 2, Bias: 12399903545.058550, T: 1280, Avg. loss: 843260087512765884113354752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 272530168488.06, NNZs: 2, Bias: 9240468564.146580, T: 1408, Avg. loss: 824087155288740260812423168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 236427667193.65, NNZs: 2, Bias: 26494308795.553467, T: 1536, Avg. loss: 886700627212618770002477056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 242508141686.24, NNZs: 2, Bias: 12727445228.807468, T: 1664, Avg. loss: 758774983640113741488455680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 258677705611.48, NNZs: 2, Bias: 21740844610.902790, T: 1792, Avg. loss: 776480604637604386088943616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 594388408215.29, NNZs: 2, Bias: 21703256376.068844, T: 1920, Avg. loss: 807634870526277071344238592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 300735297280.24, NNZs: 2, Bias: 11390917335.878277, T: 2048, Avg. loss: 871556299499405247424495616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 267640530992.11, NNZs: 2, Bias: 8380180080.783224, T: 2176, Avg. loss: 868415908421208132059922432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 426013826302.40, NNZs: 2, Bias: -2626292428.082552, T: 2304, Avg. loss: 802580173402098107206860800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 48746556298.66, NNZs: 2, Bias: -4060776916.181347, T: 2432, Avg. loss: 95735618055128108498944000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43425721854.64, NNZs: 2, Bias: -2332269643.457546, T: 2560, Avg. loss: 30134543679679736601116672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 70665006906.04, NNZs: 2, Bias: -3507082512.711389, T: 2688, Avg. loss: 30740461525280264892186624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 37480985889.20, NNZs: 2, Bias: -6114431420.043738, T: 2816, Avg. loss: 33998777830539654338707456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 94113277785.54, NNZs: 2, Bias: -5901280361.696532, T: 2944, Avg. loss: 28744031153880896236421120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 79691458873.37, NNZs: 2, Bias: -2800995537.783113, T: 3072, Avg. loss: 28331495688638008991416320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 24919738249.79, NNZs: 2, Bias: -5030978414.356412, T: 3200, Avg. loss: 34001383684725231239299072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 51435073624.60, NNZs: 2, Bias: -4507554151.621150, T: 3328, Avg. loss: 30878572899156800409960448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 44390118596.33, NNZs: 2, Bias: -3981251876.076247, T: 3456, Avg. loss: 32097624403548794230145024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 16869436843.29, NNZs: 2, Bias: -2421980981.047945, T: 3584, Avg. loss: 28985703864369637851398144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 67575875783.73, NNZs: 2, Bias: -2141343469.456437, T: 3712, Avg. loss: 30938169589517856253411328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 7560952025.26, NNZs: 2, Bias: -3538825013.345509, T: 3840, Avg. loss: 1472972431404852712570880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11775287713.97, NNZs: 2, Bias: -3413088690.945537, T: 3968, Avg. loss: 669856244853313302953984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9530727669.87, NNZs: 2, Bias: -3467373138.137607, T: 4096, Avg. loss: 560775709681133167837184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5886130786.09, NNZs: 2, Bias: -3870000312.009019, T: 4224, Avg. loss: 678030105187455745392640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2787813699.32, NNZs: 2, Bias: -3576911970.298644, T: 4352, Avg. loss: 431361592457509673631744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7521043514.04, NNZs: 2, Bias: -3690849694.993474, T: 4480, Avg. loss: 478843555635247282388992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 10541789780.87, NNZs: 2, Bias: -3460038010.388632, T: 4608, Avg. loss: 478142723581715054329856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4906057244.07, NNZs: 2, Bias: -3772833357.665792, T: 4736, Avg. loss: 519521950499189393719296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2274864643.68, NNZs: 2, Bias: -3951201516.697794, T: 4864, Avg. loss: 608066568909065862250496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6691291769.33, NNZs: 2, Bias: -3819648373.934606, T: 4992, Avg. loss: 638863307110679312334848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2036983763.93, NNZs: 2, Bias: -3813260282.568739, T: 5120, Avg. loss: 8221492213306127024128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1090228422.92, NNZs: 2, Bias: -3827058776.884781, T: 5248, Avg. loss: 465915812430613118976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 600309252.92, NNZs: 2, Bias: -3834627779.820890, T: 5376, Avg. loss: 123710908720583639040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 356168234.19, NNZs: 2, Bias: -3837351351.717810, T: 5504, Avg. loss: 33683896970554966016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 221163072.90, NNZs: 2, Bias: -3838227580.004998, T: 5632, Avg. loss: 11837983751679334400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 146695523.48, NNZs: 2, Bias: -3838363172.023354, T: 5760, Avg. loss: 4316147333488390144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 110514724.31, NNZs: 2, Bias: -3837675265.834609, T: 5888, Avg. loss: 2427382825281881600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 85268637.78, NNZs: 2, Bias: -3836847501.874526, T: 6016, Avg. loss: 1834570963561889536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 78319135.49, NNZs: 2, Bias: -3835775612.153322, T: 6144, Avg. loss: 1478705446651620096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 70276432.90, NNZs: 2, Bias: -3834694717.149811, T: 6272, Avg. loss: 1485457893871855616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 67779980.39, NNZs: 2, Bias: -3833484024.729490, T: 6400, Avg. loss: 1539206744084597760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 70460251.63, NNZs: 2, Bias: -3832311143.342834, T: 6528, Avg. loss: 1304252270494878720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 65255091.97, NNZs: 2, Bias: -3831236916.782366, T: 6656, Avg. loss: 1380330894491892992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 67212867.53, NNZs: 2, Bias: -3829993158.206797, T: 6784, Avg. loss: 1460673286530816768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 64998773.13, NNZs: 2, Bias: -3828803227.000592, T: 6912, Avg. loss: 1465148216902549248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 66525612.69, NNZs: 2, Bias: -3827631848.260381, T: 7040, Avg. loss: 1307024676444710912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 69331257.00, NNZs: 2, Bias: -3826385815.653028, T: 7168, Avg. loss: 1389985221921752320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 69065757.26, NNZs: 2, Bias: -3826149162.180184, T: 7296, Avg. loss: 1166363838871894016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 68890362.83, NNZs: 2, Bias: -3825910206.370284, T: 7424, Avg. loss: 1169065336695995392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 67978179.52, NNZs: 2, Bias: -3825688472.980814, T: 7552, Avg. loss: 1152251668581958784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 68465963.54, NNZs: 2, Bias: -3825442900.822731, T: 7680, Avg. loss: 1140345478438149120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 67007978.66, NNZs: 2, Bias: -3825228622.644354, T: 7808, Avg. loss: 1160402552917794048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 66645483.14, NNZs: 2, Bias: -3824994190.869866, T: 7936, Avg. loss: 1162682885257441024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 66807769.59, NNZs: 2, Bias: -3824753662.901182, T: 8064, Avg. loss: 1147278847909905152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 66901395.48, NNZs: 2, Bias: -3824509225.659420, T: 8192, Avg. loss: 1172227723382321664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 67347508.37, NNZs: 2, Bias: -3824261733.351948, T: 8320, Avg. loss: 1155562624300426240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 66950389.04, NNZs: 2, Bias: -3824220489.187277, T: 8448, Avg. loss: 1133085201839184512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 66799470.12, NNZs: 2, Bias: -3824175503.531633, T: 8576, Avg. loss: 1118810939481878272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 66725021.66, NNZs: 2, Bias: -3824128970.540029, T: 8704, Avg. loss: 1123504316099257344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 66732296.78, NNZs: 2, Bias: -3824080942.305017, T: 8832, Avg. loss: 1125043954391195776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 66684032.57, NNZs: 2, Bias: -3824034095.517383, T: 8960, Avg. loss: 1120006874256006912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 66739990.20, NNZs: 2, Bias: -3823985259.258561, T: 9088, Avg. loss: 1123961885655003008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 66866018.43, NNZs: 2, Bias: -3823935253.222865, T: 9216, Avg. loss: 1122419813354366848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 72 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 863803295000.81, NNZs: 2, Bias: 4834680864.358952, T: 128, Avg. loss: 23929503511429187553594441728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2090632039804.59, NNZs: 2, Bias: -49560468132.268326, T: 256, Avg. loss: 22323715224425733215863439360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1599739367014.17, NNZs: 2, Bias: -9560468132.268326, T: 384, Avg. loss: 21868347455072339927175790592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2129077833090.15, NNZs: 2, Bias: -86879851660.917328, T: 512, Avg. loss: 21445583628172596505558908928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1327974833621.49, NNZs: 2, Bias: -176240977886.412262, T: 640, Avg. loss: 25173861194470985516428820480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 284424580370.61, NNZs: 2, Bias: -185524658201.295776, T: 768, Avg. loss: 23159662037119641482046734336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 996834516444.81, NNZs: 2, Bias: -120886037136.236755, T: 896, Avg. loss: 22462765113522457501493100544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1210546100467.64, NNZs: 2, Bias: -93339991936.173141, T: 1024, Avg. loss: 23123799139172240957848420352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1167401405313.31, NNZs: 2, Bias: -153339991936.173157, T: 1152, Avg. loss: 23139318250430061074253348864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 47506039995.14, NNZs: 2, Bias: -166985917246.576080, T: 1280, Avg. loss: 1108966415061207891413303296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 246628869756.14, NNZs: 2, Bias: -168249695452.893311, T: 1408, Avg. loss: 914598179220469137109155840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 257178305103.32, NNZs: 2, Bias: -167277818013.915527, T: 1536, Avg. loss: 933466829673640537448513536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 311347692464.99, NNZs: 2, Bias: -174073447119.369476, T: 1664, Avg. loss: 909359605569461181980082176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 13834665916.55, NNZs: 2, Bias: -182051480863.778900, T: 1792, Avg. loss: 834574219177624042431578112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 383403341948.44, NNZs: 2, Bias: -186999816671.373169, T: 1920, Avg. loss: 917994171890791486100340736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 182902662937.92, NNZs: 2, Bias: -184388712711.203278, T: 2048, Avg. loss: 905271329372505438657970176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 327289169066.50, NNZs: 2, Bias: -193172064840.738831, T: 2176, Avg. loss: 931607430094169466336182272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 232772336796.60, NNZs: 2, Bias: -199398591579.551514, T: 2304, Avg. loss: 845189196033546933227225088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 185337157305.82, NNZs: 2, Bias: -222618054668.020935, T: 2432, Avg. loss: 936165328967978788568694784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 17471449583.58, NNZs: 2, Bias: -224888047601.742889, T: 2560, Avg. loss: 39975100804680102486999040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 38629173863.78, NNZs: 2, Bias: -225701528133.048004, T: 2688, Avg. loss: 36821519375119639172349952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 60414061767.53, NNZs: 2, Bias: -222232949042.530487, T: 2816, Avg. loss: 33399038621645991892221952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 80990266440.71, NNZs: 2, Bias: -223270013847.235626, T: 2944, Avg. loss: 32069206298860760256741376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 70845044865.48, NNZs: 2, Bias: -225163897378.520782, T: 3072, Avg. loss: 35212086964407222650535936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 8826489095.37, NNZs: 2, Bias: -224735875708.193542, T: 3200, Avg. loss: 37028958999382230457909248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 75731715573.45, NNZs: 2, Bias: -223526690557.243530, T: 3328, Avg. loss: 31008331152205725843849216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 48864530203.26, NNZs: 2, Bias: -227341874422.977325, T: 3456, Avg. loss: 32435944270865730317058048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 63006762667.64, NNZs: 2, Bias: -225481354397.890839, T: 3584, Avg. loss: 32332530624385005022871552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 39644204232.86, NNZs: 2, Bias: -223358350394.035278, T: 3712, Avg. loss: 33664466454070806360096768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 66460077839.38, NNZs: 2, Bias: -222178311140.809784, T: 3840, Avg. loss: 32422468402199110954778624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 65619574986.54, NNZs: 2, Bias: -218546555358.739166, T: 3968, Avg. loss: 34706275732058912736673792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3997769162.29, NNZs: 2, Bias: -218587916027.865387, T: 4096, Avg. loss: 1856545510196819705987072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9945668354.11, NNZs: 2, Bias: -218208383179.764893, T: 4224, Avg. loss: 840691927761788103294976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 13454103702.33, NNZs: 2, Bias: -217599511811.948975, T: 4352, Avg. loss: 855832663215325845651456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 14662375661.56, NNZs: 2, Bias: -217517580323.901306, T: 4480, Avg. loss: 525081374113602241298432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6207042324.99, NNZs: 2, Bias: -217391613206.493195, T: 4608, Avg. loss: 813000404555573692989440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3262561322.33, NNZs: 2, Bias: -216984042094.864502, T: 4736, Avg. loss: 685676915909475168157696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 12204656478.58, NNZs: 2, Bias: -216468413509.860138, T: 4864, Avg. loss: 795825533496200433500160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6216963447.26, NNZs: 2, Bias: -216334176640.817963, T: 4992, Avg. loss: 656965501557085738893312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1061681610.81, NNZs: 2, Bias: -215929891200.544800, T: 5120, Avg. loss: 642792767388385280000000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2249712703.06, NNZs: 2, Bias: -215839923012.719940, T: 5248, Avg. loss: 5085753916393252716544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2660730677.39, NNZs: 2, Bias: -215763738223.699066, T: 5376, Avg. loss: 4600262584468123942912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3141240391.99, NNZs: 2, Bias: -215688963871.396301, T: 5504, Avg. loss: 4565915544411132919808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3418929575.46, NNZs: 2, Bias: -215617802505.907745, T: 5632, Avg. loss: 4436885971090286313472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3496994848.61, NNZs: 2, Bias: -215541829573.632446, T: 5760, Avg. loss: 5030496853815176724480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3444601080.15, NNZs: 2, Bias: -215474695421.402618, T: 5888, Avg. loss: 4516254272497098686464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3476501089.53, NNZs: 2, Bias: -215401099042.628296, T: 6016, Avg. loss: 4999373203347166199808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3411753736.67, NNZs: 2, Bias: -215329932798.830963, T: 6144, Avg. loss: 4761882015265494925312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3136576086.63, NNZs: 2, Bias: -215258366305.624329, T: 6272, Avg. loss: 5123909503720192212992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3320347774.38, NNZs: 2, Bias: -215240227242.441742, T: 6400, Avg. loss: 4173953020968537423872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3269455696.17, NNZs: 2, Bias: -215226553701.900696, T: 6528, Avg. loss: 3933026316981976432640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3294757048.69, NNZs: 2, Bias: -215211394866.102173, T: 6656, Avg. loss: 4015289596725195440128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3366786228.54, NNZs: 2, Bias: -215195877504.837311, T: 6784, Avg. loss: 3900667637649190682624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3341569542.90, NNZs: 2, Bias: -215181790376.311127, T: 6912, Avg. loss: 3932217498952696594432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3373285858.62, NNZs: 2, Bias: -215166982825.474792, T: 7040, Avg. loss: 3886121974168710807552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3337967026.65, NNZs: 2, Bias: -215153100566.020477, T: 7168, Avg. loss: 3928725233953806483456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3376103750.26, NNZs: 2, Bias: -215137976343.894806, T: 7296, Avg. loss: 3942488713673062744064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3388445758.73, NNZs: 2, Bias: -215123283517.066101, T: 7424, Avg. loss: 3939632625643955421184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3350514761.55, NNZs: 2, Bias: -215109381759.645782, T: 7552, Avg. loss: 3947163594529126744064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3386435874.33, NNZs: 2, Bias: -215094378525.966553, T: 7680, Avg. loss: 3921187699836201730048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3368736666.08, NNZs: 2, Bias: -215091763084.041962, T: 7808, Avg. loss: 3823799822407122288640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3365921777.63, NNZs: 2, Bias: -215088915491.441162, T: 7936, Avg. loss: 3821031533174472572928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3362997169.60, NNZs: 2, Bias: -215086070050.429962, T: 8064, Avg. loss: 3820490728554137911296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3356325709.76, NNZs: 2, Bias: -215083284865.944031, T: 8192, Avg. loss: 3818191102129576345600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3362735619.53, NNZs: 2, Bias: -215080289634.284882, T: 8320, Avg. loss: 3824712119954279759872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3360059874.96, NNZs: 2, Bias: -215077437986.784760, T: 8448, Avg. loss: 3823197092368405757952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3375995715.91, NNZs: 2, Bias: -215074312500.208252, T: 8576, Avg. loss: 3797933983032095539200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3365100234.36, NNZs: 2, Bias: -215071585286.547241, T: 8704, Avg. loss: 3829957190657224212480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3355839909.34, NNZs: 2, Bias: -215068846770.589417, T: 8832, Avg. loss: 3809698144532333330432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3369653308.08, NNZs: 2, Bias: -215065751985.546265, T: 8960, Avg. loss: 3801616124894299291648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 3372553934.79, NNZs: 2, Bias: -215062824824.249054, T: 9088, Avg. loss: 3806363942469390827520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 3359607274.09, NNZs: 2, Bias: -215060138013.879822, T: 9216, Avg. loss: 3818308836817748623360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 72 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1800625195655.74, NNZs: 2, Bias: -10555740715.398308, T: 128, Avg. loss: 22530019682017766464135626752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2123822805604.95, NNZs: 2, Bias: -2394288281.430313, T: 256, Avg. loss: 22396933211236560990516543488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 975847599612.21, NNZs: 2, Bias: -62394288281.430313, T: 384, Avg. loss: 22677943472401567199828901888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1983536142784.78, NNZs: 2, Bias: -127233387489.880890, T: 512, Avg. loss: 23726964495328021863376879616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2012019136303.82, NNZs: 2, Bias: -176678565090.733276, T: 640, Avg. loss: 21841376260530792837800787968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 522235581110.87, NNZs: 2, Bias: -236678565090.733276, T: 768, Avg. loss: 23991256453158475768065425408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 648776254081.59, NNZs: 2, Bias: -236678565090.733276, T: 896, Avg. loss: 24315026738749741465465782272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1982610122412.69, NNZs: 2, Bias: -196678565090.733276, T: 1024, Avg. loss: 24605343952354368753615503360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1772549220600.14, NNZs: 2, Bias: -116678565090.733276, T: 1152, Avg. loss: 23258967851047306941008183296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2543134071037.61, NNZs: 2, Bias: -206877188547.059082, T: 1280, Avg. loss: 22826324007584745242776043520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 469854343956.62, NNZs: 2, Bias: -171391420568.263458, T: 1408, Avg. loss: 2856921781823381378133131264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 86267354162.26, NNZs: 2, Bias: -153662913200.376404, T: 1536, Avg. loss: 927400375223017860262526976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 249639392444.29, NNZs: 2, Bias: -165531646065.459564, T: 1664, Avg. loss: 989366917485243266762801152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 354092149106.49, NNZs: 2, Bias: -172994704237.921112, T: 1792, Avg. loss: 925982330488690482161385472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 182438445670.30, NNZs: 2, Bias: -158900080681.652344, T: 1920, Avg. loss: 898349678900239316134395904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 253433041793.99, NNZs: 2, Bias: -170688264949.117767, T: 2048, Avg. loss: 845614036593001719687806976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 497401362994.49, NNZs: 2, Bias: -178019017856.926697, T: 2176, Avg. loss: 884479219518087286124183552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 131736284323.95, NNZs: 2, Bias: -178438566962.291748, T: 2304, Avg. loss: 930633195907624176187342848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 44928274137.40, NNZs: 2, Bias: -181293100556.494019, T: 2432, Avg. loss: 943524667098689771948474368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 130149232893.16, NNZs: 2, Bias: -187036952357.055573, T: 2560, Avg. loss: 991398607190035207773224960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 278644347562.07, NNZs: 2, Bias: -195147476088.959442, T: 2688, Avg. loss: 937121119717525296745807872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 63646922913.36, NNZs: 2, Bias: -194564734497.926819, T: 2816, Avg. loss: 51813252343731267011870720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 69660364195.03, NNZs: 2, Bias: -191930562222.608215, T: 2944, Avg. loss: 37622199396914204466216960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 84222931445.82, NNZs: 2, Bias: -195199592322.953308, T: 3072, Avg. loss: 35745902872351504668295168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 75126167110.30, NNZs: 2, Bias: -193758611578.020660, T: 3200, Avg. loss: 35674863812440684784254976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 48381078735.98, NNZs: 2, Bias: -193760966641.217743, T: 3328, Avg. loss: 34616344050403850672144384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 91554012809.84, NNZs: 2, Bias: -191021835335.226105, T: 3456, Avg. loss: 33690358755622680742854656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 42000054491.45, NNZs: 2, Bias: -190171735466.869293, T: 3584, Avg. loss: 34814150620338050834628608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 24824822992.37, NNZs: 2, Bias: -188776720128.965302, T: 3712, Avg. loss: 37964898023893707228446720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 20221895899.63, NNZs: 2, Bias: -189256740148.552124, T: 3840, Avg. loss: 33501385309098083881058304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 88603573341.17, NNZs: 2, Bias: -187401902762.515930, T: 3968, Avg. loss: 33554765472672568070635520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 83231217831.70, NNZs: 2, Bias: -188014686964.910004, T: 4096, Avg. loss: 33418694520604784033005568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 38536685921.26, NNZs: 2, Bias: -186094057774.639709, T: 4224, Avg. loss: 40195489891114821777096704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 51362079705.82, NNZs: 2, Bias: -181252424789.106812, T: 4352, Avg. loss: 30942496120137135662563328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 18815581080.74, NNZs: 2, Bias: -180024619186.382935, T: 4480, Avg. loss: 37768453240072817629724672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 67949295882.28, NNZs: 2, Bias: -176782393356.612427, T: 4608, Avg. loss: 35367647876175393321910272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 26183152001.60, NNZs: 2, Bias: -179752467365.351440, T: 4736, Avg. loss: 36870201847732322760130560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 47235878089.79, NNZs: 2, Bias: -176934364124.492096, T: 4864, Avg. loss: 35543453186453401904349184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 38999248396.42, NNZs: 2, Bias: -174791629439.503876, T: 4992, Avg. loss: 35931786649492914889031680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2895608031.33, NNZs: 2, Bias: -174454303865.442688, T: 5120, Avg. loss: 910415356502577277566976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2356834809.67, NNZs: 2, Bias: -174472572782.228882, T: 5248, Avg. loss: 749272891086497902493696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3244750773.07, NNZs: 2, Bias: -174315988218.219635, T: 5376, Avg. loss: 667806260454224981655552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4499562286.57, NNZs: 2, Bias: -174197097009.484100, T: 5504, Avg. loss: 625560778878067499073536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3867250385.31, NNZs: 2, Bias: -173810079626.011536, T: 5632, Avg. loss: 491584429026974514544640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6020666816.38, NNZs: 2, Bias: -173830404289.155426, T: 5760, Avg. loss: 815473503606909058416640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 6142434884.64, NNZs: 2, Bias: -173455143529.075256, T: 5888, Avg. loss: 787975711794627484844032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 8873504947.12, NNZs: 2, Bias: -173289038638.588654, T: 6016, Avg. loss: 771597136329106675204096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 15282563438.22, NNZs: 2, Bias: -173136643320.272827, T: 6144, Avg. loss: 736368810169007503048704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2290159235.35, NNZs: 2, Bias: -172974331948.634369, T: 6272, Avg. loss: 820600522440790218113024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 852433914.19, NNZs: 2, Bias: -172898392215.105988, T: 6400, Avg. loss: 4399650209709866614784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1395673006.92, NNZs: 2, Bias: -172832881938.573700, T: 6528, Avg. loss: 3031918061158468157440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1919606755.74, NNZs: 2, Bias: -172775119690.951233, T: 6656, Avg. loss: 2742908670074734247936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2314076670.45, NNZs: 2, Bias: -172718041197.939545, T: 6784, Avg. loss: 2659453500137939140608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2475071317.13, NNZs: 2, Bias: -172666182334.304230, T: 6912, Avg. loss: 2579520595447666704384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2637616166.08, NNZs: 2, Bias: -172613657122.922363, T: 7040, Avg. loss: 2577976948852588019712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2577710895.91, NNZs: 2, Bias: -172563077169.373779, T: 7168, Avg. loss: 2751157181617979523072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2701859834.73, NNZs: 2, Bias: -172511682368.943634, T: 7296, Avg. loss: 2547860730482014027776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2534142653.17, NNZs: 2, Bias: -172462945877.637085, T: 7424, Avg. loss: 2759184103523386654720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2682268324.14, NNZs: 2, Bias: -172413100770.543976, T: 7552, Avg. loss: 2429504872643097526272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2553726237.70, NNZs: 2, Bias: -172365381608.483490, T: 7680, Avg. loss: 2597880551312764960768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2342672115.29, NNZs: 2, Bias: -172318909104.869873, T: 7808, Avg. loss: 2647889951833074958336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2598592306.75, NNZs: 2, Bias: -172266588279.534027, T: 7936, Avg. loss: 2496785982734839316480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2507754979.32, NNZs: 2, Bias: -172219254340.822540, T: 8064, Avg. loss: 2562864971792039542784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2505123200.00, NNZs: 2, Bias: -172166294805.954620, T: 8192, Avg. loss: 2826567081194548625408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2488716223.55, NNZs: 2, Bias: -172156402409.864990, T: 8320, Avg. loss: 2199617587048886304768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2541568171.55, NNZs: 2, Bias: -172145733203.149567, T: 8448, Avg. loss: 2145690030779548565504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2507231455.44, NNZs: 2, Bias: -172136192370.023193, T: 8576, Avg. loss: 2178978691385387909120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2512078811.90, NNZs: 2, Bias: -172126084140.185974, T: 8704, Avg. loss: 2178250908959785353216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2521845232.47, NNZs: 2, Bias: -172115839255.698914, T: 8832, Avg. loss: 2190964384334838759424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2513638641.02, NNZs: 2, Bias: -172105864248.428101, T: 8960, Avg. loss: 2188163940841459023872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2531499459.90, NNZs: 2, Bias: -172095478019.175446, T: 9088, Avg. loss: 2194430172939199447040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2525886128.91, NNZs: 2, Bias: -172093561339.392090, T: 9216, Avg. loss: 2112784404719945383936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2526721839.08, NNZs: 2, Bias: -172091549122.805359, T: 9344, Avg. loss: 2113345649673749659648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2524997415.59, NNZs: 2, Bias: -172089574484.917114, T: 9472, Avg. loss: 2113498841473357185024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2520889814.27, NNZs: 2, Bias: -172087640253.489319, T: 9600, Avg. loss: 2107601809175075094528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2524056366.05, NNZs: 2, Bias: -172085593519.794067, T: 9728, Avg. loss: 2113476189388320538624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2525777277.06, NNZs: 2, Bias: -172083565514.918854, T: 9856, Avg. loss: 2116213975618188738560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2522058239.81, NNZs: 2, Bias: -172081619829.386261, T: 9984, Avg. loss: 2113870861708403408896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2532341784.65, NNZs: 2, Bias: -172079468059.288544, T: 10112, Avg. loss: 2113489233906842468352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2524251431.00, NNZs: 2, Bias: -172077595986.555542, T: 10240, Avg. loss: 2103999770180783439872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 2534808478.59, NNZs: 2, Bias: -172075443685.202637, T: 10368, Avg. loss: 2109638166858022256640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 2528671701.64, NNZs: 2, Bias: -172073531904.812012, T: 10496, Avg. loss: 2115769063999266619392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 2530969540.48, NNZs: 2, Bias: -172071499280.399841, T: 10624, Avg. loss: 2111984942892301680640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 2537243848.88, NNZs: 2, Bias: -172069408763.468536, T: 10752, Avg. loss: 2110823029340732653568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 2521613712.94, NNZs: 2, Bias: -172067650612.948792, T: 10880, Avg. loss: 2101024652674004418560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 2535809308.63, NNZs: 2, Bias: -172065439476.539185, T: 11008, Avg. loss: 2115240036066306818048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 2535921067.91, NNZs: 2, Bias: -172063436227.114380, T: 11136, Avg. loss: 2114933508881294295040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 2529447920.91, NNZs: 2, Bias: -172061534737.943878, T: 11264, Avg. loss: 2109825494225345314816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 2526383501.02, NNZs: 2, Bias: -172059581056.839752, T: 11392, Avg. loss: 2111940382214668943360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 2537070845.16, NNZs: 2, Bias: -172057422975.292725, T: 11520, Avg. loss: 2113396772874807934976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 90 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 731568467847.19, NNZs: 2, Bias: 50233321739.973892, T: 128, Avg. loss: 20910393183939210924800344064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 360765881589.70, NNZs: 2, Bias: 130233321739.973877, T: 256, Avg. loss: 20794857188165039870701469696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 599098154313.67, NNZs: 2, Bias: 197662498493.512604, T: 384, Avg. loss: 20379765028560108265383395328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 505288354223.12, NNZs: 2, Bias: 149142261942.033722, T: 512, Avg. loss: 20271181045625610251848908800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 965341225689.64, NNZs: 2, Bias: 129142261942.033722, T: 640, Avg. loss: 20262668527324668073814786048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 764505685425.74, NNZs: 2, Bias: 169142261942.033722, T: 768, Avg. loss: 19640074252399739946997383168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1279098862727.35, NNZs: 2, Bias: 224051301920.805237, T: 896, Avg. loss: 20444298593506440135611252736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 817079820391.82, NNZs: 2, Bias: 244051301920.805237, T: 1024, Avg. loss: 20998440279340038239459213312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1410309587165.04, NNZs: 2, Bias: 256056150077.098999, T: 1152, Avg. loss: 21282705724632200761107808256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1170414112074.81, NNZs: 2, Bias: 216056150077.098999, T: 1280, Avg. loss: 19374110788088746310784516096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 732945510775.65, NNZs: 2, Bias: 225537397369.242279, T: 1408, Avg. loss: 21340450324281644533231386624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1668542562255.47, NNZs: 2, Bias: 228187603078.031372, T: 1536, Avg. loss: 24765964040518669337354043392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1411010955979.15, NNZs: 2, Bias: 233284224033.554718, T: 1664, Avg. loss: 21602490863246220059610185728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1225711286506.78, NNZs: 2, Bias: 265652490998.872437, T: 1792, Avg. loss: 22188902889738101275827896320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 2468998591610.04, NNZs: 2, Bias: 245652490998.872437, T: 1920, Avg. loss: 19578176378243490866006065152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 406198924090.20, NNZs: 2, Bias: 253351374937.584473, T: 2048, Avg. loss: 2461563747516370488580374528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 234730144002.51, NNZs: 2, Bias: 268412855868.488556, T: 2176, Avg. loss: 914868672192735287061774336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 490960054286.64, NNZs: 2, Bias: 263674290897.264801, T: 2304, Avg. loss: 823594110168263619900342272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 339062162727.12, NNZs: 2, Bias: 255744513843.132629, T: 2432, Avg. loss: 856017546560279234780069888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 157907551187.98, NNZs: 2, Bias: 271703663991.464050, T: 2560, Avg. loss: 969792459717892048462807040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 169252234346.21, NNZs: 2, Bias: 279067613959.887268, T: 2688, Avg. loss: 864704793151049236198981632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 137291786039.69, NNZs: 2, Bias: 292308824430.114685, T: 2816, Avg. loss: 951484916190911034594164736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 439705719865.07, NNZs: 2, Bias: 283547828284.845276, T: 2944, Avg. loss: 811647955935614627194339328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 243568125652.11, NNZs: 2, Bias: 283111777614.183777, T: 3072, Avg. loss: 747279952633242140222160896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 219261132732.60, NNZs: 2, Bias: 293713152937.591125, T: 3200, Avg. loss: 827613287660091127780868096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 297915060951.99, NNZs: 2, Bias: 280268104566.025513, T: 3328, Avg. loss: 953282337613620865453260800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 67157590890.93, NNZs: 2, Bias: 270293674453.542297, T: 3456, Avg. loss: 892198081483078408840675328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 216419043445.91, NNZs: 2, Bias: 293632387408.283020, T: 3584, Avg. loss: 895601231748014211982163968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 301774169828.50, NNZs: 2, Bias: 276314310856.415771, T: 3712, Avg. loss: 855927745969548975442755584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 47944223039.43, NNZs: 2, Bias: 271879681302.759979, T: 3840, Avg. loss: 59466001723513942795354112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 66952761538.66, NNZs: 2, Bias: 269904646999.375183, T: 3968, Avg. loss: 32261388138602993549312000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 36570014939.05, NNZs: 2, Bias: 267724174427.139404, T: 4096, Avg. loss: 31838856103517014187835392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 26367042903.64, NNZs: 2, Bias: 265582082293.669769, T: 4224, Avg. loss: 30973037666513588397801472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 27513448411.92, NNZs: 2, Bias: 265756909264.883667, T: 4352, Avg. loss: 32747729485930330371129344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 18828697644.56, NNZs: 2, Bias: 262949486650.108978, T: 4480, Avg. loss: 31370924673292287069913088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 50932635254.59, NNZs: 2, Bias: 260424638111.010254, T: 4608, Avg. loss: 30462747678137462688841728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 26272049030.44, NNZs: 2, Bias: 257554839870.546692, T: 4736, Avg. loss: 32816907318368561950359552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 30878145515.91, NNZs: 2, Bias: 257558619987.549255, T: 4864, Avg. loss: 31908948894673092611145728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 78603144591.04, NNZs: 2, Bias: 256739415798.298035, T: 4992, Avg. loss: 31851034222205902136541184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 98427117296.65, NNZs: 2, Bias: 254334225444.938782, T: 5120, Avg. loss: 32288429655416978267963392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 75206231318.90, NNZs: 2, Bias: 253428332428.994965, T: 5248, Avg. loss: 32806903116396038272843776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 12768242387.90, NNZs: 2, Bias: 253411381833.337799, T: 5376, Avg. loss: 2346753241690073699713024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4965979600.62, NNZs: 2, Bias: 253137449468.057373, T: 5504, Avg. loss: 693019797129900454838272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 7649864630.03, NNZs: 2, Bias: 252494238900.745636, T: 5632, Avg. loss: 526438298618959331590144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3117486220.92, NNZs: 2, Bias: 252008912557.262726, T: 5760, Avg. loss: 746142624283508718174208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 7986866878.88, NNZs: 2, Bias: 251712152938.682770, T: 5888, Avg. loss: 581413815578417046749184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 7855733439.19, NNZs: 2, Bias: 251363923860.900482, T: 6016, Avg. loss: 618700555718490079625216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 5855610527.97, NNZs: 2, Bias: 250922870667.491394, T: 6144, Avg. loss: 663635414780736228556800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 18125730146.08, NNZs: 2, Bias: 250748163737.983643, T: 6272, Avg. loss: 725195528057631117672448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3702986149.06, NNZs: 2, Bias: 250755632785.440491, T: 6400, Avg. loss: 107039871666494845747200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3914587305.53, NNZs: 2, Bias: 250664924056.399963, T: 6528, Avg. loss: 6752146039848538472448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4028265328.67, NNZs: 2, Bias: 250574800253.914917, T: 6656, Avg. loss: 6775864544147517997056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3773957561.61, NNZs: 2, Bias: 250494657607.070251, T: 6784, Avg. loss: 6326581256984600772608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3954304533.91, NNZs: 2, Bias: 250406085738.388367, T: 6912, Avg. loss: 6553072427642784841728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3758699997.21, NNZs: 2, Bias: 250316248001.154694, T: 7040, Avg. loss: 7128642793846225240064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3866108908.20, NNZs: 2, Bias: 250223970252.800659, T: 7168, Avg. loss: 6883023545431632117760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4024309077.06, NNZs: 2, Bias: 250132074766.990692, T: 7296, Avg. loss: 6920843781807421784064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3995995476.14, NNZs: 2, Bias: 250043164659.340759, T: 7424, Avg. loss: 7066716116046768504832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4053695715.02, NNZs: 2, Bias: 250024506551.257416, T: 7552, Avg. loss: 5589608225889436303360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4060409479.76, NNZs: 2, Bias: 250007116708.836700, T: 7680, Avg. loss: 5438063005936165847040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4079240035.65, NNZs: 2, Bias: 249989317253.729218, T: 7808, Avg. loss: 5515140074898941018112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4075699143.55, NNZs: 2, Bias: 249971831204.354156, T: 7936, Avg. loss: 5527209238756250877952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4047322653.07, NNZs: 2, Bias: 249954629012.441650, T: 8064, Avg. loss: 5574551503112384806912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4014001590.73, NNZs: 2, Bias: 249937535017.382568, T: 8192, Avg. loss: 5553647182737891655680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4069057720.47, NNZs: 2, Bias: 249918906024.602631, T: 8320, Avg. loss: 5574956690502695518208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4032980782.33, NNZs: 2, Bias: 249915978012.798676, T: 8448, Avg. loss: 5393780527002793541632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4045046639.08, NNZs: 2, Bias: 249912272230.470825, T: 8576, Avg. loss: 5385906057613471121408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4036155342.05, NNZs: 2, Bias: 249908903140.259125, T: 8704, Avg. loss: 5390933879168055640064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4041390286.16, NNZs: 2, Bias: 249905309875.862335, T: 8832, Avg. loss: 5382939195621604589568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4045589076.60, NNZs: 2, Bias: 249901734960.971069, T: 8960, Avg. loss: 5380100969976747261952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4036721273.49, NNZs: 2, Bias: 249898371169.154968, T: 9088, Avg. loss: 5382834200989348659200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 4047763729.79, NNZs: 2, Bias: 249894688393.717072, T: 9216, Avg. loss: 5375331097118896029696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 4039764864.11, NNZs: 2, Bias: 249891300147.756897, T: 9344, Avg. loss: 5398112326695145963520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 4040793061.44, NNZs: 2, Bias: 249887779108.628632, T: 9472, Avg. loss: 5376220165850692321280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 4047228996.58, NNZs: 2, Bias: 249884176407.974670, T: 9600, Avg. loss: 5366801863734976315392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 4027653925.39, NNZs: 2, Bias: 249880993166.018188, T: 9728, Avg. loss: 5370532886280603172864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 4035989050.81, NNZs: 2, Bias: 249877345520.120056, T: 9856, Avg. loss: 5389365567027422429184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 4050703951.77, NNZs: 2, Bias: 249873611615.952209, T: 9984, Avg. loss: 5361704795728116711424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 4039219516.10, NNZs: 2, Bias: 249870280118.929443, T: 10112, Avg. loss: 5397392829402165805056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 4029707299.56, NNZs: 2, Bias: 249866921894.349487, T: 10240, Avg. loss: 5388770270260526841856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 4036116065.65, NNZs: 2, Bias: 249863310167.122498, T: 10368, Avg. loss: 5381655083881908404224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 4030251300.14, NNZs: 2, Bias: 249859897162.470825, T: 10496, Avg. loss: 5381643081721829130240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 4031894830.41, NNZs: 2, Bias: 249856359216.605621, T: 10624, Avg. loss: 5386658935674353221632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 83 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 914007364239.25, NNZs: 2, Bias: 110031150462.012085, T: 128, Avg. loss: 20467665786477195923128582144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 617291000023.35, NNZs: 2, Bias: 58831065956.181168, T: 256, Avg. loss: 21194093124237119603928465408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 791329907513.54, NNZs: 2, Bias: -1168934043.818832, T: 384, Avg. loss: 21491969461662024476900982784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1886144200236.66, NNZs: 2, Bias: -29225952216.014885, T: 512, Avg. loss: 20208434664599764615527661568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 461880588579.46, NNZs: 2, Bias: 10774047783.985115, T: 640, Avg. loss: 18596511809729131006272733184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 818947796514.58, NNZs: 2, Bias: -1715759641.753422, T: 768, Avg. loss: 19237270326745754777138757632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1251602074067.87, NNZs: 2, Bias: -55109004583.879250, T: 896, Avg. loss: 19724830026986866286390149120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2924947366763.23, NNZs: 2, Bias: -95109004583.879242, T: 1024, Avg. loss: 20067666066114887928797724672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 653998760454.00, NNZs: 2, Bias: -35109004583.879242, T: 1152, Avg. loss: 19857843270028472867929194496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1073831672306.62, NNZs: 2, Bias: -117730991213.699463, T: 1280, Avg. loss: 20800319362833228653209321472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 415903659749.43, NNZs: 2, Bias: -105630179438.735901, T: 1408, Avg. loss: 1135026019981249278755471360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 353874628193.12, NNZs: 2, Bias: -122117013031.032166, T: 1536, Avg. loss: 756211735359320522196254720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 119273082818.97, NNZs: 2, Bias: -120819058795.103867, T: 1664, Avg. loss: 808111004063693341506666496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 200305954718.54, NNZs: 2, Bias: -130100431551.418839, T: 1792, Avg. loss: 893243594028089260785008640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 150429853759.50, NNZs: 2, Bias: -119412651613.745758, T: 1920, Avg. loss: 758261375105914576912252928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 358508063454.32, NNZs: 2, Bias: -121900178112.513611, T: 2048, Avg. loss: 832174022922002102818439168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 361041994055.23, NNZs: 2, Bias: -105545512025.269348, T: 2176, Avg. loss: 778275006721717579794087936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 72782596207.32, NNZs: 2, Bias: -107421631001.936768, T: 2304, Avg. loss: 54389887911814374772178944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 46755979089.28, NNZs: 2, Bias: -107316290427.309631, T: 2432, Avg. loss: 32249499352080627231883264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 21892788481.15, NNZs: 2, Bias: -109656281748.013748, T: 2560, Avg. loss: 31234197936846695844282368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 34156354856.02, NNZs: 2, Bias: -109673383786.891266, T: 2688, Avg. loss: 29745353330656321109753856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 44912358249.86, NNZs: 2, Bias: -109827506041.507416, T: 2816, Avg. loss: 28102767343997834277945344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 39611934307.41, NNZs: 2, Bias: -109258079566.951828, T: 2944, Avg. loss: 31227457865194053147033600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 9978272962.82, NNZs: 2, Bias: -109789863355.710480, T: 3072, Avg. loss: 28066860556424908827000832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 47112955287.53, NNZs: 2, Bias: -112147061825.948395, T: 3200, Avg. loss: 31400480133652389163958272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 82463220500.95, NNZs: 2, Bias: -114485691520.100723, T: 3328, Avg. loss: 28250032930222305194278912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 16058677138.02, NNZs: 2, Bias: -115196966845.476471, T: 3456, Avg. loss: 31269338222746902005284864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 24252549427.96, NNZs: 2, Bias: -113692999795.562393, T: 3584, Avg. loss: 27423884126619622241730560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 40978961701.41, NNZs: 2, Bias: -112257361341.809250, T: 3712, Avg. loss: 27689883052422422954246144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 48220156568.69, NNZs: 2, Bias: -110671395902.512344, T: 3840, Avg. loss: 30187576518865528125652992.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 21325095468.11, NNZs: 2, Bias: -112820744553.498337, T: 3968, Avg. loss: 32417867263249293017874432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5971205810.15, NNZs: 2, Bias: -111902778633.176331, T: 4096, Avg. loss: 30571255618815846474842112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 60634993870.32, NNZs: 2, Bias: -113295661505.643295, T: 4224, Avg. loss: 28075222239486139514748928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 11112199526.99, NNZs: 2, Bias: -112971998646.675385, T: 4352, Avg. loss: 1132188945349527631560704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4557032856.49, NNZs: 2, Bias: -112798079063.561310, T: 4480, Avg. loss: 556996368333894685032448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2335989575.85, NNZs: 2, Bias: -112593870624.207504, T: 4608, Avg. loss: 568228404705968181477376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4191550217.26, NNZs: 2, Bias: -112610495920.777069, T: 4736, Avg. loss: 485948503251450110935040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1065217259.03, NNZs: 2, Bias: -112158758642.531448, T: 4864, Avg. loss: 474420935996387427876864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 5566442124.11, NNZs: 2, Bias: -112433426241.632980, T: 4992, Avg. loss: 479057102066220984696832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 14200450867.36, NNZs: 2, Bias: -112122555757.367615, T: 5120, Avg. loss: 483132120889137410605056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2230578374.31, NNZs: 2, Bias: -112226064011.854645, T: 5248, Avg. loss: 561073585731918031224832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3529022782.38, NNZs: 2, Bias: -112026507788.999405, T: 5376, Avg. loss: 623301542331963991392256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4092345245.12, NNZs: 2, Bias: -111698041107.976959, T: 5504, Avg. loss: 526066764600820744847360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2990690336.50, NNZs: 2, Bias: -111666288046.078033, T: 5632, Avg. loss: 2450940025734813450240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2351370060.99, NNZs: 2, Bias: -111637820888.888824, T: 5760, Avg. loss: 1605575062545661689856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2073646477.44, NNZs: 2, Bias: -111603606893.099045, T: 5888, Avg. loss: 1463481893239375003648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1859655546.15, NNZs: 2, Bias: -111568553873.672180, T: 6016, Avg. loss: 1361955801118388518912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1849076847.15, NNZs: 2, Bias: -111532510428.391739, T: 6144, Avg. loss: 1305391132412120924160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1858677765.94, NNZs: 2, Bias: -111494664117.153381, T: 6272, Avg. loss: 1320407471264015056896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1850988123.93, NNZs: 2, Bias: -111456991198.287170, T: 6400, Avg. loss: 1388477478663573733376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1871568785.70, NNZs: 2, Bias: -111419120396.871506, T: 6528, Avg. loss: 1275378284351422988288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1845440046.21, NNZs: 2, Bias: -111380221302.003220, T: 6656, Avg. loss: 1372293562858388324352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1784437721.52, NNZs: 2, Bias: -111344899078.463715, T: 6784, Avg. loss: 1237060485512860270592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1750956902.64, NNZs: 2, Bias: -111307409204.094589, T: 6912, Avg. loss: 1341881451066732314624.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1821113841.55, NNZs: 2, Bias: -111269281166.816437, T: 7040, Avg. loss: 1231993550627519856640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1849578510.90, NNZs: 2, Bias: -111230344050.773758, T: 7168, Avg. loss: 1379574275270104842240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1882011579.72, NNZs: 2, Bias: -111194968546.222504, T: 7296, Avg. loss: 1228670196301495795712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1843347207.13, NNZs: 2, Bias: -111158134427.846298, T: 7424, Avg. loss: 1244174426254494662656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1797834121.56, NNZs: 2, Bias: -111121270194.831207, T: 7552, Avg. loss: 1234932221295553937408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1839416190.58, NNZs: 2, Bias: -111084425464.003983, T: 7680, Avg. loss: 1270787456054558982144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1846069674.45, NNZs: 2, Bias: -111045289706.626541, T: 7808, Avg. loss: 1376302734279971438592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1822354362.36, NNZs: 2, Bias: -111007735734.459763, T: 7936, Avg. loss: 1287105067150489157632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1808805461.48, NNZs: 2, Bias: -111000475464.334335, T: 8064, Avg. loss: 1049163310631804207104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1790703191.44, NNZs: 2, Bias: -110993242355.178329, T: 8192, Avg. loss: 1057025279797945040896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1812165386.14, NNZs: 2, Bias: -110985396353.740356, T: 8320, Avg. loss: 1051418397248966885376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1777405501.89, NNZs: 2, Bias: -110978500575.936691, T: 8448, Avg. loss: 1046613657435202781184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1777932068.37, NNZs: 2, Bias: -110971080120.559494, T: 8576, Avg. loss: 1038004647531413372928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1781563782.40, NNZs: 2, Bias: -110963526136.591049, T: 8704, Avg. loss: 1051169295368035762176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1822263580.14, NNZs: 2, Bias: -110955382262.320572, T: 8832, Avg. loss: 1046803728419834822656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1773438332.62, NNZs: 2, Bias: -110948785253.939484, T: 8960, Avg. loss: 1038575549551596929024.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1769414802.16, NNZs: 2, Bias: -110941257979.518936, T: 9088, Avg. loss: 1065020762052425809920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1795041478.17, NNZs: 2, Bias: -110933279673.961121, T: 9216, Avg. loss: 1057522707811742253056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1793679175.43, NNZs: 2, Bias: -110931805378.823792, T: 9344, Avg. loss: 1019817010331422425088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1793486084.74, NNZs: 2, Bias: -110930317279.651443, T: 9472, Avg. loss: 1016452810135623696384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1784461239.65, NNZs: 2, Bias: -110928974317.808228, T: 9600, Avg. loss: 1014885578809601687552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1788473195.60, NNZs: 2, Bias: -110927415107.451752, T: 9728, Avg. loss: 1018433422516125696000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1792390306.77, NNZs: 2, Bias: -110925856464.612732, T: 9856, Avg. loss: 1018973190733202587648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1792644206.69, NNZs: 2, Bias: -110924358091.890915, T: 9984, Avg. loss: 1018319026987675287552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1791090552.73, NNZs: 2, Bias: -110922889117.867783, T: 10112, Avg. loss: 1018210981038961065984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1786022820.05, NNZs: 2, Bias: -110921477072.734360, T: 10240, Avg. loss: 1018154938447187935232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 80 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1001487385035.88, NNZs: 2, Bias: 10568471396.959297, T: 128, Avg. loss: 20053149159828420765308420096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1636904375553.77, NNZs: 2, Bias: -9431528603.040710, T: 256, Avg. loss: 20618093225619448148883668992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 533283275615.41, NNZs: 2, Bias: -23989187755.500702, T: 384, Avg. loss: 20637777572038444396348178432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1200853308540.84, NNZs: 2, Bias: -43989187755.500702, T: 512, Avg. loss: 19268452388977385639147208704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1985117664450.13, NNZs: 2, Bias: -123989187755.500702, T: 640, Avg. loss: 19532980478629372264395571200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 326736941090.53, NNZs: 2, Bias: -122298210356.636917, T: 768, Avg. loss: 20666845493492689991442104320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 999232794245.41, NNZs: 2, Bias: -122298210356.636902, T: 896, Avg. loss: 20493213904618837672026177536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 342028276524.34, NNZs: 2, Bias: -126425110943.955429, T: 1024, Avg. loss: 20962547800039810090884136960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 636316323139.99, NNZs: 2, Bias: -105542601885.224915, T: 1152, Avg. loss: 20385020626448331475586646016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 300446210755.07, NNZs: 2, Bias: -80452184815.049774, T: 1280, Avg. loss: 787106876187978053032345600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 58954355207.39, NNZs: 2, Bias: -62996261136.479950, T: 1408, Avg. loss: 813288015414492340542242816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 273230521900.75, NNZs: 2, Bias: -71112794088.128616, T: 1536, Avg. loss: 832141545249796954819395584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 316437780241.61, NNZs: 2, Bias: -67857011659.169693, T: 1664, Avg. loss: 795258316624923239265599488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 390495878478.96, NNZs: 2, Bias: -55081608948.509293, T: 1792, Avg. loss: 842834509093836417010761728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 221779033922.12, NNZs: 2, Bias: -54914270607.024384, T: 1920, Avg. loss: 878621407437941278070800384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 30577428027.24, NNZs: 2, Bias: -62909201619.255539, T: 2048, Avg. loss: 34666687422636671409061888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 45160510729.35, NNZs: 2, Bias: -63951119654.950348, T: 2176, Avg. loss: 26637352255619417610649600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 26235223435.40, NNZs: 2, Bias: -64260209057.248795, T: 2304, Avg. loss: 32997233510490662389153792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 44667697199.74, NNZs: 2, Bias: -63887296223.523392, T: 2432, Avg. loss: 28796660037594190673084416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 20414724949.02, NNZs: 2, Bias: -64443919105.931755, T: 2560, Avg. loss: 29630567234804917829894144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 61882823219.78, NNZs: 2, Bias: -64275837976.201401, T: 2688, Avg. loss: 30571068480801304135860224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 47772176137.34, NNZs: 2, Bias: -62511167563.940681, T: 2816, Avg. loss: 30291353152188821448687616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1287245601.00, NNZs: 2, Bias: -62782560359.822014, T: 2944, Avg. loss: 1137520201374203058847744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4697512881.44, NNZs: 2, Bias: -62950996574.219597, T: 3072, Avg. loss: 482170746575573061992448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2102763977.70, NNZs: 2, Bias: -62924185119.690689, T: 3200, Avg. loss: 631071257279672090624000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8979216857.21, NNZs: 2, Bias: -63098834512.823654, T: 3328, Avg. loss: 607756965594211393994752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4769199548.19, NNZs: 2, Bias: -63025194600.766197, T: 3456, Avg. loss: 632400699043153797185536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 5669605033.12, NNZs: 2, Bias: -62873275806.009491, T: 3584, Avg. loss: 546386069749883312537600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1865153927.93, NNZs: 2, Bias: -62918761330.881157, T: 3712, Avg. loss: 460567488502221793918976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5024054619.68, NNZs: 2, Bias: -62901703692.080200, T: 3840, Avg. loss: 746205203253313769832448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11089086695.85, NNZs: 2, Bias: -62987259325.756912, T: 3968, Avg. loss: 490775706856989766189056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3633784095.84, NNZs: 2, Bias: -62669740086.172615, T: 4096, Avg. loss: 423008531240824969625600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6936942405.03, NNZs: 2, Bias: -62723203870.912971, T: 4224, Avg. loss: 515478909386971227881472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1030677632.82, NNZs: 2, Bias: -62667681438.909874, T: 4352, Avg. loss: 340216820301143969103872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1396667571.86, NNZs: 2, Bias: -62357058737.188965, T: 4480, Avg. loss: 467033197496609242349568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4277571095.61, NNZs: 2, Bias: -62254550817.428261, T: 4608, Avg. loss: 503390898577398038528000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5583016275.24, NNZs: 2, Bias: -61918309484.032829, T: 4736, Avg. loss: 580749443517630774247424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3496934388.01, NNZs: 2, Bias: -61854870891.756516, T: 4864, Avg. loss: 692451082935497744449536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2240673436.32, NNZs: 2, Bias: -61538933143.978867, T: 4992, Avg. loss: 503263004969241256394752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1474996726.71, NNZs: 2, Bias: -61520764994.560249, T: 5120, Avg. loss: 871614049641739321344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1304538494.88, NNZs: 2, Bias: -61505171113.104179, T: 5248, Avg. loss: 386211654734264205312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1195623165.77, NNZs: 2, Bias: -61487915517.445572, T: 5376, Avg. loss: 354929557490098700288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1173274306.56, NNZs: 2, Bias: -61469183064.758141, T: 5504, Avg. loss: 380913760985183027200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1141660240.92, NNZs: 2, Bias: -61450720460.151787, T: 5632, Avg. loss: 359269186919764983808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1116716436.66, NNZs: 2, Bias: -61432460199.579910, T: 5760, Avg. loss: 345730939888172531712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1062630227.06, NNZs: 2, Bias: -61413264115.267738, T: 5888, Avg. loss: 385086486325808726016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1136427187.63, NNZs: 2, Bias: -61393972440.842461, T: 6016, Avg. loss: 339947345541726208000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1085382969.98, NNZs: 2, Bias: -61375700870.630592, T: 6144, Avg. loss: 366664621765919178752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1044217059.85, NNZs: 2, Bias: -61357013980.609016, T: 6272, Avg. loss: 371109890575717629952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1066382727.67, NNZs: 2, Bias: -61336829472.824905, T: 6400, Avg. loss: 366319876448533610496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1047265594.08, NNZs: 2, Bias: -61318107659.022736, T: 6528, Avg. loss: 362284972947098828800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1055684431.18, NNZs: 2, Bias: -61298853051.270500, T: 6656, Avg. loss: 363356713069622657024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1051732691.66, NNZs: 2, Bias: -61295125307.540970, T: 6784, Avg. loss: 293854108680132231168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1049866678.43, NNZs: 2, Bias: -61291344900.817154, T: 6912, Avg. loss: 294844413338697105408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1062890089.51, NNZs: 2, Bias: -61287312860.425720, T: 7040, Avg. loss: 294232071531761991680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1065516982.14, NNZs: 2, Bias: -61283422672.338547, T: 7168, Avg. loss: 297788041004176834560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1072602892.40, NNZs: 2, Bias: -61279478554.680382, T: 7296, Avg. loss: 295264078033431953408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1065924178.18, NNZs: 2, Bias: -61275803539.808327, T: 7424, Avg. loss: 293362376858581336064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1056816366.79, NNZs: 2, Bias: -61272115290.858635, T: 7552, Avg. loss: 297501988144288890880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1057798904.06, NNZs: 2, Bias: -61268249493.434723, T: 7680, Avg. loss: 297015671788862570496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1067077430.97, NNZs: 2, Bias: -61264227411.086037, T: 7808, Avg. loss: 298118207641521881088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1067425938.22, NNZs: 2, Bias: -61260400274.066734, T: 7936, Avg. loss: 295249191181268877312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1053263598.57, NNZs: 2, Bias: -61256847886.026535, T: 8064, Avg. loss: 293408314677170569216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1063382676.07, NNZs: 2, Bias: -61255891498.969498, T: 8192, Avg. loss: 293871773234504859648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1064609998.07, NNZs: 2, Bias: -61255103414.048065, T: 8320, Avg. loss: 288445382918852444160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1061733773.61, NNZs: 2, Bias: -61254392596.476700, T: 8448, Avg. loss: 286250732348753805312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1063019347.39, NNZs: 2, Bias: -61253603017.568382, T: 8576, Avg. loss: 288627397685052276736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1062923531.72, NNZs: 2, Bias: -61252837765.740753, T: 8704, Avg. loss: 288528635663492087808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1063595031.90, NNZs: 2, Bias: -61252060110.937424, T: 8832, Avg. loss: 288142694760582578176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1066497719.77, NNZs: 2, Bias: -61251243643.597450, T: 8960, Avg. loss: 288110834676556529664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1067247179.80, NNZs: 2, Bias: -61250464830.864006, T: 9088, Avg. loss: 288042575524055154688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 71 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1556666436527.29, NNZs: 2, Bias: 90093227441.178864, T: 128, Avg. loss: 23096116445503314057347727360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 528630882726.81, NNZs: 2, Bias: 150093227441.178864, T: 256, Avg. loss: 23512662586368237827069575168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1361851125895.93, NNZs: 2, Bias: 130093227441.178864, T: 384, Avg. loss: 23265395994290058507705122816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 415958705402.89, NNZs: 2, Bias: 138456527189.337128, T: 512, Avg. loss: 22016981246453218731804852224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1586736446735.92, NNZs: 2, Bias: 178456527189.337128, T: 640, Avg. loss: 22645232799806375248875487232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1571400090809.90, NNZs: 2, Bias: 125396425918.804321, T: 768, Avg. loss: 25085058250588441997284999168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1377614769262.33, NNZs: 2, Bias: 105396425918.804321, T: 896, Avg. loss: 21792098059500931656773009408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1558292668072.71, NNZs: 2, Bias: 96163285166.569870, T: 1024, Avg. loss: 23214619349455148911700213760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1095406558959.08, NNZs: 2, Bias: 174267511160.790649, T: 1152, Avg. loss: 23153778102208992518785204224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2478673112324.68, NNZs: 2, Bias: 232960624134.726929, T: 1280, Avg. loss: 21105660267032389449588670464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 352676605664.14, NNZs: 2, Bias: 287175585513.490234, T: 1408, Avg. loss: 22304201080434711802457096192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1989165787593.93, NNZs: 2, Bias: 280973373234.046387, T: 1536, Avg. loss: 21546951695725818850463186944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2070406003370.56, NNZs: 2, Bias: 328760986770.706421, T: 1664, Avg. loss: 22665674018145810527375327232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1391929408663.99, NNZs: 2, Bias: 368760986770.706421, T: 1792, Avg. loss: 24444741518317007777661190144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 747556509202.44, NNZs: 2, Bias: 428760986770.706421, T: 1920, Avg. loss: 23335622783627338804254212096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 21114520866.44, NNZs: 2, Bias: 444036679255.038147, T: 2048, Avg. loss: 912348114815973792298303488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 98606806900.28, NNZs: 2, Bias: 430783453938.281189, T: 2176, Avg. loss: 909693909545566186265116672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 181351970438.54, NNZs: 2, Bias: 441336069331.016357, T: 2304, Avg. loss: 913609881622617198795161600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 98372697932.76, NNZs: 2, Bias: 450262984380.851868, T: 2432, Avg. loss: 896922588104188503051468800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 378512272727.60, NNZs: 2, Bias: 447975882864.741882, T: 2560, Avg. loss: 826205356317774659343876096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 503164333323.33, NNZs: 2, Bias: 454160210538.228943, T: 2688, Avg. loss: 864293853916116438650716160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 136525646342.26, NNZs: 2, Bias: 458210728714.226196, T: 2816, Avg. loss: 914124434643154024815132672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 367535627814.21, NNZs: 2, Bias: 476712238063.116699, T: 2944, Avg. loss: 890475212465161397484912640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 122959673500.76, NNZs: 2, Bias: 459725043066.652100, T: 3072, Avg. loss: 873088655014250186748723200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 43951150576.43, NNZs: 2, Bias: 469829574871.187256, T: 3200, Avg. loss: 904291708014180506548568064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 28359645464.75, NNZs: 2, Bias: 469273069523.917419, T: 3328, Avg. loss: 36676163914064100711202816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 74708777051.80, NNZs: 2, Bias: 469055005559.426941, T: 3456, Avg. loss: 32435586221626464665600000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 88899926241.65, NNZs: 2, Bias: 465336243520.261841, T: 3584, Avg. loss: 32890810144224934243598336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 82569561649.13, NNZs: 2, Bias: 460862033656.792175, T: 3712, Avg. loss: 33676893390386956995657728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 71966701482.62, NNZs: 2, Bias: 460691425770.076233, T: 3840, Avg. loss: 32078863308589851520008192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 76334349432.08, NNZs: 2, Bias: 460124661156.367432, T: 3968, Avg. loss: 32299567890628698429194240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 20158529217.92, NNZs: 2, Bias: 461562983547.045471, T: 4096, Avg. loss: 37307091423540208044343296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 47646262105.42, NNZs: 2, Bias: 459860580466.653564, T: 4224, Avg. loss: 33249103721640986440368128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 43010954070.07, NNZs: 2, Bias: 459200032802.358521, T: 4352, Avg. loss: 31870504713918484989345792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 14464324960.32, NNZs: 2, Bias: 456536104301.615784, T: 4480, Avg. loss: 36613115347595998584111104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 13339148652.33, NNZs: 2, Bias: 458264579046.399170, T: 4608, Avg. loss: 33451431061487512987893760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 83760041790.58, NNZs: 2, Bias: 456283763765.934998, T: 4736, Avg. loss: 35549615227861782279225344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8541869732.83, NNZs: 2, Bias: 452961892654.080627, T: 4864, Avg. loss: 36750862318456068919787520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 70463089254.94, NNZs: 2, Bias: 451944906251.100464, T: 4992, Avg. loss: 30971547092469434944585728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 28265443249.74, NNZs: 2, Bias: 452110459480.854187, T: 5120, Avg. loss: 34742321293941731150004224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9203642598.57, NNZs: 2, Bias: 452479530746.977905, T: 5248, Avg. loss: 34770953055570390830546944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 58047304876.07, NNZs: 2, Bias: 451181527138.594849, T: 5376, Avg. loss: 35158923572041961380511744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 40379458812.24, NNZs: 2, Bias: 452881629109.225159, T: 5504, Avg. loss: 35369718583740063094407168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 16844835325.88, NNZs: 2, Bias: 452201121452.574341, T: 5632, Avg. loss: 34640636092265175478960128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6937766004.16, NNZs: 2, Bias: 451663889072.485657, T: 5760, Avg. loss: 1045674747999014633865216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 19779608842.88, NNZs: 2, Bias: 451624260701.442078, T: 5888, Avg. loss: 803272059445304291753984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 10379461603.44, NNZs: 2, Bias: 451234115734.614319, T: 6016, Avg. loss: 735386043168078184841216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 12509547842.61, NNZs: 2, Bias: 450398037288.838562, T: 6144, Avg. loss: 893460232287189972549632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 16374497651.33, NNZs: 2, Bias: 449593624440.933350, T: 6272, Avg. loss: 744418832625693529997312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 19729218314.15, NNZs: 2, Bias: 449365901199.622375, T: 6400, Avg. loss: 729842896628824764579840.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 19147318231.41, NNZs: 2, Bias: 448377376601.685059, T: 6528, Avg. loss: 858381589803289599279104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 5605738115.02, NNZs: 2, Bias: 447545034660.638611, T: 6656, Avg. loss: 859056098195301747130368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 14456708571.48, NNZs: 2, Bias: 446893415322.481201, T: 6784, Avg. loss: 968281620790257431609344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 14678243776.44, NNZs: 2, Bias: 446047133647.057861, T: 6912, Avg. loss: 1003357749944059110096896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 11377617176.61, NNZs: 2, Bias: 445322833092.963562, T: 7040, Avg. loss: 937197660903379944079360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 6657902929.72, NNZs: 2, Bias: 445126186265.393494, T: 7168, Avg. loss: 64568657411832371216384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 6891624516.48, NNZs: 2, Bias: 444987986605.072571, T: 7296, Avg. loss: 18037330209788150153216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 7130300049.92, NNZs: 2, Bias: 444827283398.306641, T: 7424, Avg. loss: 21560823589799714619392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 6593582100.28, NNZs: 2, Bias: 444688376540.902649, T: 7552, Avg. loss: 20362419531815076233216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 7189628033.21, NNZs: 2, Bias: 444527093062.800232, T: 7680, Avg. loss: 20992016178678190833664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 6594636229.94, NNZs: 2, Bias: 444383299855.079590, T: 7808, Avg. loss: 21656643624264223686656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 6749981506.10, NNZs: 2, Bias: 444227842017.454773, T: 7936, Avg. loss: 20278068482916319494144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 6817719850.79, NNZs: 2, Bias: 444196677514.753723, T: 8064, Avg. loss: 16912595649289470869504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 6837507861.20, NNZs: 2, Bias: 444166128407.253174, T: 8192, Avg. loss: 16975240177207857905664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 6740895104.22, NNZs: 2, Bias: 444138253337.834595, T: 8320, Avg. loss: 16454584227046942048256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 6871308720.15, NNZs: 2, Bias: 444106064690.424866, T: 8448, Avg. loss: 16903966408396528156672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 6792064907.45, NNZs: 2, Bias: 444078459121.152405, T: 8576, Avg. loss: 16158390272358084509696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 6823921132.41, NNZs: 2, Bias: 444047949964.933777, T: 8704, Avg. loss: 16858063190576206970880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 6893971409.23, NNZs: 2, Bias: 444016897337.417969, T: 8832, Avg. loss: 16787949541107718684672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 6992073452.76, NNZs: 2, Bias: 443986024334.472534, T: 8960, Avg. loss: 16412496105379538665472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 6912812338.59, NNZs: 2, Bias: 443957139089.902161, T: 9088, Avg. loss: 16920205047996581150720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 6817022240.43, NNZs: 2, Bias: 443929589564.663086, T: 9216, Avg. loss: 16272083735158567469056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 6923998283.40, NNZs: 2, Bias: 443921846882.467346, T: 9344, Avg. loss: 16582379324126993055744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 6938342025.04, NNZs: 2, Bias: 443915670576.121155, T: 9472, Avg. loss: 16230475224981528641536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 6933494850.66, NNZs: 2, Bias: 443909780886.290710, T: 9600, Avg. loss: 16266972000208583393280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 6941835873.32, NNZs: 2, Bias: 443903703439.193909, T: 9728, Avg. loss: 16215958185030157598720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 6943602578.59, NNZs: 2, Bias: 443897718130.303650, T: 9856, Avg. loss: 16246002200976086269952.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 77 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 988840529013.12, NNZs: 2, Bias: 8283372587.534882, T: 128, Avg. loss: 21260245511627252349496459264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1438423984811.50, NNZs: 2, Bias: -71716627412.465118, T: 256, Avg. loss: 25922458866481360121641304064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1130915287864.88, NNZs: 2, Bias: -82149660572.181458, T: 384, Avg. loss: 24054163504794724238551416832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1674267351504.72, NNZs: 2, Bias: -100892054808.337555, T: 512, Avg. loss: 23305318067569017724254289920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 831289209129.33, NNZs: 2, Bias: -247192390707.016602, T: 640, Avg. loss: 23475984062569614691132243968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1636418345579.08, NNZs: 2, Bias: -167192390707.016602, T: 768, Avg. loss: 24725081959622067076391239680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 308926021608.84, NNZs: 2, Bias: -198478209049.498169, T: 896, Avg. loss: 1241846378480869639414874112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 235131115433.52, NNZs: 2, Bias: -217467151851.457489, T: 1024, Avg. loss: 938430716309949836681019392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 291803493745.64, NNZs: 2, Bias: -218197094519.133636, T: 1152, Avg. loss: 1009488091024350315162894336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 375120118643.16, NNZs: 2, Bias: -206326885663.694885, T: 1280, Avg. loss: 877878046574817282367684608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 104553145736.79, NNZs: 2, Bias: -209530611415.146271, T: 1408, Avg. loss: 961724314293823736519852032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 139915796769.54, NNZs: 2, Bias: -210887260606.607574, T: 1536, Avg. loss: 861359438147331731690094592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 130736397136.84, NNZs: 2, Bias: -194742220190.714355, T: 1664, Avg. loss: 1048619592042830309441404928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 235963597914.93, NNZs: 2, Bias: -175887494460.536987, T: 1792, Avg. loss: 913746917148025478631653376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 605171212622.21, NNZs: 2, Bias: -150050805807.163361, T: 1920, Avg. loss: 808046239044711041478950912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43821490281.34, NNZs: 2, Bias: -142789138626.880768, T: 2048, Avg. loss: 932598744403143005015375872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 239075845441.43, NNZs: 2, Bias: -150784044452.984222, T: 2176, Avg. loss: 944720394305461495269425152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 144299501432.93, NNZs: 2, Bias: -153760963590.164459, T: 2304, Avg. loss: 983594953527323036869459968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 87744815060.28, NNZs: 2, Bias: -130694859666.174866, T: 2432, Avg. loss: 936199602622095036052930560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 320212327192.49, NNZs: 2, Bias: -140733408131.815582, T: 2560, Avg. loss: 910667622628378187896193024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 16009966126.30, NNZs: 2, Bias: -139975393346.856476, T: 2688, Avg. loss: 64638138997466420433911808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 56954845450.09, NNZs: 2, Bias: -137228073894.915192, T: 2816, Avg. loss: 36991601155149717470969856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 82768794024.83, NNZs: 2, Bias: -136188622144.453430, T: 2944, Avg. loss: 36899467927298700109414400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 39288143918.30, NNZs: 2, Bias: -138612765667.371490, T: 3072, Avg. loss: 37404988143527294572429312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 103752561936.56, NNZs: 2, Bias: -137892300474.437500, T: 3200, Avg. loss: 35992753028086508931776512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 57246363342.08, NNZs: 2, Bias: -136651822211.986389, T: 3328, Avg. loss: 37497511657349303320444928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 45487872418.19, NNZs: 2, Bias: -135528580144.485535, T: 3456, Avg. loss: 34581348322897345625718784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9136362155.21, NNZs: 2, Bias: -135826573831.066391, T: 3584, Avg. loss: 36377005758274673253023744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 10586898126.20, NNZs: 2, Bias: -135978223622.162506, T: 3712, Avg. loss: 36967033300332377874104320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 84787095982.81, NNZs: 2, Bias: -134421191295.565948, T: 3840, Avg. loss: 31036383834356568003969024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 54719440013.14, NNZs: 2, Bias: -131767347635.675369, T: 3968, Avg. loss: 33617723166935770684456960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 77412683452.55, NNZs: 2, Bias: -132489008946.476593, T: 4096, Avg. loss: 35157820438832628214267904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 15305093794.57, NNZs: 2, Bias: -131029015208.625931, T: 4224, Avg. loss: 34963718503108378896629760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 25808549471.15, NNZs: 2, Bias: -129866140209.252365, T: 4352, Avg. loss: 32006777166587322836189184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 31213611444.70, NNZs: 2, Bias: -131699068704.008240, T: 4480, Avg. loss: 31325576708550239163777024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2234510181.88, NNZs: 2, Bias: -131052213788.111847, T: 4608, Avg. loss: 798533257578191362457600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 7346338278.47, NNZs: 2, Bias: -130754289399.988861, T: 4736, Avg. loss: 703751825346327314694144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 12771079910.44, NNZs: 2, Bias: -131043905890.268921, T: 4864, Avg. loss: 785723120116041475162112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2679789474.31, NNZs: 2, Bias: -130875329047.515137, T: 4992, Avg. loss: 804055706876990975901696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 13429230231.54, NNZs: 2, Bias: -131168628819.289413, T: 5120, Avg. loss: 706046013999571106004992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2326354781.25, NNZs: 2, Bias: -130511894642.814011, T: 5248, Avg. loss: 934827126864016197025792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 674611815.22, NNZs: 2, Bias: -130384644729.145538, T: 5376, Avg. loss: 675981085413882376224768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1184395149.22, NNZs: 2, Bias: -130246199025.655334, T: 5504, Avg. loss: 726086278159228179841024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 14048667744.21, NNZs: 2, Bias: -130006924280.254440, T: 5632, Avg. loss: 555042462449474274852864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 15292211396.44, NNZs: 2, Bias: -129698438980.525314, T: 5760, Avg. loss: 629589368082820163960832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 5370864192.97, NNZs: 2, Bias: -129461211379.273651, T: 5888, Avg. loss: 691008501989384279556096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 13415315559.03, NNZs: 2, Bias: -129140358538.087921, T: 6016, Avg. loss: 725837434685120070025216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1399601602.39, NNZs: 2, Bias: -129053412854.884308, T: 6144, Avg. loss: 738350647045335432560640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1166121620.88, NNZs: 2, Bias: -128395537628.233475, T: 6272, Avg. loss: 675891306735297223458816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1499991730.40, NNZs: 2, Bias: -128353381692.813782, T: 6400, Avg. loss: 1454671439723520851968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1694913504.24, NNZs: 2, Bias: -128314583497.030334, T: 6528, Avg. loss: 1371185906143087296512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1760817973.17, NNZs: 2, Bias: -128276408365.307266, T: 6656, Avg. loss: 1414099117082694123520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1795300272.03, NNZs: 2, Bias: -128240242960.124237, T: 6784, Avg. loss: 1372534615431823491072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1883034007.15, NNZs: 2, Bias: -128200626683.532547, T: 6912, Avg. loss: 1500649358702468136960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1909122257.40, NNZs: 2, Bias: -128164037978.818237, T: 7040, Avg. loss: 1437575797088159793152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1952743240.24, NNZs: 2, Bias: -128127747064.681488, T: 7168, Avg. loss: 1389212954211025158144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1982102395.82, NNZs: 2, Bias: -128119934704.221786, T: 7296, Avg. loss: 1186511502484119224320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1958582289.97, NNZs: 2, Bias: -128112873926.454956, T: 7424, Avg. loss: 1201406967454817583104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1937503616.45, NNZs: 2, Bias: -128105727795.703796, T: 7552, Avg. loss: 1207603982969547784192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1948320457.02, NNZs: 2, Bias: -128098130712.009918, T: 7680, Avg. loss: 1198492627740657188864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1924723149.44, NNZs: 2, Bias: -128091079307.635315, T: 7808, Avg. loss: 1198357012055263805440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1920265492.67, NNZs: 2, Bias: -128083725645.703796, T: 7936, Avg. loss: 1198586256685902594048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1934648091.92, NNZs: 2, Bias: -128082005404.553238, T: 8064, Avg. loss: 1182249676387320332288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1938106524.41, NNZs: 2, Bias: -128080462385.605621, T: 8192, Avg. loss: 1172385867331529211904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1937711419.55, NNZs: 2, Bias: -128078984855.207092, T: 8320, Avg. loss: 1166901669647199502336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1935934446.74, NNZs: 2, Bias: -128077522862.876007, T: 8448, Avg. loss: 1171123761219901849600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1940136242.81, NNZs: 2, Bias: -128075977168.556198, T: 8576, Avg. loss: 1165542117313398439936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1932874751.15, NNZs: 2, Bias: -128074595389.566971, T: 8704, Avg. loss: 1173399290842752745472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1934300543.61, NNZs: 2, Bias: -128073083707.544846, T: 8832, Avg. loss: 1171942383158679044096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1925729189.36, NNZs: 2, Bias: -128071729111.600281, T: 8960, Avg. loss: 1167221650677757378560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1932848284.36, NNZs: 2, Bias: -128070134922.400375, T: 9088, Avg. loss: 1169250804875863916544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1932308637.02, NNZs: 2, Bias: -128068653640.664337, T: 9216, Avg. loss: 1171508193869317406720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 72 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 227996025853.37, NNZs: 2, Bias: -6579899563.405800, T: 128, Avg. loss: 21552219015765591945967042560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 899532583779.36, NNZs: 2, Bias: 19234016721.908184, T: 256, Avg. loss: 21489884392276041994971643904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2034257590753.30, NNZs: 2, Bias: 59234016721.908188, T: 384, Avg. loss: 20983854219547170878370349056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 877577262927.29, NNZs: 2, Bias: 41420303261.226685, T: 512, Avg. loss: 23736190703659947925969043456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1398763260844.26, NNZs: 2, Bias: 72960414902.851990, T: 640, Avg. loss: 22274022510417673153373274112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 3066367423305.30, NNZs: 2, Bias: 147466816788.444153, T: 768, Avg. loss: 19109873844683436899375775744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 430333038848.49, NNZs: 2, Bias: 187466816788.444153, T: 896, Avg. loss: 21041396755010716970497605632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 830612856114.15, NNZs: 2, Bias: 207466816788.444153, T: 1024, Avg. loss: 23223544938958836586107633664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 350107116145.84, NNZs: 2, Bias: 229253297757.196564, T: 1152, Avg. loss: 21424074283043542455390568448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2511215231059.89, NNZs: 2, Bias: 209253297757.196564, T: 1280, Avg. loss: 22819914365975895663557214208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1166844396266.21, NNZs: 2, Bias: 181244635988.302368, T: 1408, Avg. loss: 21376422148619968370479988736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 398888031508.85, NNZs: 2, Bias: 163045073879.281891, T: 1536, Avg. loss: 1252529301316793196133482496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 276200877887.13, NNZs: 2, Bias: 164784987040.083557, T: 1664, Avg. loss: 760844601492349951405981696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 167461597962.14, NNZs: 2, Bias: 182069182289.129303, T: 1792, Avg. loss: 893633424516400087136468992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 181821575248.77, NNZs: 2, Bias: 185337321818.303772, T: 1920, Avg. loss: 846022807150662917862457344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 46468664876.97, NNZs: 2, Bias: 190949320776.311829, T: 2048, Avg. loss: 910331758726612006735970304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 302743685010.62, NNZs: 2, Bias: 195938552448.481049, T: 2176, Avg. loss: 780316851401504972628557824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 410749803024.09, NNZs: 2, Bias: 194400944958.116852, T: 2304, Avg. loss: 821289198951900915622215680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 52944467608.62, NNZs: 2, Bias: 188296299534.796478, T: 2432, Avg. loss: 66586527017639169981677568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 64028456274.19, NNZs: 2, Bias: 188303866817.906342, T: 2560, Avg. loss: 32085431308729379478044672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 41670835704.61, NNZs: 2, Bias: 190410717206.730652, T: 2688, Avg. loss: 33136642191983454114021376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 69150208762.05, NNZs: 2, Bias: 187792898979.183105, T: 2816, Avg. loss: 33826600723088765158948864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 98248434098.20, NNZs: 2, Bias: 188761011312.684845, T: 2944, Avg. loss: 30128337101101569350303744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 94213836328.00, NNZs: 2, Bias: 192564311824.371948, T: 3072, Avg. loss: 30514018355563778352873472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 51941027103.95, NNZs: 2, Bias: 191511223992.975433, T: 3200, Avg. loss: 32304788718944017125998592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 41561375982.32, NNZs: 2, Bias: 192326532934.859192, T: 3328, Avg. loss: 32172128781801586539102208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 16106611254.43, NNZs: 2, Bias: 188216500215.338745, T: 3456, Avg. loss: 29437300340906078028955648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 44674938021.72, NNZs: 2, Bias: 185311355585.334686, T: 3584, Avg. loss: 29308264931335235308617728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 44485268523.29, NNZs: 2, Bias: 186236475469.525696, T: 3712, Avg. loss: 29815942566607251514064896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 48081280406.15, NNZs: 2, Bias: 185584715577.968750, T: 3840, Avg. loss: 30211070649532237238763520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 80898950543.08, NNZs: 2, Bias: 186132408438.600067, T: 3968, Avg. loss: 33323746800671091415056384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 80705968057.19, NNZs: 2, Bias: 189417552271.880219, T: 4096, Avg. loss: 31489271314669194342039552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 77069903476.46, NNZs: 2, Bias: 189660332295.669220, T: 4224, Avg. loss: 31121190999522933886418944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 17237172791.76, NNZs: 2, Bias: 188341802652.255066, T: 4352, Avg. loss: 1698980655562179745939456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 12514516572.05, NNZs: 2, Bias: 187789901806.656525, T: 4480, Avg. loss: 919953985598053066735616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6076210508.05, NNZs: 2, Bias: 187860306671.554199, T: 4608, Avg. loss: 660206070049317410832384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 11160003274.18, NNZs: 2, Bias: 187723882374.215973, T: 4736, Avg. loss: 641223515342658630320128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7847343289.68, NNZs: 2, Bias: 187753305138.646820, T: 4864, Avg. loss: 632406426413175352066048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4473798295.65, NNZs: 2, Bias: 187350441810.485565, T: 4992, Avg. loss: 574612316201635849175040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 8339131208.71, NNZs: 2, Bias: 187211381268.076996, T: 5120, Avg. loss: 733697961929456884908032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4189011015.13, NNZs: 2, Bias: 187024086796.185608, T: 5248, Avg. loss: 558765576059870414635008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 8594427244.43, NNZs: 2, Bias: 186505150786.438812, T: 5376, Avg. loss: 485560610912757845327872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 16808025249.74, NNZs: 2, Bias: 186092012430.346436, T: 5504, Avg. loss: 542629343968119159259136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5248952956.46, NNZs: 2, Bias: 185967935534.307281, T: 5632, Avg. loss: 652884175221191075692544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4491938034.91, NNZs: 2, Bias: 185848188660.733704, T: 5760, Avg. loss: 705507571334638745944064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 5740301046.74, NNZs: 2, Bias: 185675703114.159729, T: 5888, Avg. loss: 550521496293197236666368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2882616744.14, NNZs: 2, Bias: 185620648270.691772, T: 6016, Avg. loss: 666723625697854804197376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3081605898.73, NNZs: 2, Bias: 185549248396.868347, T: 6144, Avg. loss: 4027923253277762781184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3131583046.01, NNZs: 2, Bias: 185485038992.029297, T: 6272, Avg. loss: 3743939292992939491328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3136662035.81, NNZs: 2, Bias: 185418774776.057922, T: 6400, Avg. loss: 3748407628344829411328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3068307369.87, NNZs: 2, Bias: 185351609547.323669, T: 6528, Avg. loss: 3874235537097508782080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3054344418.29, NNZs: 2, Bias: 185287973390.053558, T: 6656, Avg. loss: 3638078872570587774976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2959716544.72, NNZs: 2, Bias: 185226572676.725159, T: 6784, Avg. loss: 3626767370764958040064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3031875672.37, NNZs: 2, Bias: 185159361128.862457, T: 6912, Avg. loss: 3923966649808652337152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3009888026.82, NNZs: 2, Bias: 185097053934.821259, T: 7040, Avg. loss: 3469102392370759991296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2950210342.18, NNZs: 2, Bias: 185033868935.744537, T: 7168, Avg. loss: 3665785747649756921856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3098749198.94, NNZs: 2, Bias: 184966214928.377838, T: 7296, Avg. loss: 3547716794864302555136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3053622023.96, NNZs: 2, Bias: 184898646321.887604, T: 7424, Avg. loss: 3906612422257015259136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2948234726.49, NNZs: 2, Bias: 184831718095.168945, T: 7552, Avg. loss: 3881208505830689734656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2890841979.16, NNZs: 2, Bias: 184767343003.530273, T: 7680, Avg. loss: 3796739331340416581632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2870230655.19, NNZs: 2, Bias: 184754542859.602661, T: 7808, Avg. loss: 3052722463900223668224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2902504468.72, NNZs: 2, Bias: 184740896979.757141, T: 7936, Avg. loss: 3056073868829245046784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2914669256.30, NNZs: 2, Bias: 184727961587.707245, T: 8064, Avg. loss: 2950851816605912399872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2946769235.87, NNZs: 2, Bias: 184714400431.169617, T: 8192, Avg. loss: 3031976912722866995200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2917728116.25, NNZs: 2, Bias: 184702255853.643921, T: 8320, Avg. loss: 2926765644025500794880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2912839760.59, NNZs: 2, Bias: 184689295874.367676, T: 8448, Avg. loss: 3035289050545071325184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2963029521.91, NNZs: 2, Bias: 184675453862.512695, T: 8576, Avg. loss: 3029560948421306613760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2951639733.91, NNZs: 2, Bias: 184662645263.581818, T: 8704, Avg. loss: 3016803411478300852224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2926496340.22, NNZs: 2, Bias: 184650043320.418335, T: 8832, Avg. loss: 3026744805913649479680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2930740675.90, NNZs: 2, Bias: 184637142524.467316, T: 8960, Avg. loss: 2989616549836107546624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2944886169.54, NNZs: 2, Bias: 184634311625.224030, T: 9088, Avg. loss: 2953025271876632444928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2960028798.21, NNZs: 2, Bias: 184631483805.620331, T: 9216, Avg. loss: 2929886302998033334272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2951008603.35, NNZs: 2, Bias: 184629033826.139343, T: 9344, Avg. loss: 2941520675484217638912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2959167724.19, NNZs: 2, Bias: 184626310613.199066, T: 9472, Avg. loss: 2938261933160551940096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2953842861.84, NNZs: 2, Bias: 184623802915.661102, T: 9600, Avg. loss: 2939584928054587162624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1569354249260.99, NNZs: 2, Bias: -40037718371.944191, T: 128, Avg. loss: 19301346322407868979583385600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1397280687626.74, NNZs: 2, Bias: 39962281628.055809, T: 256, Avg. loss: 21711099240091663075184214016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 696639989460.70, NNZs: 2, Bias: 2645725229.557091, T: 384, Avg. loss: 20248346357058453416481652736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1131627836637.65, NNZs: 2, Bias: -75687091499.193329, T: 512, Avg. loss: 20536430348243114258526633984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 812845194540.00, NNZs: 2, Bias: -55687091499.193329, T: 640, Avg. loss: 18641729039233288751196143616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 951002188816.07, NNZs: 2, Bias: 84312908500.806671, T: 768, Avg. loss: 20078239564428751600862887936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 817639779795.23, NNZs: 2, Bias: 89411849192.453552, T: 896, Avg. loss: 18818151175480284157386424320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 775034910203.47, NNZs: 2, Bias: 169411849192.453552, T: 1024, Avg. loss: 20272384232294149206919086080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1465413228417.32, NNZs: 2, Bias: 149411849192.453552, T: 1152, Avg. loss: 19950479643296761685857009664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1277446626243.55, NNZs: 2, Bias: 54299119679.004272, T: 1280, Avg. loss: 19780045340799537444315725824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 297648910425.30, NNZs: 2, Bias: 64332971683.122780, T: 1408, Avg. loss: 1018498462873272999720517632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 159781744552.72, NNZs: 2, Bias: 64303758606.505371, T: 1536, Avg. loss: 771333707379496069994905600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 166613328689.84, NNZs: 2, Bias: 64397651100.386482, T: 1664, Avg. loss: 756333109284108580599889920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 94321730633.06, NNZs: 2, Bias: 70202703480.317169, T: 1792, Avg. loss: 731248324994130747204829184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 162165059694.86, NNZs: 2, Bias: 78812573413.455017, T: 1920, Avg. loss: 872715129973016420453187584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 304896031700.86, NNZs: 2, Bias: 75151187009.813843, T: 2048, Avg. loss: 789387350676418730458611712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 261329049372.04, NNZs: 2, Bias: 110374442394.541580, T: 2176, Avg. loss: 743223080052223574590619648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 423998817167.26, NNZs: 2, Bias: 107877433427.416382, T: 2304, Avg. loss: 790947325595333625087262720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 293559184899.97, NNZs: 2, Bias: 115685607336.308289, T: 2432, Avg. loss: 802015508696908494777876480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 81048477869.29, NNZs: 2, Bias: 122672361202.933929, T: 2560, Avg. loss: 40726227039878273405288448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 90001508205.80, NNZs: 2, Bias: 122255128217.571457, T: 2688, Avg. loss: 28849523184256279279304704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 60073482708.03, NNZs: 2, Bias: 121710033414.374237, T: 2816, Avg. loss: 30998868130048992731987968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2282629729.23, NNZs: 2, Bias: 121912869837.428970, T: 2944, Avg. loss: 33493197017832836097376256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 22740955032.61, NNZs: 2, Bias: 120544607634.471848, T: 3072, Avg. loss: 29913529699114989071106048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 19308240187.78, NNZs: 2, Bias: 118796693383.321060, T: 3200, Avg. loss: 25562856199316709799100416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 13151894027.23, NNZs: 2, Bias: 122798364461.368622, T: 3328, Avg. loss: 28803722619325354780655616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 3172091079.64, NNZs: 2, Bias: 124760386254.149338, T: 3456, Avg. loss: 29778202618202028091899904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 34916844290.42, NNZs: 2, Bias: 120876644849.598557, T: 3584, Avg. loss: 32079347719064340733624320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 38969451908.82, NNZs: 2, Bias: 122327885820.287186, T: 3712, Avg. loss: 26259992653512516170678272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 67109154196.13, NNZs: 2, Bias: 121919139017.194275, T: 3840, Avg. loss: 27121597793302146726232064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6428747092.09, NNZs: 2, Bias: 121704949000.155197, T: 3968, Avg. loss: 1690611706343111593558016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 10504864738.57, NNZs: 2, Bias: 121694824475.932281, T: 4096, Avg. loss: 511192232641250893758464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9859525881.87, NNZs: 2, Bias: 121626937452.508026, T: 4224, Avg. loss: 512718465491171671015424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3912049950.25, NNZs: 2, Bias: 121698083164.720367, T: 4352, Avg. loss: 571758525800049192992768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7002243310.42, NNZs: 2, Bias: 121467518930.554779, T: 4480, Avg. loss: 480898028664603600224256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2751271508.66, NNZs: 2, Bias: 121434668063.288818, T: 4608, Avg. loss: 432770180322241525317632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 19111083083.91, NNZs: 2, Bias: 121506038820.697815, T: 4736, Avg. loss: 421029107069498637156352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9554238497.59, NNZs: 2, Bias: 121062363441.011536, T: 4864, Avg. loss: 608804874546910267965440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6170047444.53, NNZs: 2, Bias: 120760463579.077026, T: 4992, Avg. loss: 640435031692315795128320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3912449925.53, NNZs: 2, Bias: 121032643763.552231, T: 5120, Avg. loss: 511247298278039373217792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2077109992.46, NNZs: 2, Bias: 120921131590.423676, T: 5248, Avg. loss: 503750893081906640846848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4199465789.17, NNZs: 2, Bias: 120913254960.656036, T: 5376, Avg. loss: 523606041379980934381568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2904076339.42, NNZs: 2, Bias: 120889527695.754211, T: 5504, Avg. loss: 2437004128378223591424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2468000323.58, NNZs: 2, Bias: 120854373762.126343, T: 5632, Avg. loss: 1785907362968231215104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2199488254.90, NNZs: 2, Bias: 120815745326.409897, T: 5760, Avg. loss: 1681467684540171157504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1995144475.43, NNZs: 2, Bias: 120778456539.350967, T: 5888, Avg. loss: 1577925152013342736384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2040755979.97, NNZs: 2, Bias: 120736050316.148788, T: 6016, Avg. loss: 1586087133288732557312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1852058871.42, NNZs: 2, Bias: 120700443407.662231, T: 6144, Avg. loss: 1480584744690142937088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1961173554.67, NNZs: 2, Bias: 120659020871.516068, T: 6272, Avg. loss: 1467002014710974906368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2051693346.34, NNZs: 2, Bias: 120614638459.128998, T: 6400, Avg. loss: 1589139243877795627008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2020639997.11, NNZs: 2, Bias: 120575743985.910858, T: 6528, Avg. loss: 1485650112082364858368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1989564683.63, NNZs: 2, Bias: 120534640373.877151, T: 6656, Avg. loss: 1568718002668890488832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1914257794.40, NNZs: 2, Bias: 120493552309.843628, T: 6784, Avg. loss: 1575222479163106000896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1866193170.32, NNZs: 2, Bias: 120457490605.184814, T: 6912, Avg. loss: 1380560476864681869312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1877718737.12, NNZs: 2, Bias: 120416286364.270660, T: 7040, Avg. loss: 1550165416597895249920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1845070918.35, NNZs: 2, Bias: 120375264298.952652, T: 7168, Avg. loss: 1555681285731423354880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1999087010.98, NNZs: 2, Bias: 120334194060.242325, T: 7296, Avg. loss: 1426628819582546345984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1913398510.05, NNZs: 2, Bias: 120294058243.833084, T: 7424, Avg. loss: 1575377456770353987584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1973120791.13, NNZs: 2, Bias: 120251514337.895416, T: 7552, Avg. loss: 1614537009652482179072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1965762692.58, NNZs: 2, Bias: 120243621215.480774, T: 7680, Avg. loss: 1218647701782191407104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1928446947.15, NNZs: 2, Bias: 120236034715.094940, T: 7808, Avg. loss: 1245871816608573816832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1960216608.56, NNZs: 2, Bias: 120227509904.058105, T: 7936, Avg. loss: 1213848384993376600064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1932125629.78, NNZs: 2, Bias: 120219821285.921448, T: 8064, Avg. loss: 1237544912686187020288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1944982200.88, NNZs: 2, Bias: 120211498639.428070, T: 8192, Avg. loss: 1233040279015140622336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1926398374.19, NNZs: 2, Bias: 120203704004.432159, T: 8320, Avg. loss: 1229989705394632523776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1946747947.87, NNZs: 2, Bias: 120195218687.503220, T: 8448, Avg. loss: 1239409641620153827328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1940022856.39, NNZs: 2, Bias: 120187125989.536072, T: 8576, Avg. loss: 1246593207450014056448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1932273010.81, NNZs: 2, Bias: 120185631006.973099, T: 8704, Avg. loss: 1196537464447758499840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1932334596.09, NNZs: 2, Bias: 120184009557.467972, T: 8832, Avg. loss: 1196598049888675561472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1940698051.30, NNZs: 2, Bias: 120182265657.707275, T: 8960, Avg. loss: 1187604314923711856640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1935329321.44, NNZs: 2, Bias: 120180733187.178864, T: 9088, Avg. loss: 1195719908787311607808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1937160856.93, NNZs: 2, Bias: 120179084831.977234, T: 9216, Avg. loss: 1195100854855468580864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1930302087.30, NNZs: 2, Bias: 120177576172.590485, T: 9344, Avg. loss: 1195767428105972219904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1932174246.23, NNZs: 2, Bias: 120175925644.447586, T: 9472, Avg. loss: 1196435519134824398848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1935671726.08, NNZs: 2, Bias: 120174248215.945709, T: 9600, Avg. loss: 1196712881448689598464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2715248139849.94, NNZs: 2, Bias: 19342611854.586143, T: 128, Avg. loss: 19051306439158276397700481024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 250613502117.55, NNZs: 2, Bias: 73937713341.128235, T: 256, Avg. loss: 21733599445412029153874542592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1468030914007.54, NNZs: 2, Bias: 160430987945.640228, T: 384, Avg. loss: 21394351062771429969789714432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1563696223537.61, NNZs: 2, Bias: 117211474719.561752, T: 512, Avg. loss: 19699919229540771280252305408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2117466869158.52, NNZs: 2, Bias: 137539401660.840881, T: 640, Avg. loss: 20473520393776889039972990976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1393600221910.67, NNZs: 2, Bias: 97539401660.840881, T: 768, Avg. loss: 20904068126649326632649621504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 156090203300.17, NNZs: 2, Bias: 69847024148.752594, T: 896, Avg. loss: 1289145729642089594507755520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 349162747790.27, NNZs: 2, Bias: 69878571397.306168, T: 1024, Avg. loss: 822586697612996057776521216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 294920338412.08, NNZs: 2, Bias: 57992083519.506828, T: 1152, Avg. loss: 803638660288561001063776256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 106226384489.55, NNZs: 2, Bias: 72495451903.629181, T: 1280, Avg. loss: 804099849352753425588158464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 289622624641.62, NNZs: 2, Bias: 71489436303.060867, T: 1408, Avg. loss: 884020187533868830279335936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 436122637584.04, NNZs: 2, Bias: 60055949067.106361, T: 1536, Avg. loss: 925773742682655093732409344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 129369378549.48, NNZs: 2, Bias: 71586101200.686127, T: 1664, Avg. loss: 923310890177422199854465024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 217699694351.19, NNZs: 2, Bias: 80428280735.765915, T: 1792, Avg. loss: 759763088566693479527219200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 244296280004.02, NNZs: 2, Bias: 73742806896.691147, T: 1920, Avg. loss: 810049018233868181395472384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 315719258729.54, NNZs: 2, Bias: 92492702382.223862, T: 2048, Avg. loss: 886045838618130966158245888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 279086604071.66, NNZs: 2, Bias: 100280711716.575653, T: 2176, Avg. loss: 789920274900494377732276224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 158509144994.89, NNZs: 2, Bias: 111980146099.028839, T: 2304, Avg. loss: 774518116516897471145705472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 66886777235.01, NNZs: 2, Bias: 119810016000.373734, T: 2432, Avg. loss: 869575990233787697610096640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 9114442598.55, NNZs: 2, Bias: 118008453194.600983, T: 2560, Avg. loss: 31171680203127704428478464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 44117592964.11, NNZs: 2, Bias: 115099128427.836380, T: 2688, Avg. loss: 31433779741768879215476736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 84273512473.06, NNZs: 2, Bias: 112707927872.647430, T: 2816, Avg. loss: 30622391548413634720825344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 48685731859.98, NNZs: 2, Bias: 114778878464.763809, T: 2944, Avg. loss: 31630074654326904141643776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 9601115629.19, NNZs: 2, Bias: 112835070676.895096, T: 3072, Avg. loss: 34849479055009486284521472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 11138756820.77, NNZs: 2, Bias: 110618712217.263062, T: 3200, Avg. loss: 32516042602040919031021568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 28282462841.47, NNZs: 2, Bias: 112750109956.292786, T: 3328, Avg. loss: 31197732531031305046982656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 31453867488.82, NNZs: 2, Bias: 111375972631.617630, T: 3456, Avg. loss: 32778877721729138497159168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 8347244936.78, NNZs: 2, Bias: 112169287449.852707, T: 3584, Avg. loss: 549772738035472085811200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3815367585.44, NNZs: 2, Bias: 112287746849.666016, T: 3712, Avg. loss: 502999933557852625436672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3391151532.39, NNZs: 2, Bias: 111652941785.941818, T: 3840, Avg. loss: 649412656623678421729280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6935988760.44, NNZs: 2, Bias: 111781287874.024170, T: 3968, Avg. loss: 440251865523927948197888.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3753664774.87, NNZs: 2, Bias: 111649376144.440598, T: 4096, Avg. loss: 587594297952535142465536.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 12070641535.30, NNZs: 2, Bias: 111617500004.516418, T: 4224, Avg. loss: 510994571749881496469504.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9124784798.63, NNZs: 2, Bias: 111212870756.674911, T: 4352, Avg. loss: 441939408609739968348160.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9402897280.40, NNZs: 2, Bias: 110910354103.362625, T: 4480, Avg. loss: 533984450365166568079360.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1037946118.98, NNZs: 2, Bias: 110772927498.297897, T: 4608, Avg. loss: 550065818435786266116096.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1190759869.87, NNZs: 2, Bias: 110729292057.720703, T: 4736, Avg. loss: 1336194940427242569728.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1508912351.25, NNZs: 2, Bias: 110691655466.440323, T: 4864, Avg. loss: 1070671594328618827776.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1653723316.85, NNZs: 2, Bias: 110654625609.984024, T: 4992, Avg. loss: 1160996491221317582848.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1813165141.43, NNZs: 2, Bias: 110617130056.551712, T: 5120, Avg. loss: 1116966096074372677632.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1796593540.04, NNZs: 2, Bias: 110583196936.264893, T: 5248, Avg. loss: 1113020160009673244672.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1874131451.40, NNZs: 2, Bias: 110546496355.189713, T: 5376, Avg. loss: 1177542089687559045120.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1888587566.52, NNZs: 2, Bias: 110513049819.657684, T: 5504, Avg. loss: 1110828031278290042880.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1889066615.17, NNZs: 2, Bias: 110506089040.677460, T: 5632, Avg. loss: 968990842405815713792.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1895657387.88, NNZs: 2, Bias: 110499023809.871109, T: 5760, Avg. loss: 968737611614160289792.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1903864736.07, NNZs: 2, Bias: 110491931122.354752, T: 5888, Avg. loss: 970326238052561190912.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1924737823.56, NNZs: 2, Bias: 110484657648.471924, T: 6016, Avg. loss: 962580082236797222912.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1913805674.62, NNZs: 2, Bias: 110477899419.967606, T: 6144, Avg. loss: 969228426357320318976.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1911303637.97, NNZs: 2, Bias: 110471059707.743591, T: 6272, Avg. loss: 958080675155068846080.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1918774315.97, NNZs: 2, Bias: 110463998231.529465, T: 6400, Avg. loss: 965429136977061478400.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1919487995.19, NNZs: 2, Bias: 110457318140.650681, T: 6528, Avg. loss: 926981850244712366080.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1907387575.90, NNZs: 2, Bias: 110450687662.314972, T: 6656, Avg. loss: 953144464447884361728.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1921624679.87, NNZs: 2, Bias: 110443587715.818069, T: 6784, Avg. loss: 954177036839133511680.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1922179352.53, NNZs: 2, Bias: 110436572216.660187, T: 6912, Avg. loss: 976656101459399671808.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1911347430.17, NNZs: 2, Bias: 110429814541.646591, T: 7040, Avg. loss: 967385641720707678208.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1910063128.13, NNZs: 2, Bias: 110422966718.757111, T: 7168, Avg. loss: 955303136634158710784.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1917236025.49, NNZs: 2, Bias: 110421454635.040848, T: 7296, Avg. loss: 940937397494511566848.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1924571240.50, NNZs: 2, Bias: 110419946390.836517, T: 7424, Avg. loss: 936072076241709826048.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1927112198.60, NNZs: 2, Bias: 110418523235.368286, T: 7552, Avg. loss: 934983315141105287168.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1922538311.30, NNZs: 2, Bias: 110417218897.729935, T: 7680, Avg. loss: 938857771846264946688.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1916636783.62, NNZs: 2, Bias: 110415946837.060165, T: 7808, Avg. loss: 932465367584347521024.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 61 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 697488873289.38, NNZs: 2, Bias: 2082765046.181618, T: 128, Avg. loss: 21351011479220530741346566144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1501242712932.85, NNZs: 2, Bias: 62082765046.181618, T: 256, Avg. loss: 25325339908487464238599634944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 419254543246.55, NNZs: 2, Bias: 2082765046.181618, T: 384, Avg. loss: 23479005337968153567204212736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1090914770931.32, NNZs: 2, Bias: 80873203946.981705, T: 512, Avg. loss: 22201155433305707683564748800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1091405532916.51, NNZs: 2, Bias: 84247227347.495331, T: 640, Avg. loss: 23146499327316037942519005184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1434863724417.85, NNZs: 2, Bias: 164247227347.495331, T: 768, Avg. loss: 23665869912754349153275871232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 143392555610.41, NNZs: 2, Bias: 170317646470.849487, T: 896, Avg. loss: 1411113046119520909406502912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 227705378608.52, NNZs: 2, Bias: 179151918865.291687, T: 1024, Avg. loss: 904739985576837398392733696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 320781656136.84, NNZs: 2, Bias: 188925272657.989594, T: 1152, Avg. loss: 895807178043452763737686016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 424777565896.21, NNZs: 2, Bias: 197381263405.196899, T: 1280, Avg. loss: 876482250023897878570729472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 13690923269.38, NNZs: 2, Bias: 198524846859.928040, T: 1408, Avg. loss: 902389493543050811950497792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 176025115061.16, NNZs: 2, Bias: 183411419176.814697, T: 1536, Avg. loss: 952351567930066154089873408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 302767782497.46, NNZs: 2, Bias: 180363032225.387512, T: 1664, Avg. loss: 836892886739599850322526208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 263004200873.68, NNZs: 2, Bias: 202543252345.524841, T: 1792, Avg. loss: 921258220871704267001430016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 266778645948.13, NNZs: 2, Bias: 202376791031.349762, T: 1920, Avg. loss: 954931802938380857290784768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 95141673908.96, NNZs: 2, Bias: 211919489948.296509, T: 2048, Avg. loss: 863275286030583375914336256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 163060273393.49, NNZs: 2, Bias: 204893143892.117920, T: 2176, Avg. loss: 858861476850478881552990208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 326529225227.62, NNZs: 2, Bias: 208388332712.156738, T: 2304, Avg. loss: 959843081684340047846834176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 36489141113.26, NNZs: 2, Bias: 212983715106.004791, T: 2432, Avg. loss: 56573885578635490994683904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 13295332445.78, NNZs: 2, Bias: 212933203927.266052, T: 2560, Avg. loss: 32823356700979290490011648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 34952247141.11, NNZs: 2, Bias: 211791196680.264465, T: 2688, Avg. loss: 33974938939373866195091456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 73898113090.96, NNZs: 2, Bias: 208271995913.797546, T: 2816, Avg. loss: 33675934835454502378668032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 46183471477.79, NNZs: 2, Bias: 205596494667.570160, T: 2944, Avg. loss: 35993757958168740018257920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 56977504566.61, NNZs: 2, Bias: 206041454640.598785, T: 3072, Avg. loss: 31567725248619771265548288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 32264118776.42, NNZs: 2, Bias: 206550001267.579010, T: 3200, Avg. loss: 32857310693674073003655168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 7819396026.27, NNZs: 2, Bias: 205344607323.278320, T: 3328, Avg. loss: 32544997964497603772022784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 74531475737.74, NNZs: 2, Bias: 200423124189.190704, T: 3456, Avg. loss: 33585044934055918628241408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 107473957005.20, NNZs: 2, Bias: 199234101525.409271, T: 3584, Avg. loss: 37640707026588922252623872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 17206346817.56, NNZs: 2, Bias: 198155972578.289734, T: 3712, Avg. loss: 34254563081181296869769216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5277060609.71, NNZs: 2, Bias: 198596911322.541595, T: 3840, Avg. loss: 852877618960465865474048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 16124418524.09, NNZs: 2, Bias: 197814222439.655640, T: 3968, Avg. loss: 711554658116948285456384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5020721240.54, NNZs: 2, Bias: 197283744086.360199, T: 4096, Avg. loss: 774983377941813564276736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8698589974.40, NNZs: 2, Bias: 196829462420.280853, T: 4224, Avg. loss: 810091521305464134434816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4999021926.51, NNZs: 2, Bias: 196661217474.895569, T: 4352, Avg. loss: 761282677048355044982784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9568049800.38, NNZs: 2, Bias: 196309143504.146606, T: 4480, Avg. loss: 698923644328433982373888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11429715852.48, NNZs: 2, Bias: 195982156350.397614, T: 4608, Avg. loss: 727503369220675688464384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 11334380136.41, NNZs: 2, Bias: 195833932835.143372, T: 4736, Avg. loss: 704886534192042715643904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4682958215.35, NNZs: 2, Bias: 195756324931.944214, T: 4864, Avg. loss: 736178070503042175729664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6104844623.08, NNZs: 2, Bias: 195264217354.967377, T: 4992, Avg. loss: 574948500119059634847744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2910276176.54, NNZs: 2, Bias: 194576788301.549133, T: 5120, Avg. loss: 705548681783174590627840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 8768004124.93, NNZs: 2, Bias: 194501953219.940338, T: 5248, Avg. loss: 608895970730334044028928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6246493398.29, NNZs: 2, Bias: 194140895525.147644, T: 5376, Avg. loss: 689126855596041689890816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 10074575108.37, NNZs: 2, Bias: 193655284426.514435, T: 5504, Avg. loss: 788633850797832892579840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3056459441.97, NNZs: 2, Bias: 193167755997.668610, T: 5632, Avg. loss: 709862838686577003069440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1239616066.79, NNZs: 2, Bias: 193093522272.044037, T: 5760, Avg. loss: 5287172043681043578880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2126763825.20, NNZs: 2, Bias: 193010618213.443054, T: 5888, Avg. loss: 4306060741214567661568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2714128518.82, NNZs: 2, Bias: 192935972061.767090, T: 6016, Avg. loss: 3888908614459654144000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2832961154.59, NNZs: 2, Bias: 192867076598.169037, T: 6144, Avg. loss: 4003558698609995153408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2938797286.49, NNZs: 2, Bias: 192799993617.879639, T: 6272, Avg. loss: 4022926238594401566720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2896866494.71, NNZs: 2, Bias: 192733685228.666077, T: 6400, Avg. loss: 4230067959237871927296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2873221014.91, NNZs: 2, Bias: 192672077420.577667, T: 6528, Avg. loss: 3913234141494019358720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3027220306.29, NNZs: 2, Bias: 192602151394.803375, T: 6656, Avg. loss: 3932115585924487708672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2984863788.40, NNZs: 2, Bias: 192589661768.511566, T: 6784, Avg. loss: 3200720400341868216320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2985267141.52, NNZs: 2, Bias: 192576560980.493378, T: 6912, Avg. loss: 3183735039732874739712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2990859856.26, NNZs: 2, Bias: 192563560177.053131, T: 7040, Avg. loss: 3138519821964236816384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3016085461.69, NNZs: 2, Bias: 192550254471.193329, T: 7168, Avg. loss: 3138079339162138312704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2952117791.79, NNZs: 2, Bias: 192538412130.357056, T: 7296, Avg. loss: 3127957698142685626368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3013535695.83, NNZs: 2, Bias: 192524642228.470642, T: 7424, Avg. loss: 3107865371200908689408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3011547358.36, NNZs: 2, Bias: 192511760166.035675, T: 7552, Avg. loss: 3140027298061951696896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3011195436.89, NNZs: 2, Bias: 192498789211.757904, T: 7680, Avg. loss: 3161093451026884722688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2965256299.08, NNZs: 2, Bias: 192486389776.520477, T: 7808, Avg. loss: 3191644687332612767744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2960658077.51, NNZs: 2, Bias: 192473431315.545044, T: 7936, Avg. loss: 3169077403675453292544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2977934733.28, NNZs: 2, Bias: 192460020335.336273, T: 8064, Avg. loss: 3195587226167799185408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2970287345.31, NNZs: 2, Bias: 192457556772.070038, T: 8192, Avg. loss: 3052620751579002175488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2985757306.77, NNZs: 2, Bias: 192454733859.173035, T: 8320, Avg. loss: 3052882945076840890368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2990687663.00, NNZs: 2, Bias: 192452069983.367767, T: 8448, Avg. loss: 3058444353098471702528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2984744741.97, NNZs: 2, Bias: 192449569921.585754, T: 8576, Avg. loss: 3065146457107138084864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2976334760.92, NNZs: 2, Bias: 192447119639.526489, T: 8704, Avg. loss: 3050912921446681935872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2975527445.45, NNZs: 2, Bias: 192444546582.538116, T: 8832, Avg. loss: 3056528797932524142592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2991917882.13, NNZs: 2, Bias: 192441710463.755188, T: 8960, Avg. loss: 3051058895819522965504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2988015486.04, NNZs: 2, Bias: 192439180370.423859, T: 9088, Avg. loss: 3062803270357821161472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2987011922.21, NNZs: 2, Bias: 192436624741.456299, T: 9216, Avg. loss: 3039762483641864159232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2995848307.19, NNZs: 2, Bias: 192433905288.516205, T: 9344, Avg. loss: 3051231687692414615552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2991663515.33, NNZs: 2, Bias: 192431378497.155884, T: 9472, Avg. loss: 3064169592410921762816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2986201079.11, NNZs: 2, Bias: 192428874521.428009, T: 9600, Avg. loss: 3060756351326792712192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2992084123.06, NNZs: 2, Bias: 192426195635.943481, T: 9728, Avg. loss: 3057954575628672434176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 3001074866.53, NNZs: 2, Bias: 192423472735.952332, T: 9856, Avg. loss: 3052553417020481208320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 77 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 414102064987.50, NNZs: 2, Bias: 15112395198.558311, T: 128, Avg. loss: 24769943659940073794523103232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 419233767557.45, NNZs: 2, Bias: -5706666042.298077, T: 256, Avg. loss: 24606608806529058836270022656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1541191016797.12, NNZs: 2, Bias: -24059906871.923798, T: 384, Avg. loss: 23098371505071399436199919616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 825925038552.98, NNZs: 2, Bias: -43335071189.300659, T: 512, Avg. loss: 22377086626411521955833315328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 643551679123.33, NNZs: 2, Bias: -54017101854.674469, T: 640, Avg. loss: 23082622475978178660310974464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1281336011441.90, NNZs: 2, Bias: -34017101854.674469, T: 768, Avg. loss: 23420777218550870846541398016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2284247475460.92, NNZs: 2, Bias: 11291832602.441971, T: 896, Avg. loss: 24208504824522590619716026368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 760728748173.82, NNZs: 2, Bias: 31291832602.441971, T: 1024, Avg. loss: 23838571690004332184925634560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1340179314936.68, NNZs: 2, Bias: 151291832602.441956, T: 1152, Avg. loss: 22897730478350551191518183424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 345520887687.94, NNZs: 2, Bias: 162793011087.240417, T: 1280, Avg. loss: 1144965089261580839142031360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 358178348569.60, NNZs: 2, Bias: 153525055184.295441, T: 1408, Avg. loss: 963239530100076105126903808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 253071346265.48, NNZs: 2, Bias: 133063172069.358276, T: 1536, Avg. loss: 906754965853090613028716544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 179202778464.91, NNZs: 2, Bias: 145377905102.755585, T: 1664, Avg. loss: 874833080859365483363696640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 210184123116.07, NNZs: 2, Bias: 156249930099.498047, T: 1792, Avg. loss: 892218536239128922587922432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 510181116116.97, NNZs: 2, Bias: 144595111968.904449, T: 1920, Avg. loss: 906483973526524361403531264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 399295785695.73, NNZs: 2, Bias: 156977745061.429108, T: 2048, Avg. loss: 894570657265397803773853696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 178577690574.29, NNZs: 2, Bias: 153558321240.406891, T: 2176, Avg. loss: 905713871451454776847368192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 246062257649.34, NNZs: 2, Bias: 154970465698.518097, T: 2304, Avg. loss: 939358093245579947822546944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 72120937346.94, NNZs: 2, Bias: 154816559483.157654, T: 2432, Avg. loss: 46153718329368464284712960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43355070783.23, NNZs: 2, Bias: 155227044657.061859, T: 2560, Avg. loss: 36429611794432845571686400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 44645955093.89, NNZs: 2, Bias: 156267067309.806702, T: 2688, Avg. loss: 36781553073653490452004864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 32633187806.86, NNZs: 2, Bias: 151355450744.629852, T: 2816, Avg. loss: 34831207411877891585081344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 61456829901.28, NNZs: 2, Bias: 148126359461.410339, T: 2944, Avg. loss: 35233876891135691242602496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 85283001306.98, NNZs: 2, Bias: 147091188518.350311, T: 3072, Avg. loss: 36396834038721117278961664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 6549074242.37, NNZs: 2, Bias: 145434506397.918884, T: 3200, Avg. loss: 33980292446068161174831104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 50342944776.60, NNZs: 2, Bias: 144000755274.702332, T: 3328, Avg. loss: 35404025454432099877519360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 21670788485.22, NNZs: 2, Bias: 143477040941.942169, T: 3456, Avg. loss: 33640766528667412020068352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 60542768634.41, NNZs: 2, Bias: 143565582219.959167, T: 3584, Avg. loss: 34913428281753594631290880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 18086855787.17, NNZs: 2, Bias: 144986920759.540619, T: 3712, Avg. loss: 35779439305671617711964160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 17441019620.64, NNZs: 2, Bias: 148001715383.826599, T: 3840, Avg. loss: 36036886221118702058733568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 95475960947.57, NNZs: 2, Bias: 149672696623.185760, T: 3968, Avg. loss: 33208054420861350192349184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 37118243131.48, NNZs: 2, Bias: 146837816424.413544, T: 4096, Avg. loss: 34726277502525442134900736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 72633024872.95, NNZs: 2, Bias: 145527669940.060883, T: 4224, Avg. loss: 33479482290466583209836544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 73213717476.45, NNZs: 2, Bias: 145543713440.506958, T: 4352, Avg. loss: 32884535050607257351880704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 12889621997.39, NNZs: 2, Bias: 147129588928.106903, T: 4480, Avg. loss: 38916461949235812001382400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 99644998547.61, NNZs: 2, Bias: 145156605441.802704, T: 4608, Avg. loss: 36181727410243119609806848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 50685707655.20, NNZs: 2, Bias: 144013362646.503815, T: 4736, Avg. loss: 34776785271786838297673728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 25405861920.00, NNZs: 2, Bias: 144848325443.657776, T: 4864, Avg. loss: 33959243132422918640762880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 39859560302.52, NNZs: 2, Bias: 142350966703.047272, T: 4992, Avg. loss: 33036196802534609914953728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7652523651.92, NNZs: 2, Bias: 142352074765.826904, T: 5120, Avg. loss: 799388401222728349122560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 7739398534.76, NNZs: 2, Bias: 142225276019.001221, T: 5248, Avg. loss: 620329036061485964460032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3851775301.57, NNZs: 2, Bias: 142083399889.568939, T: 5376, Avg. loss: 674165888166118106857472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2923794943.99, NNZs: 2, Bias: 141832438923.844330, T: 5504, Avg. loss: 795206685359311654223872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 15615866912.08, NNZs: 2, Bias: 141608625530.320526, T: 5632, Avg. loss: 708860903832872028209152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 625501280.52, NNZs: 2, Bias: 141534500112.851562, T: 5760, Avg. loss: 781695730589285272780800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 14377261138.00, NNZs: 2, Bias: 141633013949.230133, T: 5888, Avg. loss: 715232617961429806350336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4299553746.22, NNZs: 2, Bias: 141692285995.100098, T: 6016, Avg. loss: 36720365765336584159232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3262804344.49, NNZs: 2, Bias: 141666394428.149872, T: 6144, Avg. loss: 2509708260887296475136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2653833094.27, NNZs: 2, Bias: 141635713354.153778, T: 6272, Avg. loss: 1994956344300072861696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2458887938.21, NNZs: 2, Bias: 141600985280.480560, T: 6400, Avg. loss: 1671201927438940241920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2301677799.16, NNZs: 2, Bias: 141561608356.464508, T: 6528, Avg. loss: 1910941208598533111808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2268612801.28, NNZs: 2, Bias: 141523224424.194092, T: 6656, Avg. loss: 1750706664843071455232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2146426590.62, NNZs: 2, Bias: 141483425362.159851, T: 6784, Avg. loss: 1777410560499741622272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2207364786.14, NNZs: 2, Bias: 141442911793.575104, T: 6912, Avg. loss: 1702864630199605526528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2210521430.80, NNZs: 2, Bias: 141402662958.715759, T: 7040, Avg. loss: 1731059628504588222464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2159042390.52, NNZs: 2, Bias: 141395276928.668427, T: 7168, Avg. loss: 1456998910824191361024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2132787495.77, NNZs: 2, Bias: 141387337252.693512, T: 7296, Avg. loss: 1489137539752853766144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2092553183.35, NNZs: 2, Bias: 141379831406.050659, T: 7424, Avg. loss: 1447656596119391567872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2116717064.53, NNZs: 2, Bias: 141371209708.593018, T: 7552, Avg. loss: 1470288786719985106944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2091961626.58, NNZs: 2, Bias: 141363326001.091339, T: 7680, Avg. loss: 1471765929041661263872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2100517697.14, NNZs: 2, Bias: 141354938345.763092, T: 7808, Avg. loss: 1472088238732579700736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2113585948.48, NNZs: 2, Bias: 141346435434.211761, T: 7936, Avg. loss: 1480991883034370768896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2116938707.40, NNZs: 2, Bias: 141338256771.491272, T: 8064, Avg. loss: 1448390895155973980160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2107698813.29, NNZs: 2, Bias: 141336747995.309387, T: 8192, Avg. loss: 1429694589577949347840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2102319969.63, NNZs: 2, Bias: 141335183998.095917, T: 8320, Avg. loss: 1427103907855092940800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2105054697.10, NNZs: 2, Bias: 141333500712.232025, T: 8448, Avg. loss: 1425464864494887895040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2102700374.44, NNZs: 2, Bias: 141331893444.020416, T: 8576, Avg. loss: 1425406462467049521152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2092293623.48, NNZs: 2, Bias: 141330421599.866211, T: 8704, Avg. loss: 1411833423657582460928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2108849930.41, NNZs: 2, Bias: 141328543042.528473, T: 8832, Avg. loss: 1415702394859491950592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2099613047.68, NNZs: 2, Bias: 141327040348.035553, T: 8960, Avg. loss: 1423871406357987721216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2104936283.01, NNZs: 2, Bias: 141325321857.424011, T: 9088, Avg. loss: 1422457574925453754368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2102996892.62, NNZs: 2, Bias: 141323706780.510254, T: 9216, Avg. loss: 1426738043265410924544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2105521923.28, NNZs: 2, Bias: 141322030357.090057, T: 9344, Avg. loss: 1422084895279885844480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 73 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1850325540694.02, NNZs: 2, Bias: -66306106021.392090, T: 128, Avg. loss: 19987227175008417909202485248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 884393831532.03, NNZs: 2, Bias: -46306106021.392090, T: 256, Avg. loss: 20885102458579446476637732864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 489212232401.85, NNZs: 2, Bias: -10637462196.356262, T: 384, Avg. loss: 21000573257867893742231355392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2208355202906.34, NNZs: 2, Bias: -70702514310.392944, T: 512, Avg. loss: 21366602602311994669185105920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 991904635731.38, NNZs: 2, Bias: 9297485689.607056, T: 640, Avg. loss: 22843697674275479928451366912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 842664524372.44, NNZs: 2, Bias: 69297485689.607056, T: 768, Avg. loss: 21289859512809768862309416960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 115841837914.66, NNZs: 2, Bias: 47926642636.092590, T: 896, Avg. loss: 949596780234802966623682560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 431110405795.56, NNZs: 2, Bias: 35411332932.320244, T: 1024, Avg. loss: 866158965829805067535908864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 126380884974.51, NNZs: 2, Bias: 59269372352.980980, T: 1152, Avg. loss: 847496594807475079875657728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 300570837691.18, NNZs: 2, Bias: 68671245946.887527, T: 1280, Avg. loss: 943685938406082852463575040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 289244404270.81, NNZs: 2, Bias: 67810952440.677246, T: 1408, Avg. loss: 893546518139329477236228096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 147202868705.53, NNZs: 2, Bias: 54504941448.398796, T: 1536, Avg. loss: 843583874427698372488986624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 272037831722.30, NNZs: 2, Bias: 59911880758.080643, T: 1664, Avg. loss: 864211789674741248680787968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 315181541282.89, NNZs: 2, Bias: 66228281757.546257, T: 1792, Avg. loss: 857982842884421003446845440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 153330256577.87, NNZs: 2, Bias: 76135501768.631042, T: 1920, Avg. loss: 929444297541952646143803392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 291657001536.56, NNZs: 2, Bias: 83945734526.724060, T: 2048, Avg. loss: 784270463014030620474998784.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 384367570050.54, NNZs: 2, Bias: 77916597930.219345, T: 2176, Avg. loss: 843553685945493937446715392.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 337939165235.08, NNZs: 2, Bias: 70902724229.788345, T: 2304, Avg. loss: 919434255249655161224691712.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 238423236512.27, NNZs: 2, Bias: 87693678972.286667, T: 2432, Avg. loss: 876099030369457941698838528.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 308921310354.42, NNZs: 2, Bias: 104313761983.861084, T: 2560, Avg. loss: 854612764595261409622753280.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 182790899598.93, NNZs: 2, Bias: 107685430529.001755, T: 2688, Avg. loss: 859822086197475525473075200.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 58642247165.70, NNZs: 2, Bias: 114509990915.443970, T: 2816, Avg. loss: 32165090539860881563451392.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 68053451849.08, NNZs: 2, Bias: 117261783494.892685, T: 2944, Avg. loss: 35729658845596072290549760.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 107808418281.08, NNZs: 2, Bias: 115512419734.211945, T: 3072, Avg. loss: 31983119101149129163669504.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 61334537841.70, NNZs: 2, Bias: 115907710579.515381, T: 3200, Avg. loss: 34075655622763072913932288.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 34585754356.82, NNZs: 2, Bias: 120113351078.466095, T: 3328, Avg. loss: 33347190021602488275173376.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 31260848907.05, NNZs: 2, Bias: 119895239887.844574, T: 3456, Avg. loss: 29016528311525843274825728.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 82196758240.30, NNZs: 2, Bias: 119426389994.186951, T: 3584, Avg. loss: 27899596535326594304049152.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 86734497838.77, NNZs: 2, Bias: 117855901761.374359, T: 3712, Avg. loss: 27784764958251346011619328.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 32559066605.54, NNZs: 2, Bias: 117574798194.525711, T: 3840, Avg. loss: 29145136292525634385608704.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 37636080250.48, NNZs: 2, Bias: 116528678053.563263, T: 3968, Avg. loss: 30110227683182894437629952.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 98392087229.36, NNZs: 2, Bias: 116117966602.099472, T: 4096, Avg. loss: 29801643340278472401485824.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4060684340.01, NNZs: 2, Bias: 117275204165.626129, T: 4224, Avg. loss: 30512971840393334419881984.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 13484324636.11, NNZs: 2, Bias: 115865486433.199448, T: 4352, Avg. loss: 31562327632492453081120768.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2104662202.20, NNZs: 2, Bias: 115471893937.332169, T: 4480, Avg. loss: 713612874646723485499392.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3740226029.34, NNZs: 2, Bias: 115481915405.956070, T: 4608, Avg. loss: 488360053706363362082816.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 11607160033.41, NNZs: 2, Bias: 115499772358.458084, T: 4736, Avg. loss: 500402560674446738194432.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3462126738.58, NNZs: 2, Bias: 115384046187.214310, T: 4864, Avg. loss: 706905167394442896736256.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 10774764491.42, NNZs: 2, Bias: 115099198509.217468, T: 4992, Avg. loss: 602927238912374401400832.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 10245560659.36, NNZs: 2, Bias: 114806097303.609573, T: 5120, Avg. loss: 632203740182554815234048.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1788150305.49, NNZs: 2, Bias: 114498817568.025711, T: 5248, Avg. loss: 600512921283049130295296.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1816651096.14, NNZs: 2, Bias: 114455255919.261246, T: 5376, Avg. loss: 1532391923423460196352.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1791096518.28, NNZs: 2, Bias: 114413289764.561218, T: 5504, Avg. loss: 1478363198421672656896.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1856260666.10, NNZs: 2, Bias: 114371166773.373779, T: 5632, Avg. loss: 1430649007620929617920.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1826629514.08, NNZs: 2, Bias: 114328368789.708374, T: 5760, Avg. loss: 1549006223289347997696.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1643928535.63, NNZs: 2, Bias: 114290943248.718796, T: 5888, Avg. loss: 1439038443007348047872.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1772005949.47, NNZs: 2, Bias: 114247927945.113617, T: 6016, Avg. loss: 1396895267922874204160.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1825719973.21, NNZs: 2, Bias: 114209493254.705887, T: 6144, Avg. loss: 1269723109170504269824.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1851022788.95, NNZs: 2, Bias: 114170095097.694107, T: 6272, Avg. loss: 1379188070698149216256.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1907182402.47, NNZs: 2, Bias: 114129665783.187790, T: 6400, Avg. loss: 1371530678766890385408.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1880856979.95, NNZs: 2, Bias: 114092065983.737305, T: 6528, Avg. loss: 1310464270094977466368.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1827634679.88, NNZs: 2, Bias: 114052743227.877029, T: 6656, Avg. loss: 1367735054469313331200.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1808373929.30, NNZs: 2, Bias: 114010827467.046387, T: 6784, Avg. loss: 1480512628146913411072.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1839013503.20, NNZs: 2, Bias: 114002276306.961014, T: 6912, Avg. loss: 1157927847166851547136.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1836265894.99, NNZs: 2, Bias: 113994301702.451111, T: 7040, Avg. loss: 1151901445903455223808.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1831989508.87, NNZs: 2, Bias: 113986307397.354675, T: 7168, Avg. loss: 1158395716825725665280.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1813926902.43, NNZs: 2, Bias: 113978486226.438049, T: 7296, Avg. loss: 1165808400745113321472.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1814902808.81, NNZs: 2, Bias: 113970543680.363525, T: 7424, Avg. loss: 1134009941859211542528.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1820656271.73, NNZs: 2, Bias: 113962566479.980545, T: 7552, Avg. loss: 1129480563687100645376.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1808254490.29, NNZs: 2, Bias: 113954715079.711578, T: 7680, Avg. loss: 1156401907022344224768.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1820750306.01, NNZs: 2, Bias: 113946446433.511688, T: 7808, Avg. loss: 1157459632043092344832.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1851401065.41, NNZs: 2, Bias: 113937945019.042160, T: 7936, Avg. loss: 1148122850252660932608.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1846345566.19, NNZs: 2, Bias: 113930037710.952011, T: 8064, Avg. loss: 1146720637035886936064.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1819356747.06, NNZs: 2, Bias: 113922474241.219421, T: 8192, Avg. loss: 1148550046560201998336.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1848717934.79, NNZs: 2, Bias: 113920410293.479477, T: 8320, Avg. loss: 1111755528938739990528.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1837887268.06, NNZs: 2, Bias: 113918987353.777863, T: 8448, Avg. loss: 1118283252514162475008.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1837085251.87, NNZs: 2, Bias: 113917400437.099197, T: 8576, Avg. loss: 1119026367403946409984.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1845298508.76, NNZs: 2, Bias: 113915674090.428680, T: 8704, Avg. loss: 1114040924378109837312.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1839700908.72, NNZs: 2, Bias: 113914164810.638077, T: 8832, Avg. loss: 1119347922117261656064.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1834567268.54, NNZs: 2, Bias: 113912651245.935226, T: 8960, Avg. loss: 1116681818799323873280.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 70 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2225232581648.96, NNZs: 2, Bias: 22440308865.763855, T: 128, Avg. loss: 17424233618669815440850550784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1213292792425.20, NNZs: 2, Bias: 41860412908.541306, T: 256, Avg. loss: 20452644535246295512687575040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1230978761926.55, NNZs: 2, Bias: 45724155623.229675, T: 384, Avg. loss: 21992765786478743094709714944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1929808761347.17, NNZs: 2, Bias: 25724155623.229675, T: 512, Avg. loss: 20621394946458048182387474432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1526583697284.37, NNZs: 2, Bias: 65724155623.229675, T: 640, Avg. loss: 18680928147847391497959768064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 214910036750.85, NNZs: 2, Bias: 61304246520.583313, T: 768, Avg. loss: 18820026236987753800151334912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 299630553806.66, NNZs: 2, Bias: 55956325418.903694, T: 896, Avg. loss: 781464897510433201275797504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 59153249538.45, NNZs: 2, Bias: 51304601973.315674, T: 1024, Avg. loss: 813565882761023866382843904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 145492424828.71, NNZs: 2, Bias: 58254385784.937416, T: 1152, Avg. loss: 790090536987969310282481664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 228804099031.94, NNZs: 2, Bias: 59317076972.216492, T: 1280, Avg. loss: 727621716961548441655181312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 110982529935.46, NNZs: 2, Bias: 60423917434.344299, T: 1408, Avg. loss: 873426469864179992291704832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 211053288088.92, NNZs: 2, Bias: 57639558316.905396, T: 1536, Avg. loss: 806618906787279038482219008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 77593890313.88, NNZs: 2, Bias: 45172949023.860153, T: 1664, Avg. loss: 877371731295824904133279744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 282892155611.00, NNZs: 2, Bias: 36312807971.197632, T: 1792, Avg. loss: 843539596032992913970429952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 300747358980.37, NNZs: 2, Bias: 46667113766.467972, T: 1920, Avg. loss: 828489864424182377902768128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 72577000508.27, NNZs: 2, Bias: 50335036681.546280, T: 2048, Avg. loss: 46665014629371487847448576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42961466736.51, NNZs: 2, Bias: 49960031670.410912, T: 2176, Avg. loss: 29974370495217386345463808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44317593214.51, NNZs: 2, Bias: 48683335733.294533, T: 2304, Avg. loss: 27113682915659719299301376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 51031746615.59, NNZs: 2, Bias: 49208657720.683510, T: 2432, Avg. loss: 30077990587052351423512576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 18354417545.89, NNZs: 2, Bias: 49980069586.101074, T: 2560, Avg. loss: 30993765046312384881229824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 72344684606.64, NNZs: 2, Bias: 52075485394.089630, T: 2688, Avg. loss: 29728741915367594273013760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 47123294520.07, NNZs: 2, Bias: 48774719446.840950, T: 2816, Avg. loss: 27124598274229148575596544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 56364079981.14, NNZs: 2, Bias: 50000382326.258018, T: 2944, Avg. loss: 26499310755994517052063744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 82104768740.25, NNZs: 2, Bias: 51202099950.324585, T: 3072, Avg. loss: 29037281972334806515580928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 32822131631.24, NNZs: 2, Bias: 50672180370.993683, T: 3200, Avg. loss: 30910761641914091849121792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 39617983535.61, NNZs: 2, Bias: 51506419050.368065, T: 3328, Avg. loss: 29067643706945578448453632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 22438819663.28, NNZs: 2, Bias: 51901113069.027725, T: 3456, Avg. loss: 29157276294023427018194944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 82082251118.06, NNZs: 2, Bias: 50853693867.811165, T: 3584, Avg. loss: 30254723029676443748532224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 13401013852.98, NNZs: 2, Bias: 51187059111.309074, T: 3712, Avg. loss: 3017652467845819915042816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 14125474680.57, NNZs: 2, Bias: 50860301014.553299, T: 3840, Avg. loss: 413915322089825412055040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2657675685.50, NNZs: 2, Bias: 50963113593.908310, T: 3968, Avg. loss: 645376383400848207642624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 10476120448.05, NNZs: 2, Bias: 50843354781.439636, T: 4096, Avg. loss: 354967922039236155408384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 720722248.63, NNZs: 2, Bias: 50760560068.403580, T: 4224, Avg. loss: 399642142018490131808256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4359230429.57, NNZs: 2, Bias: 50409492605.716896, T: 4352, Avg. loss: 446599981456070591643648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1347077726.97, NNZs: 2, Bias: 50613696709.480637, T: 4480, Avg. loss: 508121383309420101894144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11789953607.99, NNZs: 2, Bias: 50526432769.787918, T: 4608, Avg. loss: 482171524944705917812736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8383480947.18, NNZs: 2, Bias: 50532466462.255463, T: 4736, Avg. loss: 445360124098902679879680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2138468882.02, NNZs: 2, Bias: 50583399015.112099, T: 4864, Avg. loss: 10831037322211478208512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1471037901.20, NNZs: 2, Bias: 50575042371.946648, T: 4992, Avg. loss: 548752134050269495296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1183530433.80, NNZs: 2, Bias: 50562544237.857574, T: 5120, Avg. loss: 330923016316756426752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 960852028.51, NNZs: 2, Bias: 50548359911.858025, T: 5248, Avg. loss: 308103674408844984320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 891521539.63, NNZs: 2, Bias: 50532398950.163933, T: 5376, Avg. loss: 267042626283695702016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 882279185.14, NNZs: 2, Bias: 50515589905.122902, T: 5504, Avg. loss: 265137664230288392192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 841312287.41, NNZs: 2, Bias: 50499002130.930794, T: 5632, Avg. loss: 270561530230617997312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 818802643.20, NNZs: 2, Bias: 50481615560.821800, T: 5760, Avg. loss: 283242246960581115904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 792202672.88, NNZs: 2, Bias: 50464171239.005310, T: 5888, Avg. loss: 276944111064864817152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 765259440.40, NNZs: 2, Bias: 50446724561.017372, T: 6016, Avg. loss: 274877608128032014336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 785800450.07, NNZs: 2, Bias: 50429371031.114639, T: 6144, Avg. loss: 263883476511538315264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 823573170.52, NNZs: 2, Bias: 50412191200.265732, T: 6272, Avg. loss: 254624275331732897792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 813107520.33, NNZs: 2, Bias: 50395803687.802536, T: 6400, Avg. loss: 256936107745888993280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 814781708.97, NNZs: 2, Bias: 50379979013.676170, T: 6528, Avg. loss: 236013756453115559936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 814224471.33, NNZs: 2, Bias: 50363799884.825691, T: 6656, Avg. loss: 248222648020364230656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 791685223.00, NNZs: 2, Bias: 50347743980.298706, T: 6784, Avg. loss: 252203788718530789376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 819256878.98, NNZs: 2, Bias: 50330893192.023216, T: 6912, Avg. loss: 257834518478438137856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 818509100.58, NNZs: 2, Bias: 50313857974.386612, T: 7040, Avg. loss: 265528039406766456832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 811376793.50, NNZs: 2, Bias: 50298353225.954018, T: 7168, Avg. loss: 245358131020421496832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 801350134.98, NNZs: 2, Bias: 50295152448.505081, T: 7296, Avg. loss: 213876344864060637184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 808322110.49, NNZs: 2, Bias: 50291649339.218254, T: 7424, Avg. loss: 215747067836399681536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 808574686.73, NNZs: 2, Bias: 50288277153.666603, T: 7552, Avg. loss: 214096707890749243392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 802844131.58, NNZs: 2, Bias: 50284952504.087799, T: 7680, Avg. loss: 217145288374926114816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 799414520.92, NNZs: 2, Bias: 50281619322.029968, T: 7808, Avg. loss: 215347622013127032832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 797927881.91, NNZs: 2, Bias: 50278263578.248505, T: 7936, Avg. loss: 214951173440617381888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 801002304.52, NNZs: 2, Bias: 50277534528.356819, T: 8064, Avg. loss: 210024903482238304256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 800965589.51, NNZs: 2, Bias: 50276858059.227089, T: 8192, Avg. loss: 209136582333730848768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 805784359.57, NNZs: 2, Bias: 50276105834.908607, T: 8320, Avg. loss: 208459596606741381120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 804933430.54, NNZs: 2, Bias: 50275441506.236923, T: 8448, Avg. loss: 209418554998953836544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 804616746.55, NNZs: 2, Bias: 50274768752.376442, T: 8576, Avg. loss: 209383675410400444416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 805068438.56, NNZs: 2, Bias: 50274084051.262558, T: 8704, Avg. loss: 209247372230961528832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 807810688.26, NNZs: 2, Bias: 50273366136.863754, T: 8832, Avg. loss: 208088140953770131456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 803827065.30, NNZs: 2, Bias: 50272754517.740852, T: 8960, Avg. loss: 208683358536055357440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 802106427.38, NNZs: 2, Bias: 50272107454.880508, T: 9088, Avg. loss: 208353684935689895936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 802240449.49, NNZs: 2, Bias: 50271428159.168320, T: 9216, Avg. loss: 209140705905101733888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 805336950.13, NNZs: 2, Bias: 50270700772.692177, T: 9344, Avg. loss: 209292764925374922752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 804568502.24, NNZs: 2, Bias: 50270035632.810104, T: 9472, Avg. loss: 209240812193960329216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 74 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1388610432938.88, NNZs: 2, Bias: 340566673.417770, T: 128, Avg. loss: 19310933213529683246358462464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 958758654125.56, NNZs: 2, Bias: -19659433326.582230, T: 256, Avg. loss: 20926226607328669353277128704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1433939671078.38, NNZs: 2, Bias: -61817779361.915695, T: 384, Avg. loss: 21505478733644448376928862208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 955243699644.39, NNZs: 2, Bias: -64460158598.661285, T: 512, Avg. loss: 21397990918447350672890265600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 567010203619.38, NNZs: 2, Bias: -44460158598.661285, T: 640, Avg. loss: 21105412913716345430507257856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1582764477581.10, NNZs: 2, Bias: -67223606671.578232, T: 768, Avg. loss: 21854938682469663728604282880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 240099316301.28, NNZs: 2, Bias: -54367597380.011787, T: 896, Avg. loss: 1298121634888116167426179072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 186319744772.83, NNZs: 2, Bias: -57285835013.758698, T: 1024, Avg. loss: 870207518138063936213221376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 149883328154.43, NNZs: 2, Bias: -55091049651.438965, T: 1152, Avg. loss: 832485852026242236791390208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 89773190125.42, NNZs: 2, Bias: -59012374102.140877, T: 1280, Avg. loss: 819196815692728014850752512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 370410716434.37, NNZs: 2, Bias: -68109866938.947914, T: 1408, Avg. loss: 859710528872840107730665472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 206806275866.92, NNZs: 2, Bias: -75188443355.020538, T: 1536, Avg. loss: 785246176022173912410357760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 182054488352.22, NNZs: 2, Bias: -78109185010.774414, T: 1664, Avg. loss: 863467167841427828684881920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 537663420830.01, NNZs: 2, Bias: -85464662087.063782, T: 1792, Avg. loss: 827300877570341847955406848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 153475695857.65, NNZs: 2, Bias: -82602729302.777374, T: 1920, Avg. loss: 873075105836311350733701120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 277960685605.01, NNZs: 2, Bias: -73623832557.233765, T: 2048, Avg. loss: 802609420374111547436302336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 284140168574.12, NNZs: 2, Bias: -68755727308.089203, T: 2176, Avg. loss: 802579299051060987542110208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 44799629403.69, NNZs: 2, Bias: -73096838837.641556, T: 2304, Avg. loss: 47421277579119509742026752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 14181009235.60, NNZs: 2, Bias: -71339420074.140579, T: 2432, Avg. loss: 29585964229107852219777024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 7286880309.41, NNZs: 2, Bias: -71852256514.624191, T: 2560, Avg. loss: 31043898041786303479021568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 91129568155.85, NNZs: 2, Bias: -69895530503.494461, T: 2688, Avg. loss: 29548863599547558366543872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 44457700383.62, NNZs: 2, Bias: -71633997354.456238, T: 2816, Avg. loss: 31167684570846074826129408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 5702266658.92, NNZs: 2, Bias: -72005672656.063843, T: 2944, Avg. loss: 32811297628586942465572864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 73572148058.16, NNZs: 2, Bias: -70288337907.143906, T: 3072, Avg. loss: 32180131416888959123324928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 50323085893.24, NNZs: 2, Bias: -67943502168.897522, T: 3200, Avg. loss: 30431292884443774930911232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 38583621539.61, NNZs: 2, Bias: -68341724177.334145, T: 3328, Avg. loss: 32174291477495382647242752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 9236008690.93, NNZs: 2, Bias: -68826908156.338699, T: 3456, Avg. loss: 739991248238665086795776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4431698071.78, NNZs: 2, Bias: -68958621882.619278, T: 3584, Avg. loss: 599936239613828482990080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2096861470.77, NNZs: 2, Bias: -68780813179.535263, T: 3712, Avg. loss: 519114193642361976782848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4899365446.64, NNZs: 2, Bias: -68756572273.046234, T: 3840, Avg. loss: 284030390811171991060480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 12468966666.97, NNZs: 2, Bias: -68619863971.882050, T: 3968, Avg. loss: 571209042098585604194304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 10771698924.14, NNZs: 2, Bias: -68387034758.281807, T: 4096, Avg. loss: 595607068106737441570816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1741518419.23, NNZs: 2, Bias: -68523244994.955040, T: 4224, Avg. loss: 427970770920337892704256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1869688938.19, NNZs: 2, Bias: -68338145505.226234, T: 4352, Avg. loss: 400310073476473912557568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4445456105.64, NNZs: 2, Bias: -68239286243.982628, T: 4480, Avg. loss: 328316593125772006260736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 575155164.21, NNZs: 2, Bias: -68172739593.109344, T: 4608, Avg. loss: 5112964491747141877760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 496445501.61, NNZs: 2, Bias: -68137742025.625336, T: 4736, Avg. loss: 679480834801558880256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 697755564.66, NNZs: 2, Bias: -68110069130.724968, T: 4864, Avg. loss: 521185665313133690880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 952255787.24, NNZs: 2, Bias: -68083330862.713242, T: 4992, Avg. loss: 470926269153948008448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1065048506.22, NNZs: 2, Bias: -68059591416.262314, T: 5120, Avg. loss: 467471335575553179648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1069933342.15, NNZs: 2, Bias: -68038477596.599014, T: 5248, Avg. loss: 431743300938446012416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1112167538.98, NNZs: 2, Bias: -68017193442.266441, T: 5376, Avg. loss: 427018537772401229824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1133385143.65, NNZs: 2, Bias: -67995847572.412560, T: 5504, Avg. loss: 425657068083205898240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1170967963.88, NNZs: 2, Bias: -67974383570.090538, T: 5632, Avg. loss: 433999742914700574720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1212444254.96, NNZs: 2, Bias: -67953300006.825165, T: 5760, Avg. loss: 416178278633896869888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1173483006.96, NNZs: 2, Bias: -67932671897.442078, T: 5888, Avg. loss: 463170055144864350208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1132475562.10, NNZs: 2, Bias: -67911932507.508392, T: 6016, Avg. loss: 465963840583762444288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1133690867.81, NNZs: 2, Bias: -67890323200.846565, T: 6144, Avg. loss: 456784913059314728960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1130672123.68, NNZs: 2, Bias: -67868687171.717834, T: 6272, Avg. loss: 458157563260595929088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1098115067.97, NNZs: 2, Bias: -67847537299.098244, T: 6400, Avg. loss: 434154834900798472192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1135565693.68, NNZs: 2, Bias: -67842514739.268074, T: 6528, Avg. loss: 376553236673384022016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1131226435.35, NNZs: 2, Bias: -67838317384.103943, T: 6656, Avg. loss: 365612130988368527360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1145423398.41, NNZs: 2, Bias: -67833815994.749199, T: 6784, Avg. loss: 364468290246007390208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1147946493.27, NNZs: 2, Bias: -67829480172.903282, T: 6912, Avg. loss: 368343752521231826944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1151673623.06, NNZs: 2, Bias: -67825186309.527512, T: 7040, Avg. loss: 361473520551345913856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1159729488.10, NNZs: 2, Bias: -67820786901.162895, T: 7168, Avg. loss: 364041471867798683648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1166077588.77, NNZs: 2, Bias: -67816430969.898102, T: 7296, Avg. loss: 363363467853603405824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1147896783.92, NNZs: 2, Bias: -67812500096.407402, T: 7424, Avg. loss: 363018414293670952960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1167076865.26, NNZs: 2, Bias: -67807979769.075020, T: 7552, Avg. loss: 357987314760308686848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1156433925.62, NNZs: 2, Bias: -67803860982.472961, T: 7680, Avg. loss: 367911995352977899520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1172899500.87, NNZs: 2, Bias: -67799333920.098999, T: 7808, Avg. loss: 362337100076451561472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1167596335.56, NNZs: 2, Bias: -67795115219.839218, T: 7936, Avg. loss: 368799655791824076800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1155497575.67, NNZs: 2, Bias: -67791082979.206665, T: 8064, Avg. loss: 362276277500847915008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1170808647.78, NNZs: 2, Bias: -67786515861.150612, T: 8192, Avg. loss: 367803478040339218432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1172473857.30, NNZs: 2, Bias: -67785640504.788818, T: 8320, Avg. loss: 352398739785062809600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1167574919.59, NNZs: 2, Bias: -67784878647.323524, T: 8448, Avg. loss: 352483800893318299648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1168036739.09, NNZs: 2, Bias: -67784021862.927742, T: 8576, Avg. loss: 353386607591166836736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1172906006.74, NNZs: 2, Bias: -67783092961.060921, T: 8704, Avg. loss: 351578508423604535296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1170413188.46, NNZs: 2, Bias: -67782285327.331993, T: 8832, Avg. loss: 354234224644590993408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1171195868.43, NNZs: 2, Bias: -67781423725.919609, T: 8960, Avg. loss: 353036576458368811008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1174046360.81, NNZs: 2, Bias: -67780530622.310509, T: 9088, Avg. loss: 351136621381057052672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1169844130.75, NNZs: 2, Bias: -67779754554.139679, T: 9216, Avg. loss: 353437574245129125888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1170828585.30, NNZs: 2, Bias: -67778889462.054825, T: 9344, Avg. loss: 353027843341125353472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1170395122.87, NNZs: 2, Bias: -67778049599.426323, T: 9472, Avg. loss: 352725578221481623552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1171081938.28, NNZs: 2, Bias: -67777189634.876923, T: 9600, Avg. loss: 353022178854536347648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1173158107.33, NNZs: 2, Bias: -67776308948.024887, T: 9728, Avg. loss: 351642960836880171008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 76 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2335052285492.55, NNZs: 2, Bias: -49842459103.212662, T: 128, Avg. loss: 21521484500078375836560916480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1784795087148.12, NNZs: 2, Bias: 6042206742.329880, T: 256, Avg. loss: 23570420899174716695226875904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2280661787229.95, NNZs: 2, Bias: 46042206742.329880, T: 384, Avg. loss: 22952968315076151988826669056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 903473217792.03, NNZs: 2, Bias: -11711045907.170753, T: 512, Avg. loss: 22791771023415548832217300992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 312485907794.00, NNZs: 2, Bias: -60726074133.867386, T: 640, Avg. loss: 20323853885992274108100902912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 950254477209.49, NNZs: 2, Bias: -18464565254.345467, T: 768, Avg. loss: 22108871480519256949768847360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2598248139223.81, NNZs: 2, Bias: -38464565254.345467, T: 896, Avg. loss: 20644084345188214860972818432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2146030775775.02, NNZs: 2, Bias: -98450647013.127869, T: 1024, Avg. loss: 22619573777128789118755536896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1799473804508.86, NNZs: 2, Bias: -78450647013.127869, T: 1152, Avg. loss: 22384757296839640395439669248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1305040729959.41, NNZs: 2, Bias: -98450647013.127869, T: 1280, Avg. loss: 22907636561662901692481404928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 475265631320.62, NNZs: 2, Bias: -122450647013.127869, T: 1408, Avg. loss: 1016117959656804378598178816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 150264018571.42, NNZs: 2, Bias: -136221708316.077438, T: 1536, Avg. loss: 1036233804598174488257888256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 302903070968.22, NNZs: 2, Bias: -130752234996.042587, T: 1664, Avg. loss: 921596737292577126049906688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 346179764122.12, NNZs: 2, Bias: -130505388169.545486, T: 1792, Avg. loss: 834859842970166191949086720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 316013801789.07, NNZs: 2, Bias: -121994242653.722137, T: 1920, Avg. loss: 1044353878727498239437701120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 224193131153.29, NNZs: 2, Bias: -95892288881.580978, T: 2048, Avg. loss: 905372316961279134922702848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 37724097399.67, NNZs: 2, Bias: -93528606163.466278, T: 2176, Avg. loss: 864157537546575119873212416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 153407838699.35, NNZs: 2, Bias: -100654812887.787750, T: 2304, Avg. loss: 929894282376478574860304384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 161813720240.18, NNZs: 2, Bias: -117597624737.852951, T: 2432, Avg. loss: 964795593979283933835034624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 35878191506.37, NNZs: 2, Bias: -115299659560.939438, T: 2560, Avg. loss: 41050350751777575890059264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 47813896797.78, NNZs: 2, Bias: -114944786991.030334, T: 2688, Avg. loss: 36545322110213022061428736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 44398121139.69, NNZs: 2, Bias: -114790207944.616547, T: 2816, Avg. loss: 30629168856069910550282240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 35317612944.91, NNZs: 2, Bias: -118440536909.692657, T: 2944, Avg. loss: 32744031706835625321693184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 23508919051.18, NNZs: 2, Bias: -119075661657.301453, T: 3072, Avg. loss: 30957186223160162523283456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 35626759134.62, NNZs: 2, Bias: -116601144176.616837, T: 3200, Avg. loss: 34139019578822345720070144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 37355655272.59, NNZs: 2, Bias: -119792022498.342667, T: 3328, Avg. loss: 34456188514484739891003392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 14513881220.40, NNZs: 2, Bias: -118700794257.474014, T: 3456, Avg. loss: 33255224866883035052638208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 7635757587.38, NNZs: 2, Bias: -118118776960.117294, T: 3584, Avg. loss: 683655247576228226400256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4735478207.55, NNZs: 2, Bias: -117916387838.469528, T: 3712, Avg. loss: 592510464613633335754752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 6109826282.96, NNZs: 2, Bias: -117572813308.947998, T: 3840, Avg. loss: 655989590036668380872704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 9972141671.73, NNZs: 2, Bias: -117501147995.720917, T: 3968, Avg. loss: 574716950410127919284224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 15692532363.31, NNZs: 2, Bias: -117329474509.479324, T: 4096, Avg. loss: 569486410958312977727488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 19464244572.94, NNZs: 2, Bias: -117186716369.733948, T: 4224, Avg. loss: 722014637565228288573440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4083028053.40, NNZs: 2, Bias: -116734412913.801178, T: 4352, Avg. loss: 679666754579122700156928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2215033400.51, NNZs: 2, Bias: -116417148699.277084, T: 4480, Avg. loss: 622164806372940637536256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4426834155.92, NNZs: 2, Bias: -116072802665.153168, T: 4608, Avg. loss: 647442657492485068029952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6502859671.66, NNZs: 2, Bias: -115790467435.692719, T: 4736, Avg. loss: 593428085509032985493504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3967897540.06, NNZs: 2, Bias: -115778120240.580429, T: 4864, Avg. loss: 5489269015743203115008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2827591888.42, NNZs: 2, Bias: -115754806750.752045, T: 4992, Avg. loss: 2246080855653379211264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2225612837.42, NNZs: 2, Bias: -115723202600.676071, T: 5120, Avg. loss: 1720152847744506527744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1999773240.89, NNZs: 2, Bias: -115685540416.002151, T: 5248, Avg. loss: 1550875671986654412800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1950377683.29, NNZs: 2, Bias: -115646173835.272278, T: 5376, Avg. loss: 1462888267790147649536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1715530311.10, NNZs: 2, Bias: -115609891638.676285, T: 5504, Avg. loss: 1459437553003589533696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1645672337.65, NNZs: 2, Bias: -115569036102.409470, T: 5632, Avg. loss: 1516053727726656815104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1778991882.41, NNZs: 2, Bias: -115524379254.454086, T: 5760, Avg. loss: 1563905493287012401152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1874465891.28, NNZs: 2, Bias: -115484754198.946899, T: 5888, Avg. loss: 1365885371917272088576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1832619510.60, NNZs: 2, Bias: -115446587953.340576, T: 6016, Avg. loss: 1352220354103187341312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1751838415.79, NNZs: 2, Bias: -115409634434.914551, T: 6144, Avg. loss: 1385526832457711616000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1797121185.98, NNZs: 2, Bias: -115370556061.825470, T: 6272, Avg. loss: 1362153595759009202176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1764576931.04, NNZs: 2, Bias: -115331608985.541229, T: 6400, Avg. loss: 1384269417968120627200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1783863407.07, NNZs: 2, Bias: -115293655029.284378, T: 6528, Avg. loss: 1402384452478139629568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1787902950.88, NNZs: 2, Bias: -115253461620.211365, T: 6656, Avg. loss: 1461627371003042070528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1856700762.60, NNZs: 2, Bias: -115244812966.742081, T: 6784, Avg. loss: 1096844861027041280000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1836006610.29, NNZs: 2, Bias: -115237448916.502914, T: 6912, Avg. loss: 1123317647842288730112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1816863316.51, NNZs: 2, Bias: -115229938708.218445, T: 7040, Avg. loss: 1139459626088466350080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1828225752.46, NNZs: 2, Bias: -115221950263.012192, T: 7168, Avg. loss: 1136736547441921622016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1831307028.10, NNZs: 2, Bias: -115214069198.372711, T: 7296, Avg. loss: 1139492440034098020352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1827562227.43, NNZs: 2, Bias: -115206632993.791077, T: 7424, Avg. loss: 1092099128752426975232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1825151880.50, NNZs: 2, Bias: -115198854093.774536, T: 7552, Avg. loss: 1137559731500763316224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1841440757.30, NNZs: 2, Bias: -115190832681.345764, T: 7680, Avg. loss: 1128753905458033459200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1819190495.24, NNZs: 2, Bias: -115183383863.494919, T: 7808, Avg. loss: 1136118803231980781568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1839647609.55, NNZs: 2, Bias: -115175433509.959015, T: 7936, Avg. loss: 1109757492882042650624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1826598183.18, NNZs: 2, Bias: -115168013593.186859, T: 8064, Avg. loss: 1108780600449210253312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1817404112.36, NNZs: 2, Bias: -115166607319.864990, T: 8192, Avg. loss: 1098298691231500468224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1819128728.26, NNZs: 2, Bias: -115165031867.191940, T: 8320, Avg. loss: 1095310455143037140992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1815181228.85, NNZs: 2, Bias: -115163545464.502350, T: 8448, Avg. loss: 1095901468497673584640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1813184301.64, NNZs: 2, Bias: -115162028082.791214, T: 8576, Avg. loss: 1095911228311733141504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1813732058.45, NNZs: 2, Bias: -115160473224.133804, T: 8704, Avg. loss: 1093840850854432342016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 68 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 789474525583.36, NNZs: 2, Bias: -46559127506.659195, T: 128, Avg. loss: 21929855203644305410543845376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1825059205919.81, NNZs: 2, Bias: -48473577045.416878, T: 256, Avg. loss: 22981252034629555647946948608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1091461591826.44, NNZs: 2, Bias: -21067713373.250263, T: 384, Avg. loss: 26995187614996922565417500672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1485193291776.60, NNZs: 2, Bias: 38932286626.749741, T: 512, Avg. loss: 23678738002395115394693070848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 568631242342.97, NNZs: 2, Bias: 134880608668.233490, T: 640, Avg. loss: 23689580870940236517637881856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1824618745610.28, NNZs: 2, Bias: 41498760460.063217, T: 768, Avg. loss: 22779892876034933093505695744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 37490542949.67, NNZs: 2, Bias: 50654309508.786293, T: 896, Avg. loss: 1924922916893100152018960384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 371024170277.17, NNZs: 2, Bias: 64143246780.636520, T: 1024, Avg. loss: 936093474249462719436554240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 274528304819.90, NNZs: 2, Bias: 66422429200.548096, T: 1152, Avg. loss: 911726075591585740235997184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 282011432339.72, NNZs: 2, Bias: 67237471739.823212, T: 1280, Avg. loss: 940563796108738881401126912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 120594856695.63, NNZs: 2, Bias: 75379333295.161865, T: 1408, Avg. loss: 995372052777936644818862080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 29676150404.98, NNZs: 2, Bias: 79591410628.229309, T: 1536, Avg. loss: 946252831394285898547855360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 195030903020.94, NNZs: 2, Bias: 87865669580.707855, T: 1664, Avg. loss: 979631919586270988717785088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 388951076955.64, NNZs: 2, Bias: 86065648922.569687, T: 1792, Avg. loss: 906444046626329712142581760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 182186714147.44, NNZs: 2, Bias: 78597908516.926163, T: 1920, Avg. loss: 944336383727972366631829504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 180631838754.83, NNZs: 2, Bias: 75268139231.360672, T: 2048, Avg. loss: 941466090872086233656328192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 287658609527.97, NNZs: 2, Bias: 71070315543.822800, T: 2176, Avg. loss: 935250025791262521666043904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 472564630725.24, NNZs: 2, Bias: 77513896260.598038, T: 2304, Avg. loss: 916568270080767218321195008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 150481737334.00, NNZs: 2, Bias: 73557347910.928131, T: 2432, Avg. loss: 992559206103993383024328704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43205860951.23, NNZs: 2, Bias: 76178845502.098022, T: 2560, Avg. loss: 34332808262303018259578880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 34076440205.27, NNZs: 2, Bias: 76407024599.878311, T: 2688, Avg. loss: 36082552886402016826359808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 42948536502.35, NNZs: 2, Bias: 79250565584.594727, T: 2816, Avg. loss: 38195183151829678907457536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 64919175681.84, NNZs: 2, Bias: 80796756724.092911, T: 2944, Avg. loss: 37309122771636767495815168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 80481716976.82, NNZs: 2, Bias: 77921714440.759445, T: 3072, Avg. loss: 32781163751820049831165952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 98889306635.83, NNZs: 2, Bias: 75068315805.245285, T: 3200, Avg. loss: 33100716228762353943969792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 37821443933.39, NNZs: 2, Bias: 77194226329.257706, T: 3328, Avg. loss: 36660845026498036459634688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 58004477174.88, NNZs: 2, Bias: 77195687444.460846, T: 3456, Avg. loss: 35533066258307469226803200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 27418142582.53, NNZs: 2, Bias: 75674168669.470657, T: 3584, Avg. loss: 38062879178476165254873088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 82758589081.80, NNZs: 2, Bias: 76069441872.865356, T: 3712, Avg. loss: 33894344267143765488041984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 17980918245.09, NNZs: 2, Bias: 74938241797.539612, T: 3840, Avg. loss: 1676495093725426050138112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4722814303.58, NNZs: 2, Bias: 74597007353.827164, T: 3968, Avg. loss: 763289804853850669056000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11728129013.40, NNZs: 2, Bias: 74358408049.846664, T: 4096, Avg. loss: 750085833152036627021824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8327602201.95, NNZs: 2, Bias: 74096197434.320923, T: 4224, Avg. loss: 920631012879306779000832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3994872413.98, NNZs: 2, Bias: 74298132574.991852, T: 4352, Avg. loss: 662931771814908904079360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 530832294.82, NNZs: 2, Bias: 74299720845.286331, T: 4480, Avg. loss: 656679458009398070214656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2838454486.04, NNZs: 2, Bias: 74572359078.484955, T: 4608, Avg. loss: 802430606491935334989824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3798022204.84, NNZs: 2, Bias: 74149129376.250061, T: 4736, Avg. loss: 769209561186221086998528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7499842539.18, NNZs: 2, Bias: 74238736302.922287, T: 4864, Avg. loss: 769655808617272934662144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 5251245922.01, NNZs: 2, Bias: 74301799808.222900, T: 4992, Avg. loss: 726824261297283375562752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2633712829.95, NNZs: 2, Bias: 74317921492.664856, T: 5120, Avg. loss: 669872169447020669435904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 914845416.06, NNZs: 2, Bias: 74267101200.285370, T: 5248, Avg. loss: 2053322478512442441728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 253301866.44, NNZs: 2, Bias: 74234602679.494339, T: 5376, Avg. loss: 811683532614465748992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 644704850.95, NNZs: 2, Bias: 74204337338.602127, T: 5504, Avg. loss: 590947849805061816320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 819950486.25, NNZs: 2, Bias: 74178165193.932602, T: 5632, Avg. loss: 535042698571214487552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 994297785.30, NNZs: 2, Bias: 74155112391.807175, T: 5760, Avg. loss: 456237123501708148736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1019634579.20, NNZs: 2, Bias: 74132812059.194839, T: 5888, Avg. loss: 515395212041619243008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1038290547.23, NNZs: 2, Bias: 74111465590.782211, T: 6016, Avg. loss: 467995306908652797952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1108794728.20, NNZs: 2, Bias: 74089174020.039505, T: 6144, Avg. loss: 488514131190469558272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1178585432.28, NNZs: 2, Bias: 74067746735.237701, T: 6272, Avg. loss: 456137690179128786944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1092435815.02, NNZs: 2, Bias: 74048416694.188782, T: 6400, Avg. loss: 471883231177828663296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1083677415.62, NNZs: 2, Bias: 74026189584.635681, T: 6528, Avg. loss: 525204609012576419840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1076425118.46, NNZs: 2, Bias: 74003276550.595734, T: 6656, Avg. loss: 522253239871643058176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1027300440.19, NNZs: 2, Bias: 73983559347.595596, T: 6784, Avg. loss: 462181553433043795968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1094267544.49, NNZs: 2, Bias: 73960180544.259766, T: 6912, Avg. loss: 498408202921569550336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1058965272.07, NNZs: 2, Bias: 73956261778.663223, T: 7040, Avg. loss: 414411959028347830272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1081183380.63, NNZs: 2, Bias: 73951921643.676407, T: 7168, Avg. loss: 373966139503204171776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1095708956.96, NNZs: 2, Bias: 73947495765.876068, T: 7296, Avg. loss: 391750950244425334784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1086008459.66, NNZs: 2, Bias: 73943372675.243500, T: 7424, Avg. loss: 397853367293491740672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1082146820.26, NNZs: 2, Bias: 73939127884.273956, T: 7552, Avg. loss: 401264435611181449216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1092084720.90, NNZs: 2, Bias: 73934691029.646271, T: 7680, Avg. loss: 399415548059166965760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1073929174.15, NNZs: 2, Bias: 73930671192.220749, T: 7808, Avg. loss: 398759883980519768064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1081748075.50, NNZs: 2, Bias: 73929696064.325287, T: 7936, Avg. loss: 390809521782466609152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1083586879.97, NNZs: 2, Bias: 73928809739.580078, T: 8064, Avg. loss: 390082643932101083136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1085103333.27, NNZs: 2, Bias: 73927929729.589920, T: 8192, Avg. loss: 389332249016871550976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1087513683.82, NNZs: 2, Bias: 73927037788.421738, T: 8320, Avg. loss: 388784576053025964032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1085545077.82, NNZs: 2, Bias: 73926205423.762207, T: 8448, Avg. loss: 391064037705641951232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 66 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1113796009904.09, NNZs: 2, Bias: -719515968.626011, T: 128, Avg. loss: 17735825510250788850273091584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1257939283577.98, NNZs: 2, Bias: -106674139587.134796, T: 256, Avg. loss: 20188926711474041289114124288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1749552899537.78, NNZs: 2, Bias: -167316841636.501587, T: 384, Avg. loss: 21151141036897209837024182272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 411992249905.86, NNZs: 2, Bias: -187316841636.501587, T: 512, Avg. loss: 19864458659767922024396095488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 564854173900.22, NNZs: 2, Bias: -135480706322.663025, T: 640, Avg. loss: 20004177316423835300472553472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2319884277260.98, NNZs: 2, Bias: -109433177617.662292, T: 768, Avg. loss: 21797520876866690614976053248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 186976408859.66, NNZs: 2, Bias: -156192063237.755066, T: 896, Avg. loss: 1795494391076387848156348416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 444156320845.88, NNZs: 2, Bias: -173419531561.303467, T: 1024, Avg. loss: 917602345648157861968084992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 245479937078.57, NNZs: 2, Bias: -156735283249.945068, T: 1152, Avg. loss: 817483932626974381273251840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 91113643369.97, NNZs: 2, Bias: -164391542154.040375, T: 1280, Avg. loss: 835033279329720167118667776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 312584024377.88, NNZs: 2, Bias: -151716298201.444763, T: 1408, Avg. loss: 818799493420159575338778624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 363281552974.31, NNZs: 2, Bias: -178127048736.283539, T: 1536, Avg. loss: 831482822850140989307224064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 251963342872.02, NNZs: 2, Bias: -187877958450.096039, T: 1664, Avg. loss: 878966034993641850130137088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 345273204998.02, NNZs: 2, Bias: -178518592826.707153, T: 1792, Avg. loss: 922158574643792754568593408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 14919616051.97, NNZs: 2, Bias: -188395815888.652863, T: 1920, Avg. loss: 51569017163109290062381056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 39510650721.94, NNZs: 2, Bias: -187675855391.164795, T: 2048, Avg. loss: 29037416895142225718018048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 9170340471.73, NNZs: 2, Bias: -187188220955.755066, T: 2176, Avg. loss: 32599646937910058317512704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 63013801945.89, NNZs: 2, Bias: -187432745029.759064, T: 2304, Avg. loss: 33997442252672759446372352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42486644045.77, NNZs: 2, Bias: -187815536898.512177, T: 2432, Avg. loss: 32899086318696846262796288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 31913650689.12, NNZs: 2, Bias: -190530325520.649658, T: 2560, Avg. loss: 32768715509260124107571200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 64771566221.84, NNZs: 2, Bias: -190896308646.192963, T: 2688, Avg. loss: 31621587200421103986016256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 6520880974.66, NNZs: 2, Bias: -190197902992.128357, T: 2816, Avg. loss: 1959084036188797315055616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1242626574.45, NNZs: 2, Bias: -190025571864.169708, T: 2944, Avg. loss: 660342862606802635194368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 14027885026.98, NNZs: 2, Bias: -189348977805.317413, T: 3072, Avg. loss: 532901277726746211254272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 18846923074.46, NNZs: 2, Bias: -189187679398.713867, T: 3200, Avg. loss: 743643739999902820728832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1046491055.04, NNZs: 2, Bias: -189002444014.143311, T: 3328, Avg. loss: 815291612106463236849664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10317777760.17, NNZs: 2, Bias: -188465144877.113373, T: 3456, Avg. loss: 557072262250061495271424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 13685786474.53, NNZs: 2, Bias: -188067803404.279724, T: 3584, Avg. loss: 737064936829257229795328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4683564902.28, NNZs: 2, Bias: -188083737110.603790, T: 3712, Avg. loss: 561300763014564411342848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3665157791.98, NNZs: 2, Bias: -188031516454.834290, T: 3840, Avg. loss: 4688428403434833575936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 3164044320.49, NNZs: 2, Bias: -187971502597.329773, T: 3968, Avg. loss: 4160330250503387086848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3088173640.35, NNZs: 2, Bias: -187907739607.021515, T: 4096, Avg. loss: 3606833070451593314304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3178099358.31, NNZs: 2, Bias: -187836746727.928497, T: 4224, Avg. loss: 3963206956686834139136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3214995012.63, NNZs: 2, Bias: -187771183957.043518, T: 4352, Avg. loss: 3665679100797417684992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3049114055.84, NNZs: 2, Bias: -187704454711.418060, T: 4480, Avg. loss: 4090510504933993742336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3024509198.23, NNZs: 2, Bias: -187640227710.288208, T: 4608, Avg. loss: 3607247755240690155520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2980296702.56, NNZs: 2, Bias: -187574650186.666809, T: 4736, Avg. loss: 3810320889126313787392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3007134015.31, NNZs: 2, Bias: -187560744568.443573, T: 4864, Avg. loss: 3187524677907366543360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3008005519.59, NNZs: 2, Bias: -187547363432.834076, T: 4992, Avg. loss: 3159570178845776543744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3014501069.19, NNZs: 2, Bias: -187533988949.314575, T: 5120, Avg. loss: 3133275427679617679360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3010234839.08, NNZs: 2, Bias: -187520760395.071289, T: 5248, Avg. loss: 3143793901250499051520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3042739338.79, NNZs: 2, Bias: -187507112600.372101, T: 5376, Avg. loss: 3093388634960952295424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2979630064.18, NNZs: 2, Bias: -187495035492.055603, T: 5504, Avg. loss: 3093258531144630534144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3023312337.49, NNZs: 2, Bias: -187480987881.731354, T: 5632, Avg. loss: 3148052055802568507392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2971033293.51, NNZs: 2, Bias: -187468747021.516510, T: 5760, Avg. loss: 3094328883064613634048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2988860522.07, NNZs: 2, Bias: -187455103050.872253, T: 5888, Avg. loss: 3152936439140050272256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2995303966.20, NNZs: 2, Bias: -187441915608.791840, T: 6016, Avg. loss: 3092009598390999973888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3001535255.02, NNZs: 2, Bias: -187428658158.146881, T: 6144, Avg. loss: 3108910345100935036928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2954188065.86, NNZs: 2, Bias: -187416350758.186920, T: 6272, Avg. loss: 3087677295427709829120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2977346258.08, NNZs: 2, Bias: -187402885894.428833, T: 6400, Avg. loss: 3086932893117546233856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3000276439.85, NNZs: 2, Bias: -187389358749.721375, T: 6528, Avg. loss: 3109855840729525387264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2995339334.14, NNZs: 2, Bias: -187376155393.951874, T: 6656, Avg. loss: 3136427515329593737216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3023660304.49, NNZs: 2, Bias: -187362450930.063751, T: 6784, Avg. loss: 3126782907424034521088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3027408903.86, NNZs: 2, Bias: -187349245018.428375, T: 6912, Avg. loss: 3104763566630635044864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3023607794.77, NNZs: 2, Bias: -187335986706.792877, T: 7040, Avg. loss: 3143053500192982564864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2986557137.40, NNZs: 2, Bias: -187333967194.605621, T: 7168, Avg. loss: 3008940159228767633408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2984893772.01, NNZs: 2, Bias: -187331372957.348450, T: 7296, Avg. loss: 3014333912118845243392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3006750285.02, NNZs: 2, Bias: -187328395494.034607, T: 7424, Avg. loss: 3020738027363888005120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3002639473.06, NNZs: 2, Bias: -187325828539.875031, T: 7552, Avg. loss: 3028606064449148682240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2995223417.80, NNZs: 2, Bias: -187323319793.166687, T: 7680, Avg. loss: 3022452575145216704512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3004094031.75, NNZs: 2, Bias: -187320547540.978149, T: 7808, Avg. loss: 3024229611419339849728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 61 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1581943323543.02, NNZs: 2, Bias: 59637093778.345032, T: 128, Avg. loss: 22251872252324979285063368704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1439804004867.46, NNZs: 2, Bias: 108376881271.494659, T: 256, Avg. loss: 18797289217349725237876359168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2520925890195.25, NNZs: 2, Bias: 126830671605.296722, T: 384, Avg. loss: 19279783489158394690131722240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 350143876271.92, NNZs: 2, Bias: 145233973935.080658, T: 512, Avg. loss: 18808407041013716788879294464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1229072608776.50, NNZs: 2, Bias: 117264843240.960236, T: 640, Avg. loss: 18214732832182443521381236736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1226237582739.58, NNZs: 2, Bias: 137264843240.960236, T: 768, Avg. loss: 20435116716848694695647248384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 323236438347.45, NNZs: 2, Bias: 103611615877.380737, T: 896, Avg. loss: 20367017934955190811992522752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1409016712320.57, NNZs: 2, Bias: 108490015132.964691, T: 1024, Avg. loss: 18805785910945461388944867328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1427991221824.52, NNZs: 2, Bias: 88490015132.964691, T: 1152, Avg. loss: 18471174558181663992480530432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1779532252372.80, NNZs: 2, Bias: 140729357315.396362, T: 1280, Avg. loss: 19890731970718729439889326080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 52935584151.55, NNZs: 2, Bias: 157048544234.756226, T: 1408, Avg. loss: 1620344016284778062359298048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 215807251662.49, NNZs: 2, Bias: 159962616727.862335, T: 1536, Avg. loss: 791999509932985540679827456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 274911911340.66, NNZs: 2, Bias: 161519166216.866577, T: 1664, Avg. loss: 823279676915175908221911040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 124925921118.79, NNZs: 2, Bias: 149439519175.650177, T: 1792, Avg. loss: 778435252488673006532427776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 471937290294.46, NNZs: 2, Bias: 121915052328.847565, T: 1920, Avg. loss: 726192793445911548829630464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 140275933661.30, NNZs: 2, Bias: 119551362394.250717, T: 2048, Avg. loss: 773276421301795130812923904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 188160097021.14, NNZs: 2, Bias: 112120202392.741348, T: 2176, Avg. loss: 802769018303465390096777216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 41573180631.38, NNZs: 2, Bias: 113380812798.761948, T: 2304, Avg. loss: 773354105044328784169271296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 268114544628.27, NNZs: 2, Bias: 109702542026.261353, T: 2432, Avg. loss: 753260027659910938974224384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 93338457363.29, NNZs: 2, Bias: 116069984875.545380, T: 2560, Avg. loss: 809990720979540428686622720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 31519845971.31, NNZs: 2, Bias: 116348958201.221008, T: 2688, Avg. loss: 29168857835240745143894016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 51656449086.79, NNZs: 2, Bias: 116828152326.301376, T: 2816, Avg. loss: 27034935006091930434011136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 38425537116.76, NNZs: 2, Bias: 113481344171.724731, T: 2944, Avg. loss: 32053866109770776442830848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 54992475457.51, NNZs: 2, Bias: 114011132170.661758, T: 3072, Avg. loss: 31356931654624459098161152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 7565892761.89, NNZs: 2, Bias: 113972774994.748459, T: 3200, Avg. loss: 28275901344729601939603456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 61363364925.56, NNZs: 2, Bias: 111929987954.760590, T: 3328, Avg. loss: 29356955897987547717959680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 33382406523.69, NNZs: 2, Bias: 110686543777.071259, T: 3456, Avg. loss: 32539639993529462840885248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 11338433671.82, NNZs: 2, Bias: 110362554503.349380, T: 3584, Avg. loss: 586982648371051380080640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 13920395486.70, NNZs: 2, Bias: 110133530465.527222, T: 3712, Avg. loss: 555226354478708705722368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2154906850.63, NNZs: 2, Bias: 110108269946.780411, T: 3840, Avg. loss: 385355953575922478612480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4812507866.11, NNZs: 2, Bias: 109843759178.963455, T: 3968, Avg. loss: 483614022019270129483776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1339147561.49, NNZs: 2, Bias: 109797523948.057602, T: 4096, Avg. loss: 428461134231960874385408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 12671405790.99, NNZs: 2, Bias: 109400086051.566299, T: 4224, Avg. loss: 537249955298851569008640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4407545698.95, NNZs: 2, Bias: 109367005122.554626, T: 4352, Avg. loss: 482309049073933316259840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 15134889961.50, NNZs: 2, Bias: 109424523809.541061, T: 4480, Avg. loss: 570328010437385441509376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1946367131.14, NNZs: 2, Bias: 109250616426.778946, T: 4608, Avg. loss: 73368164740427941937152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 564489487.15, NNZs: 2, Bias: 109187124699.955063, T: 4736, Avg. loss: 2530731165174151512064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1078442097.03, NNZs: 2, Bias: 109135798193.795578, T: 4864, Avg. loss: 1528387452258434154496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1360947173.63, NNZs: 2, Bias: 109094148734.632629, T: 4992, Avg. loss: 1203826608765617045504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1612349880.47, NNZs: 2, Bias: 109053331885.040283, T: 5120, Avg. loss: 1241377476364012355584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1716694331.49, NNZs: 2, Bias: 109012627334.802719, T: 5248, Avg. loss: 1340620571585318486016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1707807656.89, NNZs: 2, Bias: 108975015400.632950, T: 5376, Avg. loss: 1235979088675079192576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1571750506.20, NNZs: 2, Bias: 108938892163.441177, T: 5504, Avg. loss: 1347321151671817207808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1809404074.53, NNZs: 2, Bias: 108899304716.033859, T: 5632, Avg. loss: 1195652411650045902848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1599797644.02, NNZs: 2, Bias: 108865532177.095276, T: 5760, Avg. loss: 1234311023335697285120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1684143038.75, NNZs: 2, Bias: 108828415616.959763, T: 5888, Avg. loss: 1192194739050850025472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1658423108.61, NNZs: 2, Bias: 108793212587.862045, T: 6016, Avg. loss: 1214582736565210710016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1781314100.07, NNZs: 2, Bias: 108755671724.242889, T: 6144, Avg. loss: 1219353680741318787072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1870780185.35, NNZs: 2, Bias: 108717623880.459534, T: 6272, Avg. loss: 1233635150182208503808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1753279925.07, NNZs: 2, Bias: 108682503237.255310, T: 6400, Avg. loss: 1224390047430877642752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1857918114.01, NNZs: 2, Bias: 108644375518.001160, T: 6528, Avg. loss: 1168594480020211105792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1807943304.10, NNZs: 2, Bias: 108608157733.926865, T: 6656, Avg. loss: 1216637654839083401216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1772978094.71, NNZs: 2, Bias: 108572762646.344696, T: 6784, Avg. loss: 1230774266204004548608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1786507035.97, NNZs: 2, Bias: 108536817747.119461, T: 6912, Avg. loss: 1172998948805003444224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1759294379.75, NNZs: 2, Bias: 108500504695.222580, T: 7040, Avg. loss: 1238065027924806598656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1713068500.96, NNZs: 2, Bias: 108465017798.527100, T: 7168, Avg. loss: 1257274448125159538688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1757311755.71, NNZs: 2, Bias: 108457006270.807922, T: 7296, Avg. loss: 998755166092629114880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1720304109.51, NNZs: 2, Bias: 108450187679.141708, T: 7424, Avg. loss: 1016815436996975919104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1752111341.66, NNZs: 2, Bias: 108442350434.945480, T: 7552, Avg. loss: 1001851194790013042688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1733349529.42, NNZs: 2, Bias: 108435275325.292725, T: 7680, Avg. loss: 1010815619974099107840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1725660033.63, NNZs: 2, Bias: 108428010511.544495, T: 7808, Avg. loss: 1013286812851147898880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1742014674.37, NNZs: 2, Bias: 108420391247.836151, T: 7936, Avg. loss: 1008338425577257566208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1722977866.66, NNZs: 2, Bias: 108419230259.386093, T: 8064, Avg. loss: 976824328644651909120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1732945650.46, NNZs: 2, Bias: 108417615799.138412, T: 8192, Avg. loss: 968997737026536734720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1729176624.77, NNZs: 2, Bias: 108416212670.968842, T: 8320, Avg. loss: 974865285108361461760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1727900942.87, NNZs: 2, Bias: 108414772654.634369, T: 8448, Avg. loss: 972698781875686735872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1731354766.80, NNZs: 2, Bias: 108413257049.561935, T: 8576, Avg. loss: 972512531070530617344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1730093428.93, NNZs: 2, Bias: 108411816297.703613, T: 8704, Avg. loss: 973044245740479578112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1728537609.95, NNZs: 2, Bias: 108410378524.014481, T: 8832, Avg. loss: 974144123863672684544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 69 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 600925431664.85, NNZs: 2, Bias: 130401872671.659485, T: 128, Avg. loss: 21939442059571909158441582592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 784293751477.96, NNZs: 2, Bias: 150401872671.659485, T: 256, Avg. loss: 20696030893005021818191347712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2172524603944.49, NNZs: 2, Bias: 150401872671.659485, T: 384, Avg. loss: 20979920393732755897028968448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 475605750384.32, NNZs: 2, Bias: 152721909632.446381, T: 512, Avg. loss: 21886728952460758929754816512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2049604364205.57, NNZs: 2, Bias: 71421144475.512527, T: 640, Avg. loss: 20254618757299619730582142976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1881558526866.43, NNZs: 2, Bias: -8578855524.487473, T: 768, Avg. loss: 20365056889241416771661987840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 610757548557.77, NNZs: 2, Bias: -918712414.756676, T: 896, Avg. loss: 20408544332584393793630896128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1222899873028.31, NNZs: 2, Bias: -20918712414.756676, T: 1024, Avg. loss: 22684090933832057110367567872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1821438500509.67, NNZs: 2, Bias: 42625266639.255356, T: 1152, Avg. loss: 19232641992968840743057620992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 950461285538.29, NNZs: 2, Bias: 2625266639.255356, T: 1280, Avg. loss: 21389288030103360978938757120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2123070915557.70, NNZs: 2, Bias: 10618571873.371246, T: 1408, Avg. loss: 21236810496957353337731153920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1436454927037.17, NNZs: 2, Bias: 78187768459.812042, T: 1536, Avg. loss: 19870880564135574111214632960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 953789870992.61, NNZs: 2, Bias: 98187768459.812042, T: 1664, Avg. loss: 22308127412415811741972168704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 968456213610.73, NNZs: 2, Bias: 116738577784.878311, T: 1792, Avg. loss: 21140403866573451196608020480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 514571872321.59, NNZs: 2, Bias: 106444671045.084091, T: 1920, Avg. loss: 908175686216521031864025088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 166156237401.62, NNZs: 2, Bias: 101855212535.322433, T: 2048, Avg. loss: 862976157720794113840775168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 265305945452.64, NNZs: 2, Bias: 94050982026.005630, T: 2176, Avg. loss: 810038731925255675887747072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 477152563232.80, NNZs: 2, Bias: 103051562094.338638, T: 2304, Avg. loss: 778985192256592210741428224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 182780149968.54, NNZs: 2, Bias: 109352366757.078308, T: 2432, Avg. loss: 841773963893509956101472256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 185886471162.13, NNZs: 2, Bias: 103932884842.798050, T: 2560, Avg. loss: 852562684781947785465298944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 272409058339.23, NNZs: 2, Bias: 100968081463.704086, T: 2688, Avg. loss: 884388283318559376127557632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 288345096625.63, NNZs: 2, Bias: 88166400091.356216, T: 2816, Avg. loss: 837092235974296125201973248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 337313622337.91, NNZs: 2, Bias: 80300049683.011749, T: 2944, Avg. loss: 802204012789192700251340800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 76636147865.08, NNZs: 2, Bias: 84356135489.538330, T: 3072, Avg. loss: 59575921537567494036783104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 14676923392.09, NNZs: 2, Bias: 82661522648.639694, T: 3200, Avg. loss: 25880924427340985992740864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 14614607474.09, NNZs: 2, Bias: 84804937609.770584, T: 3328, Avg. loss: 31223030112846958408237056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 75228558921.53, NNZs: 2, Bias: 85114967885.105774, T: 3456, Avg. loss: 28638228476410663752695808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 10256647263.68, NNZs: 2, Bias: 84269018429.017075, T: 3584, Avg. loss: 29073503906217107298189312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 59414610949.35, NNZs: 2, Bias: 83509036486.816406, T: 3712, Avg. loss: 31597120841408887578951680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 105277824682.32, NNZs: 2, Bias: 84083723962.052078, T: 3840, Avg. loss: 30642743524176002310733824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1543924387.44, NNZs: 2, Bias: 82771555859.582993, T: 3968, Avg. loss: 4603783994522246339100672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4215166928.74, NNZs: 2, Bias: 82636592174.758377, T: 4096, Avg. loss: 559130149739499756716032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 17374369568.62, NNZs: 2, Bias: 82328086142.200119, T: 4224, Avg. loss: 335902561010753915060224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3362116263.50, NNZs: 2, Bias: 82228089886.271896, T: 4352, Avg. loss: 656582519758584408965120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1279968116.61, NNZs: 2, Bias: 82074784840.253448, T: 4480, Avg. loss: 474163550825210330480640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 7170895377.22, NNZs: 2, Bias: 81788322179.455124, T: 4608, Avg. loss: 696967708233674763796480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 237979291.86, NNZs: 2, Bias: 81498773289.654022, T: 4736, Avg. loss: 613113888560746755784704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 494876790.21, NNZs: 2, Bias: 81075639936.463089, T: 4864, Avg. loss: 463096601973938815238144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 950038098.38, NNZs: 2, Bias: 81041011006.294937, T: 4992, Avg. loss: 718804299709357096960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1235337070.99, NNZs: 2, Bias: 81011050727.704941, T: 5120, Avg. loss: 633546224349747085312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1259296820.06, NNZs: 2, Bias: 80984630568.908737, T: 5248, Avg. loss: 654725231173010194432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1304655879.02, NNZs: 2, Bias: 80958546089.449905, T: 5376, Avg. loss: 638453118561028538368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1431423611.74, NNZs: 2, Bias: 80932333800.262711, T: 5504, Avg. loss: 587669060474006994944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1431274318.40, NNZs: 2, Bias: 80906883897.518051, T: 5632, Avg. loss: 631413136106643783680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1407242245.57, NNZs: 2, Bias: 80882755917.647415, T: 5760, Avg. loss: 586170252409934249984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1422612219.74, NNZs: 2, Bias: 80856823271.023026, T: 5888, Avg. loss: 624773131585619230720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1467350660.81, NNZs: 2, Bias: 80831336841.871216, T: 6016, Avg. loss: 607860380021635940352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1401940406.38, NNZs: 2, Bias: 80807567352.324844, T: 6144, Avg. loss: 635813051084441649152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1475671744.04, NNZs: 2, Bias: 80781528945.177078, T: 6272, Avg. loss: 624972293948249735168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1478347790.54, NNZs: 2, Bias: 80756634157.674957, T: 6400, Avg. loss: 604073659441539579904.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1444909959.37, NNZs: 2, Bias: 80752200581.049072, T: 6528, Avg. loss: 514257286140565061632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1442972139.91, NNZs: 2, Bias: 80747171137.443436, T: 6656, Avg. loss: 517125419922507104256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1436410404.87, NNZs: 2, Bias: 80742234159.258926, T: 6784, Avg. loss: 515239614116154834944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1427292599.17, NNZs: 2, Bias: 80737369287.636307, T: 6912, Avg. loss: 512471357701445582848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1438989115.89, NNZs: 2, Bias: 80732158243.327087, T: 7040, Avg. loss: 509256892258208382976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1412904164.92, NNZs: 2, Bias: 80727546239.350586, T: 7168, Avg. loss: 517522739659112972288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1417479819.76, NNZs: 2, Bias: 80722346294.437454, T: 7296, Avg. loss: 521352992922554597376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1419443592.65, NNZs: 2, Bias: 80717237898.230865, T: 7424, Avg. loss: 516780350974912299008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1421432791.82, NNZs: 2, Bias: 80712114610.127441, T: 7552, Avg. loss: 518704464372906852352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1414908567.22, NNZs: 2, Bias: 80707132875.633850, T: 7680, Avg. loss: 519227458762086350848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1408594571.39, NNZs: 2, Bias: 80706232989.301682, T: 7808, Avg. loss: 501013839162412695552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1408812479.53, NNZs: 2, Bias: 80705218237.795700, T: 7936, Avg. loss: 501108475127037165568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1406491407.37, NNZs: 2, Bias: 80704250107.829865, T: 8064, Avg. loss: 499995739910107430912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1407979901.36, NNZs: 2, Bias: 80703215745.579407, T: 8192, Avg. loss: 499736685871540928512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1412756966.57, NNZs: 2, Bias: 80702126686.690079, T: 8320, Avg. loss: 498214774328195678208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1406330955.24, NNZs: 2, Bias: 80701232308.063568, T: 8448, Avg. loss: 499114337884425879552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1407836282.15, NNZs: 2, Bias: 80700195675.740417, T: 8576, Avg. loss: 500739791184679993344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1412744395.88, NNZs: 2, Bias: 80699105188.399872, T: 8704, Avg. loss: 497798021389730775040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1410679867.65, NNZs: 2, Bias: 80698130548.556213, T: 8832, Avg. loss: 501075699016601501696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1408693572.40, NNZs: 2, Bias: 80697157672.465759, T: 8960, Avg. loss: 499410281006541176832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1409113467.26, NNZs: 2, Bias: 80696141939.031052, T: 9088, Avg. loss: 499739944394433101824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1406601091.39, NNZs: 2, Bias: 80695176752.924194, T: 9216, Avg. loss: 500111754247547846656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1402896815.80, NNZs: 2, Bias: 80694236661.396011, T: 9344, Avg. loss: 497905427139709370368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 73 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2028529666608.04, NNZs: 2, Bias: -34629070690.829903, T: 128, Avg. loss: 21307836301737581683299844096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 65680979531.81, NNZs: 2, Bias: -11982994744.027149, T: 256, Avg. loss: 23020534948243005196566790144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3106654271684.26, NNZs: 2, Bias: -11982994744.027145, T: 384, Avg. loss: 20738171871004980553663381504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1823301766243.97, NNZs: 2, Bias: 128017005255.972839, T: 512, Avg. loss: 21579028842722767288202690560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 809419056690.06, NNZs: 2, Bias: 108017005255.972839, T: 640, Avg. loss: 22765285302686530050889613312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1599931154137.32, NNZs: 2, Bias: 138878987351.811218, T: 768, Avg. loss: 26135659675154772144775233536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 675332399688.59, NNZs: 2, Bias: 253325934143.555420, T: 896, Avg. loss: 22361973617742139143409893376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1233800619676.67, NNZs: 2, Bias: 273325934143.555420, T: 1024, Avg. loss: 21026149549351368105092186112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 407263017817.39, NNZs: 2, Bias: 259595492116.553528, T: 1152, Avg. loss: 1045504900238720978240143360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 250199482177.77, NNZs: 2, Bias: 264155159948.326782, T: 1280, Avg. loss: 843971612653186594631581696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 342916416785.94, NNZs: 2, Bias: 276743899276.015198, T: 1408, Avg. loss: 900257157280057997559595008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 376408620476.58, NNZs: 2, Bias: 292297384970.747192, T: 1536, Avg. loss: 884006399411477705132081152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 149578484364.91, NNZs: 2, Bias: 270008176604.153717, T: 1664, Avg. loss: 894442389366043948034818048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 158365477932.24, NNZs: 2, Bias: 289084862323.421570, T: 1792, Avg. loss: 893178649818368485527388160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 93720343013.61, NNZs: 2, Bias: 292143146907.252441, T: 1920, Avg. loss: 831860371521716407282696192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 182363666243.73, NNZs: 2, Bias: 287483335103.281372, T: 2048, Avg. loss: 864465593532792756812906496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 132888725671.24, NNZs: 2, Bias: 280191856493.641846, T: 2176, Avg. loss: 933459970193200092184313856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 108437333675.80, NNZs: 2, Bias: 284191856493.641846, T: 2304, Avg. loss: 885397154213652931155066880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 504306736508.48, NNZs: 2, Bias: 252802318732.494476, T: 2432, Avg. loss: 891002120143466263360831488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 499408273575.25, NNZs: 2, Bias: 257626414169.251801, T: 2560, Avg. loss: 867986147084517891874226176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8427118481.66, NNZs: 2, Bias: 253975977292.414703, T: 2688, Avg. loss: 125516933232317884574728192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 41694246138.81, NNZs: 2, Bias: 253332997423.915253, T: 2816, Avg. loss: 33048334571750797156024320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 85292577459.68, NNZs: 2, Bias: 252598779386.108887, T: 2944, Avg. loss: 34141754488930882100920320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 16092103492.11, NNZs: 2, Bias: 252194573588.311371, T: 3072, Avg. loss: 31753728404825186139897856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 79470889183.32, NNZs: 2, Bias: 249330678600.137512, T: 3200, Avg. loss: 31056133339670283940790272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 25067729513.13, NNZs: 2, Bias: 251121289635.898041, T: 3328, Avg. loss: 33217203986189700795727872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 78799335382.12, NNZs: 2, Bias: 249915111677.414825, T: 3456, Avg. loss: 32710971933845249572470784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 87676766119.52, NNZs: 2, Bias: 252367382106.613159, T: 3584, Avg. loss: 36713375817360889985630208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 73363959460.17, NNZs: 2, Bias: 251759523381.286377, T: 3712, Avg. loss: 35546041242009713489477632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 62907275753.20, NNZs: 2, Bias: 251767412126.947357, T: 3840, Avg. loss: 34192365769950635245961216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 8897790422.87, NNZs: 2, Bias: 251997502476.853271, T: 3968, Avg. loss: 1406357113933358992195584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4728811351.41, NNZs: 2, Bias: 252194618082.617096, T: 4096, Avg. loss: 907441321360498867830784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8652432888.11, NNZs: 2, Bias: 252010515021.893951, T: 4224, Avg. loss: 644170556417899612864512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8941807380.51, NNZs: 2, Bias: 251875193209.806976, T: 4352, Avg. loss: 715700256480507170127872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2214087794.14, NNZs: 2, Bias: 251632312450.879608, T: 4480, Avg. loss: 717247273471156447870976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6400128210.99, NNZs: 2, Bias: 251273637229.215881, T: 4608, Avg. loss: 818444892744654042169344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2044758599.37, NNZs: 2, Bias: 251127898559.448456, T: 4736, Avg. loss: 802386497913035901894656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5528369098.20, NNZs: 2, Bias: 250846767231.780975, T: 4864, Avg. loss: 645674241989612050317312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2162476568.18, NNZs: 2, Bias: 250757320919.375397, T: 4992, Avg. loss: 12793139190337204387840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3108398286.22, NNZs: 2, Bias: 250659040381.229492, T: 5120, Avg. loss: 6511146951553565327360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3576948055.90, NNZs: 2, Bias: 250568753499.186554, T: 5248, Avg. loss: 6266453339925681012736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3950871540.56, NNZs: 2, Bias: 250480572759.715210, T: 5376, Avg. loss: 6481982497095241695232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4115845542.89, NNZs: 2, Bias: 250392262493.939148, T: 5504, Avg. loss: 6434506230274640052224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4000916618.00, NNZs: 2, Bias: 250309452006.233002, T: 5632, Avg. loss: 6505523909193030959104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3670825660.43, NNZs: 2, Bias: 250223429912.780273, T: 5760, Avg. loss: 7317644327927813242880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3807686859.61, NNZs: 2, Bias: 250137280536.358612, T: 5888, Avg. loss: 6480887501545224011776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3988322108.09, NNZs: 2, Bias: 250116905432.746429, T: 6016, Avg. loss: 5548625749277898964992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3957682531.31, NNZs: 2, Bias: 250100406247.134766, T: 6144, Avg. loss: 5377709968241550426112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3965546171.65, NNZs: 2, Bias: 250083893755.012451, T: 6272, Avg. loss: 5170787300838352093184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3951553144.62, NNZs: 2, Bias: 250067435416.663422, T: 6400, Avg. loss: 5284772133166138785792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3967624982.27, NNZs: 2, Bias: 250050379771.665833, T: 6528, Avg. loss: 5306029478795728125952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3958790025.05, NNZs: 2, Bias: 250033578216.605255, T: 6656, Avg. loss: 5356685529161340551168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4023112585.47, NNZs: 2, Bias: 250015837183.269501, T: 6784, Avg. loss: 5270293950297232375808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3916997110.73, NNZs: 2, Bias: 250000616856.787415, T: 6912, Avg. loss: 5344324687397872730112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3933173405.58, NNZs: 2, Bias: 249996994754.808868, T: 7040, Avg. loss: 5170685568093383557120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3944076670.30, NNZs: 2, Bias: 249993469541.010925, T: 7168, Avg. loss: 5148431326752190496768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3945842055.54, NNZs: 2, Bias: 249990081641.888916, T: 7296, Avg. loss: 5159966090220638568448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3922403117.04, NNZs: 2, Bias: 249987104244.662659, T: 7424, Avg. loss: 5141280997806131118080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3932102144.52, NNZs: 2, Bias: 249983583637.648010, T: 7552, Avg. loss: 5171622161076360052736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3920764770.62, NNZs: 2, Bias: 249980441560.521667, T: 7680, Avg. loss: 5099082007708171239424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3928272393.90, NNZs: 2, Bias: 249976972561.211212, T: 7808, Avg. loss: 5145106807791581921280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3930097881.68, NNZs: 2, Bias: 249973583489.496979, T: 7936, Avg. loss: 5159703174520007294976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3927704069.63, NNZs: 2, Bias: 249970263017.821320, T: 8064, Avg. loss: 5156991139190411362304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3930236164.98, NNZs: 2, Bias: 249966864048.900482, T: 8192, Avg. loss: 5157895924173755121664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3936668023.52, NNZs: 2, Bias: 249963407238.315948, T: 8320, Avg. loss: 5152091455694161575936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 65 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1090771156733.35, NNZs: 2, Bias: 21627141322.316624, T: 128, Avg. loss: 23471518513548512201977888768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1403713190424.85, NNZs: 2, Bias: 9750174521.847267, T: 256, Avg. loss: 23328617654791513362636210176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2352000301778.63, NNZs: 2, Bias: 426175196.652390, T: 384, Avg. loss: 26047518089823045314007793664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2643843152688.11, NNZs: 2, Bias: -7626818618.148087, T: 512, Avg. loss: 22553583313870648478401560576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1547113586697.59, NNZs: 2, Bias: 12373181381.851913, T: 640, Avg. loss: 25987646487809078716797026304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 416216639881.79, NNZs: 2, Bias: -62485069605.502762, T: 768, Avg. loss: 23581093564458771819840667648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2414398076292.40, NNZs: 2, Bias: -85142165136.433868, T: 896, Avg. loss: 22813526056281703948805472256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1003628093590.24, NNZs: 2, Bias: -85142165136.433868, T: 1024, Avg. loss: 24703257854657682536226881536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1122461823032.14, NNZs: 2, Bias: -45142165136.433868, T: 1152, Avg. loss: 23083977525696033634167816192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 194461697450.01, NNZs: 2, Bias: -33074584439.483246, T: 1280, Avg. loss: 1108424096749525856816201728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 295862894558.18, NNZs: 2, Bias: -31938665780.755936, T: 1408, Avg. loss: 940225935823065970982780928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 236713419152.58, NNZs: 2, Bias: -19083532398.413422, T: 1536, Avg. loss: 862758725559773952445775872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 224987996632.19, NNZs: 2, Bias: 647777892.485688, T: 1664, Avg. loss: 912689960644727447352246272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 411899634451.27, NNZs: 2, Bias: -7477280223.785517, T: 1792, Avg. loss: 994979118638083514319241216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 478343491494.08, NNZs: 2, Bias: -23551681119.832535, T: 1920, Avg. loss: 893719636626286106390822912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 512460207637.21, NNZs: 2, Bias: -32165919032.835373, T: 2048, Avg. loss: 942114063959290936681299968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 186581819612.09, NNZs: 2, Bias: -19797149451.319031, T: 2176, Avg. loss: 1033635716787787685831901184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 27175083577.39, NNZs: 2, Bias: -19164815371.814198, T: 2304, Avg. loss: 41494528971746033186897920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 39424276613.38, NNZs: 2, Bias: -18228341786.139137, T: 2432, Avg. loss: 33497977741616951704158208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 79675827898.83, NNZs: 2, Bias: -16150780910.531454, T: 2560, Avg. loss: 33350986896809564598960128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 78176329484.24, NNZs: 2, Bias: -14804978394.994343, T: 2688, Avg. loss: 33878554305193901253722112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 67453037855.05, NNZs: 2, Bias: -12102020479.647732, T: 2816, Avg. loss: 36022951329976012572196864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 29710591667.02, NNZs: 2, Bias: -12600338334.967022, T: 2944, Avg. loss: 38054229677249647773483008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 20368020536.09, NNZs: 2, Bias: -12550860242.058098, T: 3072, Avg. loss: 38838911870409287613284352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 56509142132.13, NNZs: 2, Bias: -12951843891.424231, T: 3200, Avg. loss: 34350730960875168368427008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 7823611678.78, NNZs: 2, Bias: -12708093702.469639, T: 3328, Avg. loss: 1389511329581503174672384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 672185992.04, NNZs: 2, Bias: -12627330981.471601, T: 3456, Avg. loss: 590689428579307122327552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 8653188735.49, NNZs: 2, Bias: -12302755215.963232, T: 3584, Avg. loss: 675248815075680734674944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 7396881460.69, NNZs: 2, Bias: -12404162620.441040, T: 3712, Avg. loss: 803564534928058978664448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4248744839.64, NNZs: 2, Bias: -12706325376.996223, T: 3840, Avg. loss: 680578868126818408333312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5750004944.32, NNZs: 2, Bias: -12818266651.025225, T: 3968, Avg. loss: 709639911837142509158400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4670465287.42, NNZs: 2, Bias: -12820505494.066248, T: 4096, Avg. loss: 722255663899579391148032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2277724219.42, NNZs: 2, Bias: -12850823315.714457, T: 4224, Avg. loss: 2960882569706590437376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1285079237.61, NNZs: 2, Bias: -12860609440.876532, T: 4352, Avg. loss: 592236453888532545536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 777571822.71, NNZs: 2, Bias: -12864695423.986452, T: 4480, Avg. loss: 164796073327277277184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 493136850.80, NNZs: 2, Bias: -12865336115.744627, T: 4608, Avg. loss: 59960992419232079872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 352177108.43, NNZs: 2, Bias: -12863523589.483480, T: 4736, Avg. loss: 29057352755850653696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 270239975.48, NNZs: 2, Bias: -12860887674.970329, T: 4864, Avg. loss: 19634623346254557184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 242685864.92, NNZs: 2, Bias: -12857631030.342249, T: 4992, Avg. loss: 15575271876912525312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 212487725.06, NNZs: 2, Bias: -12854106152.780733, T: 5120, Avg. loss: 17170468942728032256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 204842820.53, NNZs: 2, Bias: -12850620992.035084, T: 5248, Avg. loss: 14435845814350444544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 193907081.78, NNZs: 2, Bias: -12846909021.316984, T: 5376, Avg. loss: 15645387864203677696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 192084886.84, NNZs: 2, Bias: -12843363349.373318, T: 5504, Avg. loss: 13839850326730747904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 191435117.36, NNZs: 2, Bias: -12839601997.390278, T: 5632, Avg. loss: 14512889575159971840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 183577275.76, NNZs: 2, Bias: -12836119894.877424, T: 5760, Avg. loss: 13964329704919410688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 182697444.14, NNZs: 2, Bias: -12832390306.345787, T: 5888, Avg. loss: 14428335153970085888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 204535366.56, NNZs: 2, Bias: -12828624382.396204, T: 6016, Avg. loss: 13403056768940406784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 190956970.48, NNZs: 2, Bias: -12825159424.019278, T: 6144, Avg. loss: 14460024411886448640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 186779355.83, NNZs: 2, Bias: -12821463590.645855, T: 6272, Avg. loss: 14833983944764160000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 190261918.02, NNZs: 2, Bias: -12817656658.381844, T: 6400, Avg. loss: 14933848246243291136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 193654253.51, NNZs: 2, Bias: -12814084209.967751, T: 6528, Avg. loss: 13615592793477003264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 198630753.34, NNZs: 2, Bias: -12810481262.565025, T: 6656, Avg. loss: 13464756693401837568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 193800930.43, NNZs: 2, Bias: -12809805402.584087, T: 6784, Avg. loss: 12126998921696323584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 194858612.26, NNZs: 2, Bias: -12809038008.300400, T: 6912, Avg. loss: 12124820129907931136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 192413576.93, NNZs: 2, Bias: -12808333277.331703, T: 7040, Avg. loss: 11984552440266338304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 196419643.66, NNZs: 2, Bias: -12807526715.538193, T: 7168, Avg. loss: 12036601066428329984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 193583605.87, NNZs: 2, Bias: -12806812709.680149, T: 7296, Avg. loss: 12274780593118318592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 195283995.35, NNZs: 2, Bias: -12806036551.103943, T: 7424, Avg. loss: 12108338856257630208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 193102132.14, NNZs: 2, Bias: -12805324235.625568, T: 7552, Avg. loss: 12040429445223192576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 190994244.26, NNZs: 2, Bias: -12804606400.291439, T: 7680, Avg. loss: 12122077137709021184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 192613127.67, NNZs: 2, Bias: -12804432052.827183, T: 7808, Avg. loss: 11797702377432543232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 192672562.48, NNZs: 2, Bias: -12804282262.297770, T: 7936, Avg. loss: 11707709381566140416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 192006006.32, NNZs: 2, Bias: -12804143875.614649, T: 8064, Avg. loss: 11671606396905881600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 192614787.17, NNZs: 2, Bias: -12803986084.432014, T: 8192, Avg. loss: 11684114331407548416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 193021899.01, NNZs: 2, Bias: -12803831464.452501, T: 8320, Avg. loss: 11673548148544983040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 192402642.64, NNZs: 2, Bias: -12803691953.621004, T: 8448, Avg. loss: 11704178954485499904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 191708144.16, NNZs: 2, Bias: -12803554134.939236, T: 8576, Avg. loss: 11656873119569836032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 192216494.77, NNZs: 2, Bias: -12803397402.800303, T: 8704, Avg. loss: 11721442958766858240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 192100336.63, NNZs: 2, Bias: -12803250484.128183, T: 8832, Avg. loss: 11688615270724173824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 192546855.83, NNZs: 2, Bias: -12803095054.838186, T: 8960, Avg. loss: 11691600024096841728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 191767471.75, NNZs: 2, Bias: -12802958379.869617, T: 9088, Avg. loss: 11667913018045546496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 191597480.14, NNZs: 2, Bias: -12802812036.049398, T: 9216, Avg. loss: 11706791329785200640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 72 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1498870034001.19, NNZs: 2, Bias: 70144803288.904282, T: 128, Avg. loss: 20362293814176903183848177664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1214888172427.10, NNZs: 2, Bias: 28182877575.063560, T: 256, Avg. loss: 21920324454427072296833253376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 905206479275.07, NNZs: 2, Bias: 15635964629.298164, T: 384, Avg. loss: 20837286873286335479265886208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 303208660072.04, NNZs: 2, Bias: -4364035370.701836, T: 512, Avg. loss: 23096823856190538305731821568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1324846673212.97, NNZs: 2, Bias: 23400316283.486572, T: 640, Avg. loss: 21482891729178893094448267264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 542921329012.47, NNZs: 2, Bias: -1748607820.078278, T: 768, Avg. loss: 20646262434214451522341699584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 375435874134.19, NNZs: 2, Bias: 5565667815.034849, T: 896, Avg. loss: 890521522090674356886700032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 416446900162.38, NNZs: 2, Bias: -2246176183.860037, T: 1024, Avg. loss: 855772756283826134606413824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 311883520836.13, NNZs: 2, Bias: 3712750765.691876, T: 1152, Avg. loss: 914654228891589406370037760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 177223087168.28, NNZs: 2, Bias: -7455599745.588230, T: 1280, Avg. loss: 846708350289193940870496256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 297496037842.48, NNZs: 2, Bias: -26237648261.964561, T: 1408, Avg. loss: 846399091790080964319772672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 66178123955.34, NNZs: 2, Bias: -16774054937.360168, T: 1536, Avg. loss: 892873211897634197042364416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 354806405342.16, NNZs: 2, Bias: -36982200794.730347, T: 1664, Avg. loss: 848251769314414625309065216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 110188810046.30, NNZs: 2, Bias: -23370286478.662312, T: 1792, Avg. loss: 933635327302827948650790912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 240141468651.15, NNZs: 2, Bias: -27215387865.771843, T: 1920, Avg. loss: 869728373375285482726883328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 114187674500.48, NNZs: 2, Bias: -27975621089.850361, T: 2048, Avg. loss: 857131369092942451596853248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 10932409972.82, NNZs: 2, Bias: -30593638220.406975, T: 2176, Avg. loss: 35175119105189165001605120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 45338894277.13, NNZs: 2, Bias: -28618583435.322906, T: 2304, Avg. loss: 28778577815939012817321984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 48709480494.95, NNZs: 2, Bias: -31088936250.619957, T: 2432, Avg. loss: 30726302578981620280197120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 30051875082.00, NNZs: 2, Bias: -31060420432.303776, T: 2560, Avg. loss: 31594459986344066288713728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 51612576401.28, NNZs: 2, Bias: -29785706130.887718, T: 2688, Avg. loss: 30743649384551334102958080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 38087681292.80, NNZs: 2, Bias: -27588890867.968315, T: 2816, Avg. loss: 33068226436121099625299968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 56266975347.76, NNZs: 2, Bias: -30879382586.607857, T: 2944, Avg. loss: 27579911654573661084450816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 42107806868.08, NNZs: 2, Bias: -28064812828.875591, T: 3072, Avg. loss: 32304971561523356842852352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 40670499016.68, NNZs: 2, Bias: -29124850510.568581, T: 3200, Avg. loss: 31934426185568119573970944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 35914690086.67, NNZs: 2, Bias: -29789470838.492947, T: 3328, Avg. loss: 30377019553231794740396032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 90206295413.58, NNZs: 2, Bias: -28524361733.630177, T: 3456, Avg. loss: 30304649234527150495760384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 7856064577.71, NNZs: 2, Bias: -27004081658.556210, T: 3584, Avg. loss: 31757867503225573967134720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 6252785427.12, NNZs: 2, Bias: -27060016774.607155, T: 3712, Avg. loss: 470571510513137505796096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2809562320.94, NNZs: 2, Bias: -27426324469.580357, T: 3840, Avg. loss: 712096770158935943413760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10276780165.92, NNZs: 2, Bias: -27484351612.820644, T: 3968, Avg. loss: 561466639870807636967424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 10789530878.52, NNZs: 2, Bias: -27418330661.838928, T: 4096, Avg. loss: 567762885630993069244416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5129822252.88, NNZs: 2, Bias: -27539603719.489498, T: 4224, Avg. loss: 578098414250554122305536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 15996913411.52, NNZs: 2, Bias: -27423088172.362267, T: 4352, Avg. loss: 439394025375950572617728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4123984859.52, NNZs: 2, Bias: -27293761115.907940, T: 4480, Avg. loss: 559882617661199271067648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2357993323.35, NNZs: 2, Bias: -27306726759.256886, T: 4608, Avg. loss: 514902366108709860409344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 13485164133.18, NNZs: 2, Bias: -27281656226.325928, T: 4736, Avg. loss: 595802891376088475238400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4967235611.47, NNZs: 2, Bias: -27438532139.832005, T: 4864, Avg. loss: 720699658670165653979136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 10603520078.37, NNZs: 2, Bias: -27515426372.465912, T: 4992, Avg. loss: 461194517507810076393472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 660432037.39, NNZs: 2, Bias: -27432545455.349663, T: 5120, Avg. loss: 27399324515401637822464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 202207339.27, NNZs: 2, Bias: -27415351076.841328, T: 5248, Avg. loss: 189119921155813048320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 198385491.57, NNZs: 2, Bias: -27402075931.936108, T: 5376, Avg. loss: 105369805708209995776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 320130408.61, NNZs: 2, Bias: -27391216671.552635, T: 5504, Avg. loss: 72653769751140786176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 374833759.60, NNZs: 2, Bias: -27380280680.824780, T: 5632, Avg. loss: 85618017592810897408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 421622123.51, NNZs: 2, Bias: -27369756910.604176, T: 5760, Avg. loss: 80427977287685865472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 462092715.99, NNZs: 2, Bias: -27360275615.884087, T: 5888, Avg. loss: 73990547949327695872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 452532510.05, NNZs: 2, Bias: -27351231389.193260, T: 6016, Avg. loss: 76847185821177921536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 449557607.21, NNZs: 2, Bias: -27341473540.368313, T: 6144, Avg. loss: 80041724752566255616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 453334685.87, NNZs: 2, Bias: -27339459595.025650, T: 6272, Avg. loss: 67377086409525379072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 452229768.37, NNZs: 2, Bias: -27337542825.856865, T: 6400, Avg. loss: 66728826361657819136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 462941413.21, NNZs: 2, Bias: -27335486672.304405, T: 6528, Avg. loss: 64516967859186786304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 453450148.61, NNZs: 2, Bias: -27333739135.066574, T: 6656, Avg. loss: 65700158764906651648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 447264973.87, NNZs: 2, Bias: -27331905702.296558, T: 6784, Avg. loss: 66617410030751424512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 451741252.33, NNZs: 2, Bias: -27329905580.204433, T: 6912, Avg. loss: 66248458884033585152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 447323520.71, NNZs: 2, Bias: -27328036480.563770, T: 7040, Avg. loss: 66977751411545899008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 443776755.74, NNZs: 2, Bias: -27326184185.604782, T: 7168, Avg. loss: 65754263168828850176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 446548708.40, NNZs: 2, Bias: -27325752919.136677, T: 7296, Avg. loss: 64753828481037115392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 447437846.40, NNZs: 2, Bias: -27325354875.973267, T: 7424, Avg. loss: 64335275263077523456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 446906929.40, NNZs: 2, Bias: -27324979680.154549, T: 7552, Avg. loss: 64422211799953055744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 447819553.14, NNZs: 2, Bias: -27324582053.031342, T: 7680, Avg. loss: 64194978032697909248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 447366652.63, NNZs: 2, Bias: -27324205634.483231, T: 7808, Avg. loss: 64404008456779800576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 446497100.33, NNZs: 2, Bias: -27323836592.270882, T: 7936, Avg. loss: 64304509766196617216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 445099059.77, NNZs: 2, Bias: -27323475951.151611, T: 8064, Avg. loss: 64345024944489357312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 445732738.85, NNZs: 2, Bias: -27323081973.383583, T: 8192, Avg. loss: 64356634840071880704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 446520399.76, NNZs: 2, Bias: -27322686446.953987, T: 8320, Avg. loss: 64184437312429883392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 445478181.59, NNZs: 2, Bias: -27322319592.500496, T: 8448, Avg. loss: 64409448196124180480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 444788528.82, NNZs: 2, Bias: -27321947493.750767, T: 8576, Avg. loss: 64316340614898819072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 444630360.88, NNZs: 2, Bias: -27321565958.792362, T: 8704, Avg. loss: 64437182698956144640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 445314422.27, NNZs: 2, Bias: -27321171711.829372, T: 8832, Avg. loss: 64258242394665943040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 446047496.55, NNZs: 2, Bias: -27320776851.896008, T: 8960, Avg. loss: 64225705083215405056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 70 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 631509747314.80, NNZs: 2, Bias: -29963467702.143028, T: 128, Avg. loss: 19675354472828717379149103104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1919018045148.28, NNZs: 2, Bias: -69963467702.143036, T: 256, Avg. loss: 20126307776127764811311218688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1960291258438.33, NNZs: 2, Bias: 70036532297.856964, T: 384, Avg. loss: 18032653800674208296363622400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1755515184329.08, NNZs: 2, Bias: 25970190513.409912, T: 512, Avg. loss: 19246684486176686448217948160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1214402172691.78, NNZs: 2, Bias: 61497547638.761169, T: 640, Avg. loss: 18687127096020349196051677184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1756048880961.92, NNZs: 2, Bias: 12969133777.369003, T: 768, Avg. loss: 20746100314709599655097794560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1321536127973.97, NNZs: 2, Bias: 132969133777.369003, T: 896, Avg. loss: 20152099403417323833124716544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1451098455694.76, NNZs: 2, Bias: 52969133777.369019, T: 1024, Avg. loss: 19453992001924605211679129600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 320006916445.75, NNZs: 2, Bias: 65331318552.385902, T: 1152, Avg. loss: 1555212882380942313196093440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 96441231744.89, NNZs: 2, Bias: 68414950195.593613, T: 1280, Avg. loss: 761719651558542034799165440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 449433463018.62, NNZs: 2, Bias: 66850038730.578857, T: 1408, Avg. loss: 745577603514010074135658496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 369559752511.17, NNZs: 2, Bias: 74322891151.800659, T: 1536, Avg. loss: 786487483786063438554333184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 123933541601.96, NNZs: 2, Bias: 74256734333.920013, T: 1664, Avg. loss: 881038344551279534953988096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 367988523957.92, NNZs: 2, Bias: 51673350726.676506, T: 1792, Avg. loss: 743602290317151795077447680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 425762714101.21, NNZs: 2, Bias: 46556495605.292969, T: 1920, Avg. loss: 775521185473703520396902400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 526197931113.71, NNZs: 2, Bias: 33244368908.626305, T: 2048, Avg. loss: 830159664497872817547640832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 382160175680.43, NNZs: 2, Bias: 32188083271.244179, T: 2176, Avg. loss: 844788346337796152870567936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 274651757842.77, NNZs: 2, Bias: 41026597655.854347, T: 2304, Avg. loss: 862291167575838968275533824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 74808400492.50, NNZs: 2, Bias: 48272096809.833298, T: 2432, Avg. loss: 794331298952483571182338048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 25787271934.16, NNZs: 2, Bias: 44819288664.257805, T: 2560, Avg. loss: 29075339680226577534156800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 24097053232.58, NNZs: 2, Bias: 45857435505.679901, T: 2688, Avg. loss: 31879794135600715748343808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 45894153646.88, NNZs: 2, Bias: 46848652064.561615, T: 2816, Avg. loss: 31508862986214771789922304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 14794199497.84, NNZs: 2, Bias: 41823559034.743835, T: 2944, Avg. loss: 31170865228329348042326016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 16109421334.40, NNZs: 2, Bias: 39567516835.290695, T: 3072, Avg. loss: 30764247502691589018353664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 43330104218.82, NNZs: 2, Bias: 37748166510.358810, T: 3200, Avg. loss: 25855451136278491316617216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 18696843549.51, NNZs: 2, Bias: 38864743638.558151, T: 3328, Avg. loss: 31384549911961566827249664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 25581170046.12, NNZs: 2, Bias: 38822565455.716774, T: 3456, Avg. loss: 26637630613189013767454720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 19492181648.07, NNZs: 2, Bias: 40223267666.862335, T: 3584, Avg. loss: 29247212445368344628953088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 15092540491.02, NNZs: 2, Bias: 42438512725.147171, T: 3712, Avg. loss: 32006871150537040944168960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 33017120246.42, NNZs: 2, Bias: 43043758223.359047, T: 3840, Avg. loss: 26982444923493222285574144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 850969542.85, NNZs: 2, Bias: 43689308039.364395, T: 3968, Avg. loss: 742107909953396985036800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6272088704.48, NNZs: 2, Bias: 43672624199.971298, T: 4096, Avg. loss: 353136286344680428273664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 14709037513.87, NNZs: 2, Bias: 43679191033.476585, T: 4224, Avg. loss: 334729116359471474409472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4976804259.17, NNZs: 2, Bias: 43495942757.960579, T: 4352, Avg. loss: 504551333316069639061504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11719066510.21, NNZs: 2, Bias: 43081884546.615372, T: 4480, Avg. loss: 614034107630999717281792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 12429810951.15, NNZs: 2, Bias: 43008829616.031761, T: 4608, Avg. loss: 543840641639950286061568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8635698949.46, NNZs: 2, Bias: 43388185914.399529, T: 4736, Avg. loss: 510302719138685765287936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5464623433.04, NNZs: 2, Bias: 43583652752.459923, T: 4864, Avg. loss: 553994763408519479689216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1164519323.34, NNZs: 2, Bias: 43539822464.742760, T: 4992, Avg. loss: 5154224935801753436160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 941405629.27, NNZs: 2, Bias: 43527378237.938583, T: 5120, Avg. loss: 263796972109160448000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 807113792.73, NNZs: 2, Bias: 43514708709.821892, T: 5248, Avg. loss: 218188889021249748992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 766439216.79, NNZs: 2, Bias: 43499837200.776367, T: 5376, Avg. loss: 219283974585453477888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 693151375.32, NNZs: 2, Bias: 43486618413.841515, T: 5504, Avg. loss: 197564044262600114176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 722576067.21, NNZs: 2, Bias: 43471004920.107819, T: 5632, Avg. loss: 201406178213627625472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 655277167.46, NNZs: 2, Bias: 43456133536.416252, T: 5760, Avg. loss: 222733089875467993088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 673600795.34, NNZs: 2, Bias: 43441234394.401619, T: 5888, Avg. loss: 201419065397665693696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 717949507.14, NNZs: 2, Bias: 43426075994.916336, T: 6016, Avg. loss: 187865148313838747648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 700846517.09, NNZs: 2, Bias: 43411702733.179459, T: 6144, Avg. loss: 198224924801167556608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 670908261.26, NNZs: 2, Bias: 43396903811.626266, T: 6272, Avg. loss: 202470558276984733696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 672255063.46, NNZs: 2, Bias: 43381697750.478477, T: 6400, Avg. loss: 202647985667739090944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 632682328.03, NNZs: 2, Bias: 43367464846.783279, T: 6528, Avg. loss: 207588255607112237056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 658967520.84, NNZs: 2, Bias: 43352743748.447845, T: 6656, Avg. loss: 193326280716179013632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 685900690.00, NNZs: 2, Bias: 43349295923.944328, T: 6784, Avg. loss: 165470875093446787072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 691479131.34, NNZs: 2, Bias: 43346269147.109909, T: 6912, Avg. loss: 160594148060944498688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 693558453.55, NNZs: 2, Bias: 43343308988.758224, T: 7040, Avg. loss: 160095408166761103360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 693934971.43, NNZs: 2, Bias: 43340385740.691788, T: 7168, Avg. loss: 159774764746914168832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 699768713.30, NNZs: 2, Bias: 43337391434.406334, T: 7296, Avg. loss: 158807388960443269120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 692753317.04, NNZs: 2, Bias: 43334571185.830360, T: 7424, Avg. loss: 160771243069801758720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 684092883.24, NNZs: 2, Bias: 43331778248.549385, T: 7552, Avg. loss: 160609319814234734592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 693434851.63, NNZs: 2, Bias: 43328678532.992485, T: 7680, Avg. loss: 161498587954804883456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 690701669.87, NNZs: 2, Bias: 43325813694.197327, T: 7808, Avg. loss: 159286489610755211264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 681139571.38, NNZs: 2, Bias: 43323101651.574654, T: 7936, Avg. loss: 156853209822835736576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 692641961.72, NNZs: 2, Bias: 43319939873.292435, T: 8064, Avg. loss: 162845479864080924672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 691217684.81, NNZs: 2, Bias: 43317021201.098175, T: 8192, Avg. loss: 161125415673101320192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 701347845.37, NNZs: 2, Bias: 43313926673.603783, T: 8320, Avg. loss: 160477584352443695104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 690406970.91, NNZs: 2, Bias: 43311164023.229713, T: 8448, Avg. loss: 160951089764655071232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 694393802.52, NNZs: 2, Bias: 43308151756.751358, T: 8576, Avg. loss: 161042770612590739456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 695992470.52, NNZs: 2, Bias: 43307542948.862526, T: 8704, Avg. loss: 155128554475504566272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 695798732.44, NNZs: 2, Bias: 43306961822.459297, T: 8832, Avg. loss: 155451753472081625088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 696501354.05, NNZs: 2, Bias: 43306366893.939568, T: 8960, Avg. loss: 155268341339282145280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 694133802.50, NNZs: 2, Bias: 43305823060.096016, T: 9088, Avg. loss: 154827566895967240192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 696387721.95, NNZs: 2, Bias: 43305205017.730850, T: 9216, Avg. loss: 154756740744514273280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 697123766.13, NNZs: 2, Bias: 43304610499.865479, T: 9344, Avg. loss: 155007527564901089280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 693454443.00, NNZs: 2, Bias: 43304086890.632004, T: 9472, Avg. loss: 155053988611822977024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 693493378.59, NNZs: 2, Bias: 43303502960.867760, T: 9600, Avg. loss: 155174196577283735552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 694718419.47, NNZs: 2, Bias: 43302898715.219666, T: 9728, Avg. loss: 155502511760339501056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 693808779.70, NNZs: 2, Bias: 43302330303.220512, T: 9856, Avg. loss: 155119616567961681920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 77 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 875259983021.66, NNZs: 2, Bias: -21997605737.105011, T: 128, Avg. loss: 20115675256188047399919288320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1001786383424.97, NNZs: 2, Bias: -90150585082.422256, T: 256, Avg. loss: 22147754647225652199534100480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1062348266727.15, NNZs: 2, Bias: -56906628768.995361, T: 384, Avg. loss: 22074642713754433743153528832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 938654117421.32, NNZs: 2, Bias: -54753669022.409409, T: 512, Avg. loss: 19150325166416872739560226816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1839643136020.47, NNZs: 2, Bias: -34753669022.409409, T: 640, Avg. loss: 22409159709969973395387842560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2140378616226.36, NNZs: 2, Bias: -94753669022.409409, T: 768, Avg. loss: 20295719211876434574571470848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1409599693893.23, NNZs: 2, Bias: -168147884174.770233, T: 896, Avg. loss: 19323455408799763485863968768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 744343300875.57, NNZs: 2, Bias: -68147884174.770233, T: 1024, Avg. loss: 19314140879278173082326401024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 686270775308.34, NNZs: 2, Bias: -67886426169.344330, T: 1152, Avg. loss: 18995361692289220449916682240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1731943272100.20, NNZs: 2, Bias: -7886426169.344330, T: 1280, Avg. loss: 20961564847321469571286695936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 813492643112.74, NNZs: 2, Bias: 52113573830.655670, T: 1408, Avg. loss: 21299013919853567900666298368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1769213136793.91, NNZs: 2, Bias: 52113573830.655670, T: 1536, Avg. loss: 22388817148829218975464292352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 868871081306.50, NNZs: 2, Bias: 49224620980.350876, T: 1664, Avg. loss: 22089211978265193112661917696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 84011106128.92, NNZs: 2, Bias: 124020890473.643433, T: 1792, Avg. loss: 20792146731284626434032664576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 288374696088.41, NNZs: 2, Bias: 118758999421.530426, T: 1920, Avg. loss: 849718592633898980211687424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 176841615367.38, NNZs: 2, Bias: 141560318356.081665, T: 2048, Avg. loss: 806748717654448720337436672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 182086349380.54, NNZs: 2, Bias: 139278498657.688629, T: 2176, Avg. loss: 800893181968052136131428352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 526157341310.48, NNZs: 2, Bias: 144472637085.107452, T: 2304, Avg. loss: 806714221215917835781406720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 571240130294.14, NNZs: 2, Bias: 128472637085.107452, T: 2432, Avg. loss: 782060190138141987143942144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 242007707730.61, NNZs: 2, Bias: 126238090753.278702, T: 2560, Avg. loss: 778343957164584652920324096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 313711396749.92, NNZs: 2, Bias: 125924638813.315384, T: 2688, Avg. loss: 737409362735421924837425152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 445120776567.87, NNZs: 2, Bias: 112108432435.052109, T: 2816, Avg. loss: 793453888907961140259061760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 294211414745.61, NNZs: 2, Bias: 94015669019.541885, T: 2944, Avg. loss: 814709620859828740592500736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 149704238566.26, NNZs: 2, Bias: 84425331751.015198, T: 3072, Avg. loss: 776907576075327728821207040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 269835130601.38, NNZs: 2, Bias: 78530135558.647064, T: 3200, Avg. loss: 821906436582958503945043968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 126400756352.32, NNZs: 2, Bias: 69733284881.072754, T: 3328, Avg. loss: 853677907101311813489262592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 80305195782.85, NNZs: 2, Bias: 66817693973.087738, T: 3456, Avg. loss: 35519238593861507488940032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 45381620457.61, NNZs: 2, Bias: 67083333488.722130, T: 3584, Avg. loss: 28344980750375116884410368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 33022736687.69, NNZs: 2, Bias: 67989470938.542770, T: 3712, Avg. loss: 28364826161090667279810560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 99472466703.98, NNZs: 2, Bias: 67587979725.805824, T: 3840, Avg. loss: 28095787452032273453416448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 79399359912.79, NNZs: 2, Bias: 67839076080.933197, T: 3968, Avg. loss: 28987124040896124486156288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 41140072771.55, NNZs: 2, Bias: 70663246278.789841, T: 4096, Avg. loss: 31599575706407588966957056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 39786249742.88, NNZs: 2, Bias: 70305260097.892166, T: 4224, Avg. loss: 33155103383784650090479616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3046501875.44, NNZs: 2, Bias: 68343670182.518982, T: 4352, Avg. loss: 29445384113463280762093568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 113530248538.77, NNZs: 2, Bias: 68847710273.549927, T: 4480, Avg. loss: 31772520608597429077409792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9048335942.12, NNZs: 2, Bias: 68281131789.195168, T: 4608, Avg. loss: 4631271314213759738707968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3640342750.63, NNZs: 2, Bias: 68382844647.911621, T: 4736, Avg. loss: 676172688524870183550976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3867252249.46, NNZs: 2, Bias: 68347354489.306290, T: 4864, Avg. loss: 600916290304829638574080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1559560900.88, NNZs: 2, Bias: 68511700571.379463, T: 4992, Avg. loss: 641522945998811266285568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3226986215.43, NNZs: 2, Bias: 68268031184.750404, T: 5120, Avg. loss: 595590814075831782998016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 13908892496.89, NNZs: 2, Bias: 68089729369.057930, T: 5248, Avg. loss: 563426058685740732121088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4078642157.61, NNZs: 2, Bias: 67916796232.599419, T: 5376, Avg. loss: 414312037465735561216000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 13036378565.90, NNZs: 2, Bias: 67833891754.889351, T: 5504, Avg. loss: 674552399077586130436096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3205997034.45, NNZs: 2, Bias: 67845389911.632668, T: 5632, Avg. loss: 492333398535952104685568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 12161371729.45, NNZs: 2, Bias: 67703641488.233498, T: 5760, Avg. loss: 502407383656052987789312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4305336245.50, NNZs: 2, Bias: 67404593145.327797, T: 5888, Avg. loss: 682996955339258396147712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 10044541800.89, NNZs: 2, Bias: 67347065405.495506, T: 6016, Avg. loss: 549856451494572174868480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4693514769.52, NNZs: 2, Bias: 67410374669.261421, T: 6144, Avg. loss: 12972640722145614233600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2947523455.28, NNZs: 2, Bias: 67417292167.033386, T: 6272, Avg. loss: 2097227479570898223104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2054884958.72, NNZs: 2, Bias: 67410194680.112221, T: 6400, Avg. loss: 919998087274270687232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1668277189.64, NNZs: 2, Bias: 67395585915.680748, T: 6528, Avg. loss: 544498077898531864576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1444963236.25, NNZs: 2, Bias: 67379201612.295670, T: 6656, Avg. loss: 452697423879132545024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1370199317.01, NNZs: 2, Bias: 67361058488.712852, T: 6784, Avg. loss: 409720148223710003200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1307916213.56, NNZs: 2, Bias: 67342662968.538017, T: 6912, Avg. loss: 400259585812230373376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1307996895.44, NNZs: 2, Bias: 67322197548.063782, T: 7040, Avg. loss: 417237135044157636608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1300705142.89, NNZs: 2, Bias: 67302121260.377182, T: 7168, Avg. loss: 416685985283727949824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1225337776.85, NNZs: 2, Bias: 67282675582.372414, T: 7296, Avg. loss: 427262711136238043136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1161456613.30, NNZs: 2, Bias: 67262565718.129852, T: 7424, Avg. loss: 449679507978560274432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1170859159.56, NNZs: 2, Bias: 67240863442.136940, T: 7552, Avg. loss: 443317502226057199616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1165710722.44, NNZs: 2, Bias: 67236750000.390556, T: 7680, Avg. loss: 356983764288704675840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1163921299.46, NNZs: 2, Bias: 67232642164.649231, T: 7808, Avg. loss: 351021292449694089216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1153791079.22, NNZs: 2, Bias: 67228620304.896942, T: 7936, Avg. loss: 356492724284175482880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1155693782.85, NNZs: 2, Bias: 67224470481.588005, T: 8064, Avg. loss: 349147721588624392192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1148122902.12, NNZs: 2, Bias: 67220323822.931000, T: 8192, Avg. loss: 363174546796366397440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1148288492.83, NNZs: 2, Bias: 67216092727.821381, T: 8320, Avg. loss: 358110945001969221632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1152893546.62, NNZs: 2, Bias: 67211760758.070015, T: 8448, Avg. loss: 360373926669230342144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1164972090.49, NNZs: 2, Bias: 67207347381.880798, T: 8576, Avg. loss: 355592572652879544320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1152960322.72, NNZs: 2, Bias: 67203317982.104790, T: 8704, Avg. loss: 359978725282250752000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1158928277.45, NNZs: 2, Bias: 67202366880.119492, T: 8832, Avg. loss: 350037549842842910720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1161496971.27, NNZs: 2, Bias: 67201481479.640755, T: 8960, Avg. loss: 347048538530174205952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1163180891.51, NNZs: 2, Bias: 67200613032.529633, T: 9088, Avg. loss: 346368292213723889664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1164041457.30, NNZs: 2, Bias: 67199757326.429642, T: 9216, Avg. loss: 346994228438494347264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1161815147.05, NNZs: 2, Bias: 67198954785.103127, T: 9344, Avg. loss: 347185034692098392064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1163140865.32, NNZs: 2, Bias: 67198091085.780640, T: 9472, Avg. loss: 346923212609019510784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1161467749.77, NNZs: 2, Bias: 67197279065.539047, T: 9600, Avg. loss: 347117412891768324096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1164308004.61, NNZs: 2, Bias: 67196388836.230522, T: 9728, Avg. loss: 347051795289007325184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 76 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2023229482800.72, NNZs: 2, Bias: -6227961020.716583, T: 128, Avg. loss: 21126182500584434945434320896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2695735266197.46, NNZs: 2, Bias: 68878080237.936340, T: 256, Avg. loss: 21458829931183949133939474432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2267754649541.10, NNZs: 2, Bias: 88878080237.936340, T: 384, Avg. loss: 24975855623748417993603809280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 850475930041.62, NNZs: 2, Bias: 128878080237.936340, T: 512, Avg. loss: 24777702219942194345513320448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2640976814678.63, NNZs: 2, Bias: 93234628951.757690, T: 640, Avg. loss: 21818460591156323516896247808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 444066493563.09, NNZs: 2, Bias: 42475860325.622391, T: 768, Avg. loss: 25032704319499303998782963712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 253976697831.73, NNZs: 2, Bias: 39010541964.469879, T: 896, Avg. loss: 917177017995940455319076864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 205292641290.81, NNZs: 2, Bias: 44200166980.566422, T: 1024, Avg. loss: 928375845719320846758051840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 151704364787.21, NNZs: 2, Bias: 44969998059.371010, T: 1152, Avg. loss: 848845498532507909089132544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 142939432643.57, NNZs: 2, Bias: 41243254752.623825, T: 1280, Avg. loss: 815687321512133648917200896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 319405173456.15, NNZs: 2, Bias: 44381280418.447044, T: 1408, Avg. loss: 845682237443919223424286720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 245344631495.29, NNZs: 2, Bias: 8009614900.935295, T: 1536, Avg. loss: 893350220909172469067153408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 139618395674.42, NNZs: 2, Bias: 8892174202.301323, T: 1664, Avg. loss: 870483259666563640563073024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 194213689664.05, NNZs: 2, Bias: -7114927371.409332, T: 1792, Avg. loss: 945221459593877301541994496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 579400474185.29, NNZs: 2, Bias: -4207309402.003906, T: 1920, Avg. loss: 897860099693022510804107264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 50838523113.42, NNZs: 2, Bias: 3949321087.607345, T: 2048, Avg. loss: 174792967308196126618812416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 18576770808.25, NNZs: 2, Bias: 4562778296.587188, T: 2176, Avg. loss: 30822354561315004661891072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 45838040472.28, NNZs: 2, Bias: 5246562234.753775, T: 2304, Avg. loss: 32647143841924235768365056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 5330669521.08, NNZs: 2, Bias: 3739888650.512218, T: 2432, Avg. loss: 33310741785639524390404096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 15625518076.40, NNZs: 2, Bias: 2780912382.972363, T: 2560, Avg. loss: 32982845367110634743791616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 9942599811.78, NNZs: 2, Bias: 5576772504.093535, T: 2688, Avg. loss: 33206230723040842350592000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 28780137568.95, NNZs: 2, Bias: 1778298607.910293, T: 2816, Avg. loss: 33407134229766584196399104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2779110358.44, NNZs: 2, Bias: 2558422420.047338, T: 2944, Avg. loss: 627713116678973103800320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 7106312935.67, NNZs: 2, Bias: 2686777653.379951, T: 3072, Avg. loss: 501699781317082692452352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1031667677.96, NNZs: 2, Bias: 2588989419.304109, T: 3200, Avg. loss: 603155694457581075431424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 5898509168.32, NNZs: 2, Bias: 2291261877.580291, T: 3328, Avg. loss: 509483058003008511016960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2456965388.23, NNZs: 2, Bias: 2156859934.533613, T: 3456, Avg. loss: 616689987682952305180672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2594121819.56, NNZs: 2, Bias: 2257305322.093417, T: 3584, Avg. loss: 652584177399185788633088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4362425261.99, NNZs: 2, Bias: 2211037605.366058, T: 3712, Avg. loss: 490432704517371276034048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 11450651426.16, NNZs: 2, Bias: 2278488869.696654, T: 3840, Avg. loss: 604039417243262701797376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1399407128.80, NNZs: 2, Bias: 2568828984.031433, T: 3968, Avg. loss: 645571755294970257342464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3385334188.97, NNZs: 2, Bias: 2423496245.826799, T: 4096, Avg. loss: 457858930776376174706688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7571171307.18, NNZs: 2, Bias: 2450011906.600498, T: 4224, Avg. loss: 483110388218362081574912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 17893694392.61, NNZs: 2, Bias: 2774758862.214255, T: 4352, Avg. loss: 694978387145931280613376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 8745588228.02, NNZs: 2, Bias: 2613484084.468837, T: 4480, Avg. loss: 696031927658091349278720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4792210864.34, NNZs: 2, Bias: 2595992187.660688, T: 4608, Avg. loss: 451563265575957357920256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6685352658.04, NNZs: 2, Bias: 2453525671.035990, T: 4736, Avg. loss: 453642156025119269453824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 12309001626.74, NNZs: 2, Bias: 2528919945.069734, T: 4864, Avg. loss: 485343301678449718984704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4007488521.57, NNZs: 2, Bias: 2392657294.166545, T: 4992, Avg. loss: 713354012691503203221504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 6162075813.21, NNZs: 2, Bias: 2342022345.923183, T: 5120, Avg. loss: 817158359225139791396864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 5366699583.40, NNZs: 2, Bias: 2524978192.664981, T: 5248, Avg. loss: 528695916837767718371328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 751069583.28, NNZs: 2, Bias: 2558967792.068832, T: 5376, Avg. loss: 5867036658354296455168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 416349812.66, NNZs: 2, Bias: 2563094725.112499, T: 5504, Avg. loss: 58448756966348816384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 238297540.43, NNZs: 2, Bias: 2564691522.326163, T: 5632, Avg. loss: 18530133807200100352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 140608967.38, NNZs: 2, Bias: 2565279719.256618, T: 5760, Avg. loss: 5848657240777216000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 93401159.68, NNZs: 2, Bias: 2565165406.749599, T: 5888, Avg. loss: 2063047004819409664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 69948045.88, NNZs: 2, Bias: 2564646463.303856, T: 6016, Avg. loss: 1121557366459970432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 55761386.64, NNZs: 2, Bias: 2564036185.821422, T: 6144, Avg. loss: 785539456263601280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 45845771.21, NNZs: 2, Bias: 2563380185.669516, T: 6272, Avg. loss: 717250175123973632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 43802033.24, NNZs: 2, Bias: 2562517273.770627, T: 6400, Avg. loss: 734663028874161664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 42326366.05, NNZs: 2, Bias: 2561670520.429632, T: 6528, Avg. loss: 692654314149595136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 37316598.10, NNZs: 2, Bias: 2560930349.256858, T: 6656, Avg. loss: 659562241773698048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 39066447.03, NNZs: 2, Bias: 2560071606.420305, T: 6784, Avg. loss: 656686016082776192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 38822370.98, NNZs: 2, Bias: 2559198557.873034, T: 6912, Avg. loss: 719975056149658240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 37094944.59, NNZs: 2, Bias: 2558371201.310386, T: 7040, Avg. loss: 698993036113412096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 39507213.79, NNZs: 2, Bias: 2557475957.577822, T: 7168, Avg. loss: 679449092642871936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 37987984.70, NNZs: 2, Bias: 2556635972.873989, T: 7296, Avg. loss: 686957951383158400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 39641706.69, NNZs: 2, Bias: 2555716547.641708, T: 7424, Avg. loss: 697269042298909312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 39267087.43, NNZs: 2, Bias: 2555549156.410406, T: 7552, Avg. loss: 560470915003299776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 39676515.91, NNZs: 2, Bias: 2555371179.759130, T: 7680, Avg. loss: 553242154782015680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 39177293.37, NNZs: 2, Bias: 2555204291.835864, T: 7808, Avg. loss: 563856584465759936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 39546172.69, NNZs: 2, Bias: 2555026240.531130, T: 7936, Avg. loss: 555125411915441984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 39311565.34, NNZs: 2, Bias: 2554855994.392864, T: 8064, Avg. loss: 561255707155506368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 39752579.64, NNZs: 2, Bias: 2554678725.630962, T: 8192, Avg. loss: 549197421626855744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 39270306.08, NNZs: 2, Bias: 2554520502.001999, T: 8320, Avg. loss: 534649972717179264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 39752353.49, NNZs: 2, Bias: 2554337369.376410, T: 8448, Avg. loss: 567007486939674240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 40213795.66, NNZs: 2, Bias: 2554156479.276493, T: 8576, Avg. loss: 559241908246987456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 40054664.28, NNZs: 2, Bias: 2553986429.862454, T: 8704, Avg. loss: 557049414043322816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 39811777.96, NNZs: 2, Bias: 2553818755.652230, T: 8832, Avg. loss: 552681710518830080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 39920654.11, NNZs: 2, Bias: 2553645190.174089, T: 8960, Avg. loss: 553385966233372736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 39893641.07, NNZs: 2, Bias: 2553611269.498589, T: 9088, Avg. loss: 538730363889419392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 39770743.42, NNZs: 2, Bias: 2553579023.694426, T: 9216, Avg. loss: 535956842121805824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 39762134.59, NNZs: 2, Bias: 2553544829.452166, T: 9344, Avg. loss: 538490520534956224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 39761697.98, NNZs: 2, Bias: 2553510496.474402, T: 9472, Avg. loss: 538692938317984384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 39895192.36, NNZs: 2, Bias: 2553474098.144571, T: 9600, Avg. loss: 538124320640005760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 795322349259.89, NNZs: 2, Bias: 3335782435.258423, T: 128, Avg. loss: 24046825978265631664377954304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1782142989368.69, NNZs: 2, Bias: -53687881415.748047, T: 256, Avg. loss: 22583440523209532267892310016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 998829207603.85, NNZs: 2, Bias: -59903615087.963608, T: 384, Avg. loss: 26692047351809064442280280064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2064616962352.23, NNZs: 2, Bias: 96384912.036392, T: 512, Avg. loss: 24058954010175677835901927424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2174498501735.78, NNZs: 2, Bias: -19903615087.963608, T: 640, Avg. loss: 25304193695343878815185108992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2164845604694.57, NNZs: 2, Bias: -23961591773.305756, T: 768, Avg. loss: 23276140356761223008582893568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2177022315340.38, NNZs: 2, Bias: -19220099712.074738, T: 896, Avg. loss: 24788162713275517009171316736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 237684636016.87, NNZs: 2, Bias: -21071752525.976757, T: 1024, Avg. loss: 2630527114850833872346677248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 237778066006.84, NNZs: 2, Bias: -28905008228.033321, T: 1152, Avg. loss: 937683021759272530680479744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 405420973457.68, NNZs: 2, Bias: -39891533638.985680, T: 1280, Avg. loss: 924949624813388622846754816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 227089402568.69, NNZs: 2, Bias: -39102924407.532196, T: 1408, Avg. loss: 970340054911733918039277568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 258640822358.33, NNZs: 2, Bias: -18458692161.548916, T: 1536, Avg. loss: 958525758716152073896853504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 345261831520.00, NNZs: 2, Bias: -19023307240.213852, T: 1664, Avg. loss: 884251407572881909150121984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 149377290442.34, NNZs: 2, Bias: -40384702129.663170, T: 1792, Avg. loss: 898271613501770698724474880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 325477251543.48, NNZs: 2, Bias: -47066223553.367905, T: 1920, Avg. loss: 903199527532372017304043520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 399344895510.41, NNZs: 2, Bias: -37132098186.851830, T: 2048, Avg. loss: 955199980269199322574225408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 122189494956.93, NNZs: 2, Bias: -59779103899.104584, T: 2176, Avg. loss: 885651554068365902339899392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 128563544063.18, NNZs: 2, Bias: -62616924272.282204, T: 2304, Avg. loss: 1019568045317564683973033984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 41670778861.48, NNZs: 2, Bias: -61036004064.603172, T: 2432, Avg. loss: 38218362209401632261668864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 75301162073.61, NNZs: 2, Bias: -60603290192.003777, T: 2560, Avg. loss: 32154467644733769744646144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 50281828179.03, NNZs: 2, Bias: -59929402265.110054, T: 2688, Avg. loss: 37748042981728565443166208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 64763606744.59, NNZs: 2, Bias: -61161675883.320366, T: 2816, Avg. loss: 34201742903229731062153216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 63563588547.36, NNZs: 2, Bias: -62714740897.072739, T: 2944, Avg. loss: 34518545621446934646489088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 81914246584.04, NNZs: 2, Bias: -61520014814.371262, T: 3072, Avg. loss: 33530903045970043850457088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 66560787159.91, NNZs: 2, Bias: -63948162846.042770, T: 3200, Avg. loss: 34799709912235017079095296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8205428625.63, NNZs: 2, Bias: -62877888285.716881, T: 3328, Avg. loss: 1382469186236718629519360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 20234303502.69, NNZs: 2, Bias: -62691772499.202812, T: 3456, Avg. loss: 652037952510554521206784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 14555720465.85, NNZs: 2, Bias: -62694101965.480774, T: 3584, Avg. loss: 630925382017303445504000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2018214431.89, NNZs: 2, Bias: -62722901864.127129, T: 3712, Avg. loss: 737401247572533337653248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4494878937.25, NNZs: 2, Bias: -62339668680.849693, T: 3840, Avg. loss: 681901303380677824086016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6238280165.03, NNZs: 2, Bias: -61987345533.676140, T: 3968, Avg. loss: 569226866053168148512768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 17963018614.87, NNZs: 2, Bias: -61993048406.611313, T: 4096, Avg. loss: 837095741039098399293440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4800836611.08, NNZs: 2, Bias: -61466200710.106209, T: 4224, Avg. loss: 895002625882254452195328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2220948193.78, NNZs: 2, Bias: -61309673831.756119, T: 4352, Avg. loss: 629129042756084145586176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11214855864.09, NNZs: 2, Bias: -61661738440.902809, T: 4480, Avg. loss: 692797821096825685278720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2173543751.46, NNZs: 2, Bias: -61865311415.872993, T: 4608, Avg. loss: 733735423871298603843584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1007470022.22, NNZs: 2, Bias: -61839177067.827408, T: 4736, Avg. loss: 1413070290266847969280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 912363840.49, NNZs: 2, Bias: -61822718484.310593, T: 4864, Avg. loss: 345230502089064710144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 921969313.55, NNZs: 2, Bias: -61804742401.986267, T: 4992, Avg. loss: 328829712336641982464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 890089665.84, NNZs: 2, Bias: -61786958425.160408, T: 5120, Avg. loss: 354350857441229012992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922298751.84, NNZs: 2, Bias: -61768413084.894402, T: 5248, Avg. loss: 342170500869146214400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 890752105.78, NNZs: 2, Bias: -61750735206.386383, T: 5376, Avg. loss: 343366530083471884288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 856299041.01, NNZs: 2, Bias: -61733216799.455864, T: 5504, Avg. loss: 354576407225052692480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 919167687.64, NNZs: 2, Bias: -61714530007.361687, T: 5632, Avg. loss: 340225598130831687680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 890489981.27, NNZs: 2, Bias: -61711253486.826431, T: 5760, Avg. loss: 288429414336158334976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 890980011.67, NNZs: 2, Bias: -61707618551.554718, T: 5888, Avg. loss: 282622243164010610688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 899032309.83, NNZs: 2, Bias: -61703909092.490150, T: 6016, Avg. loss: 279089877712488759296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 893964322.14, NNZs: 2, Bias: -61700347906.701828, T: 6144, Avg. loss: 283023346007021256704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 909153359.15, NNZs: 2, Bias: -61696539385.901672, T: 6272, Avg. loss: 278820438886714966016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 902105913.38, NNZs: 2, Bias: -61693068614.657440, T: 6400, Avg. loss: 277968879474532974592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 897219470.70, NNZs: 2, Bias: -61689559355.721130, T: 6528, Avg. loss: 277937939352952045568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 904158104.49, NNZs: 2, Bias: -61685870031.407074, T: 6656, Avg. loss: 278991813789902372864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 901927001.88, NNZs: 2, Bias: -61682264206.040657, T: 6784, Avg. loss: 283162200617944612864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 914472747.71, NNZs: 2, Bias: -61678555213.630714, T: 6912, Avg. loss: 274082903584439271424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 900030078.46, NNZs: 2, Bias: -61675134693.145386, T: 7040, Avg. loss: 282353025963764842496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 909247631.26, NNZs: 2, Bias: -61671383857.205162, T: 7168, Avg. loss: 280620168223898632192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 905161667.77, NNZs: 2, Bias: -61667846287.068390, T: 7296, Avg. loss: 280186755998206492672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 905269489.72, NNZs: 2, Bias: -61664211895.112732, T: 7424, Avg. loss: 282643747346092195840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 909730859.24, NNZs: 2, Bias: -61660554860.326607, T: 7552, Avg. loss: 279763999082998366208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 907921236.63, NNZs: 2, Bias: -61659865330.976898, T: 7680, Avg. loss: 271203791594787897344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 909682564.53, NNZs: 2, Bias: -61659121724.925476, T: 7808, Avg. loss: 271685503228685516800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 912732030.67, NNZs: 2, Bias: -61658360727.689980, T: 7936, Avg. loss: 270999662532341006336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 910999455.70, NNZs: 2, Bias: -61657668590.170883, T: 8064, Avg. loss: 271793922558387486720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 910752390.84, NNZs: 2, Bias: -61656955204.451920, T: 8192, Avg. loss: 271482194525998088192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 908984640.30, NNZs: 2, Bias: -61656264794.510818, T: 8320, Avg. loss: 271307068276956561408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 909168165.68, NNZs: 2, Bias: -61655545413.396057, T: 8448, Avg. loss: 271338295395429908480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 905607813.45, NNZs: 2, Bias: -61654885490.212425, T: 8576, Avg. loss: 269772289748443725824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 909478502.78, NNZs: 2, Bias: -61654109716.145493, T: 8704, Avg. loss: 272074425807470198784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 910569838.88, NNZs: 2, Bias: -61653377445.635460, T: 8832, Avg. loss: 271122042592835272704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 908526635.17, NNZs: 2, Bias: -61652693659.426056, T: 8960, Avg. loss: 270303360815877980160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 908003928.62, NNZs: 2, Bias: -61651985457.578468, T: 9088, Avg. loss: 271028300358022201344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 912233553.33, NNZs: 2, Bias: -61651207563.819633, T: 9216, Avg. loss: 270729785735077134336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 72 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1145748171662.79, NNZs: 2, Bias: -29293468452.881363, T: 128, Avg. loss: 18941822374725394479240445952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2162381159995.75, NNZs: 2, Bias: -21908972004.377357, T: 256, Avg. loss: 20318571040960977174905487360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1742130399552.99, NNZs: 2, Bias: 64063823299.340866, T: 384, Avg. loss: 19543027996100104609020772352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 893118834650.83, NNZs: 2, Bias: 21967123631.117432, T: 512, Avg. loss: 23336090764837725519973711872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1186042944506.73, NNZs: 2, Bias: 39482155223.283997, T: 640, Avg. loss: 20836405896593965428571635712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1520376859019.99, NNZs: 2, Bias: -60483386684.254311, T: 768, Avg. loss: 22049838834138532186586873856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 192236799145.92, NNZs: 2, Bias: -87310987757.889114, T: 896, Avg. loss: 997878266185289280826376192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 282409898723.93, NNZs: 2, Bias: -79957963183.622726, T: 1024, Avg. loss: 850701574709195838259724288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 164442157809.16, NNZs: 2, Bias: -89975843247.681900, T: 1152, Avg. loss: 871399925149658613937078272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 370076182500.60, NNZs: 2, Bias: -90510269380.568100, T: 1280, Avg. loss: 836191768398757712929751040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 266520208037.20, NNZs: 2, Bias: -68589887773.952682, T: 1408, Avg. loss: 793571336639630877971709952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 129917879409.01, NNZs: 2, Bias: -73572979991.794861, T: 1536, Avg. loss: 838464242316215194344226816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 115809386127.40, NNZs: 2, Bias: -74334200855.538574, T: 1664, Avg. loss: 831099101918510007483105280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 290660762516.65, NNZs: 2, Bias: -65015860856.527832, T: 1792, Avg. loss: 799917407294406680553455616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 215225560662.29, NNZs: 2, Bias: -62512005812.585190, T: 1920, Avg. loss: 837960075835348649427075072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 24423635570.80, NNZs: 2, Bias: -69253103650.116089, T: 2048, Avg. loss: 868042474060537390738440192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 91866703526.19, NNZs: 2, Bias: -65424754584.995956, T: 2176, Avg. loss: 31439050068692465872797696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 22009074771.93, NNZs: 2, Bias: -66517564753.108528, T: 2304, Avg. loss: 34674132917596854192963584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 65256100684.75, NNZs: 2, Bias: -66823157467.340546, T: 2432, Avg. loss: 30790472360133563965767680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 6611198023.28, NNZs: 2, Bias: -65023561176.297943, T: 2560, Avg. loss: 31862860299371970381742080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 16001612615.29, NNZs: 2, Bias: -66546634882.901436, T: 2688, Avg. loss: 30024376370171237145509888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 31035424946.92, NNZs: 2, Bias: -69628018985.725540, T: 2816, Avg. loss: 29775660960863225452167168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 42121936503.04, NNZs: 2, Bias: -66192742301.161537, T: 2944, Avg. loss: 31817835354270742637182976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 41301877167.45, NNZs: 2, Bias: -62909511612.935326, T: 3072, Avg. loss: 36574624569673966004731904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 43049009289.02, NNZs: 2, Bias: -62785364964.759079, T: 3200, Avg. loss: 31569860307067477180809216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 64331027074.42, NNZs: 2, Bias: -66891255557.740700, T: 3328, Avg. loss: 29045748425141351587250176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 31363857751.75, NNZs: 2, Bias: -67240024385.951401, T: 3456, Avg. loss: 28359300449573386862985216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 14076583421.79, NNZs: 2, Bias: -68516434502.627197, T: 3584, Avg. loss: 30308149732599730790203392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 35933875036.76, NNZs: 2, Bias: -67374882818.962540, T: 3712, Avg. loss: 32236514384360525526990848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8648627148.87, NNZs: 2, Bias: -65339860301.614815, T: 3840, Avg. loss: 32231801496076918521331712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 68012311287.64, NNZs: 2, Bias: -65629049051.905991, T: 3968, Avg. loss: 27855412658051469033865216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 49644187236.51, NNZs: 2, Bias: -66614769354.442429, T: 4096, Avg. loss: 31077753028980636194439168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 82207946791.48, NNZs: 2, Bias: -63030796933.563599, T: 4224, Avg. loss: 33638053512793573449269248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 23652480566.02, NNZs: 2, Bias: -63114821651.121155, T: 4352, Avg. loss: 37613539596722123994824704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 92918761684.02, NNZs: 2, Bias: -63821849721.973404, T: 4480, Avg. loss: 30097771382350262183133184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 24053106307.69, NNZs: 2, Bias: -61859894767.838493, T: 4608, Avg. loss: 34819610363588556051447808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6951471581.69, NNZs: 2, Bias: -61386699142.350548, T: 4736, Avg. loss: 608297752148439470178304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4289847968.11, NNZs: 2, Bias: -61281184859.123970, T: 4864, Avg. loss: 575075558225634356363264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 5393951436.89, NNZs: 2, Bias: -61221637100.987198, T: 4992, Avg. loss: 528778306959592378073088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 12465896565.37, NNZs: 2, Bias: -61093468046.694489, T: 5120, Avg. loss: 590675429860713223421952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 16677420269.51, NNZs: 2, Bias: -61084492369.563042, T: 5248, Avg. loss: 679822699536180773388288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4545864935.17, NNZs: 2, Bias: -60894674048.031563, T: 5376, Avg. loss: 675539580272323590094848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3421518939.54, NNZs: 2, Bias: -60734544448.340141, T: 5504, Avg. loss: 625149668487801048399872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 15303814849.13, NNZs: 2, Bias: -60666630369.466652, T: 5632, Avg. loss: 558561823831476727185408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1533175449.50, NNZs: 2, Bias: -60566413188.324997, T: 5760, Avg. loss: 70614429375257731137536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1281850876.37, NNZs: 2, Bias: -60550799971.025139, T: 5888, Avg. loss: 419226330031832432640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1143048790.71, NNZs: 2, Bias: -60531638895.043449, T: 6016, Avg. loss: 412676671557296914432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1126504091.66, NNZs: 2, Bias: -60511327621.757530, T: 6144, Avg. loss: 371276477176786780160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1028972665.32, NNZs: 2, Bias: -60490837070.492599, T: 6272, Avg. loss: 428401723666645254144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 989763930.68, NNZs: 2, Bias: -60469589741.202698, T: 6400, Avg. loss: 414669494223297511424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 909486706.36, NNZs: 2, Bias: -60448916116.310257, T: 6528, Avg. loss: 415158517170000429056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 973063662.66, NNZs: 2, Bias: -60426693261.661728, T: 6656, Avg. loss: 392398849607034798080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 997250606.92, NNZs: 2, Bias: -60405510471.752754, T: 6784, Avg. loss: 363348595831573774336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 967610934.45, NNZs: 2, Bias: -60385674244.269913, T: 6912, Avg. loss: 360073268309242740736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 971991025.30, NNZs: 2, Bias: -60364062939.332558, T: 7040, Avg. loss: 404360731284395196416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1005200704.96, NNZs: 2, Bias: -60340889825.290352, T: 7168, Avg. loss: 438647654238434426880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 977615331.59, NNZs: 2, Bias: -60319557441.127708, T: 7296, Avg. loss: 406389448996487233536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 978276483.89, NNZs: 2, Bias: -60298513255.476746, T: 7424, Avg. loss: 381665618607670231040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1004013541.82, NNZs: 2, Bias: -60276980776.289024, T: 7552, Avg. loss: 375526208901327355904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 994415500.39, NNZs: 2, Bias: -60272903043.923752, T: 7680, Avg. loss: 322026233520468983808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 995333167.44, NNZs: 2, Bias: -60268656508.457336, T: 7808, Avg. loss: 321212817135558393856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 989798114.78, NNZs: 2, Bias: -60264514962.136162, T: 7936, Avg. loss: 321523067098050134016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 990656166.44, NNZs: 2, Bias: -60260386753.010254, T: 8064, Avg. loss: 312362849087332089856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 988521021.02, NNZs: 2, Bias: -60256230019.157089, T: 8192, Avg. loss: 317804645088157237248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 983943969.32, NNZs: 2, Bias: -60252111039.966766, T: 8320, Avg. loss: 318899974013716725760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 997283588.72, NNZs: 2, Bias: -60247691196.324379, T: 8448, Avg. loss: 318380395287415488512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 978018954.87, NNZs: 2, Bias: -60243770437.722183, T: 8576, Avg. loss: 321873450691217391616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 993641818.62, NNZs: 2, Bias: -60239347958.432869, T: 8704, Avg. loss: 316006576561496784896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 991161958.97, NNZs: 2, Bias: -60238541416.337822, T: 8832, Avg. loss: 313515607654328369152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 989969114.06, NNZs: 2, Bias: -60237716062.021820, T: 8960, Avg. loss: 312548768883449593856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 988339081.63, NNZs: 2, Bias: -60236896454.584442, T: 9088, Avg. loss: 313062543874147418112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 984440392.93, NNZs: 2, Bias: -60236114924.274330, T: 9216, Avg. loss: 312764695793038655488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 980911497.44, NNZs: 2, Bias: -60235332668.178741, T: 9344, Avg. loss: 310669825018773569536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 983670117.38, NNZs: 2, Bias: -60234438694.450356, T: 9472, Avg. loss: 313921729785467699200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 983890639.45, NNZs: 2, Bias: -60233588302.067436, T: 9600, Avg. loss: 313174623360376700928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 985902464.04, NNZs: 2, Bias: -60232710651.050873, T: 9728, Avg. loss: 312402547073201602560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 983799548.44, NNZs: 2, Bias: -60231901260.757133, T: 9856, Avg. loss: 312127302756381032448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 982269800.77, NNZs: 2, Bias: -60231080077.015358, T: 9984, Avg. loss: 312983998858273161216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 78 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1457128705886.24, NNZs: 2, Bias: -41466586826.781601, T: 128, Avg. loss: 20770205403837392710744932352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 632110764837.10, NNZs: 2, Bias: -1466586826.781601, T: 256, Avg. loss: 19433118741018944951841456128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1310641916875.57, NNZs: 2, Bias: -104443724756.073074, T: 384, Avg. loss: 18082724923471950265049939968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2228425957721.72, NNZs: 2, Bias: -21982847823.377457, T: 512, Avg. loss: 19007056794087935080992342016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1073996870685.85, NNZs: 2, Bias: 22946848675.430908, T: 640, Avg. loss: 19932415945521605480842002432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 438378990767.86, NNZs: 2, Bias: -31709948739.143089, T: 768, Avg. loss: 18742176573516898903118577664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 415114846913.81, NNZs: 2, Bias: -151709948739.143097, T: 896, Avg. loss: 20240754058353223579260157952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 266706699423.15, NNZs: 2, Bias: -209370600918.535339, T: 1024, Avg. loss: 19306670077634015282610569216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 277121721191.55, NNZs: 2, Bias: -228509462742.938782, T: 1152, Avg. loss: 825159298462893905788534784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 395791012745.15, NNZs: 2, Bias: -229096493246.591370, T: 1280, Avg. loss: 795700238430568043299995648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 170680905768.01, NNZs: 2, Bias: -223516793005.539246, T: 1408, Avg. loss: 879605184921934541713571840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 405316236364.22, NNZs: 2, Bias: -216520598223.360382, T: 1536, Avg. loss: 783678823272618229401387008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 520002118471.67, NNZs: 2, Bias: -211284060361.484314, T: 1664, Avg. loss: 803698926277115033019219968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 287246146443.69, NNZs: 2, Bias: -215602852958.169525, T: 1792, Avg. loss: 799367170279676034779447296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 187354253938.89, NNZs: 2, Bias: -201591218375.566589, T: 1920, Avg. loss: 800491099498302986812129280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 253578258535.96, NNZs: 2, Bias: -213929560862.699127, T: 2048, Avg. loss: 807076643822276977541251072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 106053947065.69, NNZs: 2, Bias: -223270864587.110443, T: 2176, Avg. loss: 666405421401337204601520128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 102278051688.26, NNZs: 2, Bias: -215493806759.495483, T: 2304, Avg. loss: 725747970346122885338234880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 219973313585.83, NNZs: 2, Bias: -216626663542.697937, T: 2432, Avg. loss: 849888197110947393394704384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 111847896147.92, NNZs: 2, Bias: -197847246500.347656, T: 2560, Avg. loss: 805142017833239276767150080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 160529336082.07, NNZs: 2, Bias: -194339156333.039703, T: 2688, Avg. loss: 840624093626124546892365824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 89876040609.56, NNZs: 2, Bias: -192632964354.808014, T: 2816, Avg. loss: 776679064235220535336763392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 50930883465.22, NNZs: 2, Bias: -192576414241.173828, T: 2944, Avg. loss: 29764054769378726292488192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 64912584713.52, NNZs: 2, Bias: -193235850345.801422, T: 3072, Avg. loss: 30097042409365467622801408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 68246101073.82, NNZs: 2, Bias: -192874306342.004486, T: 3200, Avg. loss: 27116075347530440291385344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 67793432856.71, NNZs: 2, Bias: -193739852293.828491, T: 3328, Avg. loss: 32417642498654406625460224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2374788510.49, NNZs: 2, Bias: -194027208491.938721, T: 3456, Avg. loss: 28850016887478703410380800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 103663032598.65, NNZs: 2, Bias: -196930783940.627319, T: 3584, Avg. loss: 28162219543811782359384064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 36310338625.67, NNZs: 2, Bias: -195151529304.895447, T: 3712, Avg. loss: 29688772253626888381005824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 43298432657.38, NNZs: 2, Bias: -193819258134.003448, T: 3840, Avg. loss: 27966711154394505347596288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10505828798.23, NNZs: 2, Bias: -193954489172.792511, T: 3968, Avg. loss: 824126222380428433555456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5622491477.53, NNZs: 2, Bias: -193642388701.094330, T: 4096, Avg. loss: 622353483321341867196416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7749012689.99, NNZs: 2, Bias: -193086600139.664795, T: 4224, Avg. loss: 577269390657043407306752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3477936372.94, NNZs: 2, Bias: -192619798485.476715, T: 4352, Avg. loss: 619201578172932251713536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1570725445.49, NNZs: 2, Bias: -192395167076.376465, T: 4480, Avg. loss: 563872406641725939908608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1851015058.03, NNZs: 2, Bias: -192139099905.690155, T: 4608, Avg. loss: 588238593817433371312128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2686534198.05, NNZs: 2, Bias: -191703115812.381439, T: 4736, Avg. loss: 705718460016295411712000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3654410457.86, NNZs: 2, Bias: -191062399133.451904, T: 4864, Avg. loss: 670821148937805350567936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6084452614.73, NNZs: 2, Bias: -190430357518.926697, T: 4992, Avg. loss: 687354712987386276478976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7618192688.58, NNZs: 2, Bias: -190175180458.320587, T: 5120, Avg. loss: 492926329686848245334016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 6589816025.34, NNZs: 2, Bias: -189998936980.453766, T: 5248, Avg. loss: 582169217485983988056064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 10721282651.34, NNZs: 2, Bias: -189666796157.997437, T: 5376, Avg. loss: 568021317386244395630592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4562204345.59, NNZs: 2, Bias: -189719634501.786530, T: 5504, Avg. loss: 629440634786615767597056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 14800958084.35, NNZs: 2, Bias: -189554902702.423676, T: 5632, Avg. loss: 568618678066420593459200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 7666969106.67, NNZs: 2, Bias: -189395868846.128143, T: 5760, Avg. loss: 599617832968117546909696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4652162082.10, NNZs: 2, Bias: -189330029598.850891, T: 5888, Avg. loss: 11688751211424354664448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3623685363.49, NNZs: 2, Bias: -189278812470.857391, T: 6016, Avg. loss: 4625975657093603524608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3261711019.20, NNZs: 2, Bias: -189223120647.689484, T: 6144, Avg. loss: 3685204538259048759296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3030165446.84, NNZs: 2, Bias: -189163047224.741516, T: 6272, Avg. loss: 3694307767872986808320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2967909149.18, NNZs: 2, Bias: -189098839583.028290, T: 6400, Avg. loss: 3850035273984534642688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2978003245.89, NNZs: 2, Bias: -189036581355.806610, T: 6528, Avg. loss: 3608978284107755159552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2988029702.16, NNZs: 2, Bias: -188972194732.335297, T: 6656, Avg. loss: 3755102200116254081024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2956585411.25, NNZs: 2, Bias: -188908362944.466248, T: 6784, Avg. loss: 3850196093557494775808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2997678941.66, NNZs: 2, Bias: -188843781645.028534, T: 6912, Avg. loss: 3664109575919610888192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3198642633.13, NNZs: 2, Bias: -188775524943.031982, T: 7040, Avg. loss: 3832430878381870940160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3307599160.92, NNZs: 2, Bias: -188713786501.036285, T: 7168, Avg. loss: 3412841973813797715968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3176795675.27, NNZs: 2, Bias: -188651920639.350464, T: 7296, Avg. loss: 3824273069428680687616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3279416609.00, NNZs: 2, Bias: -188588778784.958954, T: 7424, Avg. loss: 3572221323152246964224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2999608412.95, NNZs: 2, Bias: -188529741050.069855, T: 7552, Avg. loss: 3764521876676465393664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2803863619.55, NNZs: 2, Bias: -188467768528.977356, T: 7680, Avg. loss: 3794162387789458964480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2897926462.57, NNZs: 2, Bias: -188403392631.109467, T: 7808, Avg. loss: 3673835479741020241920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2941676143.70, NNZs: 2, Bias: -188390457177.544861, T: 7936, Avg. loss: 2905685002477313720320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2910057687.53, NNZs: 2, Bias: -188378016173.608521, T: 8064, Avg. loss: 3078634300232431566848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2929129385.80, NNZs: 2, Bias: -188364928957.803467, T: 8192, Avg. loss: 3043105305157972262912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2929970721.17, NNZs: 2, Bias: -188352121487.421997, T: 8320, Avg. loss: 3047944023370815766528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2926317992.97, NNZs: 2, Bias: -188339604085.859406, T: 8448, Avg. loss: 2990145485184914423808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2968935130.88, NNZs: 2, Bias: -188326230503.562592, T: 8576, Avg. loss: 3020668806047330729984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2988309355.47, NNZs: 2, Bias: -188323399498.217987, T: 8704, Avg. loss: 2918937359772592635904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2976029832.87, NNZs: 2, Bias: -188321057001.139954, T: 8832, Avg. loss: 2936003484698275217408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2984348422.48, NNZs: 2, Bias: -188318391771.328857, T: 8960, Avg. loss: 2930272038129212325888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2991970599.37, NNZs: 2, Bias: -188315746449.736603, T: 9088, Avg. loss: 2920045326229509767168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 3000955693.27, NNZs: 2, Bias: -188313082116.363586, T: 9216, Avg. loss: 2916509939327092391936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 72 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 494712904584.12, NNZs: 2, Bias: -67236540185.552155, T: 128, Avg. loss: 18978282262846898908895903744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1562634776831.04, NNZs: 2, Bias: -87236540185.552155, T: 256, Avg. loss: 21128980269428321288712093696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 919635729186.85, NNZs: 2, Bias: -83079207410.378830, T: 384, Avg. loss: 22156901040537314269717331968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1713130758375.38, NNZs: 2, Bias: -71657226620.365204, T: 512, Avg. loss: 20273197228245512767938756608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1028230552651.09, NNZs: 2, Bias: -26891876385.773590, T: 640, Avg. loss: 22141491504670169580773048320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 788226834499.07, NNZs: 2, Bias: 20940520432.164658, T: 768, Avg. loss: 19850800807095578131322372096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 83746232824.57, NNZs: 2, Bias: 18291237132.020557, T: 896, Avg. loss: 976542118948856191028035584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 408116424192.78, NNZs: 2, Bias: 27659190305.565578, T: 1024, Avg. loss: 794766759122831139307257856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 250547790784.66, NNZs: 2, Bias: 35961327853.932213, T: 1152, Avg. loss: 862595010533675537570725888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 353309931594.26, NNZs: 2, Bias: 11049579508.080112, T: 1280, Avg. loss: 783899439084708298752000000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 88906443041.71, NNZs: 2, Bias: 9865307972.827768, T: 1408, Avg. loss: 821294558475927139137880064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 32446764735.55, NNZs: 2, Bias: -7292856268.012629, T: 1536, Avg. loss: 786315633780502304143704064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 394687896546.71, NNZs: 2, Bias: -1621529707.785796, T: 1664, Avg. loss: 768157047486549046803300352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 140972412083.26, NNZs: 2, Bias: -8886213551.584431, T: 1792, Avg. loss: 808683267779867600134078464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 245820556309.85, NNZs: 2, Bias: -12501354812.750782, T: 1920, Avg. loss: 810184928765954339104620544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 208211224356.76, NNZs: 2, Bias: -15923443868.070869, T: 2048, Avg. loss: 776965470990051235699097600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 220387260998.29, NNZs: 2, Bias: -5039506210.813244, T: 2176, Avg. loss: 796466034883960292692197376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 232266085107.72, NNZs: 2, Bias: -1937910126.545160, T: 2304, Avg. loss: 896701739201047477882978304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 39267338136.80, NNZs: 2, Bias: 1853878871.413349, T: 2432, Avg. loss: 35384448395823696876404736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42755125509.58, NNZs: 2, Bias: 2982786920.315078, T: 2560, Avg. loss: 32335272988711842582888448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 50787257869.73, NNZs: 2, Bias: 4012910396.012298, T: 2688, Avg. loss: 31041755182424278484123648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 39921853470.37, NNZs: 2, Bias: 5219866842.739631, T: 2816, Avg. loss: 31056842502135270562856960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 82848687994.18, NNZs: 2, Bias: 7126984726.873116, T: 2944, Avg. loss: 29490998647534069036875776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 78817884820.62, NNZs: 2, Bias: 4033424628.579802, T: 3072, Avg. loss: 29444115665202217461219328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 23118847206.31, NNZs: 2, Bias: 4812673267.993911, T: 3200, Avg. loss: 30398918980215989556215808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 39547098524.61, NNZs: 2, Bias: 4284578753.964225, T: 3328, Avg. loss: 31487698111374611978387456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 16495380354.95, NNZs: 2, Bias: 4333027547.119117, T: 3456, Avg. loss: 32592385784585870863499264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 42698115498.28, NNZs: 2, Bias: 7964841701.341241, T: 3584, Avg. loss: 31100730002170969457688576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 14625503625.38, NNZs: 2, Bias: 9490801456.715689, T: 3712, Avg. loss: 29475587468793931733401600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4093052064.31, NNZs: 2, Bias: 9624458042.728464, T: 3840, Avg. loss: 431078114973740754272256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 12104191729.23, NNZs: 2, Bias: 9783723611.480108, T: 3968, Avg. loss: 423794520730575317237760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3016999418.30, NNZs: 2, Bias: 9651745183.158241, T: 4096, Avg. loss: 581351891753020944285696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4080219614.02, NNZs: 2, Bias: 9890624843.228743, T: 4224, Avg. loss: 572138581227078546358272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2167190461.37, NNZs: 2, Bias: 10289914344.260212, T: 4352, Avg. loss: 476008790447206940278784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7646106209.43, NNZs: 2, Bias: 10580679646.086346, T: 4480, Avg. loss: 377808482477633330741248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9762494248.76, NNZs: 2, Bias: 10929218505.867615, T: 4608, Avg. loss: 626351883621252288479232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4051464742.40, NNZs: 2, Bias: 11222402100.691195, T: 4736, Avg. loss: 511150409796666452344832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 10730340324.96, NNZs: 2, Bias: 10990414282.356419, T: 4864, Avg. loss: 357344895730438687948800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3120032338.75, NNZs: 2, Bias: 10789268156.603468, T: 4992, Avg. loss: 531914323889350500155392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 5138392798.22, NNZs: 2, Bias: 10888576648.620403, T: 5120, Avg. loss: 413242010266341518344192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 670400913.40, NNZs: 2, Bias: 10886734701.830875, T: 5248, Avg. loss: 353103349814144429719552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4907595779.20, NNZs: 2, Bias: 11172353097.672380, T: 5376, Avg. loss: 416162260075630903164928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 764359201.92, NNZs: 2, Bias: 11254869993.248112, T: 5504, Avg. loss: 474911158494261084684288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 7843399920.41, NNZs: 2, Bias: 11402522777.467646, T: 5632, Avg. loss: 503128352098600313946112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4398327907.93, NNZs: 2, Bias: 11322814056.004055, T: 5760, Avg. loss: 565458146163464958115840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 414581067.92, NNZs: 2, Bias: 11316230058.570452, T: 5888, Avg. loss: 590713340448438443048960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 183492927.10, NNZs: 2, Bias: 11309284083.656031, T: 6016, Avg. loss: 42735406532845789184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 200554475.62, NNZs: 2, Bias: 11305369172.763288, T: 6144, Avg. loss: 12581671566877978624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 188653337.59, NNZs: 2, Bias: 11301876561.068279, T: 6272, Avg. loss: 13036476450285578240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 188810841.90, NNZs: 2, Bias: 11298465368.180042, T: 6400, Avg. loss: 11505438674487494656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 203598411.62, NNZs: 2, Bias: 11294746264.846121, T: 6528, Avg. loss: 11934719318196729856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 198015007.70, NNZs: 2, Bias: 11291248908.410223, T: 6656, Avg. loss: 12912799040899336192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 204192086.12, NNZs: 2, Bias: 11287543774.787163, T: 6784, Avg. loss: 12145930938186502144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 200819207.30, NNZs: 2, Bias: 11284010996.819256, T: 6912, Avg. loss: 12299166380400119808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 204750174.21, NNZs: 2, Bias: 11280425599.019527, T: 7040, Avg. loss: 12229898490962370560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 198662171.07, NNZs: 2, Bias: 11279827469.212143, T: 7168, Avg. loss: 10111463527303163904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 198351614.83, NNZs: 2, Bias: 11279114818.415737, T: 7296, Avg. loss: 10234443044050169856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 196233856.25, NNZs: 2, Bias: 11278447975.988819, T: 7424, Avg. loss: 10011924439954694144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 196563847.85, NNZs: 2, Bias: 11277741690.773237, T: 7552, Avg. loss: 9973382362954885120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 197542980.96, NNZs: 2, Bias: 11277013332.461433, T: 7680, Avg. loss: 10123122836100579328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 196742100.22, NNZs: 2, Bias: 11276321732.310642, T: 7808, Avg. loss: 10047555728994494464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 195878692.78, NNZs: 2, Bias: 11275634257.533207, T: 7936, Avg. loss: 9982729918018766848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 198003640.79, NNZs: 2, Bias: 11274893311.882742, T: 8064, Avg. loss: 9996071927421241344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 196922196.05, NNZs: 2, Bias: 11274198426.573730, T: 8192, Avg. loss: 10157610542846631936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 196827923.92, NNZs: 2, Bias: 11274058947.602667, T: 8320, Avg. loss: 9771782735912859648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 197525545.21, NNZs: 2, Bias: 11273906160.183243, T: 8448, Avg. loss: 9730925819401988096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 197266798.86, NNZs: 2, Bias: 11273769614.063513, T: 8576, Avg. loss: 9769654776149514240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 197808269.01, NNZs: 2, Bias: 11273619713.717831, T: 8704, Avg. loss: 9719011833782816768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 196763297.76, NNZs: 2, Bias: 11273497039.253754, T: 8832, Avg. loss: 9764246580202395648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 196950960.74, NNZs: 2, Bias: 11273352630.697941, T: 8960, Avg. loss: 9770711990502191104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 197667170.13, NNZs: 2, Bias: 11273199705.224125, T: 9088, Avg. loss: 9717036526726035456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 197055820.63, NNZs: 2, Bias: 11273069010.895496, T: 9216, Avg. loss: 9792720290873264128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 196678948.63, NNZs: 2, Bias: 11272934597.476826, T: 9344, Avg. loss: 9763750185369208832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 196776627.64, NNZs: 2, Bias: 11272791675.612553, T: 9472, Avg. loss: 9776519875150690304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 197004425.97, NNZs: 2, Bias: 11272646679.333542, T: 9600, Avg. loss: 9762553395698012160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 196701181.77, NNZs: 2, Bias: 11272510907.227833, T: 9728, Avg. loss: 9768066779847565312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 76 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 702943245304.10, NNZs: 2, Bias: 686048376.738297, T: 128, Avg. loss: 20271317815455448201324134400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1176995468998.08, NNZs: 2, Bias: 113434005128.245911, T: 256, Avg. loss: 25109149219043942003768295424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1718634683365.67, NNZs: 2, Bias: 173434005128.245911, T: 384, Avg. loss: 21378016390171209432286887936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 679719388846.82, NNZs: 2, Bias: 207388906242.159515, T: 512, Avg. loss: 24038412495161279876264099840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1679393327481.29, NNZs: 2, Bias: 327388906242.159546, T: 640, Avg. loss: 24402417755779318436247633920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 577369861673.03, NNZs: 2, Bias: 307388906242.159546, T: 768, Avg. loss: 24109198433293772139756781568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 268166125822.87, NNZs: 2, Bias: 316214984666.285217, T: 896, Avg. loss: 903860252865279626770907136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 325960998732.91, NNZs: 2, Bias: 310751099347.359009, T: 1024, Avg. loss: 874978764224069905334403072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 225200755247.37, NNZs: 2, Bias: 323633621422.120789, T: 1152, Avg. loss: 905049127681992231326056448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 258186191041.23, NNZs: 2, Bias: 323206681061.761597, T: 1280, Avg. loss: 890403749853620695908483072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 240924922423.39, NNZs: 2, Bias: 315224202079.138550, T: 1408, Avg. loss: 844407282033868625491787776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 56599472630.81, NNZs: 2, Bias: 290334586079.295410, T: 1536, Avg. loss: 979343909024860347245264896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 294793781937.43, NNZs: 2, Bias: 291843728784.335510, T: 1664, Avg. loss: 921322836717510944865910784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 481211142409.37, NNZs: 2, Bias: 290155904545.535828, T: 1792, Avg. loss: 863889778051696637754998784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 144444658996.50, NNZs: 2, Bias: 286335242731.171997, T: 1920, Avg. loss: 865921736759849893654167552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 233096592283.13, NNZs: 2, Bias: 304681339709.186829, T: 2048, Avg. loss: 931895388490980872083734528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 56415067573.77, NNZs: 2, Bias: 298125626636.684753, T: 2176, Avg. loss: 39021308426258495278415872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 38560492629.89, NNZs: 2, Bias: 297116749962.548706, T: 2304, Avg. loss: 34776008162401280006815744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 62919730682.40, NNZs: 2, Bias: 294878280741.654480, T: 2432, Avg. loss: 30776433494852745184673792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 20811022921.73, NNZs: 2, Bias: 290304572086.516785, T: 2560, Avg. loss: 32241315416681948746088448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 104066059260.27, NNZs: 2, Bias: 290511344838.360657, T: 2688, Avg. loss: 33024725748045268381597696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 37064434755.56, NNZs: 2, Bias: 287556202495.282410, T: 2816, Avg. loss: 33818119182869322572759040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 68794407368.85, NNZs: 2, Bias: 286487697269.458679, T: 2944, Avg. loss: 32977314176635739553398784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 84939067815.65, NNZs: 2, Bias: 283388863091.964783, T: 3072, Avg. loss: 32090787899822526473175040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 18434285911.94, NNZs: 2, Bias: 283729532795.919739, T: 3200, Avg. loss: 2557530721604818297683968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 14167525996.17, NNZs: 2, Bias: 283358625240.876099, T: 3328, Avg. loss: 753456275549401613598720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 11226472575.63, NNZs: 2, Bias: 282829119481.085205, T: 3456, Avg. loss: 650949292074789567987712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 6477954739.03, NNZs: 2, Bias: 282588477574.349731, T: 3584, Avg. loss: 758015235006696007925760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 7946605554.50, NNZs: 2, Bias: 282089636388.207275, T: 3712, Avg. loss: 800730280681622579707904.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 11411101652.08, NNZs: 2, Bias: 281746160217.743286, T: 3840, Avg. loss: 596645045970454800498688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6500947798.56, NNZs: 2, Bias: 281236634992.116760, T: 3968, Avg. loss: 772394362704773479661568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 12755893740.72, NNZs: 2, Bias: 280755657125.179260, T: 4096, Avg. loss: 649442158801621138538496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 16858765122.97, NNZs: 2, Bias: 280359830088.353271, T: 4224, Avg. loss: 742534356129183852134400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9270817548.72, NNZs: 2, Bias: 279746382915.678650, T: 4352, Avg. loss: 774283013691973969117184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3403263907.24, NNZs: 2, Bias: 279563498520.466064, T: 4480, Avg. loss: 718824137687071205621760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3850705906.27, NNZs: 2, Bias: 279464454847.734192, T: 4608, Avg. loss: 7676810254640476061696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4119188779.51, NNZs: 2, Bias: 279364942369.317993, T: 4736, Avg. loss: 8115699353406417141760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4163549413.40, NNZs: 2, Bias: 279270044945.158569, T: 4864, Avg. loss: 7954687857118645583872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4116855698.27, NNZs: 2, Bias: 279170880968.386414, T: 4992, Avg. loss: 8785629495583070748672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4037832091.38, NNZs: 2, Bias: 279077539375.179626, T: 5120, Avg. loss: 8246657533445740167168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4282557161.59, NNZs: 2, Bias: 278976225395.559143, T: 5248, Avg. loss: 8264048048087011164160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4223026791.02, NNZs: 2, Bias: 278958190886.349792, T: 5376, Avg. loss: 6680974748533790867456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4268056292.30, NNZs: 2, Bias: 278938592888.783020, T: 5504, Avg. loss: 6657048902725678399488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4251613832.05, NNZs: 2, Bias: 278920070480.811829, T: 5632, Avg. loss: 6611141266777066962944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4234904698.21, NNZs: 2, Bias: 278901472107.138062, T: 5760, Avg. loss: 6632554296555406884864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4280937795.83, NNZs: 2, Bias: 278882179172.541077, T: 5888, Avg. loss: 6530446573796371464192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4310105946.06, NNZs: 2, Bias: 278863152614.177063, T: 6016, Avg. loss: 6530928907792275210240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4354738526.79, NNZs: 2, Bias: 278844060613.955505, T: 6144, Avg. loss: 6470217740323249979392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4306474701.37, NNZs: 2, Bias: 278826050308.253418, T: 6272, Avg. loss: 6610721458165014069248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4363823473.49, NNZs: 2, Bias: 278806426652.874268, T: 6400, Avg. loss: 6592295632415310741504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4375407922.39, NNZs: 2, Bias: 278787415961.038696, T: 6528, Avg. loss: 6631121331128527486976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4350775896.76, NNZs: 2, Bias: 278768954359.724365, T: 6656, Avg. loss: 6646486034546179440640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4347170422.95, NNZs: 2, Bias: 278750288108.748108, T: 6784, Avg. loss: 6596930259028893761536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4352102160.40, NNZs: 2, Bias: 278746461286.331726, T: 6912, Avg. loss: 6420749923970573139968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4364572692.83, NNZs: 2, Bias: 278742524346.047913, T: 7040, Avg. loss: 6405746401015242948608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4361156028.72, NNZs: 2, Bias: 278738834576.421875, T: 7168, Avg. loss: 6409759470969738493952.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4346178485.18, NNZs: 2, Bias: 278735320820.509216, T: 7296, Avg. loss: 6418443542138759151616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4341349521.86, NNZs: 2, Bias: 278731649961.875854, T: 7424, Avg. loss: 6414428063010749677568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4346029211.50, NNZs: 2, Bias: 278727823930.622742, T: 7552, Avg. loss: 6426067882988393201664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4349878098.39, NNZs: 2, Bias: 278724020867.064148, T: 7680, Avg. loss: 6408359793917483286528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 60 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1563646708362.77, NNZs: 2, Bias: 3062623769.387753, T: 128, Avg. loss: 23417057144667427022223441920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2212583474235.68, NNZs: 2, Bias: -36937376230.612244, T: 256, Avg. loss: 23528548647252769813972385792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1798470624595.75, NNZs: 2, Bias: -56937376230.612244, T: 384, Avg. loss: 24521072440883015861003091968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 444747431723.44, NNZs: 2, Bias: -24917292549.917969, T: 512, Avg. loss: 23992581826752628881579048960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2031547400191.93, NNZs: 2, Bias: -44917292549.917969, T: 640, Avg. loss: 22513346263523603468431392768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1348002365933.66, NNZs: 2, Bias: -24917292549.917969, T: 768, Avg. loss: 23215780349351902164356694016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1530904028620.36, NNZs: 2, Bias: -19331939919.632126, T: 896, Avg. loss: 25619790798357845784165089280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 320370960007.23, NNZs: 2, Bias: -119331939919.632126, T: 1024, Avg. loss: 22653424328357287098851524608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 184718600481.19, NNZs: 2, Bias: -143819818602.986298, T: 1152, Avg. loss: 22140216784582503305465298944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 235147395053.50, NNZs: 2, Bias: -141364365606.849579, T: 1280, Avg. loss: 24015998363224852591353528320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 573568250376.25, NNZs: 2, Bias: -170328301069.777344, T: 1408, Avg. loss: 23347869613103072142994440192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 923319330330.89, NNZs: 2, Bias: -170328301069.777344, T: 1536, Avg. loss: 22427947086554205639443218432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 729633132909.31, NNZs: 2, Bias: -190328301069.777344, T: 1664, Avg. loss: 26015828762584655582986240000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 856771417610.23, NNZs: 2, Bias: -230328301069.777344, T: 1792, Avg. loss: 25130802028418144099536732160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 374512240389.07, NNZs: 2, Bias: -237127177714.775665, T: 1920, Avg. loss: 953854898306205732611031040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 191696474698.01, NNZs: 2, Bias: -238828839403.332336, T: 2048, Avg. loss: 936222182556416772503764992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 305886235630.14, NNZs: 2, Bias: -242183476301.644073, T: 2176, Avg. loss: 884699872559390383319023616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 198330174711.95, NNZs: 2, Bias: -240877238006.502777, T: 2304, Avg. loss: 947895117124873960527233024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 341571698378.22, NNZs: 2, Bias: -233455838009.452423, T: 2432, Avg. loss: 911330935467195026452250624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43467254273.41, NNZs: 2, Bias: -219288304559.799652, T: 2560, Avg. loss: 995332285212053913496190976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 327890020995.49, NNZs: 2, Bias: -224847217472.529236, T: 2688, Avg. loss: 966251771452883617085128704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 238591920277.59, NNZs: 2, Bias: -214110357820.490997, T: 2816, Avg. loss: 987799030774520544160120832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 36216651031.40, NNZs: 2, Bias: -212333837465.960510, T: 2944, Avg. loss: 45982757128273977495519232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 97432575632.80, NNZs: 2, Bias: -209329352604.902313, T: 3072, Avg. loss: 33256594563236256897040384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 39997636641.35, NNZs: 2, Bias: -211172885046.718811, T: 3200, Avg. loss: 33251853467182199522459648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 83806738600.49, NNZs: 2, Bias: -211654638978.414124, T: 3328, Avg. loss: 31039591880322941752180736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 25289639057.08, NNZs: 2, Bias: -209556594382.843903, T: 3456, Avg. loss: 38064678219305278379130880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 66506863184.38, NNZs: 2, Bias: -209387013091.561523, T: 3584, Avg. loss: 35486652721047841431093248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 22494326376.14, NNZs: 2, Bias: -210135492054.888855, T: 3712, Avg. loss: 36458871404691517706600448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 9276472127.76, NNZs: 2, Bias: -207642393966.479095, T: 3840, Avg. loss: 37539831535982616705499136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 40481937139.18, NNZs: 2, Bias: -207004878449.568451, T: 3968, Avg. loss: 34463603978832683357700096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 15683604323.55, NNZs: 2, Bias: -206582792206.417877, T: 4096, Avg. loss: 1193446613268547541925888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3677874044.36, NNZs: 2, Bias: -206423776072.064484, T: 4224, Avg. loss: 952377601794587953725440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 699062269.08, NNZs: 2, Bias: -206194413485.664429, T: 4352, Avg. loss: 730364553945600682360832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 5598133857.34, NNZs: 2, Bias: -205481804287.913879, T: 4480, Avg. loss: 876744637011006389747712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 13427886318.87, NNZs: 2, Bias: -205006695798.741394, T: 4608, Avg. loss: 749649386157094167642112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5135758846.18, NNZs: 2, Bias: -204602725758.805054, T: 4736, Avg. loss: 746227936126548632928256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7694116256.44, NNZs: 2, Bias: -204454370039.903351, T: 4864, Avg. loss: 629548650472560736075776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 7630125258.71, NNZs: 2, Bias: -204122148391.756622, T: 4992, Avg. loss: 817323454642344574320640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 10368497038.22, NNZs: 2, Bias: -203872048680.617188, T: 5120, Avg. loss: 857555244322706115526656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3060872333.45, NNZs: 2, Bias: -203266390281.567413, T: 5248, Avg. loss: 725529941577501597761536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 13638143785.75, NNZs: 2, Bias: -202969798631.617035, T: 5376, Avg. loss: 510953577733400135991296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 7579096939.17, NNZs: 2, Bias: -202752129120.339691, T: 5504, Avg. loss: 784132049259362680569856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3769647720.22, NNZs: 2, Bias: -202514413409.911987, T: 5632, Avg. loss: 660912266124671911460864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3457651991.71, NNZs: 2, Bias: -202324227571.325775, T: 5760, Avg. loss: 617925723266113748336640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1941457322.63, NNZs: 2, Bias: -201955608056.274048, T: 5888, Avg. loss: 671856495865919503859712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 7479268966.79, NNZs: 2, Bias: -201309662806.337738, T: 6016, Avg. loss: 821275170236610228781056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 5100900272.20, NNZs: 2, Bias: -201282673629.326874, T: 6144, Avg. loss: 6993169130397192159232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4034359899.75, NNZs: 2, Bias: -201241802002.802795, T: 6272, Avg. loss: 4273441134802433998848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3595467836.53, NNZs: 2, Bias: -201190577223.981476, T: 6400, Avg. loss: 3786482340894184833024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3229417021.31, NNZs: 2, Bias: -201137802076.972565, T: 6528, Avg. loss: 3812975852674020278272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3171827526.94, NNZs: 2, Bias: -201079957025.877045, T: 6656, Avg. loss: 3763063288932589895680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3102655014.17, NNZs: 2, Bias: -201020521823.174713, T: 6784, Avg. loss: 3683329024375153754112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3161315451.46, NNZs: 2, Bias: -200960510878.954498, T: 6912, Avg. loss: 3604417941327161851904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3123064083.16, NNZs: 2, Bias: -200905883769.461670, T: 7040, Avg. loss: 3375674539015263485952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2902887113.37, NNZs: 2, Bias: -200851010128.555603, T: 7168, Avg. loss: 3597750508621027868672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2822470046.43, NNZs: 2, Bias: -200795379717.178467, T: 7296, Avg. loss: 3443198928937276145664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3153303461.87, NNZs: 2, Bias: -200728941090.936951, T: 7424, Avg. loss: 3827855688397829963776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2870751839.59, NNZs: 2, Bias: -200673185756.313141, T: 7552, Avg. loss: 3775767846295495507968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2777056155.01, NNZs: 2, Bias: -200615385440.504059, T: 7680, Avg. loss: 3595179433046934290432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2908852564.27, NNZs: 2, Bias: -200601663716.643188, T: 7808, Avg. loss: 2986511505749596700672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2872829162.81, NNZs: 2, Bias: -200590382300.370636, T: 7936, Avg. loss: 2990317685439626477568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2927020302.12, NNZs: 2, Bias: -200577987134.716827, T: 8064, Avg. loss: 2934035913292092276736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2946955123.20, NNZs: 2, Bias: -200565971671.890381, T: 8192, Avg. loss: 2964804466860816859136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2945972665.58, NNZs: 2, Bias: -200554493368.359924, T: 8320, Avg. loss: 2900708617257061711872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2865878869.91, NNZs: 2, Bias: -200544047057.264618, T: 8448, Avg. loss: 2937105106689473904640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2921706064.01, NNZs: 2, Bias: -200531451307.437592, T: 8576, Avg. loss: 2976171603877277728768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2935730369.64, NNZs: 2, Bias: -200519601808.918976, T: 8704, Avg. loss: 2938832389585516888064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2904662722.36, NNZs: 2, Bias: -200508449078.850494, T: 8832, Avg. loss: 2935720488620985942016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2952965863.92, NNZs: 2, Bias: -200496132416.382965, T: 8960, Avg. loss: 2931727005663024906240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2928897853.82, NNZs: 2, Bias: -200494160308.019775, T: 9088, Avg. loss: 2863857680872289337344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2939131637.53, NNZs: 2, Bias: -200491676626.791962, T: 9216, Avg. loss: 2872564839435741429760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2945469088.65, NNZs: 2, Bias: -200489260227.797180, T: 9344, Avg. loss: 2859959129259670241280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2932286121.96, NNZs: 2, Bias: -200487126481.517578, T: 9472, Avg. loss: 2865451775560007024640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2935325726.79, NNZs: 2, Bias: -200484751314.935608, T: 9600, Avg. loss: 2869039493513472901120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2937205530.79, NNZs: 2, Bias: -200482396230.133453, T: 9728, Avg. loss: 2865209541596624191488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2948948970.99, NNZs: 2, Bias: -200479897311.304840, T: 9856, Avg. loss: 2863329503977937567744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2945436827.96, NNZs: 2, Bias: -200477615427.091187, T: 9984, Avg. loss: 2872900676006780076032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 78 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1715799986399.28, NNZs: 2, Bias: -109994503134.133118, T: 128, Avg. loss: 21926106570837229192240693248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 415958043494.00, NNZs: 2, Bias: -206220988554.706055, T: 256, Avg. loss: 22742759959011308873537552384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1811274889863.96, NNZs: 2, Bias: -306220988554.706055, T: 384, Avg. loss: 20212873855534596487596998656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1667468793455.19, NNZs: 2, Bias: -286596911380.616211, T: 512, Avg. loss: 20408469941609809653513846784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 188648072962.54, NNZs: 2, Bias: -177864150359.320343, T: 640, Avg. loss: 21270574806292290971283488768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 713951603943.28, NNZs: 2, Bias: -137864150359.320343, T: 768, Avg. loss: 21326823823471239379766214656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 791744941340.25, NNZs: 2, Bias: -95452352893.338638, T: 896, Avg. loss: 23136909804114310144074973184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 402045798988.69, NNZs: 2, Bias: -115452352893.338638, T: 1024, Avg. loss: 20368385041425300223663538176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 10253899777.50, NNZs: 2, Bias: -122791300988.051514, T: 1152, Avg. loss: 824069908481228026108968960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 262882756414.35, NNZs: 2, Bias: -110373157821.776108, T: 1280, Avg. loss: 825967069952792916872134656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 382204581799.38, NNZs: 2, Bias: -130815020835.369354, T: 1408, Avg. loss: 816269594809478368165101568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 245190580857.18, NNZs: 2, Bias: -125940506627.905655, T: 1536, Avg. loss: 879837299690422584769249280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 338071052113.01, NNZs: 2, Bias: -118828070094.587326, T: 1664, Avg. loss: 859455938769806241763950592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 217648773116.32, NNZs: 2, Bias: -108874189028.673767, T: 1792, Avg. loss: 880561835933105966251245568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 243041971247.68, NNZs: 2, Bias: -99093423988.017212, T: 1920, Avg. loss: 806845144599055343055536128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 207048682165.58, NNZs: 2, Bias: -106929876810.469925, T: 2048, Avg. loss: 845290428201037461354184704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 424584126012.28, NNZs: 2, Bias: -128489351915.573700, T: 2176, Avg. loss: 837559210535685089440825344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 259083096470.10, NNZs: 2, Bias: -105966605180.631699, T: 2304, Avg. loss: 837590353046033595665219584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 33280371641.94, NNZs: 2, Bias: -102641123935.217514, T: 2432, Avg. loss: 863757655011005603128541184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 181574782087.25, NNZs: 2, Bias: -87803083811.964600, T: 2560, Avg. loss: 885662304439792547666067456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 29345127923.30, NNZs: 2, Bias: -87118361588.105118, T: 2688, Avg. loss: 37345382311135204513677312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 28279693835.04, NNZs: 2, Bias: -88128774444.562881, T: 2816, Avg. loss: 34545617788407854529511424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 54384434187.20, NNZs: 2, Bias: -84918430971.759506, T: 2944, Avg. loss: 38775654609984868312940544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 42820852320.12, NNZs: 2, Bias: -89261408075.737534, T: 3072, Avg. loss: 29870106995162738195431424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 21072601691.52, NNZs: 2, Bias: -86900288126.569489, T: 3200, Avg. loss: 32424962939514175182864384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 30076781185.50, NNZs: 2, Bias: -82954659969.597855, T: 3328, Avg. loss: 31785340101895709075177472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 46200240772.25, NNZs: 2, Bias: -83553022086.645569, T: 3456, Avg. loss: 29773639797859134006624256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 43911721223.42, NNZs: 2, Bias: -85748790755.240799, T: 3584, Avg. loss: 32531138328088406531244032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 87743105095.68, NNZs: 2, Bias: -84768634011.516052, T: 3712, Avg. loss: 30392516055688858812022784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 14918070510.24, NNZs: 2, Bias: -83795271251.376373, T: 3840, Avg. loss: 34369195881400502094659584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6964594831.17, NNZs: 2, Bias: -86001996347.773087, T: 3968, Avg. loss: 31130701476753537882914816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 17687202844.08, NNZs: 2, Bias: -85522212441.036789, T: 4096, Avg. loss: 31519556648635180683100160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1548607703.83, NNZs: 2, Bias: -85352040258.913986, T: 4224, Avg. loss: 695214215055260178710528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2408946580.49, NNZs: 2, Bias: -85086297230.662598, T: 4352, Avg. loss: 568791214832808940797952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7756240600.01, NNZs: 2, Bias: -85252104857.297089, T: 4480, Avg. loss: 341744574042842922483712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6316303029.54, NNZs: 2, Bias: -85169695082.005005, T: 4608, Avg. loss: 620068099362340036673536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3800812756.78, NNZs: 2, Bias: -85361144376.475067, T: 4736, Avg. loss: 653972747014835537969152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 11954637408.91, NNZs: 2, Bias: -85225827388.351395, T: 4864, Avg. loss: 767035766391709238296576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 16979550568.46, NNZs: 2, Bias: -84861687220.281586, T: 4992, Avg. loss: 589231436217596071903232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1447041262.72, NNZs: 2, Bias: -85029596767.071945, T: 5120, Avg. loss: 752775913674619276492800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1089634642.38, NNZs: 2, Bias: -84999500299.950851, T: 5248, Avg. loss: 925688095822462844928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1175164921.84, NNZs: 2, Bias: -84968046497.044678, T: 5376, Avg. loss: 780486042988186435584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1369443609.89, NNZs: 2, Bias: -84935093294.500107, T: 5504, Avg. loss: 767902242291600195584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1421315162.84, NNZs: 2, Bias: -84906064145.407379, T: 5632, Avg. loss: 720773056444905160704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1376837671.86, NNZs: 2, Bias: -84877843059.584900, T: 5760, Avg. loss: 724722519901509517312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1438413746.66, NNZs: 2, Bias: -84847828202.976212, T: 5888, Avg. loss: 755250349714518441984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1323564656.08, NNZs: 2, Bias: -84820792451.947327, T: 6016, Avg. loss: 736758882746074923008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1339596544.63, NNZs: 2, Bias: -84790396114.886169, T: 6144, Avg. loss: 775100448155125678080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1380789667.19, NNZs: 2, Bias: -84760417683.316879, T: 6272, Avg. loss: 743227196137159131136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1383456972.65, NNZs: 2, Bias: -84754477872.010254, T: 6400, Avg. loss: 629409750317259554816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1380399666.28, NNZs: 2, Bias: -84748532640.868027, T: 6528, Avg. loss: 640519671074114109440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1383369669.39, NNZs: 2, Bias: -84742510299.280121, T: 6656, Avg. loss: 638318270512298983424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1387859117.31, NNZs: 2, Bias: -84736496992.815582, T: 6784, Avg. loss: 633098024039623688192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1367490678.58, NNZs: 2, Bias: -84730866314.153244, T: 6912, Avg. loss: 637095808344651333632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1376452878.98, NNZs: 2, Bias: -84724696864.354843, T: 7040, Avg. loss: 642839623560228896768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1369573415.23, NNZs: 2, Bias: -84723614601.015869, T: 7168, Avg. loss: 621223869235744866304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1369920039.25, NNZs: 2, Bias: -84722419470.556168, T: 7296, Avg. loss: 618710662125287768064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1362562796.31, NNZs: 2, Bias: -84721361474.910416, T: 7424, Avg. loss: 612246373492794982400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1369922181.50, NNZs: 2, Bias: -84720051563.108826, T: 7552, Avg. loss: 619395564465985290240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1366368787.67, NNZs: 2, Bias: -84718920278.343948, T: 7680, Avg. loss: 618386515342411825152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1366305429.15, NNZs: 2, Bias: -84717731584.598160, T: 7808, Avg. loss: 618882239588639834112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1365431435.17, NNZs: 2, Bias: -84716557592.284348, T: 7936, Avg. loss: 618009665759496765440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1372856849.13, NNZs: 2, Bias: -84715255806.809616, T: 8064, Avg. loss: 614419527216154279936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 63 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1279431537677.06, NNZs: 2, Bias: -34467757500.279388, T: 128, Avg. loss: 19230048518223987413631369216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 764692782619.75, NNZs: 2, Bias: -20807777581.496231, T: 256, Avg. loss: 19680703629261629335107796992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1110970043622.23, NNZs: 2, Bias: -60807777581.496231, T: 384, Avg. loss: 21036411709531549393047519232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1418930779861.30, NNZs: 2, Bias: -132048385149.025391, T: 512, Avg. loss: 21982989140196829953561460736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1208261559614.75, NNZs: 2, Bias: -151672264819.219513, T: 640, Avg. loss: 20775236003213403487182258176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 840304281630.19, NNZs: 2, Bias: -83016893884.839783, T: 768, Avg. loss: 19381797615766424703138267136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 227191979345.73, NNZs: 2, Bias: -65657379097.688705, T: 896, Avg. loss: 877127695305776428092489728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 344553112598.21, NNZs: 2, Bias: -48689622664.296455, T: 1024, Avg. loss: 753014078303004626666913792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 307510653998.67, NNZs: 2, Bias: -49615119745.078369, T: 1152, Avg. loss: 857617163647928144328916992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 196087820122.25, NNZs: 2, Bias: -35545283977.085289, T: 1280, Avg. loss: 815320145319295996361965568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 27590789069.28, NNZs: 2, Bias: -51037590114.723991, T: 1408, Avg. loss: 787951153079988289768783872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 32512902635.41, NNZs: 2, Bias: -63928390901.650391, T: 1536, Avg. loss: 759108292743806915157426176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 284136732190.87, NNZs: 2, Bias: -62012225358.425407, T: 1664, Avg. loss: 827579571386348027940700160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 19007815956.03, NNZs: 2, Bias: -61709590113.246887, T: 1792, Avg. loss: 37620076743714131220103168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 71502218744.39, NNZs: 2, Bias: -60101065537.644859, T: 1920, Avg. loss: 24683685512008252772057088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 69200772118.28, NNZs: 2, Bias: -61086106644.320305, T: 2048, Avg. loss: 29853523447620477952983040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 22544348036.90, NNZs: 2, Bias: -58970868473.232140, T: 2176, Avg. loss: 32438795115250367091179520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 24291020918.18, NNZs: 2, Bias: -59109481497.059563, T: 2304, Avg. loss: 35439596214973058225537024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 80958154850.54, NNZs: 2, Bias: -60384400878.385719, T: 2432, Avg. loss: 29094396633209098985275392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 39374072079.71, NNZs: 2, Bias: -61985128728.155678, T: 2560, Avg. loss: 31325059753777181310844928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 948376501.86, NNZs: 2, Bias: -61658237668.584854, T: 2688, Avg. loss: 751879524848286138630144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4186673645.43, NNZs: 2, Bias: -61287559426.417572, T: 2816, Avg. loss: 448641840755969529741312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 3779522405.94, NNZs: 2, Bias: -60999512184.195343, T: 2944, Avg. loss: 601734350013130826842112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 3162858809.44, NNZs: 2, Bias: -60720046460.701241, T: 3072, Avg. loss: 409625773797461003862016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 5359647179.44, NNZs: 2, Bias: -60442346597.234726, T: 3200, Avg. loss: 449226836898536197455872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 9733335048.51, NNZs: 2, Bias: -60556103398.925888, T: 3328, Avg. loss: 380306675969342872485888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 6436669899.93, NNZs: 2, Bias: -60806656881.030457, T: 3456, Avg. loss: 527186165136486712737792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2343757157.99, NNZs: 2, Bias: -60928824793.693832, T: 3584, Avg. loss: 558489107111647444467712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2865879658.56, NNZs: 2, Bias: -60844348147.159286, T: 3712, Avg. loss: 409197757067372726845440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 18999975406.67, NNZs: 2, Bias: -60646156832.219795, T: 3840, Avg. loss: 402228294079571176718336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 3150495995.48, NNZs: 2, Bias: -60677867512.423569, T: 3968, Avg. loss: 476350249502524372418560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2074573420.26, NNZs: 2, Bias: -60675490373.166397, T: 4096, Avg. loss: 1062204347674366050304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1590329182.02, NNZs: 2, Bias: -60663267885.189262, T: 4224, Avg. loss: 544950192381179592704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1273271048.36, NNZs: 2, Bias: -60647542340.814789, T: 4352, Avg. loss: 458803792815773384704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1128626591.24, NNZs: 2, Bias: -60631626875.379623, T: 4480, Avg. loss: 354464844960067551232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1015820790.85, NNZs: 2, Bias: -60612487300.631073, T: 4608, Avg. loss: 415392850010767622144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1075227376.96, NNZs: 2, Bias: -60591195266.532845, T: 4736, Avg. loss: 380801764806192332800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1050205810.33, NNZs: 2, Bias: -60571081506.697304, T: 4864, Avg. loss: 374377886479924396032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 998808113.36, NNZs: 2, Bias: -60551665100.182106, T: 4992, Avg. loss: 372644123200800948224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 973700579.34, NNZs: 2, Bias: -60531751118.462982, T: 5120, Avg. loss: 374511835438918598656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 967727086.75, NNZs: 2, Bias: -60527752745.034698, T: 5248, Avg. loss: 312344266096126394368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 978487350.18, NNZs: 2, Bias: -60523485265.833580, T: 5376, Avg. loss: 312646099338098638848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 971906980.43, NNZs: 2, Bias: -60519510823.894249, T: 5504, Avg. loss: 312068576323375333376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 962967240.19, NNZs: 2, Bias: -60515548729.164894, T: 5632, Avg. loss: 314442486398856724480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 983620221.56, NNZs: 2, Bias: -60511145065.979179, T: 5760, Avg. loss: 310755296606328717312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 962215874.70, NNZs: 2, Bias: -60507460811.459221, T: 5888, Avg. loss: 308851034398540890112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 969873378.05, NNZs: 2, Bias: -60503303129.564514, T: 6016, Avg. loss: 308371714835098238976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 979933932.67, NNZs: 2, Bias: -60499048332.386353, T: 6144, Avg. loss: 312651628559285157888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 959926220.53, NNZs: 2, Bias: -60495296471.845818, T: 6272, Avg. loss: 311888773495758585856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 968876832.48, NNZs: 2, Bias: -60491070315.141830, T: 6400, Avg. loss: 311586020633196756992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 965085091.43, NNZs: 2, Bias: -60487010607.521072, T: 6528, Avg. loss: 315311949532100231168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 963093616.94, NNZs: 2, Bias: -60482969118.473282, T: 6656, Avg. loss: 311667387180692209664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 969074001.36, NNZs: 2, Bias: -60482060239.083679, T: 6784, Avg. loss: 302041071471317614592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 967668590.33, NNZs: 2, Bias: -60481266852.950172, T: 6912, Avg. loss: 303179051331430252544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 965882526.19, NNZs: 2, Bias: -60480482683.379921, T: 7040, Avg. loss: 302037468184730337280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 966889924.81, NNZs: 2, Bias: -60479650676.202797, T: 7168, Avg. loss: 303138574793295986688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 969718335.98, NNZs: 2, Bias: -60478790896.342392, T: 7296, Avg. loss: 302555220304474013696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 968374763.24, NNZs: 2, Bias: -60477999613.248909, T: 7424, Avg. loss: 302040225322300801024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 970197992.20, NNZs: 2, Bias: -60477157198.635597, T: 7552, Avg. loss: 302056631965815799808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 965824867.41, NNZs: 2, Bias: -60476414193.965034, T: 7680, Avg. loss: 302172260955092680704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 60 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1551377090488.18, NNZs: 2, Bias: 70568059976.526352, T: 128, Avg. loss: 18154614611216139145516679168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 940620895678.18, NNZs: 2, Bias: -31839579804.093033, T: 256, Avg. loss: 19589838393854669340396224512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1116756466067.22, NNZs: 2, Bias: -114094515586.196396, T: 384, Avg. loss: 20138279279201534657523875840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 172744197214.08, NNZs: 2, Bias: -214094515586.196411, T: 512, Avg. loss: 21453506490938039045111939072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 707996666553.52, NNZs: 2, Bias: -294094515586.196411, T: 640, Avg. loss: 20316026924494542060906348544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1642209745136.17, NNZs: 2, Bias: -294094515586.196411, T: 768, Avg. loss: 21100509188277133913719046144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 121156258670.42, NNZs: 2, Bias: -276761128651.213135, T: 896, Avg. loss: 1443280077694160829123919872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 54532955817.17, NNZs: 2, Bias: -263141959446.815704, T: 1024, Avg. loss: 904948765078267669428305920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 113797405873.05, NNZs: 2, Bias: -256110194626.791626, T: 1152, Avg. loss: 838031879699780126489182208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 230787759482.45, NNZs: 2, Bias: -258931446511.650848, T: 1280, Avg. loss: 845875355541765192698298368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 226523676044.70, NNZs: 2, Bias: -257024414418.369476, T: 1408, Avg. loss: 722649802498826143820414976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 118762685575.07, NNZs: 2, Bias: -249958741295.472473, T: 1536, Avg. loss: 839152961596677411594829824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 306407312694.85, NNZs: 2, Bias: -243322107959.068237, T: 1664, Avg. loss: 793683456217135254891134976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 431467981119.53, NNZs: 2, Bias: -243340313101.070374, T: 1792, Avg. loss: 820281156396104204670730240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 325487592817.28, NNZs: 2, Bias: -231477868649.632202, T: 1920, Avg. loss: 866825806122570643866124288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 462545791861.16, NNZs: 2, Bias: -227665440184.131653, T: 2048, Avg. loss: 801111580389864182172876800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 58284129496.23, NNZs: 2, Bias: -225590552505.724060, T: 2176, Avg. loss: 99699971328865817482756096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 38850462966.11, NNZs: 2, Bias: -225215304210.848999, T: 2304, Avg. loss: 31800799209946653034283008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 57967140959.46, NNZs: 2, Bias: -226720006745.873322, T: 2432, Avg. loss: 31095147156477958393167872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43616762729.84, NNZs: 2, Bias: -227220235417.807587, T: 2560, Avg. loss: 33269567783797801302884352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 44247746791.82, NNZs: 2, Bias: -225223954591.347473, T: 2688, Avg. loss: 32061535146507514956218368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 59583439073.98, NNZs: 2, Bias: -226876560102.796082, T: 2816, Avg. loss: 30141150198314172525051904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 45959733889.22, NNZs: 2, Bias: -228488012845.145966, T: 2944, Avg. loss: 32215025807952839050264576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 92294799014.54, NNZs: 2, Bias: -226691187107.920380, T: 3072, Avg. loss: 30576024499243427366436864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 7077157465.06, NNZs: 2, Bias: -224845420885.516022, T: 3200, Avg. loss: 34486056580924904205975552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 13550537896.66, NNZs: 2, Bias: -227470870207.729126, T: 3328, Avg. loss: 32211038722722511502442496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 21132477166.39, NNZs: 2, Bias: -232354531845.547180, T: 3456, Avg. loss: 29019442234043974509658112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 33916627279.42, NNZs: 2, Bias: -231424858745.652039, T: 3584, Avg. loss: 30209683411778244834230272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 84296439217.39, NNZs: 2, Bias: -233578175660.342377, T: 3712, Avg. loss: 28279759191329344703168512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 43328774520.99, NNZs: 2, Bias: -233391756911.366241, T: 3840, Avg. loss: 30334157971059554151038976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 46873138942.23, NNZs: 2, Bias: -231168130815.050201, T: 3968, Avg. loss: 30350290575717783694213120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 96222809153.58, NNZs: 2, Bias: -231942568791.726501, T: 4096, Avg. loss: 26655432170933773773307904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 73174675264.83, NNZs: 2, Bias: -233940576776.217712, T: 4224, Avg. loss: 28137336590302553797820416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 10858885079.88, NNZs: 2, Bias: -236576597829.488983, T: 4352, Avg. loss: 29646341076666772602486784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 59059371341.17, NNZs: 2, Bias: -234821391088.341187, T: 4480, Avg. loss: 29784922761991563140661248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 21056141743.00, NNZs: 2, Bias: -234326253709.408417, T: 4608, Avg. loss: 29141791536966109663068160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 23898242648.62, NNZs: 2, Bias: -232169566198.917236, T: 4736, Avg. loss: 29562534763924301683884032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8288281689.01, NNZs: 2, Bias: -231808788426.781158, T: 4864, Avg. loss: 854546221542345310994432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 7105950043.63, NNZs: 2, Bias: -231382646407.795532, T: 4992, Avg. loss: 532546202430798500462592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 15361406731.27, NNZs: 2, Bias: -231274975138.074127, T: 5120, Avg. loss: 650300123258504706260992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4176231754.72, NNZs: 2, Bias: -230989680610.636902, T: 5248, Avg. loss: 777515399875253212545024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 11435170236.18, NNZs: 2, Bias: -230700068262.478210, T: 5376, Avg. loss: 587393400649039627681792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 5270045983.95, NNZs: 2, Bias: -230720139053.037323, T: 5504, Avg. loss: 523056718775722172219392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3249069603.11, NNZs: 2, Bias: -230244263647.737488, T: 5632, Avg. loss: 677139982093105330388992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4517779252.14, NNZs: 2, Bias: -230131780022.711639, T: 5760, Avg. loss: 636143655422089819586560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 6862355449.56, NNZs: 2, Bias: -229482054607.630249, T: 5888, Avg. loss: 676116234738795490050048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 13592314563.87, NNZs: 2, Bias: -229278030030.289886, T: 6016, Avg. loss: 568780177901845204697088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 5508934779.03, NNZs: 2, Bias: -228995719100.446259, T: 6144, Avg. loss: 563852329174415571943424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4235248381.69, NNZs: 2, Bias: -228944359124.999054, T: 6272, Avg. loss: 5549002914433262944256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4051922937.92, NNZs: 2, Bias: -228877677974.508331, T: 6400, Avg. loss: 4832578568952501764096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4191793107.44, NNZs: 2, Bias: -228803096154.139191, T: 6528, Avg. loss: 4983420243220235288576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4176495982.14, NNZs: 2, Bias: -228734057599.804474, T: 6656, Avg. loss: 4935205873931811553280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3793641180.28, NNZs: 2, Bias: -228667132680.843445, T: 6784, Avg. loss: 5409064226819687841792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3979248288.60, NNZs: 2, Bias: -228587596058.025879, T: 6912, Avg. loss: 5333113548873264005120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3778647510.55, NNZs: 2, Bias: -228516164943.771667, T: 7040, Avg. loss: 5384462535897647153152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3874785991.41, NNZs: 2, Bias: -228500343415.111267, T: 7168, Avg. loss: 4090412237940953448448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3890443744.56, NNZs: 2, Bias: -228485797384.180298, T: 7296, Avg. loss: 4117312680531838107648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3851782241.23, NNZs: 2, Bias: -228472065300.073303, T: 7424, Avg. loss: 4144408559751299334144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3862513567.59, NNZs: 2, Bias: -228457354544.754486, T: 7552, Avg. loss: 4188992262280080523264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3883920502.13, NNZs: 2, Bias: -228442531256.181274, T: 7680, Avg. loss: 4168289429553180835840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3908028709.52, NNZs: 2, Bias: -228427932586.713043, T: 7808, Avg. loss: 4085695953182562189312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3936086304.88, NNZs: 2, Bias: -228413267835.545868, T: 7936, Avg. loss: 4081991437210865369088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3966818983.11, NNZs: 2, Bias: -228398399776.456329, T: 8064, Avg. loss: 4129879253815093362688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3898694570.95, NNZs: 2, Bias: -228385265818.267517, T: 8192, Avg. loss: 4125299614445759102976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3933248371.00, NNZs: 2, Bias: -228370337312.105591, T: 8320, Avg. loss: 4131731848978735562752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3958504254.66, NNZs: 2, Bias: -228355541159.511292, T: 8448, Avg. loss: 4135368928985578733568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3969401415.15, NNZs: 2, Bias: -228340977200.890991, T: 8576, Avg. loss: 4137343267086662631424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3952758303.44, NNZs: 2, Bias: -228338392681.473938, T: 8704, Avg. loss: 4030495519175613612032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3938965675.60, NNZs: 2, Bias: -228335783926.096558, T: 8832, Avg. loss: 3993628160583885389824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3949624236.91, NNZs: 2, Bias: -228332748219.336761, T: 8960, Avg. loss: 3997856307451050065920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 3947458737.54, NNZs: 2, Bias: -228329932528.024200, T: 9088, Avg. loss: 4001329329740937428992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 3959721012.26, NNZs: 2, Bias: -228326871292.982971, T: 9216, Avg. loss: 3993909247939716841472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 3945315401.06, NNZs: 2, Bias: -228324274809.240845, T: 9344, Avg. loss: 3991509714752506953728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 3956731581.42, NNZs: 2, Bias: -228321221964.942017, T: 9472, Avg. loss: 4002940647441286299648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 3959069719.65, NNZs: 2, Bias: -228318330668.444397, T: 9600, Avg. loss: 3997681433903771418624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 3952323105.94, NNZs: 2, Bias: -228315589728.687988, T: 9728, Avg. loss: 4007676015068727738368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 3955755797.43, NNZs: 2, Bias: -228312673909.748810, T: 9856, Avg. loss: 4005332973930848190464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 3952051283.46, NNZs: 2, Bias: -228309880594.064453, T: 9984, Avg. loss: 4006979691158979477504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 78 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1382964903925.25, NNZs: 2, Bias: -93381087551.345734, T: 128, Avg. loss: 23982369091961930756451729408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 922917186791.53, NNZs: 2, Bias: -34824061652.348137, T: 256, Avg. loss: 24361240231474159533846167552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 874110746813.31, NNZs: 2, Bias: 6132710558.975462, T: 384, Avg. loss: 22775956456322856695109779456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1212657015445.31, NNZs: 2, Bias: 6132710558.975464, T: 512, Avg. loss: 21071043192884313147737899008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 802018632462.22, NNZs: 2, Bias: 46132710558.975464, T: 640, Avg. loss: 23698931247651901195939741696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2102035346858.67, NNZs: 2, Bias: 13230235962.158310, T: 768, Avg. loss: 23822050588295599553213628416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 126945052612.55, NNZs: 2, Bias: -6769764037.841690, T: 896, Avg. loss: 22415052564651831785032777728.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 467294180183.10, NNZs: 2, Bias: -24349214147.179062, T: 1024, Avg. loss: 22599127256357277436546646016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2708525962345.97, NNZs: 2, Bias: -44349214147.179062, T: 1152, Avg. loss: 21481074820432976541906894848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 82646165680.09, NNZs: 2, Bias: -62577926809.788231, T: 1280, Avg. loss: 4159534799400371214425784320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 143396659703.56, NNZs: 2, Bias: -55548328012.522972, T: 1408, Avg. loss: 848352469102933422066630656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 421120344904.95, NNZs: 2, Bias: -67040496449.129715, T: 1536, Avg. loss: 831367354941702343447543808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 243060601218.02, NNZs: 2, Bias: -66744396391.692719, T: 1664, Avg. loss: 916588461253501047885791232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 55577541876.41, NNZs: 2, Bias: -60094841060.372696, T: 1792, Avg. loss: 961131288091684947695239168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 303428269085.82, NNZs: 2, Bias: -74798960783.612534, T: 1920, Avg. loss: 975353624931680488523825152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 111347884411.59, NNZs: 2, Bias: -73743500222.235992, T: 2048, Avg. loss: 904431734028898067766312960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 377162161633.88, NNZs: 2, Bias: -77171294582.846573, T: 2176, Avg. loss: 883538156640260798459936768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 64862318565.08, NNZs: 2, Bias: -75229167573.555161, T: 2304, Avg. loss: 63960726559430699420483584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 22532707064.49, NNZs: 2, Bias: -74797636350.480164, T: 2432, Avg. loss: 34857610657894511138570240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 18329407064.44, NNZs: 2, Bias: -73854048791.697510, T: 2560, Avg. loss: 35967560315591155601375232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 37627446540.87, NNZs: 2, Bias: -71841149040.388092, T: 2688, Avg. loss: 34874712848000069526355968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 18068720848.21, NNZs: 2, Bias: -73378203293.190826, T: 2816, Avg. loss: 37391495747364124023062528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 32634027503.30, NNZs: 2, Bias: -74741747732.381714, T: 2944, Avg. loss: 35175448170909044639268864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 49846501067.74, NNZs: 2, Bias: -77837257084.014313, T: 3072, Avg. loss: 31450198878864527853617152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 70605179719.25, NNZs: 2, Bias: -77588752911.632217, T: 3200, Avg. loss: 31214931828490501179310080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 42057353745.69, NNZs: 2, Bias: -80573886727.346054, T: 3328, Avg. loss: 33283792188925223012139008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 66064612508.20, NNZs: 2, Bias: -78999421341.810455, T: 3456, Avg. loss: 35308475356597547691933696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 14876954882.69, NNZs: 2, Bias: -78395225447.651245, T: 3584, Avg. loss: 34210141489134299558969344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 18150191350.04, NNZs: 2, Bias: -78457944754.608261, T: 3712, Avg. loss: 33538166307307804164096000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 65735947470.10, NNZs: 2, Bias: -78870561690.222672, T: 3840, Avg. loss: 36556250703185825580974080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 8814903827.38, NNZs: 2, Bias: -77611552183.265320, T: 3968, Avg. loss: 1307259199167261673783296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1370139889.74, NNZs: 2, Bias: -77683449054.268875, T: 4096, Avg. loss: 661592371131235442884608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 11537676133.43, NNZs: 2, Bias: -77304154424.511917, T: 4224, Avg. loss: 596106065311432938881024.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7683265315.58, NNZs: 2, Bias: -77310033369.877548, T: 4352, Avg. loss: 624050946028336230432768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3542783064.96, NNZs: 2, Bias: -77090370703.203445, T: 4480, Avg. loss: 566862855035881105915904.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5820389291.67, NNZs: 2, Bias: -76884072702.898056, T: 4608, Avg. loss: 645556576772921560662016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3413919091.46, NNZs: 2, Bias: -76517418444.855011, T: 4736, Avg. loss: 763816912923621429608448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 13204567495.98, NNZs: 2, Bias: -76196216153.869080, T: 4864, Avg. loss: 570246977337927223214080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3366748448.13, NNZs: 2, Bias: -76255344670.392609, T: 4992, Avg. loss: 714077749839791799664640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 5466610591.75, NNZs: 2, Bias: -76290414758.798431, T: 5120, Avg. loss: 703850033791747676438528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3280798508.65, NNZs: 2, Bias: -76300242905.364380, T: 5248, Avg. loss: 3075438474502664617984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2154339532.92, NNZs: 2, Bias: -76292686268.739853, T: 5376, Avg. loss: 1274941290675097829376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1716665852.93, NNZs: 2, Bias: -76272992831.369186, T: 5504, Avg. loss: 796899112939496144896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1427618142.81, NNZs: 2, Bias: -76251843897.327942, T: 5632, Avg. loss: 655122527617748697088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1376437459.78, NNZs: 2, Bias: -76225943344.585770, T: 5760, Avg. loss: 659604204334032748544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1268533855.57, NNZs: 2, Bias: -76201561821.784668, T: 5888, Avg. loss: 639022675632709304320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1204138796.90, NNZs: 2, Bias: -76176172886.008301, T: 6016, Avg. loss: 649472664407839866880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1188909160.87, NNZs: 2, Bias: -76151983869.974213, T: 6144, Avg. loss: 572724447740661858304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1161909559.08, NNZs: 2, Bias: -76128165822.772537, T: 6272, Avg. loss: 568900436953697878016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1223851528.88, NNZs: 2, Bias: -76103189996.165436, T: 6400, Avg. loss: 546064607764043268096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1353215018.44, NNZs: 2, Bias: -76077279910.710022, T: 6528, Avg. loss: 550338041600123600896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1295147771.78, NNZs: 2, Bias: -76052948169.455856, T: 6656, Avg. loss: 585514650196150321152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1202823729.81, NNZs: 2, Bias: -76027904212.772400, T: 6784, Avg. loss: 663908220572660137984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1253207918.20, NNZs: 2, Bias: -76001714246.253708, T: 6912, Avg. loss: 584735286431180193792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1174871278.56, NNZs: 2, Bias: -75977762485.046783, T: 7040, Avg. loss: 602439653271194042368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1235242065.53, NNZs: 2, Bias: -75971330813.910080, T: 7168, Avg. loss: 524888384238684143616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1215074797.31, NNZs: 2, Bias: -75966555292.145477, T: 7296, Avg. loss: 490597389704921677824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1215827721.91, NNZs: 2, Bias: -75961450061.801376, T: 7424, Avg. loss: 488429671072296140800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1200381381.37, NNZs: 2, Bias: -75956535610.657990, T: 7552, Avg. loss: 496282356590541406208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1202354334.16, NNZs: 2, Bias: -75951408827.241043, T: 7680, Avg. loss: 489112285899078828032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1203630248.91, NNZs: 2, Bias: -75946228045.649292, T: 7808, Avg. loss: 495673379638759063552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1203719922.41, NNZs: 2, Bias: -75941186853.145111, T: 7936, Avg. loss: 482952404202939744256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1215713471.80, NNZs: 2, Bias: -75935873259.342987, T: 8064, Avg. loss: 491089939735087022080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1201667899.09, NNZs: 2, Bias: -75930994084.298691, T: 8192, Avg. loss: 489767504858715652096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1195960015.17, NNZs: 2, Bias: -75925990783.688354, T: 8320, Avg. loss: 488372030139163148288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1192426021.26, NNZs: 2, Bias: -75920900095.606461, T: 8448, Avg. loss: 493146430001542594560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1204842930.85, NNZs: 2, Bias: -75915619431.504578, T: 8576, Avg. loss: 487193407643458076672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1191913782.03, NNZs: 2, Bias: -75914801085.143631, T: 8704, Avg. loss: 477243896796909142016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1197649586.05, NNZs: 2, Bias: -75913694776.269196, T: 8832, Avg. loss: 473624313476719050752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1195208851.20, NNZs: 2, Bias: -75912713005.822357, T: 8960, Avg. loss: 475815726948744495104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1194278975.98, NNZs: 2, Bias: -75911706157.593979, T: 9088, Avg. loss: 476341274741282963456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1196673195.40, NNZs: 2, Bias: -75910652874.887131, T: 9216, Avg. loss: 473471221274418348032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1190942823.16, NNZs: 2, Bias: -75909725651.275787, T: 9344, Avg. loss: 474569284886576693248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1194507195.76, NNZs: 2, Bias: -75908650195.794449, T: 9472, Avg. loss: 475256765919206047744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1190868513.60, NNZs: 2, Bias: -75907689317.898270, T: 9600, Avg. loss: 474809318514030018560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1188133349.61, NNZs: 2, Bias: -75906715346.475449, T: 9728, Avg. loss: 474263748712134606848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1190374228.30, NNZs: 2, Bias: -75905657433.453476, T: 9856, Avg. loss: 476859214539846254592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 77 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 376847521522.81, NNZs: 2, Bias: 57665512129.363525, T: 128, Avg. loss: 23050655768033724095801589760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 798743319606.89, NNZs: 2, Bias: 45802938851.273689, T: 256, Avg. loss: 21937277542453167876630118400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1158938736453.76, NNZs: 2, Bias: 33674032089.173019, T: 384, Avg. loss: 23194007314987011448061820928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1213200740860.83, NNZs: 2, Bias: 99740289690.114471, T: 512, Avg. loss: 23420943302272741403323793408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2120781592133.54, NNZs: 2, Bias: 66633463880.628311, T: 640, Avg. loss: 23284905842680051807140446208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1437366037691.17, NNZs: 2, Bias: -33366536119.371689, T: 768, Avg. loss: 23467378063414441845064728576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1660999497682.78, NNZs: 2, Bias: -53366536119.371689, T: 896, Avg. loss: 20849058629413646084981391360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2095233901023.01, NNZs: 2, Bias: -44922662501.477692, T: 1024, Avg. loss: 24369028521518171797640445952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 449463288711.27, NNZs: 2, Bias: -24922662501.477692, T: 1152, Avg. loss: 24107958115044189151806095360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1578618817356.83, NNZs: 2, Bias: -70383763728.329346, T: 1280, Avg. loss: 21690537380620432183218143232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1312328027203.26, NNZs: 2, Bias: -170383763728.329346, T: 1408, Avg. loss: 22717920283635774482731237376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 3336374955914.66, NNZs: 2, Bias: -262402901799.816650, T: 1536, Avg. loss: 23992397579525445102621163520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 340725075153.88, NNZs: 2, Bias: -213313764199.619781, T: 1664, Avg. loss: 3794568459121057470837948416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 19660308873.13, NNZs: 2, Bias: -214825813666.199890, T: 1792, Avg. loss: 949954336499169821540220928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 189922238104.74, NNZs: 2, Bias: -220399756418.295288, T: 1920, Avg. loss: 934700057076619852570951680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 414053737303.10, NNZs: 2, Bias: -213680452421.087311, T: 2048, Avg. loss: 970598261409973785086394368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 84321006355.76, NNZs: 2, Bias: -205476042892.021851, T: 2176, Avg. loss: 970589783867415571250282496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 371452874432.00, NNZs: 2, Bias: -207187374741.259155, T: 2304, Avg. loss: 914329626857132796686630912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 146059454892.20, NNZs: 2, Bias: -200987419060.897034, T: 2432, Avg. loss: 1006580386772276087546183680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 278386305914.20, NNZs: 2, Bias: -205831058464.899780, T: 2560, Avg. loss: 916015896069403347242713088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 308731831934.62, NNZs: 2, Bias: -225423385152.266327, T: 2688, Avg. loss: 901004313141309823738970112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 140942128740.01, NNZs: 2, Bias: -235449886931.556152, T: 2816, Avg. loss: 848138302335343629965459456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 214027429691.63, NNZs: 2, Bias: -233747903679.671570, T: 2944, Avg. loss: 978308481952722365456580608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 473241150646.73, NNZs: 2, Bias: -239439383267.128876, T: 3072, Avg. loss: 924744492465969017137397760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 418132417718.73, NNZs: 2, Bias: -234793620176.617310, T: 3200, Avg. loss: 928691492043532391606648832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 479567605988.34, NNZs: 2, Bias: -230793620176.617310, T: 3328, Avg. loss: 982487144587134947540598784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 40061274094.79, NNZs: 2, Bias: -239838483286.239471, T: 3456, Avg. loss: 888892413068229304033214464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 38020082952.02, NNZs: 2, Bias: -239757024564.403931, T: 3584, Avg. loss: 33821347898038102316285952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 40773614339.40, NNZs: 2, Bias: -237915242044.149384, T: 3712, Avg. loss: 38420418034648890770194432.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 58784073368.13, NNZs: 2, Bias: -236118594134.424591, T: 3840, Avg. loss: 34998816808580366464974848.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 41970123043.69, NNZs: 2, Bias: -235033823250.558838, T: 3968, Avg. loss: 34742451738441339847573504.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 28674940221.65, NNZs: 2, Bias: -237019546838.278351, T: 4096, Avg. loss: 36131688446804921994444800.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 71386505786.41, NNZs: 2, Bias: -239481629160.231689, T: 4224, Avg. loss: 31881531841058204723183616.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 75679871427.22, NNZs: 2, Bias: -239084262869.121704, T: 4352, Avg. loss: 35933417377078122463100928.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 24606384835.74, NNZs: 2, Bias: -237318618994.364960, T: 4480, Avg. loss: 30669245915134347477778432.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 91984430719.13, NNZs: 2, Bias: -237003350315.343903, T: 4608, Avg. loss: 33830193775148315638235136.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 49734009745.37, NNZs: 2, Bias: -237008536950.280853, T: 4736, Avg. loss: 35455215637687618756411392.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 67002707239.44, NNZs: 2, Bias: -237789464772.266693, T: 4864, Avg. loss: 35704411493471706413006848.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 37081450267.91, NNZs: 2, Bias: -237622161503.259949, T: 4992, Avg. loss: 37435001793529227461525504.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 29833116556.38, NNZs: 2, Bias: -235183822751.473938, T: 5120, Avg. loss: 36586286794152908089720832.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 13948205172.01, NNZs: 2, Bias: -234253877896.296143, T: 5248, Avg. loss: 991466290463848913698816.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 8406672387.32, NNZs: 2, Bias: -233785042234.093353, T: 5376, Avg. loss: 690546049085775991013376.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 7060663733.04, NNZs: 2, Bias: -233727271604.404907, T: 5504, Avg. loss: 812320010457050282721280.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 10881268790.16, NNZs: 2, Bias: -234048887659.510437, T: 5632, Avg. loss: 788352641051453791666176.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 10726938466.06, NNZs: 2, Bias: -233742734977.180389, T: 5760, Avg. loss: 803538332355251618709504.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 6387342062.64, NNZs: 2, Bias: -233748903892.770142, T: 5888, Avg. loss: 806764452297874627100672.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 11062509284.11, NNZs: 2, Bias: -233509200259.255554, T: 6016, Avg. loss: 902710609035304709914624.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4883453192.62, NNZs: 2, Bias: -233497370343.670807, T: 6144, Avg. loss: 23442329774475567955968.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4246046044.02, NNZs: 2, Bias: -233435878461.123657, T: 6272, Avg. loss: 5657870630218862952448.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3853196507.37, NNZs: 2, Bias: -233374351697.420288, T: 6400, Avg. loss: 5113647193820725510144.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3665868184.09, NNZs: 2, Bias: -233307335857.058472, T: 6528, Avg. loss: 4940998013943415832576.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3288572499.84, NNZs: 2, Bias: -233247856199.684296, T: 6656, Avg. loss: 4608215577953488601088.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3419696445.01, NNZs: 2, Bias: -233175313279.639587, T: 6784, Avg. loss: 5432119561846250274816.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3498800479.05, NNZs: 2, Bias: -233106152359.796936, T: 6912, Avg. loss: 4864363505092839604224.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3377923904.42, NNZs: 2, Bias: -233038478695.700867, T: 7040, Avg. loss: 5147161446963980795904.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3315638359.28, NNZs: 2, Bias: -232970816898.622803, T: 7168, Avg. loss: 4893769163345139597312.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3380054848.29, NNZs: 2, Bias: -232901061821.492462, T: 7296, Avg. loss: 4833832613018852130816.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3285827319.89, NNZs: 2, Bias: -232888513853.626953, T: 7424, Avg. loss: 4092060132914519080960.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3317293429.60, NNZs: 2, Bias: -232874793822.895996, T: 7552, Avg. loss: 3884267887442509430784.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3239327826.16, NNZs: 2, Bias: -232862557426.937469, T: 7680, Avg. loss: 3908927234503415955456.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3308984706.61, NNZs: 2, Bias: -232847913409.662689, T: 7808, Avg. loss: 4004684879865812353024.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3365835054.45, NNZs: 2, Bias: -232833620653.571442, T: 7936, Avg. loss: 3947393313790504730624.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3353578702.93, NNZs: 2, Bias: -232820316939.486298, T: 8064, Avg. loss: 3950773756621986725888.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3298902020.01, NNZs: 2, Bias: -232807723589.959045, T: 8192, Avg. loss: 3918674341499482144768.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3345207369.94, NNZs: 2, Bias: -232804277697.725525, T: 8320, Avg. loss: 3979458085262618787840.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3376442033.71, NNZs: 2, Bias: -232801120839.662384, T: 8448, Avg. loss: 3866119438888811888640.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3378832904.65, NNZs: 2, Bias: -232798380847.006805, T: 8576, Avg. loss: 3866997893871991521280.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3374624342.50, NNZs: 2, Bias: -232795737279.231049, T: 8704, Avg. loss: 3866749619192453398528.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3373866905.96, NNZs: 2, Bias: -232793041629.340912, T: 8832, Avg. loss: 3869096496036411604992.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3371730444.48, NNZs: 2, Bias: -232790365161.227386, T: 8960, Avg. loss: 3870033967922062819328.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 3378484184.69, NNZs: 2, Bias: -232787560544.380676, T: 9088, Avg. loss: 3868270885109713338368.000000\n",
      "Total training time: 0.11 seconds.\n",
      "Convergence after 71 epochs took 0.11 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2527506274165.56, NNZs: 2, Bias: 60489528754.988831, T: 128, Avg. loss: 20554880711403014838655385600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2115096653610.27, NNZs: 2, Bias: 40886613031.160515, T: 256, Avg. loss: 22895554004608552180150960128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1568430099224.05, NNZs: 2, Bias: 60886613031.160522, T: 384, Avg. loss: 23644984246900398368032292864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1381204062785.56, NNZs: 2, Bias: 60889203419.290802, T: 512, Avg. loss: 19994981620196045638267305984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1065589441749.27, NNZs: 2, Bias: -75770079464.604767, T: 640, Avg. loss: 20463797057462998236120743936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 485703327046.43, NNZs: 2, Bias: -32802923713.585022, T: 768, Avg. loss: 22619140589271821959940800512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 430217929809.75, NNZs: 2, Bias: -49683752691.417816, T: 896, Avg. loss: 21886010455932286408457191424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1090288637249.57, NNZs: 2, Bias: -47751334800.255081, T: 1024, Avg. loss: 21102817623577217916265824256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1422065483285.39, NNZs: 2, Bias: -75496788232.916290, T: 1152, Avg. loss: 22725454016108972218750337024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 256709935172.39, NNZs: 2, Bias: -48396363114.082237, T: 1280, Avg. loss: 1333181314471394062343602176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 505012530915.63, NNZs: 2, Bias: -59152326953.604889, T: 1408, Avg. loss: 762722980012666666478469120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 127935138629.99, NNZs: 2, Bias: -65080812723.086304, T: 1536, Avg. loss: 865290670694199879253622784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 435900653325.83, NNZs: 2, Bias: -70009144343.845306, T: 1664, Avg. loss: 776282999801924985420775424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 401391837866.52, NNZs: 2, Bias: -68723567023.780319, T: 1792, Avg. loss: 848636283187622912829947904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 29851787452.88, NNZs: 2, Bias: -69252105461.112823, T: 1920, Avg. loss: 871147706853317293794918400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 215170949081.34, NNZs: 2, Bias: -77619387749.893875, T: 2048, Avg. loss: 855760990478340115753074688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 54023156429.88, NNZs: 2, Bias: -75570236008.154388, T: 2176, Avg. loss: 38779575482433115000930304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 17933930532.28, NNZs: 2, Bias: -76142267935.058319, T: 2304, Avg. loss: 34774255926820977690804224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 11516220935.74, NNZs: 2, Bias: -74495505348.523026, T: 2432, Avg. loss: 33217425395285780246560768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 33464549632.31, NNZs: 2, Bias: -70090094129.704514, T: 2560, Avg. loss: 30884891720474951881326592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 31086221390.31, NNZs: 2, Bias: -71361873961.795990, T: 2688, Avg. loss: 33696148991310282828546048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 66001725930.77, NNZs: 2, Bias: -74156248013.059036, T: 2816, Avg. loss: 32445464898396672413925376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 55157077633.08, NNZs: 2, Bias: -73467703614.469574, T: 2944, Avg. loss: 30029898697085354365681664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 20250297017.12, NNZs: 2, Bias: -75629160828.826279, T: 3072, Avg. loss: 33893558143816622600617984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 70578600796.32, NNZs: 2, Bias: -74678276203.058380, T: 3200, Avg. loss: 29666394174212506256408576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 47572295284.48, NNZs: 2, Bias: -75266060819.774323, T: 3328, Avg. loss: 27313674199443713202061312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 34719459653.29, NNZs: 2, Bias: -72954615223.149170, T: 3456, Avg. loss: 34054593320737364036812800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 20642578599.53, NNZs: 2, Bias: -72342731284.046021, T: 3584, Avg. loss: 31612451396205413291524096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 48447512708.89, NNZs: 2, Bias: -71830405215.134430, T: 3712, Avg. loss: 31317214075248230338134016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2010222894.96, NNZs: 2, Bias: -71049725926.538773, T: 3840, Avg. loss: 31984983732549635041918976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11398342503.12, NNZs: 2, Bias: -71943551600.049011, T: 3968, Avg. loss: 29320222867445213189636096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4955797304.49, NNZs: 2, Bias: -71839405526.008102, T: 4096, Avg. loss: 666306382635109531516928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5515360979.21, NNZs: 2, Bias: -71951680004.072693, T: 4224, Avg. loss: 471888120519388913729536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 16076577956.38, NNZs: 2, Bias: -71673103331.247391, T: 4352, Avg. loss: 600368758573733433573376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1292642795.19, NNZs: 2, Bias: -71823685652.306564, T: 4480, Avg. loss: 737398143162543121629184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5520637711.56, NNZs: 2, Bias: -71370223772.670761, T: 4608, Avg. loss: 600151939375424784564224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8292296481.85, NNZs: 2, Bias: -71563331056.061523, T: 4736, Avg. loss: 520907143386571498061824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1102845986.40, NNZs: 2, Bias: -71810315095.083633, T: 4864, Avg. loss: 543522211562590469881856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 413826226.66, NNZs: 2, Bias: -71767348854.324585, T: 4992, Avg. loss: 1046149793015553851392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 719848067.30, NNZs: 2, Bias: -71734430789.179337, T: 5120, Avg. loss: 609485793130628382720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 876412838.54, NNZs: 2, Bias: -71704769877.545517, T: 5248, Avg. loss: 611520464888805064704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 988895375.64, NNZs: 2, Bias: -71677707197.862534, T: 5376, Avg. loss: 545643571515876376576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 989090241.62, NNZs: 2, Bias: -71652764795.476074, T: 5504, Avg. loss: 545861656465565810688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1117558535.19, NNZs: 2, Bias: -71626227833.728287, T: 5632, Avg. loss: 532885029275887403008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1060743275.20, NNZs: 2, Bias: -71602881293.286606, T: 5760, Avg. loss: 534349075840227082240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1131216823.61, NNZs: 2, Bias: -71576658600.712585, T: 5888, Avg. loss: 533535404412457123840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1148604518.37, NNZs: 2, Bias: -71550909974.081955, T: 6016, Avg. loss: 557686864680512847872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1148876230.89, NNZs: 2, Bias: -71526627941.231537, T: 6144, Avg. loss: 546478005501593124864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1205530075.85, NNZs: 2, Bias: -71499894337.322357, T: 6272, Avg. loss: 545190613573533827072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1158104505.83, NNZs: 2, Bias: -71495622458.090393, T: 6400, Avg. loss: 457312064358787907584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1184031781.22, NNZs: 2, Bias: -71490242886.754929, T: 6528, Avg. loss: 445776228509748494336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1150497000.34, NNZs: 2, Bias: -71485830596.709930, T: 6656, Avg. loss: 446545796250732396544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1164847487.52, NNZs: 2, Bias: -71480513759.442444, T: 6784, Avg. loss: 457749027334486753280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1168929208.00, NNZs: 2, Bias: -71475386923.707108, T: 6912, Avg. loss: 455497591802460110848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1170201939.68, NNZs: 2, Bias: -71470313858.749771, T: 7040, Avg. loss: 454978121569181499392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1173872809.08, NNZs: 2, Bias: -71465354324.553177, T: 7168, Avg. loss: 441758678053722783744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1163702343.01, NNZs: 2, Bias: -71460518244.985474, T: 7296, Avg. loss: 449891363281207558144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1160047400.44, NNZs: 2, Bias: -71455466458.455444, T: 7424, Avg. loss: 460181640720479813632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1159215182.31, NNZs: 2, Bias: -71450530290.670105, T: 7552, Avg. loss: 445349687183488188416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1157404196.56, NNZs: 2, Bias: -71445490506.216003, T: 7680, Avg. loss: 456684493111685414912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1151984469.29, NNZs: 2, Bias: -71440516638.105774, T: 7808, Avg. loss: 455694793558864166912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1154163711.34, NNZs: 2, Bias: -71439477592.653824, T: 7936, Avg. loss: 440261061449251356672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1154188851.95, NNZs: 2, Bias: -71438472296.880066, T: 8064, Avg. loss: 440767188660137689088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1152461580.52, NNZs: 2, Bias: -71437499241.222519, T: 8192, Avg. loss: 439022388736666042368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1156924908.76, NNZs: 2, Bias: -71436423622.502274, T: 8320, Avg. loss: 440030555650008678400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1153708642.85, NNZs: 2, Bias: -71435472304.210297, T: 8448, Avg. loss: 440168063665037115392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1156059820.69, NNZs: 2, Bias: -71434431721.892807, T: 8576, Avg. loss: 439676037457726930944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1153150155.41, NNZs: 2, Bias: -71433475051.224442, T: 8704, Avg. loss: 440301773770171088896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1153993478.70, NNZs: 2, Bias: -71432457118.938766, T: 8832, Avg. loss: 440458111250721996800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 69 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 510967138237.40, NNZs: 2, Bias: 40349601185.194778, T: 128, Avg. loss: 19105114289041021776559079424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 503711069553.46, NNZs: 2, Bias: 20349601185.194778, T: 256, Avg. loss: 22013235375599270006443999232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 957169331631.03, NNZs: 2, Bias: 349601185.194778, T: 384, Avg. loss: 18795932414410413457658609664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1794664330809.72, NNZs: 2, Bias: 349601185.194778, T: 512, Avg. loss: 20264164530414383378234081280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 424423121058.41, NNZs: 2, Bias: 20349601185.194778, T: 640, Avg. loss: 20737005304958964274386960384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2273037384351.25, NNZs: 2, Bias: -548934792.393524, T: 768, Avg. loss: 19274635452696098757251432448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 356533715425.15, NNZs: 2, Bias: -20548934792.393524, T: 896, Avg. loss: 23308003156454038747570241536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 949727390083.52, NNZs: 2, Bias: -40548934792.393524, T: 1024, Avg. loss: 20131062738435514150646972416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 491110930163.29, NNZs: 2, Bias: -44795733900.328964, T: 1152, Avg. loss: 1012754647597461466454687744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 274466819263.79, NNZs: 2, Bias: -51184153970.452919, T: 1280, Avg. loss: 860768614473292441494487040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 250945968330.22, NNZs: 2, Bias: -47515934412.221283, T: 1408, Avg. loss: 790491685195550033969152000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 707543920.15, NNZs: 2, Bias: -68069639068.262238, T: 1536, Avg. loss: 862863300551090252634128384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 114930632175.21, NNZs: 2, Bias: -57303483137.061714, T: 1664, Avg. loss: 717067802088972585741058048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 212252335731.78, NNZs: 2, Bias: -57784171404.113121, T: 1792, Avg. loss: 840982848553588201445392384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 444949619978.97, NNZs: 2, Bias: -56876759211.914963, T: 1920, Avg. loss: 695658059657641690600046592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 273690010018.53, NNZs: 2, Bias: -72448363755.836182, T: 2048, Avg. loss: 831500995287199343328624640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 289038643413.12, NNZs: 2, Bias: -55381134326.100136, T: 2176, Avg. loss: 853484933470425073192009728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 259082195057.86, NNZs: 2, Bias: -65197099549.065376, T: 2304, Avg. loss: 810590065021204339454115840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 195281718869.37, NNZs: 2, Bias: -53822665370.692802, T: 2432, Avg. loss: 723159666191359396913610752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 206098084981.06, NNZs: 2, Bias: -47325292021.103912, T: 2560, Avg. loss: 839037487664340012592267264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 9818231788.16, NNZs: 2, Bias: -49967757793.126480, T: 2688, Avg. loss: 30873337817221541832687616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 21397743104.87, NNZs: 2, Bias: -47993076188.294716, T: 2816, Avg. loss: 29296819618249683861766144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 76155902234.89, NNZs: 2, Bias: -46072957568.648857, T: 2944, Avg. loss: 32184995887159825791975424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 19062089797.11, NNZs: 2, Bias: -45640158509.119133, T: 3072, Avg. loss: 32430270411430002883035136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 79735577092.65, NNZs: 2, Bias: -45795719282.088364, T: 3200, Avg. loss: 26451716041288234762764288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 33187562632.80, NNZs: 2, Bias: -45806987405.863770, T: 3328, Avg. loss: 30557657731178613285322752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 65488184518.51, NNZs: 2, Bias: -44947709863.532364, T: 3456, Avg. loss: 28153924474350615660593152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 25855107269.38, NNZs: 2, Bias: -43244248572.911156, T: 3584, Avg. loss: 30299831239095502527004672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 12657837680.82, NNZs: 2, Bias: -41002668054.583557, T: 3712, Avg. loss: 27275885848924729559220224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 43597318829.87, NNZs: 2, Bias: -41649286025.490295, T: 3840, Avg. loss: 31898246302654094922219520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1146043263.32, NNZs: 2, Bias: -42067732513.714890, T: 3968, Avg. loss: 724215452555487179964416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1227528550.33, NNZs: 2, Bias: -42068118698.656036, T: 4096, Avg. loss: 439977068538100115832832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 853783282.76, NNZs: 2, Bias: -42103294122.849770, T: 4224, Avg. loss: 447660792298481549049856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2322774602.92, NNZs: 2, Bias: -41919261933.601517, T: 4352, Avg. loss: 453701090296253560913920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6207305493.74, NNZs: 2, Bias: -41692544027.199654, T: 4480, Avg. loss: 465524096782091604197376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1033864764.09, NNZs: 2, Bias: -41739662938.892700, T: 4608, Avg. loss: 607556425791805405003776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1202906828.64, NNZs: 2, Bias: -41810373256.542633, T: 4736, Avg. loss: 620176622738644674805760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 766738549.70, NNZs: 2, Bias: -41790087203.220047, T: 4864, Avg. loss: 418156187837766434816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 742144446.60, NNZs: 2, Bias: -41776788188.433380, T: 4992, Avg. loss: 186122914532411834368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 686621156.38, NNZs: 2, Bias: -41763264934.729614, T: 5120, Avg. loss: 189515035910566903808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 685097788.46, NNZs: 2, Bias: -41748842489.582657, T: 5248, Avg. loss: 183890371333863440384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 698278291.10, NNZs: 2, Bias: -41734957103.116333, T: 5376, Avg. loss: 177875809609004056576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 667639036.91, NNZs: 2, Bias: -41721680604.243248, T: 5504, Avg. loss: 176030715703369629696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 659832332.99, NNZs: 2, Bias: -41707668974.568512, T: 5632, Avg. loss: 195444720185474646016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 669637974.94, NNZs: 2, Bias: -41693052221.825920, T: 5760, Avg. loss: 191282219796340834304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 672632234.52, NNZs: 2, Bias: -41678746449.882469, T: 5888, Avg. loss: 187341592681640361984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 693442845.67, NNZs: 2, Bias: -41664906317.166664, T: 6016, Avg. loss: 176218903050553524224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 700159967.79, NNZs: 2, Bias: -41651047878.247818, T: 6144, Avg. loss: 177202154827355127808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 688734999.58, NNZs: 2, Bias: -41648445995.827934, T: 6272, Avg. loss: 147132975594671636480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 685509837.02, NNZs: 2, Bias: -41645690047.693008, T: 6400, Avg. loss: 148033853603100164096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 691902179.73, NNZs: 2, Bias: -41642801883.806587, T: 6528, Avg. loss: 146144928411290353664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 672029372.99, NNZs: 2, Bias: -41640409163.894028, T: 6656, Avg. loss: 143454783349284945920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 678986358.42, NNZs: 2, Bias: -41637446944.020538, T: 6784, Avg. loss: 149840742736409657344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 673568274.26, NNZs: 2, Bias: -41634801802.393631, T: 6912, Avg. loss: 143676786724582686720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 678046488.57, NNZs: 2, Bias: -41631881346.830391, T: 7040, Avg. loss: 149927578380152832000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 673873304.31, NNZs: 2, Bias: -41629100928.037727, T: 7168, Avg. loss: 150374075852679315456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 679794052.30, NNZs: 2, Bias: -41626208799.817223, T: 7296, Avg. loss: 147088482557388357632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 672280178.66, NNZs: 2, Bias: -41625767299.680588, T: 7424, Avg. loss: 144265121780677263360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 671195945.20, NNZs: 2, Bias: -41625224207.450119, T: 7552, Avg. loss: 143387276789747105792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 670826141.51, NNZs: 2, Bias: -41624669522.635719, T: 7680, Avg. loss: 143368041911545020416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 673109638.02, NNZs: 2, Bias: -41624071539.469658, T: 7808, Avg. loss: 143444775107681239040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 670142740.05, NNZs: 2, Bias: -41623562627.660713, T: 7936, Avg. loss: 142428704180507508736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 670021077.67, NNZs: 2, Bias: -41623003382.768517, T: 8064, Avg. loss: 143506700241633427456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 669389275.79, NNZs: 2, Bias: -41622455366.398727, T: 8192, Avg. loss: 142729642829591707648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 672449566.67, NNZs: 2, Bias: -41621845084.334045, T: 8320, Avg. loss: 143378813776239132672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 672499794.94, NNZs: 2, Bias: -41621284355.562172, T: 8448, Avg. loss: 143169540336550690816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 671404346.54, NNZs: 2, Bias: -41620741859.942238, T: 8576, Avg. loss: 143263234789174820864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 67 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2495758208645.72, NNZs: 2, Bias: -48562849633.393814, T: 128, Avg. loss: 19809857213074803798059253760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1684292801758.02, NNZs: 2, Bias: -86428015766.072281, T: 256, Avg. loss: 20910719652414733866078568448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1021690944922.02, NNZs: 2, Bias: -166428015766.072266, T: 384, Avg. loss: 21041157752360053623639506944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 440355888366.54, NNZs: 2, Bias: -146428015766.072266, T: 512, Avg. loss: 20813562392266835093314600960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 848628014710.58, NNZs: 2, Bias: -29119443976.737274, T: 640, Avg. loss: 20099930291532731313352081408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1408481469348.39, NNZs: 2, Bias: -139139191302.241089, T: 768, Avg. loss: 19760833462839884992177242112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1585127275214.95, NNZs: 2, Bias: -149533411074.173859, T: 896, Avg. loss: 21665931112248727706024280064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 709849749171.56, NNZs: 2, Bias: -122525679431.808228, T: 1024, Avg. loss: 19805830431527238094502756352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1428280017275.81, NNZs: 2, Bias: -62525679431.808228, T: 1152, Avg. loss: 22355578588564629838310146048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 477643075830.58, NNZs: 2, Bias: -34597096631.509315, T: 1280, Avg. loss: 23693534579650638412429393920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 34512404085.96, NNZs: 2, Bias: 25402903368.490685, T: 1408, Avg. loss: 23258297564176182096103997440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 379152564481.77, NNZs: 2, Bias: 28210255245.222477, T: 1536, Avg. loss: 924972730950011007207997440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 110105684304.04, NNZs: 2, Bias: 32743137613.862347, T: 1664, Avg. loss: 903107045239372634755432448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 226751085850.47, NNZs: 2, Bias: 37996744608.548027, T: 1792, Avg. loss: 912116068468846812362440704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 63956026855.38, NNZs: 2, Bias: 19322439143.903275, T: 1920, Avg. loss: 911505952314553738591207424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 149890568706.05, NNZs: 2, Bias: 40511446604.028419, T: 2048, Avg. loss: 782429971151991798251913216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 470398279685.73, NNZs: 2, Bias: 42552162256.424873, T: 2176, Avg. loss: 846210883076359823936192512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 325843735267.13, NNZs: 2, Bias: 65686609944.078125, T: 2304, Avg. loss: 855170999092711658971201536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 154196767541.23, NNZs: 2, Bias: 69290906585.557419, T: 2432, Avg. loss: 849340153936416267726487552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 47510310931.41, NNZs: 2, Bias: 41595421375.805191, T: 2560, Avg. loss: 820142554990219135023054848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 172882848415.59, NNZs: 2, Bias: 54563295967.128593, T: 2688, Avg. loss: 770547214217912798465228800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 515627114255.02, NNZs: 2, Bias: 45485626074.251724, T: 2816, Avg. loss: 813346203094392605402726400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 297946736317.44, NNZs: 2, Bias: 64375023488.485992, T: 2944, Avg. loss: 888865588480932844876595200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 259140498648.61, NNZs: 2, Bias: 61235128971.973625, T: 3072, Avg. loss: 844577828039077626898284544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 184379750191.92, NNZs: 2, Bias: 52586561855.632851, T: 3200, Avg. loss: 896976354715624007465435136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 119068241122.57, NNZs: 2, Bias: 59050840361.578537, T: 3328, Avg. loss: 871788992609417407819153408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 12026982523.94, NNZs: 2, Bias: 59018764747.882423, T: 3456, Avg. loss: 35565438246190322517278720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 24017422729.15, NNZs: 2, Bias: 58955987610.860817, T: 3584, Avg. loss: 32108280390731183163441152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 28012627779.62, NNZs: 2, Bias: 60850834020.940643, T: 3712, Avg. loss: 30978259865237707210883072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 66739286526.54, NNZs: 2, Bias: 61159811837.987396, T: 3840, Avg. loss: 28417416723943567308881920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 32861722562.64, NNZs: 2, Bias: 61680313502.103363, T: 3968, Avg. loss: 33930998165313286624509952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 15739349058.41, NNZs: 2, Bias: 59099898758.512192, T: 4096, Avg. loss: 31142067246213957525962752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 43646410151.39, NNZs: 2, Bias: 60354537239.303268, T: 4224, Avg. loss: 32527281702116788742914048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 40190950317.79, NNZs: 2, Bias: 59033962198.109703, T: 4352, Avg. loss: 28226513520689620218544128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 83068066072.58, NNZs: 2, Bias: 58467017448.358521, T: 4480, Avg. loss: 29402283227732545397325824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 61393330524.22, NNZs: 2, Bias: 58844718789.480949, T: 4608, Avg. loss: 30438463767009628505767936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 13190986966.50, NNZs: 2, Bias: 59808922994.789017, T: 4736, Avg. loss: 30989095357103165835051008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 50490289545.45, NNZs: 2, Bias: 60458579335.923325, T: 4864, Avg. loss: 28100598332506169285804032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 47286858343.99, NNZs: 2, Bias: 60536033330.661934, T: 4992, Avg. loss: 30832864926654512792338432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 24825092878.34, NNZs: 2, Bias: 59400297153.447746, T: 5120, Avg. loss: 32099111888300422815809536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 92391440976.52, NNZs: 2, Bias: 56740261185.129745, T: 5248, Avg. loss: 31526775729714043065204736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 38138092309.42, NNZs: 2, Bias: 61008487261.620636, T: 5376, Avg. loss: 34641954267505116233859072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 28110634293.62, NNZs: 2, Bias: 61998944526.326111, T: 5504, Avg. loss: 30380106112410496972881920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2103058682.36, NNZs: 2, Bias: 62599240994.372009, T: 5632, Avg. loss: 751833969040671744458752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 314058299.19, NNZs: 2, Bias: 62361669684.599503, T: 5760, Avg. loss: 485175243714552855003136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 570374150.80, NNZs: 2, Bias: 62442240084.036659, T: 5888, Avg. loss: 659017065081456170106880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 7644125797.86, NNZs: 2, Bias: 62210122633.347893, T: 6016, Avg. loss: 570099143109482695884800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 8380381574.63, NNZs: 2, Bias: 62055323278.156723, T: 6144, Avg. loss: 530394707220401693392896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2395561508.30, NNZs: 2, Bias: 62082642638.275452, T: 6272, Avg. loss: 513343575904416975290368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 5433740409.09, NNZs: 2, Bias: 61992419118.150871, T: 6400, Avg. loss: 427027529986039890313216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3221517942.28, NNZs: 2, Bias: 61712929483.545677, T: 6528, Avg. loss: 536793412461141591851008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3838282519.53, NNZs: 2, Bias: 61677003667.707283, T: 6656, Avg. loss: 462164733213943776935936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1488611312.95, NNZs: 2, Bias: 61722869042.448853, T: 6784, Avg. loss: 599009454923054659403776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 7225260842.04, NNZs: 2, Bias: 61999730352.680244, T: 6912, Avg. loss: 364369303742858389356544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1895193797.09, NNZs: 2, Bias: 62025810743.987480, T: 7040, Avg. loss: 508758635805979269136384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2163802699.18, NNZs: 2, Bias: 62447282368.433746, T: 7168, Avg. loss: 581056281787367684046848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1230703791.53, NNZs: 2, Bias: 62660632533.151718, T: 7296, Avg. loss: 527060184148708184555520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1927125462.55, NNZs: 2, Bias: 62530563388.547707, T: 7424, Avg. loss: 475777767526142618632192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9089323162.13, NNZs: 2, Bias: 62415340083.842285, T: 7552, Avg. loss: 585283289195944540635136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 5197816510.56, NNZs: 2, Bias: 62448732625.646675, T: 7680, Avg. loss: 8687117852697675431936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3108043042.24, NNZs: 2, Bias: 62464186805.358826, T: 7808, Avg. loss: 2630809212564552024064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2170317888.63, NNZs: 2, Bias: 62463801327.772827, T: 7936, Avg. loss: 824008444704724090880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1714816456.05, NNZs: 2, Bias: 62450517101.462151, T: 8064, Avg. loss: 584802307834227458048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1448810138.91, NNZs: 2, Bias: 62434957441.798325, T: 8192, Avg. loss: 449005545198679949312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1305336807.87, NNZs: 2, Bias: 62418382128.645164, T: 8320, Avg. loss: 385455121912361779200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1220249103.26, NNZs: 2, Bias: 62400434182.269867, T: 8448, Avg. loss: 378601660635128791040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1185302226.15, NNZs: 2, Bias: 62383477552.410263, T: 8576, Avg. loss: 347525207117679165440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1092016886.92, NNZs: 2, Bias: 62365193846.856300, T: 8704, Avg. loss: 391864204881763958784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1051722213.72, NNZs: 2, Bias: 62345679817.835411, T: 8832, Avg. loss: 397539448899174072320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1098488284.88, NNZs: 2, Bias: 62325493105.887680, T: 8960, Avg. loss: 363916306242807922688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1043311054.28, NNZs: 2, Bias: 62306548863.306374, T: 9088, Avg. loss: 390270292393975283712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1069551758.71, NNZs: 2, Bias: 62287799651.815208, T: 9216, Avg. loss: 338573686159936913408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1074268127.06, NNZs: 2, Bias: 62268477268.233604, T: 9344, Avg. loss: 362782304731656880128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1072064871.88, NNZs: 2, Bias: 62248819067.717278, T: 9472, Avg. loss: 384915386667105320960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1097374026.09, NNZs: 2, Bias: 62229830574.696350, T: 9600, Avg. loss: 341985336182493413376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1018971251.48, NNZs: 2, Bias: 62212027444.275276, T: 9728, Avg. loss: 366768821732169678848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1038232686.25, NNZs: 2, Bias: 62192250877.165131, T: 9856, Avg. loss: 364904313550821654528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1035721321.77, NNZs: 2, Bias: 62188389147.162018, T: 9984, Avg. loss: 306455005832222081024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1046921011.02, NNZs: 2, Bias: 62184265972.857086, T: 10112, Avg. loss: 308943539170062303232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1045104358.07, NNZs: 2, Bias: 62180448304.998123, T: 10240, Avg. loss: 302027881523612876800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1043764636.54, NNZs: 2, Bias: 62176663571.475342, T: 10368, Avg. loss: 297813002325507440640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1070913377.24, NNZs: 2, Bias: 62172315088.503464, T: 10496, Avg. loss: 304352235893497069568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 1062365091.67, NNZs: 2, Bias: 62168511485.457153, T: 10624, Avg. loss: 309878664872124350464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 1054952157.46, NNZs: 2, Bias: 62164743568.540131, T: 10752, Avg. loss: 305480609057484439552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 1064652837.12, NNZs: 2, Bias: 62160654154.490067, T: 10880, Avg. loss: 307868570049914470400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 1072610136.35, NNZs: 2, Bias: 62156578438.377922, T: 11008, Avg. loss: 308487239111681835008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 1067718987.83, NNZs: 2, Bias: 62155881679.912933, T: 11136, Avg. loss: 298239782432445038592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 1067833946.32, NNZs: 2, Bias: 62155101093.443481, T: 11264, Avg. loss: 297214689321012953088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 1064732692.50, NNZs: 2, Bias: 62154380592.783829, T: 11392, Avg. loss: 295424674875114848256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 1064613026.75, NNZs: 2, Bias: 62153605747.303627, T: 11520, Avg. loss: 296552187877814173696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 1065971033.74, NNZs: 2, Bias: 62152805685.091347, T: 11648, Avg. loss: 296466627686406946816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 1065227432.85, NNZs: 2, Bias: 62152045244.763939, T: 11776, Avg. loss: 295193892457335226368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 1069309758.28, NNZs: 2, Bias: 62151197138.671967, T: 11904, Avg. loss: 296873734489225232384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 1067960286.49, NNZs: 2, Bias: 62150442350.338692, T: 12032, Avg. loss: 296999298327943184384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 1068771908.62, NNZs: 2, Bias: 62149651052.700211, T: 12160, Avg. loss: 296688802676312113152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 1068935873.09, NNZs: 2, Bias: 62148869803.097198, T: 12288, Avg. loss: 297120286090314579968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 1069325586.18, NNZs: 2, Bias: 62148087532.071281, T: 12416, Avg. loss: 296007707163121811456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 97 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 517858488186.96, NNZs: 2, Bias: -83649705812.646927, T: 128, Avg. loss: 19455750345034836182621487104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1525252975900.36, NNZs: 2, Bias: -6195225879.651688, T: 256, Avg. loss: 22895055524526537155119415296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1150991873021.82, NNZs: 2, Bias: 25515093768.773315, T: 384, Avg. loss: 22952795976195463123314933760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 520213396127.18, NNZs: 2, Bias: 28351003728.442154, T: 512, Avg. loss: 22867445276986643835806285824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2200182978828.89, NNZs: 2, Bias: 148351003728.442139, T: 640, Avg. loss: 22351416761808747280860184576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2088917762589.91, NNZs: 2, Bias: 54616029352.313995, T: 768, Avg. loss: 22170509260583013933952008192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 163647322040.68, NNZs: 2, Bias: 46252794772.099518, T: 896, Avg. loss: 2672207543468333887614091264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 445512108037.44, NNZs: 2, Bias: 38449672068.689667, T: 1024, Avg. loss: 810533227352267697061625856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 243641082555.10, NNZs: 2, Bias: 41520485891.172287, T: 1152, Avg. loss: 931880428607057164557615104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 225404874842.42, NNZs: 2, Bias: 40106655180.103104, T: 1280, Avg. loss: 851444755735958988580192256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 175047408792.17, NNZs: 2, Bias: 36776102890.238396, T: 1408, Avg. loss: 963803611198438112835403776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 144286213722.60, NNZs: 2, Bias: 43443844175.294838, T: 1536, Avg. loss: 885037821945468268094423040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 281424805797.29, NNZs: 2, Bias: 43451914567.352486, T: 1664, Avg. loss: 951494114450334445358546944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 87410597572.99, NNZs: 2, Bias: 41163807254.729462, T: 1792, Avg. loss: 43025519438969824822165504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 24175987852.38, NNZs: 2, Bias: 39010361145.277908, T: 1920, Avg. loss: 34758047911707829241643008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 29639436753.35, NNZs: 2, Bias: 37663432423.505974, T: 2048, Avg. loss: 32672291451006012612411392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 23499232593.42, NNZs: 2, Bias: 37149467996.239014, T: 2176, Avg. loss: 33523654792733185387003904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 33022289540.52, NNZs: 2, Bias: 36969220876.887123, T: 2304, Avg. loss: 35487734916483376887103488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 77375038513.35, NNZs: 2, Bias: 35342328891.037148, T: 2432, Avg. loss: 32270267179696116608270336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 44933834326.53, NNZs: 2, Bias: 33290877538.239052, T: 2560, Avg. loss: 33446505333740000749027328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 37984569397.83, NNZs: 2, Bias: 36498391852.024475, T: 2688, Avg. loss: 32594622578077290412900352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 37486547593.57, NNZs: 2, Bias: 35006086727.532242, T: 2816, Avg. loss: 33818102584403620844797952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 49177286075.14, NNZs: 2, Bias: 37803365331.376213, T: 2944, Avg. loss: 34577655431232238081015808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 44756189758.59, NNZs: 2, Bias: 36113203704.146019, T: 3072, Avg. loss: 35914314250143301235638272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 5336674287.63, NNZs: 2, Bias: 35569089490.145424, T: 3200, Avg. loss: 1162900345458539074945024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4431393713.63, NNZs: 2, Bias: 35318119955.813034, T: 3328, Avg. loss: 539771779457954359541760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 5458527988.10, NNZs: 2, Bias: 35511098727.902351, T: 3456, Avg. loss: 691143798190898453413888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 5578449993.34, NNZs: 2, Bias: 35483554498.429794, T: 3584, Avg. loss: 600575075047821394575360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1293011852.31, NNZs: 2, Bias: 34918425662.879875, T: 3712, Avg. loss: 655654811859746862137344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 12372910082.41, NNZs: 2, Bias: 35086536417.481552, T: 3840, Avg. loss: 560691063258934824402944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 915650657.39, NNZs: 2, Bias: 35102194952.436600, T: 3968, Avg. loss: 576659391322711669080064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 313415115.89, NNZs: 2, Bias: 35079967737.811386, T: 4096, Avg. loss: 335834874907901952000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 427884924.77, NNZs: 2, Bias: 35066772231.968636, T: 4224, Avg. loss: 123825615234005401600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 479354580.27, NNZs: 2, Bias: 35054416938.406700, T: 4352, Avg. loss: 123248497131741544448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 541293307.22, NNZs: 2, Bias: 35041324937.684822, T: 4480, Avg. loss: 131797137036204457984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 528321443.95, NNZs: 2, Bias: 35029377842.354004, T: 4608, Avg. loss: 134161856493569032192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 564180009.69, NNZs: 2, Bias: 35016863429.305809, T: 4736, Avg. loss: 127050848995293577216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 536580541.36, NNZs: 2, Bias: 35004843986.720192, T: 4864, Avg. loss: 137008976312726929408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 555862584.94, NNZs: 2, Bias: 34993286960.728401, T: 4992, Avg. loss: 119430438314542956544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 551084284.81, NNZs: 2, Bias: 34982148727.436729, T: 5120, Avg. loss: 124704401808308011008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 534650810.67, NNZs: 2, Bias: 34970123579.712288, T: 5248, Avg. loss: 134468156418786377728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 545860737.04, NNZs: 2, Bias: 34957643062.327713, T: 5376, Avg. loss: 130912849005656408064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 535208005.70, NNZs: 2, Bias: 34945899309.052002, T: 5504, Avg. loss: 131294102951845117952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 561133153.57, NNZs: 2, Bias: 34933811653.628838, T: 5632, Avg. loss: 125360015604085080064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 546987111.54, NNZs: 2, Bias: 34931695053.993774, T: 5760, Avg. loss: 103484221469243244544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 556338624.69, NNZs: 2, Bias: 34929271984.093758, T: 5888, Avg. loss: 100161282549254602752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 553986462.01, NNZs: 2, Bias: 34926987250.648170, T: 6016, Avg. loss: 102487473435728674816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 552482732.28, NNZs: 2, Bias: 34924654188.713760, T: 6144, Avg. loss: 104095311931195572224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 543878245.34, NNZs: 2, Bias: 34922429354.642258, T: 6272, Avg. loss: 104055781004641337344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 548128827.51, NNZs: 2, Bias: 34920013969.095131, T: 6400, Avg. loss: 103473233885875503104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 553386901.20, NNZs: 2, Bias: 34917599575.394730, T: 6528, Avg. loss: 102633349663519965184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 549265010.20, NNZs: 2, Bias: 34917193746.601166, T: 6656, Avg. loss: 101070554328215896064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 549569504.37, NNZs: 2, Bias: 34916719052.005142, T: 6784, Avg. loss: 100792884213785116672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 548338950.12, NNZs: 2, Bias: 34916271784.881882, T: 6912, Avg. loss: 100099023790495268864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 549440363.17, NNZs: 2, Bias: 34915785235.773903, T: 7040, Avg. loss: 100633805851411890176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 548544589.79, NNZs: 2, Bias: 34915330495.048859, T: 7168, Avg. loss: 100555524901078892544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 548068547.95, NNZs: 2, Bias: 34914869633.255157, T: 7296, Avg. loss: 100450255219194806272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 548980075.40, NNZs: 2, Bias: 34914385464.302658, T: 7424, Avg. loss: 100766865272874074112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 549539914.95, NNZs: 2, Bias: 34913907283.125450, T: 7552, Avg. loss: 100654306724447305728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 59 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1940197344182.10, NNZs: 2, Bias: 59352693223.356949, T: 128, Avg. loss: 22077714827118807788946456576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 832901031780.22, NNZs: 2, Bias: 82744095224.928589, T: 256, Avg. loss: 24919933833382296367226945536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1199369130046.77, NNZs: 2, Bias: 71410860818.473221, T: 384, Avg. loss: 23876473351783936918814720000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1878780748869.17, NNZs: 2, Bias: -2853391107.396713, T: 512, Avg. loss: 23562544018009978896363028480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1614945136808.25, NNZs: 2, Bias: -1201236732.918777, T: 640, Avg. loss: 23356840224597164136681439232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 385247784445.81, NNZs: 2, Bias: -47318932769.505684, T: 768, Avg. loss: 22827404240659784409334939648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 192550436901.42, NNZs: 2, Bias: -45629485995.141747, T: 896, Avg. loss: 988823981788423055527116800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 180385194621.05, NNZs: 2, Bias: -51819957576.047913, T: 1024, Avg. loss: 897342381591819999168692224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 153444697789.34, NNZs: 2, Bias: -58260236746.796852, T: 1152, Avg. loss: 972463572902891843412295680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 374202815604.47, NNZs: 2, Bias: -62260236746.796852, T: 1280, Avg. loss: 980695993468846910673518592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 261664063181.43, NNZs: 2, Bias: -62441762145.567863, T: 1408, Avg. loss: 966080130773800832552927232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 162147184118.99, NNZs: 2, Bias: -53572293067.410912, T: 1536, Avg. loss: 1003589597553456510763270144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 331549115350.50, NNZs: 2, Bias: -56014049272.522842, T: 1664, Avg. loss: 910004912804685495635279872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 68941613065.23, NNZs: 2, Bias: -50594288534.993736, T: 1792, Avg. loss: 51865300662778563483664384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 66015968063.91, NNZs: 2, Bias: -53564716203.227318, T: 1920, Avg. loss: 36575631475655059802423296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 34434387054.21, NNZs: 2, Bias: -50308225232.385986, T: 2048, Avg. loss: 32778481666738155065180160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 34467174258.09, NNZs: 2, Bias: -50609192105.791054, T: 2176, Avg. loss: 36462616818810577573904384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 22225982033.79, NNZs: 2, Bias: -49177543726.117577, T: 2304, Avg. loss: 35008224690271680060194816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10635479444.54, NNZs: 2, Bias: -48313046384.377060, T: 2432, Avg. loss: 37859375278173824122617856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 75811467414.73, NNZs: 2, Bias: -48919408581.123199, T: 2560, Avg. loss: 32011027730439099362836480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 82300212398.29, NNZs: 2, Bias: -50295538218.841476, T: 2688, Avg. loss: 36380393965562339224715264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 23069465549.07, NNZs: 2, Bias: -49013611535.482086, T: 2816, Avg. loss: 35009974792898402012102656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 82610854291.14, NNZs: 2, Bias: -49703398923.952415, T: 2944, Avg. loss: 34022718376985282647949312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 46135128333.92, NNZs: 2, Bias: -47933517066.734093, T: 3072, Avg. loss: 31535801392354460174385152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 28767762686.81, NNZs: 2, Bias: -48923471149.459465, T: 3200, Avg. loss: 36319778739880092816637952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 31034873225.93, NNZs: 2, Bias: -49035608160.955170, T: 3328, Avg. loss: 33135123305720081786339328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 43434750274.66, NNZs: 2, Bias: -46276695989.865135, T: 3456, Avg. loss: 33994395714915725628932096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 116007471269.91, NNZs: 2, Bias: -46186781299.813660, T: 3584, Avg. loss: 33984679458130617515900928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 76973526818.11, NNZs: 2, Bias: -50169829717.813049, T: 3712, Avg. loss: 34076400381988953781174272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5407574995.97, NNZs: 2, Bias: -49668229756.631218, T: 3840, Avg. loss: 2827797156101230296039424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10133237152.63, NNZs: 2, Bias: -49515109272.393936, T: 3968, Avg. loss: 717250540551123215843328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 7834086864.77, NNZs: 2, Bias: -49202839506.161377, T: 4096, Avg. loss: 812113388904849424252928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7245723136.24, NNZs: 2, Bias: -49142404812.506912, T: 4224, Avg. loss: 730970581814549881552896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7337072236.86, NNZs: 2, Bias: -48899051377.464806, T: 4352, Avg. loss: 718903820703225962561536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1426982027.31, NNZs: 2, Bias: -48732000976.521370, T: 4480, Avg. loss: 766920739954447309864960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1380472182.09, NNZs: 2, Bias: -48783185659.618591, T: 4608, Avg. loss: 734739563306099685720064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 431717745.66, NNZs: 2, Bias: -48761667729.249939, T: 4736, Avg. loss: 560211571930859438080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 260395281.78, NNZs: 2, Bias: -48741442798.412209, T: 4864, Avg. loss: 297457002447423602688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 486822551.91, NNZs: 2, Bias: -48723607028.923798, T: 4992, Avg. loss: 226896846606146371584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 577904933.89, NNZs: 2, Bias: -48707928964.068245, T: 5120, Avg. loss: 213692424414998233088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 700356142.93, NNZs: 2, Bias: -48692498335.148132, T: 5248, Avg. loss: 193208083455404179456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 664923387.30, NNZs: 2, Bias: -48678324332.789742, T: 5376, Avg. loss: 225732440685115211776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 686580102.12, NNZs: 2, Bias: -48663849642.186127, T: 5504, Avg. loss: 212146842341424168960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 682248507.34, NNZs: 2, Bias: -48650061853.913223, T: 5632, Avg. loss: 201093486198700474368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 775910412.83, NNZs: 2, Bias: -48634844661.960449, T: 5760, Avg. loss: 204091190998754230272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 767312254.84, NNZs: 2, Bias: -48620637248.558998, T: 5888, Avg. loss: 213644309608208793600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 744477970.52, NNZs: 2, Bias: -48618195459.564468, T: 6016, Avg. loss: 171963221555906084864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 740511298.64, NNZs: 2, Bias: -48615410543.764534, T: 6144, Avg. loss: 174771589224051146752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 743077260.46, NNZs: 2, Bias: -48612546018.203018, T: 6272, Avg. loss: 172881304621928153088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 736633162.57, NNZs: 2, Bias: -48609803666.181816, T: 6400, Avg. loss: 174459638110983192576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 734410762.23, NNZs: 2, Bias: -48606973094.027336, T: 6528, Avg. loss: 175654237144189075456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 743303001.99, NNZs: 2, Bias: -48604034654.160240, T: 6656, Avg. loss: 171098608570150060032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 736793039.84, NNZs: 2, Bias: -48601276224.209648, T: 6784, Avg. loss: 175299050794526474240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 726100732.36, NNZs: 2, Bias: -48598658637.487511, T: 6912, Avg. loss: 170471184410377388032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 722350552.29, NNZs: 2, Bias: -48596041306.585152, T: 7040, Avg. loss: 163066301794368454656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 716488102.26, NNZs: 2, Bias: -48593349538.468781, T: 7168, Avg. loss: 170206358783876333568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 725881729.31, NNZs: 2, Bias: -48590322722.653038, T: 7296, Avg. loss: 176678896281266159616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 739968951.41, NNZs: 2, Bias: -48587288861.423416, T: 7424, Avg. loss: 172696399172010049536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 727584215.43, NNZs: 2, Bias: -48584667878.887413, T: 7552, Avg. loss: 172094015178240950272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 723829587.95, NNZs: 2, Bias: -48581905694.657959, T: 7680, Avg. loss: 172466091224741675008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 722552714.88, NNZs: 2, Bias: -48581359981.497520, T: 7808, Avg. loss: 168486797323094425600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 720246933.99, NNZs: 2, Bias: -48580832778.935760, T: 7936, Avg. loss: 167532299821765197824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 723204770.80, NNZs: 2, Bias: -48580222766.401726, T: 8064, Avg. loss: 168838079598861221888.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 723467831.12, NNZs: 2, Bias: -48579655645.916901, T: 8192, Avg. loss: 168006998495061442560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 724738810.21, NNZs: 2, Bias: -48579072377.476463, T: 8320, Avg. loss: 168331206455141138432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 65 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2086946423787.88, NNZs: 2, Bias: 10170714500.502991, T: 128, Avg. loss: 20033616826708350274453372928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1041965217455.11, NNZs: 2, Bias: 30170714500.502991, T: 256, Avg. loss: 21132045882431828497868521472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 916342258943.11, NNZs: 2, Bias: 89128900396.022766, T: 384, Avg. loss: 20689252363502032791831314432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1509828712590.17, NNZs: 2, Bias: 9128900396.022766, T: 512, Avg. loss: 20744303066149270928303849472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1533335147364.80, NNZs: 2, Bias: -26111945417.335602, T: 640, Avg. loss: 20601783217809406455850205184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 559828436468.88, NNZs: 2, Bias: 33888054582.664398, T: 768, Avg. loss: 22100957991275409842733318144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 297550668998.06, NNZs: 2, Bias: 28885020904.081558, T: 896, Avg. loss: 826926336849589746618335232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 269038088250.76, NNZs: 2, Bias: 27150202821.373779, T: 1024, Avg. loss: 876235078640990250988470272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 368004647320.34, NNZs: 2, Bias: 25100854715.071835, T: 1152, Avg. loss: 907241842158976648702066688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 467681095413.57, NNZs: 2, Bias: 21106577390.609444, T: 1280, Avg. loss: 860346378654335875619487744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 300481019363.58, NNZs: 2, Bias: 21580216215.300938, T: 1408, Avg. loss: 890966694564878567367245824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 69498292094.82, NNZs: 2, Bias: 17640205055.036953, T: 1536, Avg. loss: 943392290715071834239270912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 42985034804.62, NNZs: 2, Bias: 16124327649.311089, T: 1664, Avg. loss: 29479296793094941310976000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 31702281235.37, NNZs: 2, Bias: 12128556492.127483, T: 1792, Avg. loss: 33358926496147103417368576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 47048608100.91, NNZs: 2, Bias: 14910734511.314594, T: 1920, Avg. loss: 32186252730304781537509376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 62281043535.72, NNZs: 2, Bias: 12926527144.023430, T: 2048, Avg. loss: 35436459894131083593121792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 83614273635.85, NNZs: 2, Bias: 12186766171.710619, T: 2176, Avg. loss: 29659833089912833956642816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 51007624786.91, NNZs: 2, Bias: 11457599139.507486, T: 2304, Avg. loss: 35992843941283654354862080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 5474456392.30, NNZs: 2, Bias: 12166708662.130157, T: 2432, Avg. loss: 1166564523003099782053888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1322103350.85, NNZs: 2, Bias: 12049297108.674520, T: 2560, Avg. loss: 512109028713144434819072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 622997909.38, NNZs: 2, Bias: 11883518319.433704, T: 2688, Avg. loss: 424435858374700040192000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4603396441.19, NNZs: 2, Bias: 11645048172.195770, T: 2816, Avg. loss: 542469781422613934899200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 3258327628.16, NNZs: 2, Bias: 12029705179.587912, T: 2944, Avg. loss: 606159519699707814215680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 14601284747.17, NNZs: 2, Bias: 11615550104.017384, T: 3072, Avg. loss: 437049524491677192945664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10461836120.04, NNZs: 2, Bias: 11875746314.617899, T: 3200, Avg. loss: 547375343705150996873216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 3521467262.41, NNZs: 2, Bias: 11385022468.791395, T: 3328, Avg. loss: 495823399619939484565504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1379285751.05, NNZs: 2, Bias: 11391968531.770966, T: 3456, Avg. loss: 2093501218523752693760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 747218623.54, NNZs: 2, Bias: 11396784012.393476, T: 3584, Avg. loss: 213876514988561104896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 451173900.45, NNZs: 2, Bias: 11396981434.662241, T: 3712, Avg. loss: 61998685417424044032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 308710731.38, NNZs: 2, Bias: 11395589238.915018, T: 3840, Avg. loss: 23236654508608061440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 243573061.14, NNZs: 2, Bias: 11392466798.413143, T: 3968, Avg. loss: 17692857678669684736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 215219394.89, NNZs: 2, Bias: 11388848696.343189, T: 4096, Avg. loss: 15732659431839483904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 200265769.43, NNZs: 2, Bias: 11385169938.827513, T: 4224, Avg. loss: 13600257837105244160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 206715122.31, NNZs: 2, Bias: 11381220363.447239, T: 4352, Avg. loss: 13452234267323834368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 179745475.67, NNZs: 2, Bias: 11377409552.992558, T: 4480, Avg. loss: 15559671171566170112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 177861255.22, NNZs: 2, Bias: 11373186361.703165, T: 4608, Avg. loss: 14719229611719133184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 182044361.63, NNZs: 2, Bias: 11369132612.962479, T: 4736, Avg. loss: 13757142687085586432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 187313320.37, NNZs: 2, Bias: 11365214202.065321, T: 4864, Avg. loss: 13341514530667356160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 184630072.44, NNZs: 2, Bias: 11361168920.050093, T: 4992, Avg. loss: 14171866153160558592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 175874471.15, NNZs: 2, Bias: 11357407621.696543, T: 5120, Avg. loss: 13488327944511870976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 181438802.87, NNZs: 2, Bias: 11353454490.941364, T: 5248, Avg. loss: 13086024362665601024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 184953268.71, NNZs: 2, Bias: 11349326049.907766, T: 5376, Avg. loss: 14306084803370033152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 184745576.06, NNZs: 2, Bias: 11345265129.516184, T: 5504, Avg. loss: 13825423181716838400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 169911713.90, NNZs: 2, Bias: 11341492679.679867, T: 5632, Avg. loss: 13730161883334129664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 175742487.36, NNZs: 2, Bias: 11337373894.943623, T: 5760, Avg. loss: 14133340853678217216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 178520783.57, NNZs: 2, Bias: 11333282070.827757, T: 5888, Avg. loss: 13769226966674712576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 180382696.74, NNZs: 2, Bias: 11332460003.139029, T: 6016, Avg. loss: 11303634697629208576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 181637284.15, NNZs: 2, Bias: 11331658194.827501, T: 6144, Avg. loss: 11123496868941979648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 181739846.54, NNZs: 2, Bias: 11330860633.736897, T: 6272, Avg. loss: 11346954771272714240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 183400136.61, NNZs: 2, Bias: 11330029783.800560, T: 6400, Avg. loss: 11466799200311572480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 183046786.70, NNZs: 2, Bias: 11329230904.479753, T: 6528, Avg. loss: 11497022412028747776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 182777882.64, NNZs: 2, Bias: 11328441162.295906, T: 6656, Avg. loss: 11338467358978555904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 183914542.46, NNZs: 2, Bias: 11327617006.693689, T: 6784, Avg. loss: 11484047514235467776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 183474289.12, NNZs: 2, Bias: 11327464646.148224, T: 6912, Avg. loss: 11094543547416625152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 183677160.83, NNZs: 2, Bias: 11327302401.495890, T: 7040, Avg. loss: 11053946931957858304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 183711082.23, NNZs: 2, Bias: 11327142849.691774, T: 7168, Avg. loss: 11057891126357147648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 183461081.08, NNZs: 2, Bias: 11326987934.471039, T: 7296, Avg. loss: 11056655118488027136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 183509698.14, NNZs: 2, Bias: 11326827904.889467, T: 7424, Avg. loss: 11075109258670331904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 183383583.29, NNZs: 2, Bias: 11326670631.200489, T: 7552, Avg. loss: 11080117008206561280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 182788566.13, NNZs: 2, Bias: 11326522215.123251, T: 7680, Avg. loss: 10992523244170715136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 183459733.21, NNZs: 2, Bias: 11326351851.447189, T: 7808, Avg. loss: 11090490825797218304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 183694912.01, NNZs: 2, Bias: 11326189091.837723, T: 7936, Avg. loss: 11052409509863139328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 183485701.16, NNZs: 2, Bias: 11326033346.975296, T: 8064, Avg. loss: 11066935651583188992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 183336000.17, NNZs: 2, Bias: 11325876715.161652, T: 8192, Avg. loss: 11061373270140684288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 183416059.69, NNZs: 2, Bias: 11325716350.216591, T: 8320, Avg. loss: 11060454649942382592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 65 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 945502407462.93, NNZs: 2, Bias: 51896704510.960434, T: 128, Avg. loss: 18352477981579419375114387456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 749029331103.82, NNZs: 2, Bias: 51896704510.960434, T: 256, Avg. loss: 20445706949646691514349256704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2657315471050.96, NNZs: 2, Bias: -1389596939.189644, T: 384, Avg. loss: 20340813530248676886251044864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1015395608237.96, NNZs: 2, Bias: -31299494914.549408, T: 512, Avg. loss: 22489749716333774857918480384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 870864931290.35, NNZs: 2, Bias: -51299494914.549408, T: 640, Avg. loss: 20763633784654058282538762240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2104630966101.29, NNZs: 2, Bias: -96208812480.403870, T: 768, Avg. loss: 19336385157706705420823822336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 318546554150.52, NNZs: 2, Bias: -81564856650.490936, T: 896, Avg. loss: 2486307583136958442654138368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 263838571721.09, NNZs: 2, Bias: -72975305320.357941, T: 1024, Avg. loss: 814742910111597586024497152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 228569408600.33, NNZs: 2, Bias: -70459015429.267120, T: 1152, Avg. loss: 740517249693140523365171200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 449982308543.88, NNZs: 2, Bias: -70557278075.358566, T: 1280, Avg. loss: 699810030161922506365075456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 97325812867.43, NNZs: 2, Bias: -68023485426.569977, T: 1408, Avg. loss: 749392861769360073321086976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 231593103725.21, NNZs: 2, Bias: -75927525740.975571, T: 1536, Avg. loss: 773405644123104751650865152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 108869680900.98, NNZs: 2, Bias: -72130977547.941284, T: 1664, Avg. loss: 765631334334139701447884800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 31573730224.51, NNZs: 2, Bias: -59359860389.002998, T: 1792, Avg. loss: 807278971233537497277399040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 434728729170.29, NNZs: 2, Bias: -46886648621.716438, T: 1920, Avg. loss: 770428019591174675108986880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 48816964464.01, NNZs: 2, Bias: -45140506681.101700, T: 2048, Avg. loss: 105466378813761769420357632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 55860560986.60, NNZs: 2, Bias: -42919918961.503273, T: 2176, Avg. loss: 32154975174612176435412992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 63047486213.74, NNZs: 2, Bias: -44302849321.969711, T: 2304, Avg. loss: 28808997056852051837845504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 47327490932.83, NNZs: 2, Bias: -44630048103.639801, T: 2432, Avg. loss: 28522025390847423129059328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 16285377200.55, NNZs: 2, Bias: -47576199611.445427, T: 2560, Avg. loss: 27300481875434751288934400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 39357327991.83, NNZs: 2, Bias: -47741611932.181885, T: 2688, Avg. loss: 29785151520011075297738752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 60700436276.10, NNZs: 2, Bias: -48083448605.100899, T: 2816, Avg. loss: 30654159896441568664485888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 18793536217.98, NNZs: 2, Bias: -47173719781.102158, T: 2944, Avg. loss: 24722231096403719192838144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 14109439671.48, NNZs: 2, Bias: -48798995078.329002, T: 3072, Avg. loss: 31328418346257505811693568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 79522965130.84, NNZs: 2, Bias: -50122370664.089676, T: 3200, Avg. loss: 30552042863380539092500480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 32129146036.62, NNZs: 2, Bias: -48911810130.714066, T: 3328, Avg. loss: 27862278636962310013321216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 54959339644.39, NNZs: 2, Bias: -48552853368.227699, T: 3456, Avg. loss: 31801960727209754520190976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 18487757493.00, NNZs: 2, Bias: -49177049203.193375, T: 3584, Avg. loss: 27695437697126904513953792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 12729390493.67, NNZs: 2, Bias: -48806714688.115585, T: 3712, Avg. loss: 773205029699635027902464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5576927808.31, NNZs: 2, Bias: -48518372789.501099, T: 3840, Avg. loss: 679618505745707298717696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2548755340.89, NNZs: 2, Bias: -48350439555.219887, T: 3968, Avg. loss: 274077238384407074570240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3957330678.63, NNZs: 2, Bias: -48338642060.573723, T: 4096, Avg. loss: 606186211263745804468224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4731131228.00, NNZs: 2, Bias: -48206962767.247215, T: 4224, Avg. loss: 470073649441232249683968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2725713097.89, NNZs: 2, Bias: -48200345440.841354, T: 4352, Avg. loss: 651002291960862612652032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9269130854.19, NNZs: 2, Bias: -48059382200.105522, T: 4480, Avg. loss: 380299545517458970378240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5510402640.56, NNZs: 2, Bias: -47885465699.002693, T: 4608, Avg. loss: 472681159194521093799936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3212258573.31, NNZs: 2, Bias: -47907422775.339241, T: 4736, Avg. loss: 2885366944989096968192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1977806382.18, NNZs: 2, Bias: -47908355279.141800, T: 4864, Avg. loss: 1067433112911204057088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1334040841.16, NNZs: 2, Bias: -47901257325.144569, T: 4992, Avg. loss: 471114939403180113920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1051499422.24, NNZs: 2, Bias: -47889150929.307426, T: 5120, Avg. loss: 315274911578136838144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 909713779.97, NNZs: 2, Bias: -47875380557.649895, T: 5248, Avg. loss: 257002086900645363712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 786806726.67, NNZs: 2, Bias: -47860827639.405449, T: 5376, Avg. loss: 250691127975781466112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 805845097.79, NNZs: 2, Bias: -47844946776.101097, T: 5504, Avg. loss: 224710116785468899328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 805750215.73, NNZs: 2, Bias: -47829300240.368851, T: 5632, Avg. loss: 235689979637894905856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 832386138.15, NNZs: 2, Bias: -47812817213.811615, T: 5760, Avg. loss: 233895514991747530752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 758115825.49, NNZs: 2, Bias: -47797295114.666962, T: 5888, Avg. loss: 253073334864054714368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 765269685.19, NNZs: 2, Bias: -47780343982.136658, T: 6016, Avg. loss: 254482210626664923136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 735540615.59, NNZs: 2, Bias: -47764223912.778191, T: 6144, Avg. loss: 260847116002808397824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 766708603.74, NNZs: 2, Bias: -47760472778.205444, T: 6272, Avg. loss: 196211371791117615104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 753070646.94, NNZs: 2, Bias: -47757482730.147339, T: 6400, Avg. loss: 193612720909713932288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 760901691.56, NNZs: 2, Bias: -47754115415.088120, T: 6528, Avg. loss: 195510887422909218816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 764445325.74, NNZs: 2, Bias: -47750831629.950089, T: 6656, Avg. loss: 194447583162373079040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 758862469.05, NNZs: 2, Bias: -47747713946.503944, T: 6784, Avg. loss: 193713328721434836992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 761330784.88, NNZs: 2, Bias: -47744422495.909477, T: 6912, Avg. loss: 196281284962020163584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 761829783.44, NNZs: 2, Bias: -47741229523.774513, T: 7040, Avg. loss: 191991911782565412864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 758300223.98, NNZs: 2, Bias: -47738088830.159248, T: 7168, Avg. loss: 192729348380299100160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 756072309.17, NNZs: 2, Bias: -47734884124.132103, T: 7296, Avg. loss: 195209632225051541504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 757688403.97, NNZs: 2, Bias: -47731573114.460487, T: 7424, Avg. loss: 198365704836963336192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 763913788.43, NNZs: 2, Bias: -47728246080.958427, T: 7552, Avg. loss: 194560118819963830272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 780176337.26, NNZs: 2, Bias: -47724813264.333557, T: 7680, Avg. loss: 190775791013694832640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 762468928.12, NNZs: 2, Bias: -47722018744.671684, T: 7808, Avg. loss: 186303908623947431936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 775499975.04, NNZs: 2, Bias: -47718561582.009102, T: 7936, Avg. loss: 195477711866928365568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 760561265.06, NNZs: 2, Bias: -47715561100.375534, T: 8064, Avg. loss: 196073643612985524224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 774852812.50, NNZs: 2, Bias: -47712112374.731285, T: 8192, Avg. loss: 193583723065247301632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 767526091.58, NNZs: 2, Bias: -47708999836.764824, T: 8320, Avg. loss: 194988418348765544448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 781534903.15, NNZs: 2, Bias: -47705631103.637512, T: 8448, Avg. loss: 188981506417234477056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 765603736.59, NNZs: 2, Bias: -47705236916.340584, T: 8576, Avg. loss: 191606295048099495936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 768099703.19, NNZs: 2, Bias: -47704553914.855049, T: 8704, Avg. loss: 188381475053701300224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 769504742.95, NNZs: 2, Bias: -47703890293.026085, T: 8832, Avg. loss: 187831140069313380352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 765484306.42, NNZs: 2, Bias: -47703313191.785469, T: 8960, Avg. loss: 188181647534318452736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 764512719.57, NNZs: 2, Bias: -47702687191.336823, T: 9088, Avg. loss: 188038022321426595840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 71 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 835536186098.20, NNZs: 2, Bias: 33062604027.046143, T: 128, Avg. loss: 19475452610599259259556331520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2335168073596.18, NNZs: 2, Bias: 120539802394.336304, T: 256, Avg. loss: 21203363867274390341056200704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1291666049372.51, NNZs: 2, Bias: 120539802394.336304, T: 384, Avg. loss: 22467766945019138143720308736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 632566444285.43, NNZs: 2, Bias: 80539802394.336304, T: 512, Avg. loss: 21825252182616767426816114688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 835448392876.73, NNZs: 2, Bias: 35087435789.975632, T: 640, Avg. loss: 20416847373140002644279951360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 574017153040.44, NNZs: 2, Bias: 139104018088.308563, T: 768, Avg. loss: 20872327147737645759535775744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 71559320243.17, NNZs: 2, Bias: 121662717525.037964, T: 896, Avg. loss: 831539900696239410853707776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 411265673846.66, NNZs: 2, Bias: 134008565249.140121, T: 1024, Avg. loss: 781300835348354901578088448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 532178632680.96, NNZs: 2, Bias: 144758613911.491882, T: 1152, Avg. loss: 788531687274235935779192832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 152559325840.63, NNZs: 2, Bias: 141175454477.230865, T: 1280, Avg. loss: 872526203828916792930074624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 366422417772.94, NNZs: 2, Bias: 137022661604.380890, T: 1408, Avg. loss: 724205204242659433148055552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 369552133238.54, NNZs: 2, Bias: 112991238479.681595, T: 1536, Avg. loss: 795668369402588827477868544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 80743006798.72, NNZs: 2, Bias: 126704167863.840286, T: 1664, Avg. loss: 736368071102474954767073280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 261838144971.18, NNZs: 2, Bias: 114825663696.777924, T: 1792, Avg. loss: 760343184980443917751156736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 318464499287.16, NNZs: 2, Bias: 132912329588.185638, T: 1920, Avg. loss: 756500207595132132123475968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 70652133856.81, NNZs: 2, Bias: 137992482720.337280, T: 2048, Avg. loss: 847607891427707505726193664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41409015747.21, NNZs: 2, Bias: 139310508784.717041, T: 2176, Avg. loss: 27477875688059447659200512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 48302874073.65, NNZs: 2, Bias: 141414169574.644104, T: 2304, Avg. loss: 31405930901307907379298304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 34557625758.32, NNZs: 2, Bias: 140593985939.996765, T: 2432, Avg. loss: 29419934824289172855980032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 50166433106.89, NNZs: 2, Bias: 138422201984.502014, T: 2560, Avg. loss: 29645867375894283383996416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 37364387130.85, NNZs: 2, Bias: 140652123141.977539, T: 2688, Avg. loss: 30461029070386191501623296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 57571278621.97, NNZs: 2, Bias: 140212983506.438843, T: 2816, Avg. loss: 28480856255678571008229376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4373228800.15, NNZs: 2, Bias: 139902292161.847931, T: 2944, Avg. loss: 1269278004611670840705024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 7757467699.90, NNZs: 2, Bias: 139662613496.438263, T: 3072, Avg. loss: 498242246518385397465088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4881582959.69, NNZs: 2, Bias: 139712434868.516602, T: 3200, Avg. loss: 567708906036006129500160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8982109254.39, NNZs: 2, Bias: 139507792371.548126, T: 3328, Avg. loss: 536969883689322702438400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 7090618185.32, NNZs: 2, Bias: 139420142278.181519, T: 3456, Avg. loss: 580047289701266859491328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 7060424646.08, NNZs: 2, Bias: 138932560753.329956, T: 3584, Avg. loss: 398065564249163762237440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4016637392.29, NNZs: 2, Bias: 138948851543.695801, T: 3712, Avg. loss: 623265194067218850119680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8933139734.37, NNZs: 2, Bias: 138731726459.380676, T: 3840, Avg. loss: 723069366326388664041472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6190101761.11, NNZs: 2, Bias: 138288849991.395691, T: 3968, Avg. loss: 653269235193742276689920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9059098290.01, NNZs: 2, Bias: 137926435801.371613, T: 4096, Avg. loss: 361054186765539753328640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1634337232.35, NNZs: 2, Bias: 137694248443.913788, T: 4224, Avg. loss: 697570083488389276893184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4868893611.49, NNZs: 2, Bias: 137602392308.683685, T: 4352, Avg. loss: 680650365923815858372608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6070950452.95, NNZs: 2, Bias: 137323837164.611191, T: 4480, Avg. loss: 549020667728909534494720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9393839369.23, NNZs: 2, Bias: 137099753491.003540, T: 4608, Avg. loss: 548450603432565956149248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8906795211.22, NNZs: 2, Bias: 137156786263.437897, T: 4736, Avg. loss: 612849256894141195878400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1262736132.43, NNZs: 2, Bias: 137046868631.943466, T: 4864, Avg. loss: 33290918373322936811520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1791093207.29, NNZs: 2, Bias: 136993186632.933395, T: 4992, Avg. loss: 1912921709930292969472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2067057465.26, NNZs: 2, Bias: 136942697156.572357, T: 5120, Avg. loss: 1959453945152535265280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2211993314.88, NNZs: 2, Bias: 136896864915.200394, T: 5248, Avg. loss: 1794135348732893593600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2279888611.01, NNZs: 2, Bias: 136852949578.633347, T: 5376, Avg. loss: 1748912472514285273088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2301237386.57, NNZs: 2, Bias: 136811439912.476868, T: 5504, Avg. loss: 1736612263960844697600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2368711540.44, NNZs: 2, Bias: 136764883631.093826, T: 5632, Avg. loss: 1869827889963236327424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2444958559.04, NNZs: 2, Bias: 136719836456.160416, T: 5760, Avg. loss: 1783471991958775267328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2401620101.72, NNZs: 2, Bias: 136677731255.781158, T: 5888, Avg. loss: 1835262401112158502912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2393153180.33, NNZs: 2, Bias: 136636699063.545898, T: 6016, Avg. loss: 1739804871384553226240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2402519362.10, NNZs: 2, Bias: 136590637090.234360, T: 6144, Avg. loss: 2012760528593381752832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2401502670.38, NNZs: 2, Bias: 136582021669.606262, T: 6272, Avg. loss: 1488024618050164883456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2391062642.80, NNZs: 2, Bias: 136573647517.603058, T: 6400, Avg. loss: 1472962522177279885312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2374885638.84, NNZs: 2, Bias: 136565325209.265076, T: 6528, Avg. loss: 1484295221481579479040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2377034247.54, NNZs: 2, Bias: 136556638253.202972, T: 6656, Avg. loss: 1490816403128685690880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2357899322.34, NNZs: 2, Bias: 136548412673.395386, T: 6784, Avg. loss: 1474364771245555187712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2374481528.24, NNZs: 2, Bias: 136539517450.340668, T: 6912, Avg. loss: 1484201614116793352192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2367092038.27, NNZs: 2, Bias: 136531067227.911346, T: 7040, Avg. loss: 1478536845073043685376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2379922924.42, NNZs: 2, Bias: 136529135976.892609, T: 7168, Avg. loss: 1431710290821890965504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2371012886.36, NNZs: 2, Bias: 136527591820.155380, T: 7296, Avg. loss: 1425303626159654436864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2380856889.76, NNZs: 2, Bias: 136525714101.807068, T: 7424, Avg. loss: 1430345589160195391488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2376583314.40, NNZs: 2, Bias: 136524079124.456970, T: 7552, Avg. loss: 1433499564476537765888.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2373862513.18, NNZs: 2, Bias: 136522421141.224457, T: 7680, Avg. loss: 1430119486113082507264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2378334565.97, NNZs: 2, Bias: 136520635819.219482, T: 7808, Avg. loss: 1431452326829562003456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2375822635.89, NNZs: 2, Bias: 136518969862.805679, T: 7936, Avg. loss: 1433620161415277182976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 62 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 786472172027.15, NNZs: 2, Bias: 65591751177.222687, T: 128, Avg. loss: 22809906614352581119174508544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1457513393676.68, NNZs: 2, Bias: 60999623037.466995, T: 256, Avg. loss: 25561123058093588821886107648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 366806328601.74, NNZs: 2, Bias: -19000376962.533005, T: 384, Avg. loss: 21767045132737269418061463552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1713223090671.63, NNZs: 2, Bias: 20999623037.466995, T: 512, Avg. loss: 23757800879850681866920132608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1707092990188.61, NNZs: 2, Bias: 31660828205.480606, T: 640, Avg. loss: 21686012927769517857076936704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 682832934890.05, NNZs: 2, Bias: 78085997069.106705, T: 768, Avg. loss: 24337799370023157087309135872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 664946392228.68, NNZs: 2, Bias: 48576641828.024368, T: 896, Avg. loss: 24296038109064213312051347456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1369171987897.29, NNZs: 2, Bias: 48427573619.756683, T: 1024, Avg. loss: 21709578512335906105056034816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 706979539937.48, NNZs: 2, Bias: 66700668405.393692, T: 1152, Avg. loss: 23882975296106907156363608064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1862696602161.69, NNZs: 2, Bias: 106700668405.393677, T: 1280, Avg. loss: 21913090840685851680664715264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 249395961243.06, NNZs: 2, Bias: 82464892142.957825, T: 1408, Avg. loss: 1990683963332454481200676864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 348277552350.83, NNZs: 2, Bias: 86109276723.933380, T: 1536, Avg. loss: 818613907231454359128637440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 278670606196.47, NNZs: 2, Bias: 82108594119.291290, T: 1664, Avg. loss: 864430827533120645059575808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 127821735510.27, NNZs: 2, Bias: 88111558097.723190, T: 1792, Avg. loss: 847927441905001474492989440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 223803350797.38, NNZs: 2, Bias: 106737286335.885910, T: 1920, Avg. loss: 929456658574185664958431232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 153772813380.75, NNZs: 2, Bias: 110922720184.824127, T: 2048, Avg. loss: 933216624530361770418634752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 181518568062.10, NNZs: 2, Bias: 118251596784.194077, T: 2176, Avg. loss: 916422519101220725117157376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 73383199080.65, NNZs: 2, Bias: 121799256773.549973, T: 2304, Avg. loss: 39233897848923716510023680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40233372429.90, NNZs: 2, Bias: 119730569144.285080, T: 2432, Avg. loss: 32906707918139731740721152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 13859308010.54, NNZs: 2, Bias: 121470198226.084106, T: 2560, Avg. loss: 35681782374829069212581888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 56145435499.50, NNZs: 2, Bias: 123713417371.679047, T: 2688, Avg. loss: 29451963014591953315561472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 24045705040.97, NNZs: 2, Bias: 124829407926.746689, T: 2816, Avg. loss: 31037155859693869486571520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 77816491523.68, NNZs: 2, Bias: 125794385234.954895, T: 2944, Avg. loss: 34555105305267391789268992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 32479234047.32, NNZs: 2, Bias: 127710330628.071976, T: 3072, Avg. loss: 34051770801764337618780160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 36372159834.27, NNZs: 2, Bias: 127000906894.283524, T: 3200, Avg. loss: 36181042909392656272457728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 27375795080.22, NNZs: 2, Bias: 123323276242.627548, T: 3328, Avg. loss: 32692602143150368607961088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 9598050124.76, NNZs: 2, Bias: 123008319949.891632, T: 3456, Avg. loss: 915962955611677495656448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 7988463200.25, NNZs: 2, Bias: 122658700795.053070, T: 3584, Avg. loss: 940080892409909021245440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2216466918.77, NNZs: 2, Bias: 122601577053.300385, T: 3712, Avg. loss: 799134839346462894063616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 6434266048.82, NNZs: 2, Bias: 122482559598.576263, T: 3840, Avg. loss: 552416171583321183092736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4849921477.12, NNZs: 2, Bias: 122391990803.839600, T: 3968, Avg. loss: 765892446914923758354432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3132632358.25, NNZs: 2, Bias: 122325870504.486237, T: 4096, Avg. loss: 701115538212870403653632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2546931153.79, NNZs: 2, Bias: 122096168841.668076, T: 4224, Avg. loss: 717360023992901671321600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6374786422.05, NNZs: 2, Bias: 121565962350.754486, T: 4352, Avg. loss: 735989399416986897743872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1881099067.49, NNZs: 2, Bias: 121485503599.121887, T: 4480, Avg. loss: 608347346503201776992256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1209603108.75, NNZs: 2, Bias: 121427998894.088272, T: 4608, Avg. loss: 3470441294364860743680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1587110425.80, NNZs: 2, Bias: 121380067047.997543, T: 4736, Avg. loss: 1569518059925188378624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1743059616.86, NNZs: 2, Bias: 121335806278.122040, T: 4864, Avg. loss: 1623196264423429505024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1807594599.59, NNZs: 2, Bias: 121293647172.799988, T: 4992, Avg. loss: 1541238719402492559360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1816137168.36, NNZs: 2, Bias: 121251315833.830978, T: 5120, Avg. loss: 1603350808446643732480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1956461015.38, NNZs: 2, Bias: 121210102131.586380, T: 5248, Avg. loss: 1436478681682419122176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1956055428.95, NNZs: 2, Bias: 121169846124.982101, T: 5376, Avg. loss: 1535318723848546025472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1915591675.45, NNZs: 2, Bias: 121129738211.390106, T: 5504, Avg. loss: 1523172173071464529920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1822951365.84, NNZs: 2, Bias: 121091993443.927078, T: 5632, Avg. loss: 1468962278371224715264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1731954913.87, NNZs: 2, Bias: 121051153992.330826, T: 5760, Avg. loss: 1622114992401347248128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1880152545.28, NNZs: 2, Bias: 121006868448.695175, T: 5888, Avg. loss: 1613704516285799333888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1854866685.65, NNZs: 2, Bias: 120999329371.757935, T: 6016, Avg. loss: 1212004955772115484672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1902392007.58, NNZs: 2, Bias: 120990425926.740295, T: 6144, Avg. loss: 1243929863604481818624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1889660642.85, NNZs: 2, Bias: 120982731355.959824, T: 6272, Avg. loss: 1207185677499703230464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1889433436.56, NNZs: 2, Bias: 120974554394.732407, T: 6400, Avg. loss: 1248089098923475206144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1895564742.88, NNZs: 2, Bias: 120966302031.536896, T: 6528, Avg. loss: 1246270162428332081152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1871370522.56, NNZs: 2, Bias: 120958625962.362762, T: 6656, Avg. loss: 1230855720770461237248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1873993013.72, NNZs: 2, Bias: 120950341593.696838, T: 6784, Avg. loss: 1260673787125659336704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1875822590.04, NNZs: 2, Bias: 120942150628.178497, T: 6912, Avg. loss: 1245714945594340409344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1870921991.25, NNZs: 2, Bias: 120940600085.008469, T: 7040, Avg. loss: 1208595649510154960896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1884301105.78, NNZs: 2, Bias: 120938779875.851639, T: 7168, Avg. loss: 1197173643364142153728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1868403729.04, NNZs: 2, Bias: 120937410920.485992, T: 7296, Avg. loss: 1200864923238395281408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1878523897.32, NNZs: 2, Bias: 120935628743.333511, T: 7424, Avg. loss: 1206878454348467404800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1882260393.15, NNZs: 2, Bias: 120933950107.459244, T: 7552, Avg. loss: 1203502624301244481536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1875317141.66, NNZs: 2, Bias: 120932432433.144348, T: 7680, Avg. loss: 1207871609299170230272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1881955598.02, NNZs: 2, Bias: 120930707194.283539, T: 7808, Avg. loss: 1204699544635392393216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 61 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1921682543117.49, NNZs: 2, Bias: 13169078948.053787, T: 128, Avg. loss: 21457967541282511506439667712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1699512735438.83, NNZs: 2, Bias: 93169078948.053787, T: 256, Avg. loss: 25539574600438211466812719104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1153993105955.25, NNZs: 2, Bias: 73169078948.053787, T: 384, Avg. loss: 22855561361735576764085698560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 361455168051.02, NNZs: 2, Bias: 130466982671.403442, T: 512, Avg. loss: 22155332520560620478492835840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2303744749266.98, NNZs: 2, Bias: 80855968481.757462, T: 640, Avg. loss: 21550373564260346069421916160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1716586178054.08, NNZs: 2, Bias: 200855968481.757446, T: 768, Avg. loss: 23127677997733768652430245888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 548566117124.50, NNZs: 2, Bias: 191970363288.888184, T: 896, Avg. loss: 1645765795413385969502519296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 199976858990.57, NNZs: 2, Bias: 194457999126.770416, T: 1024, Avg. loss: 935984868885315104851099648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 282808567975.36, NNZs: 2, Bias: 188933208549.526947, T: 1152, Avg. loss: 911000715772262176180404224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 105715271797.68, NNZs: 2, Bias: 167605611538.765747, T: 1280, Avg. loss: 899402610542385062293274624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 228832734617.01, NNZs: 2, Bias: 172422225161.670319, T: 1408, Avg. loss: 973688161523168868946673664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 274179078588.60, NNZs: 2, Bias: 174353697405.336121, T: 1536, Avg. loss: 896864533865478591931744256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 460829368190.95, NNZs: 2, Bias: 165918022424.441315, T: 1664, Avg. loss: 953763243879269266375049216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 363294818667.14, NNZs: 2, Bias: 151388557481.644318, T: 1792, Avg. loss: 895074239561120840673132544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 479443174118.92, NNZs: 2, Bias: 160477160101.119354, T: 1920, Avg. loss: 922236197679117622243753984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 247494083796.18, NNZs: 2, Bias: 159531047932.528839, T: 2048, Avg. loss: 948177074532427280794255360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 499422524151.98, NNZs: 2, Bias: 147832932630.095123, T: 2176, Avg. loss: 835032461308225594685652992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 401473173194.90, NNZs: 2, Bias: 151832932630.095123, T: 2304, Avg. loss: 928012560586328679206879232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 389429423458.59, NNZs: 2, Bias: 153396777284.304413, T: 2432, Avg. loss: 929474754806088436551778304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 343111293549.23, NNZs: 2, Bias: 160303984042.994812, T: 2560, Avg. loss: 898963527080068666682769408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 214400005256.43, NNZs: 2, Bias: 176728845589.649353, T: 2688, Avg. loss: 1040208373111671873398112256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 409948491708.75, NNZs: 2, Bias: 179844580146.477753, T: 2816, Avg. loss: 894147853081318970194132992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 18345787497.77, NNZs: 2, Bias: 172800432135.209167, T: 2944, Avg. loss: 84151273663526522656391168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 58180104212.05, NNZs: 2, Bias: 169860673083.785950, T: 3072, Avg. loss: 35127966776566439322058752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 11606654406.27, NNZs: 2, Bias: 170624287355.331482, T: 3200, Avg. loss: 32877658732883315041239040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 92601728158.64, NNZs: 2, Bias: 170094991044.746338, T: 3328, Avg. loss: 34421301156444848139534336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 27154559676.42, NNZs: 2, Bias: 170016436507.237518, T: 3456, Avg. loss: 35526674944349757423747072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 79452110294.64, NNZs: 2, Bias: 168337896807.794342, T: 3584, Avg. loss: 34070912326905355839733760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 48713895636.65, NNZs: 2, Bias: 169002799072.160370, T: 3712, Avg. loss: 36323422689117768255537152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 54143360920.96, NNZs: 2, Bias: 165252872035.672089, T: 3840, Avg. loss: 37323873451354544070983680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 13261597836.68, NNZs: 2, Bias: 165267534254.590424, T: 3968, Avg. loss: 1127585193277562000769024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3163858034.27, NNZs: 2, Bias: 164870726505.469360, T: 4096, Avg. loss: 870850852873253381210112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 14693689344.41, NNZs: 2, Bias: 164533798496.073486, T: 4224, Avg. loss: 619255546497933126926336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8992277578.10, NNZs: 2, Bias: 164438083645.010986, T: 4352, Avg. loss: 842447551529018351157248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9176064847.35, NNZs: 2, Bias: 164504714143.519409, T: 4480, Avg. loss: 813547089046962819825664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4153299433.37, NNZs: 2, Bias: 164392017833.806030, T: 4608, Avg. loss: 783158447279396184129536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9195827118.57, NNZs: 2, Bias: 164231456003.088806, T: 4736, Avg. loss: 775916974742358062006272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 961422472.34, NNZs: 2, Bias: 163994048229.333374, T: 4864, Avg. loss: 620508408572024912347136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1753277684.34, NNZs: 2, Bias: 163931197919.262390, T: 4992, Avg. loss: 2703987921656196104192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2076816192.69, NNZs: 2, Bias: 163879033586.460510, T: 5120, Avg. loss: 2328298333072014180352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2367408633.62, NNZs: 2, Bias: 163826962394.584534, T: 5248, Avg. loss: 2380666056620732579840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2309697163.04, NNZs: 2, Bias: 163779148239.767273, T: 5376, Avg. loss: 2442094484697817022464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2526777402.17, NNZs: 2, Bias: 163728608565.938263, T: 5504, Avg. loss: 2288004220435008061440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2321467876.01, NNZs: 2, Bias: 163684110195.039215, T: 5632, Avg. loss: 2441011779711230017536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2347677509.38, NNZs: 2, Bias: 163635890503.799164, T: 5760, Avg. loss: 2425670595598629732352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2298692597.44, NNZs: 2, Bias: 163588439505.029205, T: 5888, Avg. loss: 2341946457321770582016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2245074656.74, NNZs: 2, Bias: 163538759690.388489, T: 6016, Avg. loss: 2509576935663067463680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2481817367.93, NNZs: 2, Bias: 163487263631.528381, T: 6144, Avg. loss: 2345165458137680183296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2372539928.69, NNZs: 2, Bias: 163479204795.077271, T: 6272, Avg. loss: 2003165694388246413312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2373126238.28, NNZs: 2, Bias: 163469649318.718933, T: 6400, Avg. loss: 1965566625885321428992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2397517802.96, NNZs: 2, Bias: 163459645484.975830, T: 6528, Avg. loss: 1986735627839047729152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2413475753.93, NNZs: 2, Bias: 163449792488.734558, T: 6656, Avg. loss: 1980343309248470188032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2416363081.93, NNZs: 2, Bias: 163440227835.796692, T: 6784, Avg. loss: 1961045613644009701376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2430092812.74, NNZs: 2, Bias: 163430520610.973145, T: 6912, Avg. loss: 1956065018827498061824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2393548316.30, NNZs: 2, Bias: 163421504437.266510, T: 7040, Avg. loss: 1969389195718923386880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2415405192.80, NNZs: 2, Bias: 163411791540.488892, T: 7168, Avg. loss: 1933697627790683668480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2433266238.18, NNZs: 2, Bias: 163402086080.447693, T: 7296, Avg. loss: 1943062934373024661504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2422903894.47, NNZs: 2, Bias: 163392787133.340851, T: 7424, Avg. loss: 1947497483631863005184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2416118723.52, NNZs: 2, Bias: 163383498723.749573, T: 7552, Avg. loss: 1934761080637027254272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2394677768.10, NNZs: 2, Bias: 163374219838.484741, T: 7680, Avg. loss: 1978486645592064262144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2383579154.68, NNZs: 2, Bias: 163364824719.466766, T: 7808, Avg. loss: 1968205968155903787008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2395077108.71, NNZs: 2, Bias: 163362744209.065857, T: 7936, Avg. loss: 1917540467637298659328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2401478217.24, NNZs: 2, Bias: 163360749127.373169, T: 8064, Avg. loss: 1906577111096160419840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2396740374.07, NNZs: 2, Bias: 163358926033.902618, T: 8192, Avg. loss: 1898392529477648252928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2395288157.54, NNZs: 2, Bias: 163357058888.617004, T: 8320, Avg. loss: 1893721316585708716032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2409813914.03, NNZs: 2, Bias: 163354952202.727081, T: 8448, Avg. loss: 1897877958584660918272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2403019121.36, NNZs: 2, Bias: 163353151380.721771, T: 8576, Avg. loss: 1906810069226191585280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2409278985.35, NNZs: 2, Bias: 163351160489.777191, T: 8704, Avg. loss: 1903911310219148263424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2402094451.63, NNZs: 2, Bias: 163349367248.784363, T: 8832, Avg. loss: 1904965221559051747328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2404820524.11, NNZs: 2, Bias: 163347428771.342682, T: 8960, Avg. loss: 1903669169079743938560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 70 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 916878998645.72, NNZs: 2, Bias: 44129990503.265228, T: 128, Avg. loss: 20991679341131737144647221248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2858732966278.10, NNZs: 2, Bias: 84129990503.265228, T: 256, Avg. loss: 20433014358604847128747442176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1535388717928.13, NNZs: 2, Bias: 65447545718.358185, T: 384, Avg. loss: 24575602405863841241594068992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2790812634597.31, NNZs: 2, Bias: 31644827010.703613, T: 512, Avg. loss: 21163936422147061980390752256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1966858752457.38, NNZs: 2, Bias: 31644827010.703613, T: 640, Avg. loss: 21338883567135604812478939136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1346380762549.24, NNZs: 2, Bias: 141200418342.090942, T: 768, Avg. loss: 20178167306700656301324632064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2700471873912.08, NNZs: 2, Bias: 204974512163.058533, T: 896, Avg. loss: 20239482397292186680204197888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2436348816693.92, NNZs: 2, Bias: 252319987886.624268, T: 1024, Avg. loss: 20566869491335208784942333952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1566056528364.15, NNZs: 2, Bias: 130276574977.760681, T: 1152, Avg. loss: 19867254741867358939301019648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 502769187406.58, NNZs: 2, Bias: 212994179081.907471, T: 1280, Avg. loss: 20926272826297279128667160576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2303241838527.11, NNZs: 2, Bias: 289493976527.663757, T: 1408, Avg. loss: 20419616953700498194630180864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1757087449573.30, NNZs: 2, Bias: 249493976527.663757, T: 1536, Avg. loss: 19848410086735169847069507584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2086169532938.53, NNZs: 2, Bias: 267631507173.363037, T: 1664, Avg. loss: 22218860516235816191639158784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2743189197817.29, NNZs: 2, Bias: 289509920817.787598, T: 1792, Avg. loss: 21971079518370885178773995520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1673708374160.22, NNZs: 2, Bias: 290074106777.930847, T: 1920, Avg. loss: 22672769402623015718897057792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2858417946750.00, NNZs: 2, Bias: 317121195377.871582, T: 2048, Avg. loss: 20123097691927097395575259136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1344187607094.84, NNZs: 2, Bias: 257121195377.871582, T: 2176, Avg. loss: 24142988026293851718475055104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 531466409825.45, NNZs: 2, Bias: 265754846405.388916, T: 2304, Avg. loss: 1005588081025956221007429632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 180665917949.02, NNZs: 2, Bias: 267001001148.010590, T: 2432, Avg. loss: 808497866243158759081771008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 501064238562.83, NNZs: 2, Bias: 278944033099.068787, T: 2560, Avg. loss: 837887761832929044933378048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 425840895961.06, NNZs: 2, Bias: 264973152417.108368, T: 2688, Avg. loss: 791848591851495282328993792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 511681470807.34, NNZs: 2, Bias: 271891063838.927185, T: 2816, Avg. loss: 847448088788246213221679104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 384363160388.60, NNZs: 2, Bias: 276663876577.405823, T: 2944, Avg. loss: 824092116109403322203504640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 391412074245.17, NNZs: 2, Bias: 280497489365.396606, T: 3072, Avg. loss: 875468647623851093599977472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 318401836308.28, NNZs: 2, Bias: 287806036266.373657, T: 3200, Avg. loss: 860868923527335344928194560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 489237316631.03, NNZs: 2, Bias: 282241504686.283203, T: 3328, Avg. loss: 824891274501383808203358208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 63903911294.88, NNZs: 2, Bias: 280779669997.805603, T: 3456, Avg. loss: 138190470973950349077905408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 109566740576.28, NNZs: 2, Bias: 276611962497.421021, T: 3584, Avg. loss: 29647754545888827602370560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 109044292741.95, NNZs: 2, Bias: 276763574452.399048, T: 3712, Avg. loss: 31662359276317021938122752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 41648523782.42, NNZs: 2, Bias: 276341089482.509216, T: 3840, Avg. loss: 35314710011829820311207936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 75287645957.55, NNZs: 2, Bias: 272279510099.463074, T: 3968, Avg. loss: 30846079055679641509429248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 99941234125.51, NNZs: 2, Bias: 273152902868.937958, T: 4096, Avg. loss: 33555368649769500285075456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 27775175185.89, NNZs: 2, Bias: 271367092045.837616, T: 4224, Avg. loss: 32771265150120265816997888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 17601633965.57, NNZs: 2, Bias: 270300011132.267548, T: 4352, Avg. loss: 753752975954056748990464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 13036751410.32, NNZs: 2, Bias: 270081340592.950653, T: 4480, Avg. loss: 820808862030464060227584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 15007784210.71, NNZs: 2, Bias: 269642811875.011566, T: 4608, Avg. loss: 836321773900894585225216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3175760302.99, NNZs: 2, Bias: 268944501988.239899, T: 4736, Avg. loss: 683202957202153577381888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 14912756746.14, NNZs: 2, Bias: 268098851245.322906, T: 4864, Avg. loss: 818372860523564106776576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 20207742507.24, NNZs: 2, Bias: 267552739343.471313, T: 4992, Avg. loss: 763139979861613971767296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 17998979271.31, NNZs: 2, Bias: 267153685639.515411, T: 5120, Avg. loss: 758190918092011994087424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 16257636007.74, NNZs: 2, Bias: 266850598847.252289, T: 5248, Avg. loss: 767753849282304898236416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 18660455079.04, NNZs: 2, Bias: 266430100945.324585, T: 5376, Avg. loss: 625710952075344494985216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 17555199886.63, NNZs: 2, Bias: 265682734735.358124, T: 5504, Avg. loss: 680373594564426175873024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 7638024286.21, NNZs: 2, Bias: 265377546158.132111, T: 5632, Avg. loss: 826334666778889347399680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 11857046288.12, NNZs: 2, Bias: 264586612375.596130, T: 5760, Avg. loss: 632175300344285770022912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 15690410491.99, NNZs: 2, Bias: 264098950222.106232, T: 5888, Avg. loss: 618302542276114681692160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 16750530564.28, NNZs: 2, Bias: 263702163039.117493, T: 6016, Avg. loss: 565185838309226837966848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 14288177233.33, NNZs: 2, Bias: 263330272555.207794, T: 6144, Avg. loss: 663746937451345692590080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 5370034399.51, NNZs: 2, Bias: 262757808757.987091, T: 6272, Avg. loss: 709895978343069000925184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 10281575865.34, NNZs: 2, Bias: 262148776346.893982, T: 6400, Avg. loss: 724184734573474409873408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 13290859283.29, NNZs: 2, Bias: 261704240139.999481, T: 6528, Avg. loss: 627858656698886814433280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 18313175721.94, NNZs: 2, Bias: 261472025300.562805, T: 6656, Avg. loss: 690190102899492877500416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 5992337361.19, NNZs: 2, Bias: 261243869824.617401, T: 6784, Avg. loss: 86370217973884127281152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 5181556790.89, NNZs: 2, Bias: 261168074035.214905, T: 6912, Avg. loss: 7553536227165873373184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4560558367.44, NNZs: 2, Bias: 261090160645.930359, T: 7040, Avg. loss: 7492321597826275475456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4406927633.78, NNZs: 2, Bias: 261003974355.232300, T: 7168, Avg. loss: 7229210191337253502976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4175166102.83, NNZs: 2, Bias: 260912053640.344238, T: 7296, Avg. loss: 7522497313796891082752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4257904900.02, NNZs: 2, Bias: 260823737829.618896, T: 7424, Avg. loss: 6810873750945906294784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4313779410.85, NNZs: 2, Bias: 260733715037.120575, T: 7552, Avg. loss: 6813012327707420131328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4146250415.48, NNZs: 2, Bias: 260646265613.726837, T: 7680, Avg. loss: 7255575078192662183936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4257518485.30, NNZs: 2, Bias: 260552130874.962738, T: 7808, Avg. loss: 7495278064371416170496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4260117451.95, NNZs: 2, Bias: 260462337622.471863, T: 7936, Avg. loss: 7069426076445762912256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4245147328.02, NNZs: 2, Bias: 260370845100.439850, T: 8064, Avg. loss: 7341160428797982408704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4238553872.61, NNZs: 2, Bias: 260352510904.548431, T: 8192, Avg. loss: 6049134957023284166656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4257664159.64, NNZs: 2, Bias: 260333770828.992920, T: 8320, Avg. loss: 6050916397400169906176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4189360823.96, NNZs: 2, Bias: 260316764667.395172, T: 8448, Avg. loss: 5937687141055857688576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4217487756.81, NNZs: 2, Bias: 260297941478.026855, T: 8576, Avg. loss: 6024623047361373929472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4215190296.51, NNZs: 2, Bias: 260279483076.011200, T: 8704, Avg. loss: 6072324621987458580480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4256892355.92, NNZs: 2, Bias: 260260593061.644257, T: 8832, Avg. loss: 5961384438410517676032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4245730606.22, NNZs: 2, Bias: 260242509883.209595, T: 8960, Avg. loss: 5986371729301972189184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4170497452.28, NNZs: 2, Bias: 260225781967.450287, T: 9088, Avg. loss: 5899632796033265696768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 4203598048.57, NNZs: 2, Bias: 260207133239.160278, T: 9216, Avg. loss: 5935751146993133551616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 4218445493.01, NNZs: 2, Bias: 260188715264.452484, T: 9344, Avg. loss: 5955622864465342496768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 4198090561.36, NNZs: 2, Bias: 260170575486.389008, T: 9472, Avg. loss: 6057500069331806978048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 4194841557.65, NNZs: 2, Bias: 260152700175.051697, T: 9600, Avg. loss: 5875566137481268035584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 4203140556.52, NNZs: 2, Bias: 260134021221.990814, T: 9728, Avg. loss: 6074781507905246986240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 4207811149.01, NNZs: 2, Bias: 260115620414.551666, T: 9856, Avg. loss: 5992057885332498022400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 4196398387.08, NNZs: 2, Bias: 260097432363.914642, T: 9984, Avg. loss: 6022027570383127838720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 4149241645.64, NNZs: 2, Bias: 260079981191.669403, T: 10112, Avg. loss: 5968569286460122857472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 4167939870.43, NNZs: 2, Bias: 260061717688.035065, T: 10240, Avg. loss: 5877717609569501315072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 4197713714.63, NNZs: 2, Bias: 260057552473.846832, T: 10368, Avg. loss: 5882648153646418624512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 4198644804.93, NNZs: 2, Bias: 260053881400.709290, T: 10496, Avg. loss: 5836963281521880334336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 4203057531.28, NNZs: 2, Bias: 260050156135.602386, T: 10624, Avg. loss: 5832301056315439972352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 4207966034.96, NNZs: 2, Bias: 260046432409.443115, T: 10752, Avg. loss: 5817304673192322793472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 4223121816.46, NNZs: 2, Bias: 260042568401.894104, T: 10880, Avg. loss: 5774448861314120941568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 4186055143.13, NNZs: 2, Bias: 260039529285.151459, T: 11008, Avg. loss: 5811708110636526338048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 4185480225.86, NNZs: 2, Bias: 260035885050.033447, T: 11136, Avg. loss: 5832599184995568844800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 4196921842.84, NNZs: 2, Bias: 260032044995.930817, T: 11264, Avg. loss: 5834015352190140416000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 4210321523.95, NNZs: 2, Bias: 260028187957.048492, T: 11392, Avg. loss: 5809486593540181983232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 4204185564.70, NNZs: 2, Bias: 260024628336.151672, T: 11520, Avg. loss: 5841335470469331025920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 90 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 908799469440.11, NNZs: 2, Bias: -8705949399.935455, T: 128, Avg. loss: 20259444639179450429697163264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 854408308361.99, NNZs: 2, Bias: 33607216694.595303, T: 256, Avg. loss: 20036586070332542635479138304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 599032714992.44, NNZs: 2, Bias: 86561812645.068741, T: 384, Avg. loss: 19504281368223325327829499904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1984494776651.43, NNZs: 2, Bias: 106561812645.068741, T: 512, Avg. loss: 19134231357850979136949977088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2026785118366.41, NNZs: 2, Bias: 13746499694.038517, T: 640, Avg. loss: 19524805183026882455963435008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 993958695047.78, NNZs: 2, Bias: -12333126337.393173, T: 768, Avg. loss: 19671991354560552174167785472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 616362932622.34, NNZs: 2, Bias: -54050913070.313507, T: 896, Avg. loss: 21397337803966003970272395264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1898963637936.43, NNZs: 2, Bias: -69256037156.159973, T: 1024, Avg. loss: 18984204641708512997774721024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1944837564806.96, NNZs: 2, Bias: 10743962843.840027, T: 1152, Avg. loss: 19541790876063056922044006400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 285587765207.40, NNZs: 2, Bias: 17862379974.540527, T: 1280, Avg. loss: 19063107187282539376277454848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2172353977058.27, NNZs: 2, Bias: 157862379974.540527, T: 1408, Avg. loss: 19260682134416113433522995200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 975473714576.05, NNZs: 2, Bias: 178492564217.658112, T: 1536, Avg. loss: 19211628348879842404735123456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1350496348398.77, NNZs: 2, Bias: 158492564217.658112, T: 1664, Avg. loss: 21130221761777256277731180544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 204807819977.65, NNZs: 2, Bias: 178847703405.442749, T: 1792, Avg. loss: 1153433663820077661641768960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 425537391830.30, NNZs: 2, Bias: 199049439640.612640, T: 1920, Avg. loss: 740053856288111129849233408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 224426164986.93, NNZs: 2, Bias: 193190644382.785095, T: 2048, Avg. loss: 843727638090519873639677952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 183733854233.11, NNZs: 2, Bias: 192146453376.865417, T: 2176, Avg. loss: 800035048340282545325211648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 98288247658.04, NNZs: 2, Bias: 181359044192.373840, T: 2304, Avg. loss: 845832107583641358140702720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 210998755236.65, NNZs: 2, Bias: 169046660752.682678, T: 2432, Avg. loss: 739517473229502287676702720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 272482306321.13, NNZs: 2, Bias: 172428118758.718658, T: 2560, Avg. loss: 859152716695259343335981056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 560134614840.26, NNZs: 2, Bias: 163305451226.738983, T: 2688, Avg. loss: 781723800664597797602852864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 422766360472.75, NNZs: 2, Bias: 181327815903.941498, T: 2816, Avg. loss: 818654433549961245145169920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 99811071765.87, NNZs: 2, Bias: 166325095230.328979, T: 2944, Avg. loss: 814158344470353764518199296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 221463151782.98, NNZs: 2, Bias: 179952288638.432709, T: 3072, Avg. loss: 854977739717563716936400896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 46634148763.59, NNZs: 2, Bias: 176148852147.468536, T: 3200, Avg. loss: 33263141359321582525218816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 16392113981.50, NNZs: 2, Bias: 172629466497.311218, T: 3328, Avg. loss: 31649493019397656108072960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 33505466432.89, NNZs: 2, Bias: 172740741737.680817, T: 3456, Avg. loss: 26829527229474322186764288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 74743590589.83, NNZs: 2, Bias: 172901295494.991852, T: 3584, Avg. loss: 26537906444207775354454016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 80193799866.91, NNZs: 2, Bias: 172235629082.417999, T: 3712, Avg. loss: 27824233040660567462772736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 29619187961.08, NNZs: 2, Bias: 172640812982.239929, T: 3840, Avg. loss: 29449660389817376785301504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 33492241223.08, NNZs: 2, Bias: 170705786751.702606, T: 3968, Avg. loss: 30008115065778575106899968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 32431978750.97, NNZs: 2, Bias: 164720747755.324982, T: 4096, Avg. loss: 28838309368359783961198592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 29875142493.75, NNZs: 2, Bias: 162753617605.817322, T: 4224, Avg. loss: 28870795797470835768295424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7075524156.52, NNZs: 2, Bias: 162694534964.830719, T: 4352, Avg. loss: 685867585422142749016064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2716760310.14, NNZs: 2, Bias: 162350852970.450806, T: 4480, Avg. loss: 696067681548541173432320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9312288311.70, NNZs: 2, Bias: 162096214594.533783, T: 4608, Avg. loss: 556147007987285485420544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3881846957.24, NNZs: 2, Bias: 161775969431.308167, T: 4736, Avg. loss: 510762545447852732055552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1692189453.41, NNZs: 2, Bias: 161491986705.450043, T: 4864, Avg. loss: 529888982388056185110528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 293224800.25, NNZs: 2, Bias: 161561317489.075378, T: 4992, Avg. loss: 585748799171014133022720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 8151173380.25, NNZs: 2, Bias: 161140079390.671204, T: 5120, Avg. loss: 467321381561606405619712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 10808786615.40, NNZs: 2, Bias: 160800616372.394379, T: 5248, Avg. loss: 529136251277880888131584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 5850189125.55, NNZs: 2, Bias: 161278226548.292023, T: 5376, Avg. loss: 562442001021692224208896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 15145989730.02, NNZs: 2, Bias: 160827028064.440460, T: 5504, Avg. loss: 545832568944216414093312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2412926010.82, NNZs: 2, Bias: 160697008710.996796, T: 5632, Avg. loss: 628612840704333181878272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2795275836.11, NNZs: 2, Bias: 160784531899.240326, T: 5760, Avg. loss: 611739590369955077423104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1461972781.05, NNZs: 2, Bias: 160692482636.930176, T: 5888, Avg. loss: 5688902285262943420416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2042956459.29, NNZs: 2, Bias: 160628512153.324860, T: 6016, Avg. loss: 2827883815584920502272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2106723455.60, NNZs: 2, Bias: 160571704317.896698, T: 6144, Avg. loss: 2774561680234601512960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2373947908.36, NNZs: 2, Bias: 160509588957.425568, T: 6272, Avg. loss: 2989853107752886337536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2531306991.55, NNZs: 2, Bias: 160453122807.011108, T: 6400, Avg. loss: 2682172587276150243328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2658248800.74, NNZs: 2, Bias: 160396054232.668671, T: 6528, Avg. loss: 2726406704061054713856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2426434694.75, NNZs: 2, Bias: 160345680754.373566, T: 6656, Avg. loss: 2675196246548348403712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2555682401.63, NNZs: 2, Bias: 160287318550.938171, T: 6784, Avg. loss: 2829810680181133148160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2534351841.25, NNZs: 2, Bias: 160231101133.107147, T: 6912, Avg. loss: 2869580220186997817344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2549429606.42, NNZs: 2, Bias: 160175935388.657318, T: 7040, Avg. loss: 2733164329670997442560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2500626000.30, NNZs: 2, Bias: 160123546492.199921, T: 7168, Avg. loss: 2580733902520541773824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2521572465.93, NNZs: 2, Bias: 160065700624.718414, T: 7296, Avg. loss: 2884777933407676530688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2655859470.74, NNZs: 2, Bias: 160009738213.099457, T: 7424, Avg. loss: 2759992291667089031168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2610435890.95, NNZs: 2, Bias: 159957066800.342682, T: 7552, Avg. loss: 2689052042861368836096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2691786605.24, NNZs: 2, Bias: 159905699691.118530, T: 7680, Avg. loss: 2504054391819718885376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2650781034.17, NNZs: 2, Bias: 159850391319.835358, T: 7808, Avg. loss: 2870471203744420724736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2659467549.62, NNZs: 2, Bias: 159796092717.209991, T: 7936, Avg. loss: 2645712840765371580416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2526662542.40, NNZs: 2, Bias: 159743766231.975830, T: 8064, Avg. loss: 2682609065390271102976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2548815820.79, NNZs: 2, Bias: 159691274940.832428, T: 8192, Avg. loss: 2503491248252027666432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2492089569.57, NNZs: 2, Bias: 159639813029.015533, T: 8320, Avg. loss: 2559434703759160115200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2568432696.97, NNZs: 2, Bias: 159585756991.297211, T: 8448, Avg. loss: 2694131595219483754496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2579924747.75, NNZs: 2, Bias: 159527615750.201294, T: 8576, Avg. loss: 2856261018277762301952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2550665830.31, NNZs: 2, Bias: 159475591332.721222, T: 8704, Avg. loss: 2605379315194780450816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2604006286.74, NNZs: 2, Bias: 159420241484.716858, T: 8832, Avg. loss: 2668550510121137471488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2558649414.83, NNZs: 2, Bias: 159410026146.345398, T: 8960, Avg. loss: 2211935199300630347776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2523175988.53, NNZs: 2, Bias: 159399970589.584656, T: 9088, Avg. loss: 2144029077999915892736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2598145571.02, NNZs: 2, Bias: 159388631107.815582, T: 9216, Avg. loss: 2030031448221262807040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2572885358.19, NNZs: 2, Bias: 159378224151.900482, T: 9344, Avg. loss: 2184849459629879721984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2580170278.23, NNZs: 2, Bias: 159367305451.516357, T: 9472, Avg. loss: 2174532100101582356480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2537406104.00, NNZs: 2, Bias: 159357146736.070801, T: 9600, Avg. loss: 2184265469863423377408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2539689977.24, NNZs: 2, Bias: 159346244546.720856, T: 9728, Avg. loss: 2187166133628585902080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2541736800.13, NNZs: 2, Bias: 159335370552.169342, T: 9856, Avg. loss: 2183194014049883127808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2547557197.15, NNZs: 2, Bias: 159333123704.253754, T: 9984, Avg. loss: 2107613211994631438336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2551167890.22, NNZs: 2, Bias: 159330921057.077118, T: 10112, Avg. loss: 2098901288803248111616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2561831975.41, NNZs: 2, Bias: 159328607864.545380, T: 10240, Avg. loss: 2095882347107417849856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 2552673979.10, NNZs: 2, Bias: 159326609118.696472, T: 10368, Avg. loss: 2100424293073149493248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 2553558745.37, NNZs: 2, Bias: 159324445597.696930, T: 10496, Avg. loss: 2103425455345642766336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 82 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 910478135771.45, NNZs: 2, Bias: -6557274042.395142, T: 128, Avg. loss: 20545182776160311107936845824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1334024149910.25, NNZs: 2, Bias: 25365098859.999352, T: 256, Avg. loss: 18817241468303552776260026368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1564226611381.84, NNZs: 2, Bias: 45365098859.999352, T: 384, Avg. loss: 21124989125300198290443206656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 490130200376.62, NNZs: 2, Bias: -10291334584.004227, T: 512, Avg. loss: 21398698535759347593032761344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1238865216980.76, NNZs: 2, Bias: -20887571932.016186, T: 640, Avg. loss: 24171832427617053432996691968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1766794177470.40, NNZs: 2, Bias: -6072429773.243824, T: 768, Avg. loss: 21791628532602486220528812032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2110554198241.36, NNZs: 2, Bias: -6072429773.243820, T: 896, Avg. loss: 21447063695717794895890481152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 100047834593.82, NNZs: 2, Bias: 19733537078.373299, T: 1024, Avg. loss: 2010266692723834085816926208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 269871167031.15, NNZs: 2, Bias: 6417980747.474819, T: 1152, Avg. loss: 776432642922997399020371968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 157285078496.33, NNZs: 2, Bias: 9241922861.794701, T: 1280, Avg. loss: 848467753707158970241646592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 82539447732.56, NNZs: 2, Bias: 8181556783.313148, T: 1408, Avg. loss: 852420637320969964434227200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 293567149019.60, NNZs: 2, Bias: 9250939172.889355, T: 1536, Avg. loss: 809313967131944160128401408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 253362924399.89, NNZs: 2, Bias: -4700771616.388298, T: 1664, Avg. loss: 828595892417405862302187520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 386776305777.15, NNZs: 2, Bias: -17783679513.095432, T: 1792, Avg. loss: 791938520790625095228850176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62753748803.67, NNZs: 2, Bias: -16264948228.463844, T: 1920, Avg. loss: 79578937980171335755628544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 66374905120.26, NNZs: 2, Bias: -13477100170.136515, T: 2048, Avg. loss: 32325173306153614522187776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 59637982750.34, NNZs: 2, Bias: -15980077449.819807, T: 2176, Avg. loss: 30199157162327633622466560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 21010230015.68, NNZs: 2, Bias: -18749039713.135986, T: 2304, Avg. loss: 33174790650589144953126912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40773509295.52, NNZs: 2, Bias: -15792251912.636230, T: 2432, Avg. loss: 31121630989425565834936320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37657381286.49, NNZs: 2, Bias: -13826448779.970795, T: 2560, Avg. loss: 28062795743758059204247552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 51500917487.37, NNZs: 2, Bias: -13745997546.150354, T: 2688, Avg. loss: 33061029961135169858437120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 92104440803.26, NNZs: 2, Bias: -16750701840.669273, T: 2816, Avg. loss: 31258718180746039270572032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 58422277846.76, NNZs: 2, Bias: -16681992274.881176, T: 2944, Avg. loss: 32676772392261614645018624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 25034488440.61, NNZs: 2, Bias: -18565869843.483944, T: 3072, Avg. loss: 30858456323162143289507840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 29984596764.08, NNZs: 2, Bias: -19474917561.098717, T: 3200, Avg. loss: 33580647724085383100628992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 11349293126.51, NNZs: 2, Bias: -19150685146.740654, T: 3328, Avg. loss: 866632957464611003564032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2407105651.02, NNZs: 2, Bias: -19188440031.218994, T: 3456, Avg. loss: 500220706212683997773824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2297883985.96, NNZs: 2, Bias: -19062048388.173557, T: 3584, Avg. loss: 497141846431353184190464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 10274305570.60, NNZs: 2, Bias: -19184305612.827095, T: 3712, Avg. loss: 406612571297339049771008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 12032552340.85, NNZs: 2, Bias: -19142208433.135632, T: 3840, Avg. loss: 473972132817638231375872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 600600982.06, NNZs: 2, Bias: -19293038696.151833, T: 3968, Avg. loss: 572528688543258111901696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5636449353.08, NNZs: 2, Bias: -19140657773.640373, T: 4096, Avg. loss: 323615007704204674334720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7321150765.59, NNZs: 2, Bias: -19090680256.708702, T: 4224, Avg. loss: 412670529497213207314432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8447513615.53, NNZs: 2, Bias: -19145214167.677753, T: 4352, Avg. loss: 516261726726788285988864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2781034984.64, NNZs: 2, Bias: -19512239976.513042, T: 4480, Avg. loss: 559337689024852891009024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6115183538.94, NNZs: 2, Bias: -19543986378.688950, T: 4608, Avg. loss: 426605251310529487568896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4775953679.55, NNZs: 2, Bias: -19678434581.860847, T: 4736, Avg. loss: 442361717173793499119616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1681493148.89, NNZs: 2, Bias: -19708767567.136925, T: 4864, Avg. loss: 3802571363878593101824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1036333447.31, NNZs: 2, Bias: -19712034347.421688, T: 4992, Avg. loss: 260431469114174865408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 727160435.60, NNZs: 2, Bias: -19710627053.625259, T: 5120, Avg. loss: 105438513654796910592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 549548139.99, NNZs: 2, Bias: -19707862909.800667, T: 5248, Avg. loss: 56836995459603611648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 441824941.77, NNZs: 2, Bias: -19703987520.450726, T: 5376, Avg. loss: 41888595123591102464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 386115867.33, NNZs: 2, Bias: -19698765779.399918, T: 5504, Avg. loss: 40312792656748716032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 352243423.93, NNZs: 2, Bias: -19693541607.315388, T: 5632, Avg. loss: 37425325771951013888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 348236482.57, NNZs: 2, Bias: -19687573553.919220, T: 5760, Avg. loss: 35675505148724183040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 351651727.60, NNZs: 2, Bias: -19680908955.293442, T: 5888, Avg. loss: 39658215769132646400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 347069862.90, NNZs: 2, Bias: -19674880409.475533, T: 6016, Avg. loss: 36579104544032677888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 338196234.42, NNZs: 2, Bias: -19668707490.245178, T: 6144, Avg. loss: 37585509136116228096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 329007707.16, NNZs: 2, Bias: -19662420056.208298, T: 6272, Avg. loss: 38800080532940996608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 321877071.38, NNZs: 2, Bias: -19656353322.736320, T: 6400, Avg. loss: 36911599933638074368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 327328186.48, NNZs: 2, Bias: -19655036000.331402, T: 6528, Avg. loss: 30399619355945435136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 329665128.98, NNZs: 2, Bias: -19653750780.052074, T: 6656, Avg. loss: 30907365703260958720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 332722591.81, NNZs: 2, Bias: -19652473383.184544, T: 6784, Avg. loss: 30334153105170059264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 331526469.68, NNZs: 2, Bias: -19651254213.669605, T: 6912, Avg. loss: 30727441737828896768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 333220521.95, NNZs: 2, Bias: -19649983355.808342, T: 7040, Avg. loss: 30804495631999246336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 334771528.30, NNZs: 2, Bias: -19648736218.566948, T: 7168, Avg. loss: 30278507486926999552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 333078346.09, NNZs: 2, Bias: -19647535672.232929, T: 7296, Avg. loss: 30471330613511749632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 334469767.98, NNZs: 2, Bias: -19646279320.864132, T: 7424, Avg. loss: 30546856190481403904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 336398773.33, NNZs: 2, Bias: -19644998747.165943, T: 7552, Avg. loss: 30908132014437314560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 336215589.37, NNZs: 2, Bias: -19643769503.160801, T: 7680, Avg. loss: 30517249697876193280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 339849872.84, NNZs: 2, Bias: -19642466810.026592, T: 7808, Avg. loss: 30696308847569489920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 337863398.48, NNZs: 2, Bias: -19642253399.744137, T: 7936, Avg. loss: 29896957734239834112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 337128943.57, NNZs: 2, Bias: -19642020114.728523, T: 8064, Avg. loss: 29664988606560325632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 336375181.26, NNZs: 2, Bias: -19641788006.846237, T: 8192, Avg. loss: 29555141143160713216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 337747973.83, NNZs: 2, Bias: -19641518760.567749, T: 8320, Avg. loss: 29620726087178010624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 336837711.26, NNZs: 2, Bias: -19641288719.397427, T: 8448, Avg. loss: 29636160604434391040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 336835311.00, NNZs: 2, Bias: -19641042978.825840, T: 8576, Avg. loss: 29641205347252641792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 337816230.30, NNZs: 2, Bias: -19640780812.644737, T: 8704, Avg. loss: 29575796712098201600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 337402132.54, NNZs: 2, Bias: -19640542861.101109, T: 8832, Avg. loss: 29560766627890978816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 69 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 991936925692.81, NNZs: 2, Bias: 6751262768.128052, T: 128, Avg. loss: 21086774874633856995762896896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1598237568428.80, NNZs: 2, Bias: -13248737231.871948, T: 256, Avg. loss: 21977714106204359471568781312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 176431472006.55, NNZs: 2, Bias: -73248737231.871948, T: 384, Avg. loss: 21044927115825588045195771904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 851047864905.21, NNZs: 2, Bias: -103622993676.774292, T: 512, Avg. loss: 21963058436952735960031821824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 792340768483.12, NNZs: 2, Bias: -119689339386.419724, T: 640, Avg. loss: 24046445905267103846845382656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 438405027538.26, NNZs: 2, Bias: -129666815935.439301, T: 768, Avg. loss: 23483824465627483558341771264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1188498212207.03, NNZs: 2, Bias: -92546705178.267410, T: 896, Avg. loss: 24263832226515636303958114304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 780513498838.70, NNZs: 2, Bias: -133608652488.246796, T: 1024, Avg. loss: 22265574257927087056941481984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 178860450844.76, NNZs: 2, Bias: -116175575549.068130, T: 1152, Avg. loss: 935843501744045352313421824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 376742887998.51, NNZs: 2, Bias: -116009813022.512833, T: 1280, Avg. loss: 957645663903365336322277376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 168299162491.75, NNZs: 2, Bias: -114459108241.523224, T: 1408, Avg. loss: 935193095017152660637745152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 133441284964.93, NNZs: 2, Bias: -103417328183.050217, T: 1536, Avg. loss: 901200671045984800433242112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 608055104971.95, NNZs: 2, Bias: -110648908859.938629, T: 1664, Avg. loss: 884214100581023564752224256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 258362296287.70, NNZs: 2, Bias: -113381778251.136520, T: 1792, Avg. loss: 884266786650211314147786752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 461411608058.87, NNZs: 2, Bias: -115218789948.395477, T: 1920, Avg. loss: 802958181672239283910475776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 256005969852.06, NNZs: 2, Bias: -111629158538.797928, T: 2048, Avg. loss: 957558233622231765795995648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 178602358222.01, NNZs: 2, Bias: -125975558627.184402, T: 2176, Avg. loss: 895767320461129073047896064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 212715346233.45, NNZs: 2, Bias: -135122663897.467316, T: 2304, Avg. loss: 862711521656722278953517056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 149311006854.93, NNZs: 2, Bias: -136309568797.046448, T: 2432, Avg. loss: 867234349149157613016973312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 52835655555.10, NNZs: 2, Bias: -144263915603.722992, T: 2560, Avg. loss: 939547141541496989381820416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 17725193388.19, NNZs: 2, Bias: -142303943173.421631, T: 2688, Avg. loss: 35989975010223239368540160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 46254398122.69, NNZs: 2, Bias: -141714167502.607300, T: 2816, Avg. loss: 32011360880719937453162496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 3539997358.26, NNZs: 2, Bias: -137867506057.724213, T: 2944, Avg. loss: 30571507826944465046601728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 13271687047.91, NNZs: 2, Bias: -134720444897.199036, T: 3072, Avg. loss: 37227630490370183215972352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 41787574355.56, NNZs: 2, Bias: -137070225392.201141, T: 3200, Avg. loss: 33029762391187437138214912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 54349961717.47, NNZs: 2, Bias: -132899070442.618668, T: 3328, Avg. loss: 33963813505717019674148864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 15625632239.75, NNZs: 2, Bias: -135340493098.049637, T: 3456, Avg. loss: 32293801011711771618050048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 90125713362.56, NNZs: 2, Bias: -135061747040.657974, T: 3584, Avg. loss: 31541493333245518971666432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1870433079.17, NNZs: 2, Bias: -134244849237.801971, T: 3712, Avg. loss: 3825105056129289654632448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8616843089.54, NNZs: 2, Bias: -134191400738.117035, T: 3840, Avg. loss: 833764917403760344432640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11683546555.21, NNZs: 2, Bias: -133899762021.662704, T: 3968, Avg. loss: 576089685058692122148864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11155827247.23, NNZs: 2, Bias: -133830739390.365280, T: 4096, Avg. loss: 802864833485509199134720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 18295152143.01, NNZs: 2, Bias: -133830202354.437515, T: 4224, Avg. loss: 719787339984519403929600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8799107756.21, NNZs: 2, Bias: -133255140691.667938, T: 4352, Avg. loss: 774994150229287796473856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7980421625.43, NNZs: 2, Bias: -132871263174.258102, T: 4480, Avg. loss: 676067601029190280806400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2143353875.11, NNZs: 2, Bias: -132432310242.679474, T: 4608, Avg. loss: 582395499612657523097600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2061241521.52, NNZs: 2, Bias: -132390198707.383881, T: 4736, Avg. loss: 1880217088710520864768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2131534558.91, NNZs: 2, Bias: -132346186948.940613, T: 4864, Avg. loss: 1735696027337519005696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2220515876.28, NNZs: 2, Bias: -132300145456.393707, T: 4992, Avg. loss: 1836166746794246012928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2098396007.28, NNZs: 2, Bias: -132257037889.962753, T: 5120, Avg. loss: 1850917814504517009408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2112308666.67, NNZs: 2, Bias: -132210275470.953613, T: 5248, Avg. loss: 1933019135806587273216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2004415231.79, NNZs: 2, Bias: -132165171425.469009, T: 5376, Avg. loss: 1928915944199514488832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2061846799.06, NNZs: 2, Bias: -132123128738.571808, T: 5504, Avg. loss: 1636243380083821641728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2047688212.20, NNZs: 2, Bias: -132077581570.925278, T: 5632, Avg. loss: 1839541780496416243712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2084753542.09, NNZs: 2, Bias: -132033718672.588989, T: 5760, Avg. loss: 1782088316006240092160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2047189052.57, NNZs: 2, Bias: -131988968544.507446, T: 5888, Avg. loss: 1827622259860091437056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2043274144.24, NNZs: 2, Bias: -131943541045.826752, T: 6016, Avg. loss: 1973041156492556763136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2102286540.75, NNZs: 2, Bias: -131897287703.979858, T: 6144, Avg. loss: 1890576208915666567168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2064639890.99, NNZs: 2, Bias: -131889152402.129303, T: 6272, Avg. loss: 1457069057798273499136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2037226262.91, NNZs: 2, Bias: -131880699210.818695, T: 6400, Avg. loss: 1482483292481492353024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2040425878.40, NNZs: 2, Bias: -131871776101.767548, T: 6528, Avg. loss: 1479186209931906514944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2074556270.67, NNZs: 2, Bias: -131862316719.896469, T: 6656, Avg. loss: 1484349911055499001856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2075700502.92, NNZs: 2, Bias: -131853311083.311462, T: 6784, Avg. loss: 1497324274971803648000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2042759070.43, NNZs: 2, Bias: -131844906824.337997, T: 6912, Avg. loss: 1486587284979157565440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2049766364.26, NNZs: 2, Bias: -131843021238.424377, T: 7040, Avg. loss: 1438448744165863587840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2041766859.83, NNZs: 2, Bias: -131841389002.741714, T: 7168, Avg. loss: 1422550961541770641408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2050147518.10, NNZs: 2, Bias: -131839483538.669128, T: 7296, Avg. loss: 1437305469421553451008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2048937038.49, NNZs: 2, Bias: -131837732190.683914, T: 7424, Avg. loss: 1433337942308524130304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2052683465.45, NNZs: 2, Bias: -131835899246.224197, T: 7552, Avg. loss: 1436823179348317569024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2050508905.46, NNZs: 2, Bias: -131834162814.967148, T: 7680, Avg. loss: 1433547546516241776640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2049875939.75, NNZs: 2, Bias: -131832399219.974808, T: 7808, Avg. loss: 1435906062798705655808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 61 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 157684911190.42, NNZs: 2, Bias: 39715233720.294365, T: 128, Avg. loss: 24332777090372529262222639104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 622899657735.50, NNZs: 2, Bias: 110890733687.097702, T: 256, Avg. loss: 26033176786758108378336067584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 843781480547.63, NNZs: 2, Bias: 104455023233.219238, T: 384, Avg. loss: 24588944342277638599823327232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1409668219061.52, NNZs: 2, Bias: 146173130560.915253, T: 512, Avg. loss: 22993104774420380094673453056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 600737001940.05, NNZs: 2, Bias: 98663850478.826050, T: 640, Avg. loss: 25772906572792208864934100992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1993031906357.82, NNZs: 2, Bias: 78663850478.826050, T: 768, Avg. loss: 21839671556432526314678779904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1520726817082.67, NNZs: 2, Bias: 56182224275.431992, T: 896, Avg. loss: 25237872233051033340966076416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 221680565405.26, NNZs: 2, Bias: 65950900571.587036, T: 1024, Avg. loss: 24970455334485057058491072512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 813471231610.51, NNZs: 2, Bias: 185950900571.587036, T: 1152, Avg. loss: 24689882095653354375592542208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1513123170320.12, NNZs: 2, Bias: 185950900571.587036, T: 1280, Avg. loss: 23100587711595425167050801152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 914900599120.42, NNZs: 2, Bias: 201083522114.394806, T: 1408, Avg. loss: 23443525183052686515593281536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 205291359982.14, NNZs: 2, Bias: 184606171941.965302, T: 1536, Avg. loss: 1029551794549138990087274496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 160987575328.93, NNZs: 2, Bias: 188899962493.048553, T: 1664, Avg. loss: 926986519109346980366647296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 483937958653.61, NNZs: 2, Bias: 175083992207.371735, T: 1792, Avg. loss: 936922371605149123625353216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 329510658814.37, NNZs: 2, Bias: 175189551507.233643, T: 1920, Avg. loss: 993458733435794989556695040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 434517711793.93, NNZs: 2, Bias: 193854547828.510498, T: 2048, Avg. loss: 998012290670601849668632576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 175979555769.94, NNZs: 2, Bias: 198714374813.909607, T: 2176, Avg. loss: 949664375456546049373503488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 228101086726.06, NNZs: 2, Bias: 206714374813.909607, T: 2304, Avg. loss: 946073733227849940423671808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 19856462076.47, NNZs: 2, Bias: 203614199490.827545, T: 2432, Avg. loss: 46284439950543573533851648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 8425665256.55, NNZs: 2, Bias: 205189451861.852661, T: 2560, Avg. loss: 32259498486069888559349760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 35977663149.30, NNZs: 2, Bias: 204101107748.177185, T: 2688, Avg. loss: 36467468454275212969508864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 34316109496.94, NNZs: 2, Bias: 204215095768.366058, T: 2816, Avg. loss: 33921206563626001119576064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 46157810647.49, NNZs: 2, Bias: 202951094376.453674, T: 2944, Avg. loss: 34566894242850326574006272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 32132565864.21, NNZs: 2, Bias: 201998115488.434692, T: 3072, Avg. loss: 37450473300067641529991168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 78594726236.86, NNZs: 2, Bias: 201817502958.678955, T: 3200, Avg. loss: 39232482586428347277901824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 11811558337.88, NNZs: 2, Bias: 202567966786.566528, T: 3328, Avg. loss: 2266381563008640591331328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 7102742225.11, NNZs: 2, Bias: 202241263097.841217, T: 3456, Avg. loss: 865195938430462373920768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 6406187825.70, NNZs: 2, Bias: 201712986871.428711, T: 3584, Avg. loss: 714736926231062802071552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 5214162735.71, NNZs: 2, Bias: 201597441376.974426, T: 3712, Avg. loss: 676228548846906675036160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 14878421290.40, NNZs: 2, Bias: 201567208218.468384, T: 3840, Avg. loss: 751283060162826749345792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 12475701542.76, NNZs: 2, Bias: 201082125524.019165, T: 3968, Avg. loss: 618924432905768301232128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 20502430154.26, NNZs: 2, Bias: 200593130857.466492, T: 4096, Avg. loss: 789792709136813729513472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 15960395869.17, NNZs: 2, Bias: 200477044512.136810, T: 4224, Avg. loss: 725159909196102853722112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 12923386777.01, NNZs: 2, Bias: 200167757437.469879, T: 4352, Avg. loss: 803635330930711547871232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9675162527.52, NNZs: 2, Bias: 199913801049.893463, T: 4480, Avg. loss: 751777570359199391547392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5562787716.41, NNZs: 2, Bias: 199865686021.860016, T: 4608, Avg. loss: 761541473165717241069568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3620474130.95, NNZs: 2, Bias: 199838273695.159210, T: 4736, Avg. loss: 4730396686636397101056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3282790879.35, NNZs: 2, Bias: 199784828047.042816, T: 4864, Avg. loss: 3710648494797723533312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3200130303.22, NNZs: 2, Bias: 199727240080.059845, T: 4992, Avg. loss: 3606023119062007021568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3139004876.57, NNZs: 2, Bias: 199666960143.611053, T: 5120, Avg. loss: 3694815014161342267392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3118338336.93, NNZs: 2, Bias: 199611445456.822418, T: 5248, Avg. loss: 3522381248226214805504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2944298434.29, NNZs: 2, Bias: 199556164744.538940, T: 5376, Avg. loss: 3489907451060497154048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2924072007.33, NNZs: 2, Bias: 199498333770.913696, T: 5504, Avg. loss: 3467899775103384682496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3007394060.70, NNZs: 2, Bias: 199442189315.485168, T: 5632, Avg. loss: 3365718468086513270784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2942989287.58, NNZs: 2, Bias: 199383006031.023987, T: 5760, Avg. loss: 3709706126800471982080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2917657758.90, NNZs: 2, Bias: 199325272949.086761, T: 5888, Avg. loss: 3627049596469342371840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3109568310.84, NNZs: 2, Bias: 199264053275.602875, T: 6016, Avg. loss: 3443138846091981094912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3032863094.09, NNZs: 2, Bias: 199206784963.472839, T: 6144, Avg. loss: 3417528657085867753472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3111263095.10, NNZs: 2, Bias: 199145985700.472504, T: 6272, Avg. loss: 3594759811376879763456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3124153153.72, NNZs: 2, Bias: 199134343489.877197, T: 6400, Avg. loss: 2869096279989122760704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3046161072.99, NNZs: 2, Bias: 199123972210.366882, T: 6528, Avg. loss: 2905916950903161094144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3038302713.51, NNZs: 2, Bias: 199112426966.348907, T: 6656, Avg. loss: 2932929457452062605312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3008020468.84, NNZs: 2, Bias: 199101431093.756042, T: 6784, Avg. loss: 2879853648753813094400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3051526334.96, NNZs: 2, Bias: 199089107653.711304, T: 6912, Avg. loss: 2923748741324389482496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3063969727.02, NNZs: 2, Bias: 199077447527.004944, T: 7040, Avg. loss: 2875943344764253372416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3026602584.52, NNZs: 2, Bias: 199075686129.769440, T: 7168, Avg. loss: 2854065055313650253824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3018131866.07, NNZs: 2, Bias: 199073512138.666595, T: 7296, Avg. loss: 2815235372701980819456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3014159532.18, NNZs: 2, Bias: 199071258954.301056, T: 7424, Avg. loss: 2828081600200443428864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3023141997.09, NNZs: 2, Bias: 199068804610.215485, T: 7552, Avg. loss: 2832934345434564919296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3016342577.68, NNZs: 2, Bias: 199066591278.610718, T: 7680, Avg. loss: 2831886604860002402304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3012694165.21, NNZs: 2, Bias: 199064329993.209808, T: 7808, Avg. loss: 2831844878215967932416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2998141713.49, NNZs: 2, Bias: 199062266764.583771, T: 7936, Avg. loss: 2790855826034174984192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2995482041.45, NNZs: 2, Bias: 199059999516.747589, T: 8064, Avg. loss: 2820163126111358681088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3009894514.40, NNZs: 2, Bias: 199057453468.809998, T: 8192, Avg. loss: 2845577351263482281984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3020326418.79, NNZs: 2, Bias: 199054986876.052124, T: 8320, Avg. loss: 2821101240032169558016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3012223830.29, NNZs: 2, Bias: 199052793673.494751, T: 8448, Avg. loss: 2831083938857890086912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2999564254.21, NNZs: 2, Bias: 199050675126.828003, T: 8576, Avg. loss: 2823709468478801444864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 67 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 716948036090.08, NNZs: 2, Bias: 25537023576.671768, T: 128, Avg. loss: 17069398090153504052034404352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 565053440848.05, NNZs: 2, Bias: -71500913102.528412, T: 256, Avg. loss: 21104629130477891805033529344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1737187342453.98, NNZs: 2, Bias: -88004422496.416077, T: 384, Avg. loss: 22318059494879992270498562048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 520385609947.66, NNZs: 2, Bias: 51995577503.583923, T: 512, Avg. loss: 21644368719786214812297461760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 897582872750.88, NNZs: 2, Bias: 18394565049.662048, T: 640, Avg. loss: 24206346282306160925786243072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 419280609806.36, NNZs: 2, Bias: 38394565049.662048, T: 768, Avg. loss: 23882335824641019270507003904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 343173552440.20, NNZs: 2, Bias: 43723213379.882286, T: 896, Avg. loss: 842020479621977445031215104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 159283324238.88, NNZs: 2, Bias: 34690336049.555595, T: 1024, Avg. loss: 890145742843338561129807872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 63945671482.39, NNZs: 2, Bias: 20404929063.383240, T: 1152, Avg. loss: 837812762619743792971907072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 59095460268.40, NNZs: 2, Bias: 24286345948.849674, T: 1280, Avg. loss: 879442545248125115963539456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 130782559639.14, NNZs: 2, Bias: 23139231897.650677, T: 1408, Avg. loss: 954629444423501177342132224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 340722294577.99, NNZs: 2, Bias: 31574160726.877033, T: 1536, Avg. loss: 775517423392570084325064704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 149899764319.55, NNZs: 2, Bias: 27507507200.611248, T: 1664, Avg. loss: 846645804212121985097924608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 196309073156.42, NNZs: 2, Bias: 33016287270.010452, T: 1792, Avg. loss: 850789079801808373275426816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 159080537802.42, NNZs: 2, Bias: 40257868816.275177, T: 1920, Avg. loss: 784984673342971796646789120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 171761858084.16, NNZs: 2, Bias: 55346419072.121719, T: 2048, Avg. loss: 768858229012873752677974016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 276892661545.74, NNZs: 2, Bias: 79914532033.410660, T: 2176, Avg. loss: 900816923318228780725567488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 465661922130.44, NNZs: 2, Bias: 74496848935.523254, T: 2304, Avg. loss: 824484159282630374090342400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 272144702368.43, NNZs: 2, Bias: 69535457184.659744, T: 2432, Avg. loss: 890327629018313554237849600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 432526357333.88, NNZs: 2, Bias: 56412368556.280487, T: 2560, Avg. loss: 759448774502293770854203392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 440508554011.51, NNZs: 2, Bias: 67840990764.099258, T: 2688, Avg. loss: 827338396512730387006357504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 297165031583.98, NNZs: 2, Bias: 71631874649.682724, T: 2816, Avg. loss: 771332670411915295163678720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 300219765277.25, NNZs: 2, Bias: 68642973396.015808, T: 2944, Avg. loss: 791098006680357653538930688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 275391595086.36, NNZs: 2, Bias: 73862190820.076660, T: 3072, Avg. loss: 783706833323051140325048320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100121931819.13, NNZs: 2, Bias: 73802874204.077774, T: 3200, Avg. loss: 971658699063243556905811968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 76041789721.67, NNZs: 2, Bias: 75471974996.085724, T: 3328, Avg. loss: 34160576782989863304560640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 37732587293.98, NNZs: 2, Bias: 77275000780.825302, T: 3456, Avg. loss: 36700199858545028103143424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 16024684917.42, NNZs: 2, Bias: 77917031108.385406, T: 3584, Avg. loss: 31423669558464608315899904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 44051785253.44, NNZs: 2, Bias: 77276131585.136047, T: 3712, Avg. loss: 32246168245609543480901632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 26806434881.39, NNZs: 2, Bias: 75948277996.497299, T: 3840, Avg. loss: 34655372692014728998813696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 50790614854.44, NNZs: 2, Bias: 72725398841.337112, T: 3968, Avg. loss: 34680431425179589327978496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 50804709481.63, NNZs: 2, Bias: 73017154108.958527, T: 4096, Avg. loss: 29656004578111130722893824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 47874720540.63, NNZs: 2, Bias: 72796616693.440369, T: 4224, Avg. loss: 30851839685130328974819328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 23033715696.43, NNZs: 2, Bias: 71781662580.312897, T: 4352, Avg. loss: 29772972560179119037349888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 41059684093.74, NNZs: 2, Bias: 71278016620.395203, T: 4480, Avg. loss: 31113810481881383140589568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 45805483116.28, NNZs: 2, Bias: 71794875329.990326, T: 4608, Avg. loss: 34392892273579355669528576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 25391557718.20, NNZs: 2, Bias: 69034273094.553528, T: 4736, Avg. loss: 33894737211353312964640768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1329966268.35, NNZs: 2, Bias: 68919453989.652420, T: 4864, Avg. loss: 858630830899945168437248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 12894701793.89, NNZs: 2, Bias: 68409601361.408730, T: 4992, Avg. loss: 418298409731830067494912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 15230230343.13, NNZs: 2, Bias: 68683451642.072708, T: 5120, Avg. loss: 630143028207185660215296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1051412773.09, NNZs: 2, Bias: 68460481338.231667, T: 5248, Avg. loss: 667749538102238011981824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2456779811.50, NNZs: 2, Bias: 68254453396.572479, T: 5376, Avg. loss: 547029108864004109893632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3883492009.63, NNZs: 2, Bias: 68667040910.574982, T: 5504, Avg. loss: 532481735729653651341312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4513574518.80, NNZs: 2, Bias: 68481835330.678802, T: 5632, Avg. loss: 669088692528777531490304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2783724994.11, NNZs: 2, Bias: 68484076353.714561, T: 5760, Avg. loss: 2250562201209905086464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2021011343.72, NNZs: 2, Bias: 68470321524.022751, T: 5888, Avg. loss: 956593158262126411776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1567176385.77, NNZs: 2, Bias: 68454300266.226448, T: 6016, Avg. loss: 614614909267120095232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1268532754.63, NNZs: 2, Bias: 68434458971.149918, T: 6144, Avg. loss: 581874340448485703680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1199600296.55, NNZs: 2, Bias: 68411191868.917488, T: 6272, Avg. loss: 539801341386274177024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1077086719.16, NNZs: 2, Bias: 68388710240.478043, T: 6400, Avg. loss: 528056775816965586944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1134197894.30, NNZs: 2, Bias: 68363559628.988052, T: 6528, Avg. loss: 493008614707611959296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1125327134.61, NNZs: 2, Bias: 68338765786.267090, T: 6656, Avg. loss: 525263091783042924544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1081987557.92, NNZs: 2, Bias: 68315824407.809914, T: 6784, Avg. loss: 494227027738517831680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1172328708.59, NNZs: 2, Bias: 68290727981.779594, T: 6912, Avg. loss: 480435454843606794240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1145289717.93, NNZs: 2, Bias: 68265845878.650993, T: 7040, Avg. loss: 527110203239959756800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1104557317.62, NNZs: 2, Bias: 68243359284.353653, T: 7168, Avg. loss: 469899980709287821312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1070330516.54, NNZs: 2, Bias: 68219466303.464729, T: 7296, Avg. loss: 506785690112698286080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1121111872.12, NNZs: 2, Bias: 68194766395.690231, T: 7424, Avg. loss: 504635856357217533952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1135682760.54, NNZs: 2, Bias: 68172009138.444427, T: 7552, Avg. loss: 460447806138665467904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1044205938.86, NNZs: 2, Bias: 68148798915.350494, T: 7680, Avg. loss: 535629553578039902208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1063577274.65, NNZs: 2, Bias: 68125309505.664917, T: 7808, Avg. loss: 478139019619142467584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1137102661.51, NNZs: 2, Bias: 68099649703.370987, T: 7936, Avg. loss: 515000582598783205376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1235569541.69, NNZs: 2, Bias: 68076011159.678848, T: 8064, Avg. loss: 460146501740074303488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1181980123.54, NNZs: 2, Bias: 68052298083.905876, T: 8192, Avg. loss: 529129522459772911616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1174701986.79, NNZs: 2, Bias: 68028707831.113052, T: 8320, Avg. loss: 511043813706525704192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1070021961.50, NNZs: 2, Bias: 68006011089.625946, T: 8448, Avg. loss: 513431576447464636416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1071376454.93, NNZs: 2, Bias: 67980444613.275101, T: 8576, Avg. loss: 527503557661436084224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1023893340.96, NNZs: 2, Bias: 67956989366.844749, T: 8704, Avg. loss: 500371617564464906240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1061571006.26, NNZs: 2, Bias: 67951601544.754395, T: 8832, Avg. loss: 410551354208166543360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1062636282.77, NNZs: 2, Bias: 67946818113.979019, T: 8960, Avg. loss: 407027276123908931584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1068608388.23, NNZs: 2, Bias: 67941941545.942017, T: 9088, Avg. loss: 409627661351056179200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1078994063.15, NNZs: 2, Bias: 67936975783.030571, T: 9216, Avg. loss: 410082520420184031232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1067009301.81, NNZs: 2, Bias: 67932381849.698036, T: 9344, Avg. loss: 409677759736242896896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1087083522.58, NNZs: 2, Bias: 67927299531.812546, T: 9472, Avg. loss: 406741018549523775488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1083502310.40, NNZs: 2, Bias: 67922635079.446472, T: 9600, Avg. loss: 404137098969677103104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1073970808.18, NNZs: 2, Bias: 67918055156.478455, T: 9728, Avg. loss: 404475202041029853184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1074114345.41, NNZs: 2, Bias: 67913304443.781586, T: 9856, Avg. loss: 406638889949894803456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1084720173.21, NNZs: 2, Bias: 67908358357.068161, T: 9984, Avg. loss: 408468762303267799040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1093138920.78, NNZs: 2, Bias: 67903485519.065132, T: 10112, Avg. loss: 404486465277102522368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1098509887.66, NNZs: 2, Bias: 67898625934.380592, T: 10240, Avg. loss: 407563858637025181696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1097751576.63, NNZs: 2, Bias: 67897685493.229698, T: 10368, Avg. loss: 397135415792605069312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1098283357.72, NNZs: 2, Bias: 67896724271.801323, T: 10496, Avg. loss: 397070549637986385920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 1094413411.46, NNZs: 2, Bias: 67895832585.451385, T: 10624, Avg. loss: 397864238169051168768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 1092782634.60, NNZs: 2, Bias: 67894905255.765953, T: 10752, Avg. loss: 397509147412739653632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 1093877036.49, NNZs: 2, Bias: 67893933948.739159, T: 10880, Avg. loss: 397466795321868353536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 1098766153.70, NNZs: 2, Bias: 67892907422.674217, T: 11008, Avg. loss: 394779449272598200320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 1093220742.33, NNZs: 2, Bias: 67892044577.070587, T: 11136, Avg. loss: 397065923790693335040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 1094684824.94, NNZs: 2, Bias: 67891069051.712532, T: 11264, Avg. loss: 396673887443528253440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 1095656632.90, NNZs: 2, Bias: 67890099898.028122, T: 11392, Avg. loss: 397384262527076532224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 1094362008.84, NNZs: 2, Bias: 67889165896.848602, T: 11520, Avg. loss: 398028171722481860608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 1091524556.90, NNZs: 2, Bias: 67888258674.373749, T: 11648, Avg. loss: 397204193856277839872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 91 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 714540511058.18, NNZs: 2, Bias: 9368818577.939644, T: 128, Avg. loss: 19908868218155608109758808064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1043046512861.75, NNZs: 2, Bias: 49368818577.939636, T: 256, Avg. loss: 19818355439841769294166753280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1482272256817.35, NNZs: 2, Bias: 9368818577.939636, T: 384, Avg. loss: 20666883807346037429626732544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2978407274624.33, NNZs: 2, Bias: 20093695165.630234, T: 512, Avg. loss: 17687024856485270543338045440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 652764344616.88, NNZs: 2, Bias: 33807896648.606613, T: 640, Avg. loss: 19812782144979728923661172736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1720369219063.67, NNZs: 2, Bias: 13807896648.606613, T: 768, Avg. loss: 19188574943685107386542981120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2492017683878.75, NNZs: 2, Bias: -20248134975.340927, T: 896, Avg. loss: 19838491941733973203856916480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1055253904811.13, NNZs: 2, Bias: 39751865024.659073, T: 1024, Avg. loss: 20454475712212104609374666752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 806068008950.76, NNZs: 2, Bias: -20785783833.959267, T: 1152, Avg. loss: 20416324878093958226672353280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 407315849596.29, NNZs: 2, Bias: -33775157961.910210, T: 1280, Avg. loss: 793330499676140861650894848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 377456706956.25, NNZs: 2, Bias: -18473864541.220131, T: 1408, Avg. loss: 798698799464702729812705280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 215414613812.41, NNZs: 2, Bias: -18085105809.980667, T: 1536, Avg. loss: 844153398699479202367799296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 471846879864.56, NNZs: 2, Bias: -2708425697.849571, T: 1664, Avg. loss: 758756493813967592571797504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 180209803695.85, NNZs: 2, Bias: -6233935934.130688, T: 1792, Avg. loss: 804914457711492633016139776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 400761798695.92, NNZs: 2, Bias: -1302179700.861458, T: 1920, Avg. loss: 851109160303620693061271552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 183997134312.71, NNZs: 2, Bias: 787325706.814192, T: 2048, Avg. loss: 799665570623330272241778688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 436913194397.62, NNZs: 2, Bias: -11328907623.102165, T: 2176, Avg. loss: 737561735232400444335587328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 75422364022.80, NNZs: 2, Bias: -22052461881.885048, T: 2304, Avg. loss: 826638916455196657503436800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 408661419115.01, NNZs: 2, Bias: -10825812440.108095, T: 2432, Avg. loss: 897792832429267438928920576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 527902363313.98, NNZs: 2, Bias: -17179676049.939140, T: 2560, Avg. loss: 712110690891090786563129344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 266397610073.00, NNZs: 2, Bias: -15475483951.230396, T: 2688, Avg. loss: 864221513272004938903322624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 73248748459.51, NNZs: 2, Bias: -5619874126.356043, T: 2816, Avg. loss: 810035428283490069248999424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 232271535333.21, NNZs: 2, Bias: -4882777977.234693, T: 2944, Avg. loss: 802826276849867155501481984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 228468233219.52, NNZs: 2, Bias: -13910349993.651270, T: 3072, Avg. loss: 788289413434967861023997952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 291720131005.41, NNZs: 2, Bias: -3513694318.512630, T: 3200, Avg. loss: 850192506629640692059602944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 83391610017.33, NNZs: 2, Bias: -2850155405.217000, T: 3328, Avg. loss: 43983850917357066796400640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 20092632690.39, NNZs: 2, Bias: -2322651881.295441, T: 3456, Avg. loss: 34783656517038272411598848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 51160500426.47, NNZs: 2, Bias: -4556982246.873770, T: 3584, Avg. loss: 26758438776072497327505408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 63483282236.27, NNZs: 2, Bias: -4692101339.476693, T: 3712, Avg. loss: 31430005271410606879014912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 101445858987.47, NNZs: 2, Bias: -4152435542.590546, T: 3840, Avg. loss: 31309545231913156199055360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 20870951508.10, NNZs: 2, Bias: -5659736335.537004, T: 3968, Avg. loss: 27768637613776427307499520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 44352989239.09, NNZs: 2, Bias: -5185095791.950416, T: 4096, Avg. loss: 29969018329813370424786944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 39051323327.75, NNZs: 2, Bias: -3169992921.319204, T: 4224, Avg. loss: 28647676937163898619953152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4999504111.81, NNZs: 2, Bias: -3034506291.138320, T: 4352, Avg. loss: 892239520135081837461504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 14679590836.55, NNZs: 2, Bias: -3014959687.463763, T: 4480, Avg. loss: 421794718908738541977600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 18745690061.18, NNZs: 2, Bias: -2836779669.975659, T: 4608, Avg. loss: 477342444292495997140992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 14931067911.97, NNZs: 2, Bias: -3135136278.593140, T: 4736, Avg. loss: 705237952030782695407616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 718935676.01, NNZs: 2, Bias: -2813801529.451839, T: 4864, Avg. loss: 530425904081039972630528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 18234080235.30, NNZs: 2, Bias: -3124610035.356209, T: 4992, Avg. loss: 384396004195235090399232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3200392352.57, NNZs: 2, Bias: -2869819176.482045, T: 5120, Avg. loss: 484106648315015846690816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 5507754854.25, NNZs: 2, Bias: -2652711830.630149, T: 5248, Avg. loss: 378117594635433809018880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2031155973.73, NNZs: 2, Bias: -2803051636.604652, T: 5376, Avg. loss: 429371581144378638336000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 17511454842.39, NNZs: 2, Bias: -2883152301.390868, T: 5504, Avg. loss: 360079773205633500708864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4858038961.57, NNZs: 2, Bias: -2683298739.767483, T: 5632, Avg. loss: 391800037641902331265024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2718727559.35, NNZs: 2, Bias: -2529423328.206947, T: 5760, Avg. loss: 403373003408044762071040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 8096808108.89, NNZs: 2, Bias: -2504223352.876934, T: 5888, Avg. loss: 255258209264114077794304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1148245565.73, NNZs: 2, Bias: -2518956339.209371, T: 6016, Avg. loss: 449927147556867613392896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2943619710.30, NNZs: 2, Bias: -2363308907.289509, T: 6144, Avg. loss: 454877938618687142494208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 17661372097.51, NNZs: 2, Bias: -2135020614.525863, T: 6272, Avg. loss: 420775898065984345341952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 11658472672.91, NNZs: 2, Bias: -2299212106.737170, T: 6400, Avg. loss: 423387582371405051723776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 11763595516.68, NNZs: 2, Bias: -2425965355.705713, T: 6528, Avg. loss: 365481489681781025144832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1522101772.33, NNZs: 2, Bias: -2335711948.038807, T: 6656, Avg. loss: 31314869316312784437248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 722355877.76, NNZs: 2, Bias: -2321061385.116600, T: 6784, Avg. loss: 294886493331509444608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 327499715.46, NNZs: 2, Bias: -2313896134.391903, T: 6912, Avg. loss: 72228519137908482048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 141184417.77, NNZs: 2, Bias: -2310332884.903205, T: 7040, Avg. loss: 15687907996654340096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 52017962.81, NNZs: 2, Bias: -2308221293.570043, T: 7168, Avg. loss: 3990456658307630592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 22269940.60, NNZs: 2, Bias: -2306727023.049813, T: 7296, Avg. loss: 1326372866863677696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 27693588.28, NNZs: 2, Bias: -2305611089.665693, T: 7424, Avg. loss: 712768692674840576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 31457963.83, NNZs: 2, Bias: -2304690178.313372, T: 7552, Avg. loss: 600291425021022592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 34932064.94, NNZs: 2, Bias: -2303804100.274197, T: 7680, Avg. loss: 584119498376515712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 36464903.00, NNZs: 2, Bias: -2302982294.781126, T: 7808, Avg. loss: 548259972753575552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 38725968.11, NNZs: 2, Bias: -2302178133.829628, T: 7936, Avg. loss: 554994212653282560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 39528599.06, NNZs: 2, Bias: -2301401845.924640, T: 8064, Avg. loss: 556016523907894720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 38285127.69, NNZs: 2, Bias: -2300585418.604928, T: 8192, Avg. loss: 586842568295710592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 40333457.46, NNZs: 2, Bias: -2299844371.384704, T: 8320, Avg. loss: 493841005238460928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 38768969.86, NNZs: 2, Bias: -2299143142.987451, T: 8448, Avg. loss: 514475755109466176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 40202465.46, NNZs: 2, Bias: -2298325710.981149, T: 8576, Avg. loss: 598092178716515200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 40688099.51, NNZs: 2, Bias: -2297574290.746786, T: 8704, Avg. loss: 517917440525733760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 38501154.36, NNZs: 2, Bias: -2296880254.008554, T: 8832, Avg. loss: 526713837387326336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 40689470.17, NNZs: 2, Bias: -2296024676.008584, T: 8960, Avg. loss: 567014285206518912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 39995133.56, NNZs: 2, Bias: -2295880522.028841, T: 9088, Avg. loss: 455134406452068288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 40051807.13, NNZs: 2, Bias: -2295723280.439550, T: 9216, Avg. loss: 453745143434664640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 40121356.93, NNZs: 2, Bias: -2295565965.473812, T: 9344, Avg. loss: 453480425317270336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 39893170.73, NNZs: 2, Bias: -2295417841.524330, T: 9472, Avg. loss: 440959504451376320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 39915952.87, NNZs: 2, Bias: -2295262237.092000, T: 9600, Avg. loss: 450285520595625280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 39864788.18, NNZs: 2, Bias: -2295108201.201390, T: 9728, Avg. loss: 449899243021093952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 40007149.70, NNZs: 2, Bias: -2294949631.375706, T: 9856, Avg. loss: 452537013967725120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 40221326.76, NNZs: 2, Bias: -2294790065.005558, T: 9984, Avg. loss: 452558370017060608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 40339090.81, NNZs: 2, Bias: -2294638310.399571, T: 10112, Avg. loss: 433868949199618560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 40012093.51, NNZs: 2, Bias: -2294486731.820652, T: 10240, Avg. loss: 456824925252530048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 39990884.05, NNZs: 2, Bias: -2294334331.971137, T: 10368, Avg. loss: 441713137010321152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 39904433.85, NNZs: 2, Bias: -2294181877.625454, T: 10496, Avg. loss: 446242089132023104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 39914836.39, NNZs: 2, Bias: -2294025782.838302, T: 10624, Avg. loss: 451988127375116160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 40093775.10, NNZs: 2, Bias: -2293868908.251926, T: 10752, Avg. loss: 445845047707065600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 39793332.23, NNZs: 2, Bias: -2293843353.124516, T: 10880, Avg. loss: 434081356952987648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 39958405.85, NNZs: 2, Bias: -2293809583.682548, T: 11008, Avg. loss: 435218696555061440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 39786863.92, NNZs: 2, Bias: -2293781901.025683, T: 11136, Avg. loss: 432182716220079744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 39882294.36, NNZs: 2, Bias: -2293749222.699924, T: 11264, Avg. loss: 436985850830018176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 39885436.83, NNZs: 2, Bias: -2293718238.114983, T: 11392, Avg. loss: 435803273772398656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 39844123.54, NNZs: 2, Bias: -2293688104.775038, T: 11520, Avg. loss: 434675945417054272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 39979596.02, NNZs: 2, Bias: -2293654811.351418, T: 11648, Avg. loss: 435731209306408576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 39964051.23, NNZs: 2, Bias: -2293624292.556271, T: 11776, Avg. loss: 433809415414217984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 92 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 596274741716.62, NNZs: 2, Bias: -9243676769.003036, T: 128, Avg. loss: 18617001867401993308994535424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 529656288344.83, NNZs: 2, Bias: -29243676769.003036, T: 256, Avg. loss: 20350263158307684253282861056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1569307152018.71, NNZs: 2, Bias: -52672146018.018921, T: 384, Avg. loss: 20894368683968854075547582464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1429115125519.70, NNZs: 2, Bias: 53841118680.711624, T: 512, Avg. loss: 20288806042199387037883170816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 181526950387.27, NNZs: 2, Bias: 113841118680.711624, T: 640, Avg. loss: 19519084928067900948478951424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2251004652154.12, NNZs: 2, Bias: 59858897306.443100, T: 768, Avg. loss: 20969240521134948177760223232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 296696299696.59, NNZs: 2, Bias: 52856080346.920486, T: 896, Avg. loss: 2744479029750874446864842752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 206752158510.40, NNZs: 2, Bias: 36833803569.327332, T: 1024, Avg. loss: 805725915987131531966545920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 178487187679.16, NNZs: 2, Bias: 56670605564.776344, T: 1152, Avg. loss: 879126798266813731454320640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 208082022118.94, NNZs: 2, Bias: 58900927448.691002, T: 1280, Avg. loss: 824178769857503359645253632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 202300818683.40, NNZs: 2, Bias: 62464919029.949471, T: 1408, Avg. loss: 881082488141359264481411072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 151834055246.45, NNZs: 2, Bias: 48583618336.141510, T: 1536, Avg. loss: 784764465881286656565182464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 177142908553.22, NNZs: 2, Bias: 44485587306.280930, T: 1664, Avg. loss: 807465680926359486359142400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 51201201082.69, NNZs: 2, Bias: 41348581583.523270, T: 1792, Avg. loss: 784861529679467435245174784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 224005242445.01, NNZs: 2, Bias: 43608201013.086784, T: 1920, Avg. loss: 844705053977866288932847616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 196454947735.74, NNZs: 2, Bias: 52552673873.288269, T: 2048, Avg. loss: 752855243479530369745682432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 333154745293.89, NNZs: 2, Bias: 30879401409.379333, T: 2176, Avg. loss: 735949631943809008280797184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 126267503462.47, NNZs: 2, Bias: 26973381423.082718, T: 2304, Avg. loss: 905646550137382502274170880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 233066593529.29, NNZs: 2, Bias: 36048983816.797707, T: 2432, Avg. loss: 796148005973852671872860160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 126199169244.40, NNZs: 2, Bias: 45603851376.119591, T: 2560, Avg. loss: 789696170278656775393640448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 338988167149.76, NNZs: 2, Bias: 40761210968.922981, T: 2688, Avg. loss: 801329960537224664504598528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 299731142349.37, NNZs: 2, Bias: 50584161815.785408, T: 2816, Avg. loss: 787143510810274559481085952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 40194166312.29, NNZs: 2, Bias: 56530192070.880608, T: 2944, Avg. loss: 42217762682230195884130304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 81660389982.02, NNZs: 2, Bias: 53593734643.010902, T: 3072, Avg. loss: 32856817273630598023348224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4257959780.13, NNZs: 2, Bias: 53109270990.696045, T: 3200, Avg. loss: 31190300369704042228613120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 20430371429.29, NNZs: 2, Bias: 55573436243.086609, T: 3328, Avg. loss: 31558467880858780765782016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 25984148499.92, NNZs: 2, Bias: 55895248507.528015, T: 3456, Avg. loss: 31822754059568428938690560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 66135526394.05, NNZs: 2, Bias: 54448229694.763130, T: 3584, Avg. loss: 30681386799518983414349824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1799141649.82, NNZs: 2, Bias: 57682306618.724403, T: 3712, Avg. loss: 28928548169660992361332736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 37832636706.36, NNZs: 2, Bias: 60424535408.880585, T: 3840, Avg. loss: 32182163049723377645256704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 81241039103.28, NNZs: 2, Bias: 57860945655.074257, T: 3968, Avg. loss: 31007831713138551889592320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8012091758.38, NNZs: 2, Bias: 55228884013.403969, T: 4096, Avg. loss: 30449661500197884754132992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 57188829215.04, NNZs: 2, Bias: 57731831602.714294, T: 4224, Avg. loss: 32912124176725206991110144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 64867509616.08, NNZs: 2, Bias: 57875000339.547684, T: 4352, Avg. loss: 27463556717666305463812096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 59265157404.01, NNZs: 2, Bias: 58132172582.260460, T: 4480, Avg. loss: 28314685034717914702282752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 25327618875.13, NNZs: 2, Bias: 53333539070.583031, T: 4608, Avg. loss: 31096990548675366282592256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 54373468051.25, NNZs: 2, Bias: 54953317180.104050, T: 4736, Avg. loss: 30119029920905368468193280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2217656377.69, NNZs: 2, Bias: 54215694528.991608, T: 4864, Avg. loss: 29172430299544071721451520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 46833809591.45, NNZs: 2, Bias: 52414705317.135529, T: 4992, Avg. loss: 33766391285913122957688832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3285196424.71, NNZs: 2, Bias: 51831426341.212410, T: 5120, Avg. loss: 1052018570824220590211072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3796231046.67, NNZs: 2, Bias: 51630721361.888214, T: 5248, Avg. loss: 494235437876960240336896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2991505573.19, NNZs: 2, Bias: 51631198336.964653, T: 5376, Avg. loss: 430117281799869017620480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 13061454229.03, NNZs: 2, Bias: 51484113095.356308, T: 5504, Avg. loss: 492406042231317465137152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 732785866.78, NNZs: 2, Bias: 51683828479.979820, T: 5632, Avg. loss: 492420625194762536747008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 8013752622.82, NNZs: 2, Bias: 51974399228.681084, T: 5760, Avg. loss: 447199900482285133103104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9174049344.55, NNZs: 2, Bias: 51722557852.776451, T: 5888, Avg. loss: 462932478054571259723776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2530360888.03, NNZs: 2, Bias: 51755544769.953331, T: 6016, Avg. loss: 734956260516719163867136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1513055744.68, NNZs: 2, Bias: 51757297226.870354, T: 6144, Avg. loss: 737941672817232838656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1202592272.85, NNZs: 2, Bias: 51746186522.498154, T: 6272, Avg. loss: 321577691802435518464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1075499082.20, NNZs: 2, Bias: 51732353488.012566, T: 6400, Avg. loss: 272108889801712304128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 958560340.32, NNZs: 2, Bias: 51717715980.116821, T: 6528, Avg. loss: 277208196516564041728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 946056182.13, NNZs: 2, Bias: 51701121957.556099, T: 6656, Avg. loss: 283328709327354232832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 947066903.21, NNZs: 2, Bias: 51685311675.960007, T: 6784, Avg. loss: 253304469931760254976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 928322030.06, NNZs: 2, Bias: 51668992434.427071, T: 6912, Avg. loss: 264672426706003329024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 914287130.83, NNZs: 2, Bias: 51652054386.220520, T: 7040, Avg. loss: 270477298577636032512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 968078046.98, NNZs: 2, Bias: 51636211709.873444, T: 7168, Avg. loss: 230357078608277012480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 918995219.38, NNZs: 2, Bias: 51619821805.260048, T: 7296, Avg. loss: 279063600985847234560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 892261287.75, NNZs: 2, Bias: 51603590407.735359, T: 7424, Avg. loss: 267571779647104712704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 911369438.86, NNZs: 2, Bias: 51587160394.935631, T: 7552, Avg. loss: 254155138653304619008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 886370894.78, NNZs: 2, Bias: 51572225232.480698, T: 7680, Avg. loss: 241296329749907275776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 921196677.23, NNZs: 2, Bias: 51555109318.368561, T: 7808, Avg. loss: 262122130188002918400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 905239418.86, NNZs: 2, Bias: 51552133307.587631, T: 7936, Avg. loss: 212183243222685810688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 892627411.66, NNZs: 2, Bias: 51549101003.540504, T: 8064, Avg. loss: 211840244300265979904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 902804444.01, NNZs: 2, Bias: 51545683323.086372, T: 8192, Avg. loss: 210577787994602766336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 904017322.00, NNZs: 2, Bias: 51542435465.167969, T: 8320, Avg. loss: 209772126542299398144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 895627157.66, NNZs: 2, Bias: 51539314953.159683, T: 8448, Avg. loss: 212522015207821869056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 895037185.04, NNZs: 2, Bias: 51536083637.885979, T: 8576, Avg. loss: 210651811835750285312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 893170262.66, NNZs: 2, Bias: 51532877725.953087, T: 8704, Avg. loss: 210689939512820006912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 902396677.78, NNZs: 2, Bias: 51529446608.230843, T: 8832, Avg. loss: 212396429597883039744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 903334638.11, NNZs: 2, Bias: 51526164823.855080, T: 8960, Avg. loss: 212182814105152323584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 896403819.82, NNZs: 2, Bias: 51525643056.568565, T: 9088, Avg. loss: 203527019807295176704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 895329568.27, NNZs: 2, Bias: 51525017349.106033, T: 9216, Avg. loss: 203906755312091693056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 895219037.13, NNZs: 2, Bias: 51524376684.599335, T: 9344, Avg. loss: 203315365783943643136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 895723468.81, NNZs: 2, Bias: 51523722107.795151, T: 9472, Avg. loss: 204316698722141437952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 897739826.28, NNZs: 2, Bias: 51523042029.623360, T: 9600, Avg. loss: 204033363235164749824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 896822911.07, NNZs: 2, Bias: 51522413030.190056, T: 9728, Avg. loss: 204084875193032048640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 899775656.86, NNZs: 2, Bias: 51521719353.571884, T: 9856, Avg. loss: 203109011944090271744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 898175737.76, NNZs: 2, Bias: 51521101768.061279, T: 9984, Avg. loss: 204260779666075582464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 895595169.47, NNZs: 2, Bias: 51520501594.234894, T: 10112, Avg. loss: 204146347384053465088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 896279528.89, NNZs: 2, Bias: 51519845471.602211, T: 10240, Avg. loss: 203799393039082520576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 895447081.44, NNZs: 2, Bias: 51519215598.280914, T: 10368, Avg. loss: 203844702391514103808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 893305700.97, NNZs: 2, Bias: 51518612279.148300, T: 10496, Avg. loss: 202639849459572637696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 897025529.81, NNZs: 2, Bias: 51517903342.106346, T: 10624, Avg. loss: 203748902451168772096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 895684993.15, NNZs: 2, Bias: 51517283125.413132, T: 10752, Avg. loss: 203620798586702036992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 897232178.58, NNZs: 2, Bias: 51516611531.421738, T: 10880, Avg. loss: 203904247162431602688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 898336779.93, NNZs: 2, Bias: 51515949162.380989, T: 11008, Avg. loss: 203424837605751652352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 898580803.77, NNZs: 2, Bias: 51515300420.776917, T: 11136, Avg. loss: 203888159163879718912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 87 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1375924391625.92, NNZs: 2, Bias: 68181779486.108612, T: 128, Avg. loss: 20758691763362030796398395392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1323765771650.47, NNZs: 2, Bias: 68181779486.108612, T: 256, Avg. loss: 20762036336025926817651097600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1577167571654.27, NNZs: 2, Bias: -54521826767.678406, T: 384, Avg. loss: 22412866815537690906944602112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1202361828621.22, NNZs: 2, Bias: 5478173232.321594, T: 512, Avg. loss: 21567209627641164965691260928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 221757043374.72, NNZs: 2, Bias: -14521826767.678406, T: 640, Avg. loss: 20865000602717204671262359552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1425283556698.51, NNZs: 2, Bias: 16341459503.114525, T: 768, Avg. loss: 22930285149156385359493332992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 351181683406.49, NNZs: 2, Bias: 35095645949.555405, T: 896, Avg. loss: 1249781296182874896114647040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 155586278439.89, NNZs: 2, Bias: 50383561932.078125, T: 1024, Avg. loss: 953503196349372633232441344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 300899500097.60, NNZs: 2, Bias: 29010281712.280933, T: 1152, Avg. loss: 842659229631166522297679872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 278467225563.91, NNZs: 2, Bias: 45462345147.409218, T: 1280, Avg. loss: 902356977443511445433090048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 264916791885.02, NNZs: 2, Bias: 43956139331.001595, T: 1408, Avg. loss: 897031568773500303432482816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 190658161766.15, NNZs: 2, Bias: 60172554889.534615, T: 1536, Avg. loss: 858480192544524008712830976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 382500012714.19, NNZs: 2, Bias: 61591422444.327110, T: 1664, Avg. loss: 908514171879171555512549376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 22568715762.05, NNZs: 2, Bias: 55156243140.552490, T: 1792, Avg. loss: 905562261600824716425166848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 56264415329.84, NNZs: 2, Bias: 55110265469.750206, T: 1920, Avg. loss: 36178131176724104107524096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 7466979589.99, NNZs: 2, Bias: 55089290316.639359, T: 2048, Avg. loss: 33504526044857914120732672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 25878810076.10, NNZs: 2, Bias: 58053230138.490822, T: 2176, Avg. loss: 34081477128756669701947392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 20875751004.01, NNZs: 2, Bias: 59634285391.255226, T: 2304, Avg. loss: 39906009319918617820659712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 41566087733.08, NNZs: 2, Bias: 58253707998.981239, T: 2432, Avg. loss: 35775665332656492234407936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 57702072941.52, NNZs: 2, Bias: 56898079132.366570, T: 2560, Avg. loss: 32680772083259378730270720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 78643021427.67, NNZs: 2, Bias: 58953940648.590027, T: 2688, Avg. loss: 31145362110817838674477056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 14895246304.94, NNZs: 2, Bias: 58377829264.588524, T: 2816, Avg. loss: 30016082949825981369548800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 9395304715.19, NNZs: 2, Bias: 57337121484.647743, T: 2944, Avg. loss: 36212463670973462963290112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 24076853382.98, NNZs: 2, Bias: 59665345206.416733, T: 3072, Avg. loss: 31863409536111903581929472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 31061495528.20, NNZs: 2, Bias: 58349436831.372818, T: 3200, Avg. loss: 33231354167468745866346496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 70108570924.36, NNZs: 2, Bias: 59184439407.692833, T: 3328, Avg. loss: 38240569098725335196762112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 60896124059.13, NNZs: 2, Bias: 58932701971.323242, T: 3456, Avg. loss: 34397810080329154472968192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 8787285676.25, NNZs: 2, Bias: 58602629242.471672, T: 3584, Avg. loss: 1715193525202948624220160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2802208939.50, NNZs: 2, Bias: 58806051698.146172, T: 3712, Avg. loss: 708466806173650502287360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 7937375995.57, NNZs: 2, Bias: 59011616702.785912, T: 3840, Avg. loss: 607036825770577075634176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 8770656106.00, NNZs: 2, Bias: 59089965895.092697, T: 3968, Avg. loss: 622677519726831365783552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2137759690.48, NNZs: 2, Bias: 58860200907.750549, T: 4096, Avg. loss: 719819721509372730277888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4524092691.48, NNZs: 2, Bias: 58661160446.003326, T: 4224, Avg. loss: 534274941428664371249152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1437279766.59, NNZs: 2, Bias: 58487383350.665466, T: 4352, Avg. loss: 502662588708033172340736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1755274006.96, NNZs: 2, Bias: 58457835879.663223, T: 4480, Avg. loss: 425938313913758272978944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 12583135931.46, NNZs: 2, Bias: 58382274913.064171, T: 4608, Avg. loss: 596465231937398150004736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3502644163.20, NNZs: 2, Bias: 58056575495.275040, T: 4736, Avg. loss: 646051650422152324186112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5583677199.96, NNZs: 2, Bias: 58193652055.451271, T: 4864, Avg. loss: 607886331202724232691712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 15620704959.87, NNZs: 2, Bias: 58086906769.248367, T: 4992, Avg. loss: 471817777920448854491136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1129718731.07, NNZs: 2, Bias: 58074320329.983002, T: 5120, Avg. loss: 613201027561003199496192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 300641445.01, NNZs: 2, Bias: 58038852287.533569, T: 5248, Avg. loss: 770572568369410342912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 476662624.15, NNZs: 2, Bias: 58012079402.335548, T: 5376, Avg. loss: 422726454845647355904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 684817483.59, NNZs: 2, Bias: 57987741103.385963, T: 5504, Avg. loss: 377625140531070042112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 790114886.21, NNZs: 2, Bias: 57966020349.572693, T: 5632, Avg. loss: 359182676811425644544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 851484788.81, NNZs: 2, Bias: 57945747428.634254, T: 5760, Avg. loss: 348997987535608610816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 851231630.39, NNZs: 2, Bias: 57926565679.658775, T: 5888, Avg. loss: 350739198870667591680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 888580316.74, NNZs: 2, Bias: 57906681122.362190, T: 6016, Avg. loss: 344827124257578221568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 936527973.75, NNZs: 2, Bias: 57885328164.731827, T: 6144, Avg. loss: 366509189246256349184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 895510823.63, NNZs: 2, Bias: 57865450390.830093, T: 6272, Avg. loss: 373056797097486123008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 947049408.44, NNZs: 2, Bias: 57844756466.722115, T: 6400, Avg. loss: 352212137647698870272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 949643232.09, NNZs: 2, Bias: 57824975622.899796, T: 6528, Avg. loss: 371580208248675565568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 935528060.89, NNZs: 2, Bias: 57805910855.125610, T: 6656, Avg. loss: 341008663676251013120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 952287150.92, NNZs: 2, Bias: 57786578799.337540, T: 6784, Avg. loss: 333248746996154368000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 981607642.47, NNZs: 2, Bias: 57767133450.736053, T: 6912, Avg. loss: 344018735961496682496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 936195873.61, NNZs: 2, Bias: 57749091602.766502, T: 7040, Avg. loss: 343602766320387293184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1007197493.55, NNZs: 2, Bias: 57727924041.176186, T: 7168, Avg. loss: 357030986916248682496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 901451839.76, NNZs: 2, Bias: 57709616209.021904, T: 7296, Avg. loss: 372724463617903951872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 973948141.18, NNZs: 2, Bias: 57688900336.123810, T: 7424, Avg. loss: 363636758522835435520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 956903571.08, NNZs: 2, Bias: 57685305999.558174, T: 7552, Avg. loss: 283281327002965573632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 943097528.60, NNZs: 2, Bias: 57681641412.327255, T: 7680, Avg. loss: 283858507576364695552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 939138973.97, NNZs: 2, Bias: 57677819558.638474, T: 7808, Avg. loss: 283568624835340500992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 943962332.04, NNZs: 2, Bias: 57673797687.529198, T: 7936, Avg. loss: 287155080351284592640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 935915342.96, NNZs: 2, Bias: 57670105540.805801, T: 8064, Avg. loss: 279472517455800139776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 928289228.12, NNZs: 2, Bias: 57666319227.087868, T: 8192, Avg. loss: 285536338506541727744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 921857428.21, NNZs: 2, Bias: 57662634888.895149, T: 8320, Avg. loss: 275560345418814914560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 926080561.04, NNZs: 2, Bias: 57658672696.977066, T: 8448, Avg. loss: 284044929088676986880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 921081017.92, NNZs: 2, Bias: 57654886063.588326, T: 8576, Avg. loss: 281811853081496223744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 915893443.87, NNZs: 2, Bias: 57651081905.205223, T: 8704, Avg. loss: 283552066963104825344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 913634661.00, NNZs: 2, Bias: 57647200897.132492, T: 8832, Avg. loss: 285265905880815894528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 927601494.64, NNZs: 2, Bias: 57643106847.299103, T: 8960, Avg. loss: 281458929634013773824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 920218951.44, NNZs: 2, Bias: 57642439252.916618, T: 9088, Avg. loss: 278515952814921646080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 913887934.29, NNZs: 2, Bias: 57641764922.691132, T: 9216, Avg. loss: 274551335320060166144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 912715820.41, NNZs: 2, Bias: 57641010977.728394, T: 9344, Avg. loss: 273554169770545414144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 912688635.22, NNZs: 2, Bias: 57640235909.979736, T: 9472, Avg. loss: 274565514797898465280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 916955854.54, NNZs: 2, Bias: 57639396492.241013, T: 9600, Avg. loss: 273111650315635261440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 913550855.95, NNZs: 2, Bias: 57638676902.320770, T: 9728, Avg. loss: 273979249389771685888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 912072176.11, NNZs: 2, Bias: 57637927824.992889, T: 9856, Avg. loss: 273498135742826053632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 915618349.65, NNZs: 2, Bias: 57637096855.783432, T: 9984, Avg. loss: 274200806055631781888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 915176332.52, NNZs: 2, Bias: 57636328672.372208, T: 10112, Avg. loss: 274438742840873451520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 914101913.49, NNZs: 2, Bias: 57635570067.852943, T: 10240, Avg. loss: 274583275115799740416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 80 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 883816522565.70, NNZs: 2, Bias: 25676995020.940903, T: 128, Avg. loss: 23571158983908689778009178112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1484100232945.38, NNZs: 2, Bias: 41802403993.469604, T: 256, Avg. loss: 23815865251192645746897715200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 107071392575.28, NNZs: 2, Bias: 22795221015.198502, T: 384, Avg. loss: 24748772108489708708730765312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2138518912925.51, NNZs: 2, Bias: 47765479956.968918, T: 512, Avg. loss: 22223456468453301028585996288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3255310962813.24, NNZs: 2, Bias: -52234520043.031082, T: 640, Avg. loss: 21928445972556769073706303488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2768171013100.64, NNZs: 2, Bias: 4393362299.613319, T: 768, Avg. loss: 23005233244370163301923946496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1781533719701.64, NNZs: 2, Bias: 44393362299.613312, T: 896, Avg. loss: 22834795134977823288242208768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1339046561177.53, NNZs: 2, Bias: 119071808027.004654, T: 1024, Avg. loss: 23074389450238374529311178752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1703251896896.03, NNZs: 2, Bias: 27791943306.325394, T: 1152, Avg. loss: 24647346138085840458577084416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1950624840703.66, NNZs: 2, Bias: -12208056693.674606, T: 1280, Avg. loss: 25126289840421705841582800896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 378546900130.81, NNZs: 2, Bias: -28197969844.420448, T: 1408, Avg. loss: 1923576305757907110110167040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 188989250492.52, NNZs: 2, Bias: -39376941252.848351, T: 1536, Avg. loss: 961480097891395529028403200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 322960263216.22, NNZs: 2, Bias: -31010749817.386070, T: 1664, Avg. loss: 895231163002742502678593536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 155272921741.75, NNZs: 2, Bias: -45951039757.337799, T: 1792, Avg. loss: 969409795316222293293662208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 172398377596.00, NNZs: 2, Bias: -44780676551.802391, T: 1920, Avg. loss: 904035448335331036640575488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 156117216250.91, NNZs: 2, Bias: -22181036761.979565, T: 2048, Avg. loss: 934306036281587534728790016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 380542570939.52, NNZs: 2, Bias: -20945786501.809807, T: 2176, Avg. loss: 902637530905359242726735872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 381011946818.63, NNZs: 2, Bias: -37762077905.985764, T: 2304, Avg. loss: 927087140462908035269918720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 60600407534.03, NNZs: 2, Bias: -42041872513.409843, T: 2432, Avg. loss: 52764282280149990076579840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 98817509876.02, NNZs: 2, Bias: -41259380098.584457, T: 2560, Avg. loss: 34893974672227434126901248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 28089258188.74, NNZs: 2, Bias: -42751767936.892197, T: 2688, Avg. loss: 40106152291477308183674880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 28585282534.82, NNZs: 2, Bias: -41973186715.987549, T: 2816, Avg. loss: 33954407205874857119055872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 70823175205.35, NNZs: 2, Bias: -41986346122.742836, T: 2944, Avg. loss: 34650137329286590352064512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 80656175073.41, NNZs: 2, Bias: -39151896217.841919, T: 3072, Avg. loss: 34624347125661388968558592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 24637521468.90, NNZs: 2, Bias: -39502318103.665359, T: 3200, Avg. loss: 35643366502731142532169728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 106554336087.12, NNZs: 2, Bias: -38582260582.922874, T: 3328, Avg. loss: 29930154230422235101790208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 50534201638.48, NNZs: 2, Bias: -39822538187.790321, T: 3456, Avg. loss: 36892934426537814686433280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 42865872989.49, NNZs: 2, Bias: -39263839654.861588, T: 3584, Avg. loss: 38892386133012268114247680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 71386442275.39, NNZs: 2, Bias: -39868455525.238754, T: 3712, Avg. loss: 35620735917749531895136256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 59740483997.24, NNZs: 2, Bias: -38865387104.303535, T: 3840, Avg. loss: 36831168258977881525321728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 50120278565.23, NNZs: 2, Bias: -37774805037.498741, T: 3968, Avg. loss: 33798437928453953262977024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 16826820040.90, NNZs: 2, Bias: -37417458646.897232, T: 4096, Avg. loss: 1184391520864909626703872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4168881738.75, NNZs: 2, Bias: -37556307658.817284, T: 4224, Avg. loss: 771059777485177517768704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7022391880.59, NNZs: 2, Bias: -37511561564.909523, T: 4352, Avg. loss: 618730012676413951311872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3482968714.19, NNZs: 2, Bias: -37511628492.927979, T: 4480, Avg. loss: 684632210564192588005376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1936613533.53, NNZs: 2, Bias: -37849968902.647339, T: 4608, Avg. loss: 726545359542443900403712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3448150753.20, NNZs: 2, Bias: -37814163769.358612, T: 4736, Avg. loss: 848013323805720689246208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6921020961.55, NNZs: 2, Bias: -37404127331.698303, T: 4864, Avg. loss: 850352234446291961118720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 14115325021.29, NNZs: 2, Bias: -37555513264.348648, T: 4992, Avg. loss: 847835306741485237436416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4419783286.45, NNZs: 2, Bias: -37523362274.337517, T: 5120, Avg. loss: 54691041532291194028032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2129359742.69, NNZs: 2, Bias: -37482751222.044350, T: 5248, Avg. loss: 2872106531749666750464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 878197822.69, NNZs: 2, Bias: -37455737354.348969, T: 5376, Avg. loss: 896251355126623240192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 315966861.41, NNZs: 2, Bias: -37435126591.603516, T: 5504, Avg. loss: 316508819219385745408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 327923523.80, NNZs: 2, Bias: -37418920785.877007, T: 5632, Avg. loss: 174366801831798112256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 456823887.07, NNZs: 2, Bias: -37405965124.803703, T: 5760, Avg. loss: 123696756332294029312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 541170836.64, NNZs: 2, Bias: -37394239949.601997, T: 5888, Avg. loss: 113945874110176280576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 545511932.54, NNZs: 2, Bias: -37382841439.499474, T: 6016, Avg. loss: 133821660111654436864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 560094196.72, NNZs: 2, Bias: -37371502225.865852, T: 6144, Avg. loss: 123919202194066669568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 551844706.16, NNZs: 2, Bias: -37360752037.920738, T: 6272, Avg. loss: 124612643391530975232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 571208199.71, NNZs: 2, Bias: -37348894763.435677, T: 6400, Avg. loss: 132334236242661425152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 589979591.12, NNZs: 2, Bias: -37337870800.340195, T: 6528, Avg. loss: 119477726607664693248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 584318552.79, NNZs: 2, Bias: -37335763172.782906, T: 6656, Avg. loss: 103543632948965998592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 590426705.70, NNZs: 2, Bias: -37333485996.948448, T: 6784, Avg. loss: 102615166021428740096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 582870017.80, NNZs: 2, Bias: -37331471146.811684, T: 6912, Avg. loss: 100482629749601091584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 587790601.17, NNZs: 2, Bias: -37329222503.222755, T: 7040, Avg. loss: 102183292572977315840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 584370465.43, NNZs: 2, Bias: -37327112154.676239, T: 7168, Avg. loss: 101922690828107366400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 593471257.07, NNZs: 2, Bias: -37324827319.770203, T: 7296, Avg. loss: 100337582428971220992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 582967300.05, NNZs: 2, Bias: -37322802661.658852, T: 7424, Avg. loss: 103188682096063266816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 584855374.53, NNZs: 2, Bias: -37320602216.491631, T: 7552, Avg. loss: 102117447738052657152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 586380001.98, NNZs: 2, Bias: -37318402509.574440, T: 7680, Avg. loss: 102342035150715764736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 597304128.59, NNZs: 2, Bias: -37316109527.313759, T: 7808, Avg. loss: 99408919427988668416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 588476610.95, NNZs: 2, Bias: -37314042820.771904, T: 7936, Avg. loss: 104032150364926574592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 590943053.29, NNZs: 2, Bias: -37311867362.872444, T: 8064, Avg. loss: 100442213782582771712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 584915595.72, NNZs: 2, Bias: -37309773396.255089, T: 8192, Avg. loss: 103079752328727658496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 585786677.29, NNZs: 2, Bias: -37307598817.706879, T: 8320, Avg. loss: 101682134731796627456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 590149857.60, NNZs: 2, Bias: -37305369971.379425, T: 8448, Avg. loss: 101619283351216848896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 584086186.06, NNZs: 2, Bias: -37305026572.157257, T: 8576, Avg. loss: 100599896702447861760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 584684712.10, NNZs: 2, Bias: -37304583767.988510, T: 8704, Avg. loss: 99274336036565123072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 582251662.87, NNZs: 2, Bias: -37304190339.860596, T: 8832, Avg. loss: 98862621975496507392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 584098736.33, NNZs: 2, Bias: -37303729752.005493, T: 8960, Avg. loss: 98858240202634477568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 582970131.39, NNZs: 2, Bias: -37303314297.469521, T: 9088, Avg. loss: 99221933004058116096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 583740078.85, NNZs: 2, Bias: -37302868491.927818, T: 9216, Avg. loss: 99355849646566752256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 582826104.22, NNZs: 2, Bias: -37302449086.591217, T: 9344, Avg. loss: 99355590294084468736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 583576726.96, NNZs: 2, Bias: -37302003989.350197, T: 9472, Avg. loss: 99253416661367570432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 583132298.49, NNZs: 2, Bias: -37301579159.659119, T: 9600, Avg. loss: 98907974950808059904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2280208851307.71, NNZs: 2, Bias: 6964476561.444221, T: 128, Avg. loss: 20522822419862300033315504128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1067595944243.07, NNZs: 2, Bias: -16686457693.660675, T: 256, Avg. loss: 22614263541669968596101496832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 860275496019.24, NNZs: 2, Bias: 17556098023.075668, T: 384, Avg. loss: 22445185005965604524904153088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 949950272756.68, NNZs: 2, Bias: 70817796151.366333, T: 512, Avg. loss: 22161729112341585559218552832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1248051304755.18, NNZs: 2, Bias: 76993741427.121124, T: 640, Avg. loss: 20029570442500470831971303424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1100644036092.80, NNZs: 2, Bias: 16993741427.121124, T: 768, Avg. loss: 21036021247800054157978632192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 83158570587.52, NNZs: 2, Bias: -11388413068.187143, T: 896, Avg. loss: 21945312123769561764251828224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 692730657785.64, NNZs: 2, Bias: -23080741941.593182, T: 1024, Avg. loss: 22750355379678633118769610752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 728385010686.17, NNZs: 2, Bias: 4491533846.491982, T: 1152, Avg. loss: 21845584965036059629281345536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1072222630133.24, NNZs: 2, Bias: 104491533846.491974, T: 1280, Avg. loss: 20279361247566632106057531392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 378131926407.47, NNZs: 2, Bias: 78131583441.074265, T: 1408, Avg. loss: 907538933814834871750623232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 173079870491.70, NNZs: 2, Bias: 77974623739.673309, T: 1536, Avg. loss: 841573395725481564037971968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 91681056014.89, NNZs: 2, Bias: 79071182800.591095, T: 1664, Avg. loss: 859528231111953431698341888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 358380096656.85, NNZs: 2, Bias: 85817980536.378952, T: 1792, Avg. loss: 818905540552919926821617664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 123977215033.65, NNZs: 2, Bias: 76799340474.389618, T: 1920, Avg. loss: 863848938802826391515561984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 181688330082.44, NNZs: 2, Bias: 88017117875.058533, T: 2048, Avg. loss: 892829480589776556388253696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 346770000064.29, NNZs: 2, Bias: 59841999665.940102, T: 2176, Avg. loss: 869520749325400395481088000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 202833385965.82, NNZs: 2, Bias: 66356399308.901100, T: 2304, Avg. loss: 858395903561222691309486080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 325920822128.86, NNZs: 2, Bias: 83205360057.432541, T: 2432, Avg. loss: 894047513814087692562989056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40551804233.93, NNZs: 2, Bias: 80083111597.228912, T: 2560, Avg. loss: 59711551830858860630900736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 62403173857.76, NNZs: 2, Bias: 80567214904.509583, T: 2688, Avg. loss: 33568020792309862329483264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 9735191111.61, NNZs: 2, Bias: 76628898237.992966, T: 2816, Avg. loss: 30078060338648477847257088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 44715700427.83, NNZs: 2, Bias: 72565317765.132462, T: 2944, Avg. loss: 33221890797063845212848128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 37216340656.33, NNZs: 2, Bias: 72887810651.054367, T: 3072, Avg. loss: 31189193997517613241991168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 43705010946.54, NNZs: 2, Bias: 71589148658.054031, T: 3200, Avg. loss: 31190894472662116068229120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 66478440338.40, NNZs: 2, Bias: 71228744528.883698, T: 3328, Avg. loss: 30447182387801145877725184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 51678050641.22, NNZs: 2, Bias: 74034777603.809402, T: 3456, Avg. loss: 32006944108616576441253888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3231072382.63, NNZs: 2, Bias: 73322856510.872940, T: 3584, Avg. loss: 1068345087985210053623808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 15581841766.17, NNZs: 2, Bias: 73259481028.974625, T: 3712, Avg. loss: 472868388775920287088640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2469539937.20, NNZs: 2, Bias: 73109153570.869583, T: 3840, Avg. loss: 411759630848694113271808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 7044275832.68, NNZs: 2, Bias: 72992681784.820587, T: 3968, Avg. loss: 577930636050347065344000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2462287455.40, NNZs: 2, Bias: 73130912066.528687, T: 4096, Avg. loss: 783457649506252356583424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4304917396.58, NNZs: 2, Bias: 73194545861.378754, T: 4224, Avg. loss: 716858050654219964252160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2379072735.74, NNZs: 2, Bias: 72988794708.873062, T: 4352, Avg. loss: 531956995252556847382528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4563039975.57, NNZs: 2, Bias: 72861384695.807404, T: 4480, Avg. loss: 613836323051805389881344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2804897893.01, NNZs: 2, Bias: 72866802534.209274, T: 4608, Avg. loss: 2027209775103536791552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1934233360.78, NNZs: 2, Bias: 72852891650.687241, T: 4736, Avg. loss: 1085416703518790909952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1514184261.30, NNZs: 2, Bias: 72833773331.668427, T: 4864, Avg. loss: 709761928541654614016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1432058465.93, NNZs: 2, Bias: 72810552681.894348, T: 4992, Avg. loss: 551874946578303156224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1297256450.95, NNZs: 2, Bias: 72788326239.227005, T: 5120, Avg. loss: 553106378114985426944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1220682237.21, NNZs: 2, Bias: 72762077753.549881, T: 5248, Avg. loss: 628230746676346486784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1226981151.01, NNZs: 2, Bias: 72738020209.035431, T: 5376, Avg. loss: 514427981175577772032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1259793114.44, NNZs: 2, Bias: 72712858791.256287, T: 5504, Avg. loss: 536832502286274330624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1197122689.53, NNZs: 2, Bias: 72687571688.643509, T: 5632, Avg. loss: 593398604195129327616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1186756608.43, NNZs: 2, Bias: 72662519634.698303, T: 5760, Avg. loss: 559898631093530263552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1190613328.69, NNZs: 2, Bias: 72636864827.465179, T: 5888, Avg. loss: 576456265313211580416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1162151179.65, NNZs: 2, Bias: 72611828706.370056, T: 6016, Avg. loss: 571000255137070841856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1144891852.83, NNZs: 2, Bias: 72607051093.866516, T: 6144, Avg. loss: 463263893336894537728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1166700819.99, NNZs: 2, Bias: 72601534220.308655, T: 6272, Avg. loss: 471883870375122960384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1147219128.32, NNZs: 2, Bias: 72596747922.804947, T: 6400, Avg. loss: 466274087730395414528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1161348582.39, NNZs: 2, Bias: 72591396432.574905, T: 6528, Avg. loss: 468373359239433158656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1160093636.71, NNZs: 2, Bias: 72586296710.826019, T: 6656, Avg. loss: 467753257358112718848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1175584122.12, NNZs: 2, Bias: 72581024363.675201, T: 6784, Avg. loss: 458645285338601553920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1176807670.38, NNZs: 2, Bias: 72575988422.125000, T: 6912, Avg. loss: 457671096707347972096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1171490510.90, NNZs: 2, Bias: 72570948834.655121, T: 7040, Avg. loss: 468316462768582295552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1166094347.81, NNZs: 2, Bias: 72565942364.874512, T: 7168, Avg. loss: 465876815191084433408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1163387718.01, NNZs: 2, Bias: 72560844068.832184, T: 7296, Avg. loss: 470264962777792905216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1182370581.61, NNZs: 2, Bias: 72555475266.153519, T: 7424, Avg. loss: 461728779854599028736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1181760569.06, NNZs: 2, Bias: 72550369304.712860, T: 7552, Avg. loss: 467471444511153586176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1177394787.58, NNZs: 2, Bias: 72549420042.787399, T: 7680, Avg. loss: 454585944840605532160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1180209633.71, NNZs: 2, Bias: 72548355909.399994, T: 7808, Avg. loss: 453567915149091012608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1181117580.12, NNZs: 2, Bias: 72547324281.518158, T: 7936, Avg. loss: 452948706717380444160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1177343691.53, NNZs: 2, Bias: 72546368062.545624, T: 8064, Avg. loss: 453346827959742889984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1179796432.55, NNZs: 2, Bias: 72545309673.803619, T: 8192, Avg. loss: 453609451380777680896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1179886610.64, NNZs: 2, Bias: 72544289374.600754, T: 8320, Avg. loss: 453784829886145626112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1178180037.76, NNZs: 2, Bias: 72543298642.168503, T: 8448, Avg. loss: 453638913770033577984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1178866806.00, NNZs: 2, Bias: 72542269970.369858, T: 8576, Avg. loss: 453132866991986049024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 67 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 845433762943.87, NNZs: 2, Bias: 53923368957.252350, T: 128, Avg. loss: 18737123739084395132449980416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 791525270618.69, NNZs: 2, Bias: 153923368957.252350, T: 256, Avg. loss: 20552765816960957678868234240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 933414999035.41, NNZs: 2, Bias: 253923368957.252350, T: 384, Avg. loss: 18769327681551266815185780736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 823497560184.38, NNZs: 2, Bias: 293307455312.489319, T: 512, Avg. loss: 17928004448514152598979215360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2260621598509.65, NNZs: 2, Bias: 193307455312.489319, T: 640, Avg. loss: 19809123156881026559944687616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 935076280997.51, NNZs: 2, Bias: 164876190797.080505, T: 768, Avg. loss: 20535457940585552327703789568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1380102159504.96, NNZs: 2, Bias: 64876190797.080505, T: 896, Avg. loss: 20357076063058268515934928896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1624185623941.10, NNZs: 2, Bias: 49023293715.422852, T: 1024, Avg. loss: 21564872760080079781233688576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 771465726111.22, NNZs: 2, Bias: 69023293715.422852, T: 1152, Avg. loss: 20840333848280395292910551040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 384690634845.44, NNZs: 2, Bias: 91332053568.280060, T: 1280, Avg. loss: 827593102326436942823030784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 269521124901.17, NNZs: 2, Bias: 112698353379.688141, T: 1408, Avg. loss: 834657971035151100001910784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 317112417903.74, NNZs: 2, Bias: 103683118480.016220, T: 1536, Avg. loss: 720246310960768767584370688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 324617319017.69, NNZs: 2, Bias: 111396687114.402176, T: 1664, Avg. loss: 780946499452120802705539072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 280833788428.28, NNZs: 2, Bias: 105585010132.101578, T: 1792, Avg. loss: 784070151455663252328939520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 114532013187.68, NNZs: 2, Bias: 105055761734.053299, T: 1920, Avg. loss: 838193727942345536359628800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 155803791268.65, NNZs: 2, Bias: 93067507349.137253, T: 2048, Avg. loss: 774434121587110268408692736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 330802617978.91, NNZs: 2, Bias: 108925912373.806625, T: 2176, Avg. loss: 769568486754623527573258240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 22903374814.06, NNZs: 2, Bias: 110946834322.642822, T: 2304, Avg. loss: 49693127921669704303771648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58114715957.45, NNZs: 2, Bias: 108343836099.972122, T: 2432, Avg. loss: 29521973931992950174121984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 55527594642.08, NNZs: 2, Bias: 108700196244.388687, T: 2560, Avg. loss: 29460748316541089614921728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 40160053872.76, NNZs: 2, Bias: 110738106684.089493, T: 2688, Avg. loss: 27553547312154192023388160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 85731606816.56, NNZs: 2, Bias: 110227103469.591431, T: 2816, Avg. loss: 26192376187014630640451584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 54761388284.73, NNZs: 2, Bias: 111025684788.221512, T: 2944, Avg. loss: 31381346321528587309547520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 98833936806.11, NNZs: 2, Bias: 108873697994.938034, T: 3072, Avg. loss: 28858180977512620249579520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 69219264103.99, NNZs: 2, Bias: 108632907786.322662, T: 3200, Avg. loss: 30342033912062015589842944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 16603650130.67, NNZs: 2, Bias: 106824016064.098801, T: 3328, Avg. loss: 28158936381161227639848960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 5745452599.23, NNZs: 2, Bias: 105240915111.521362, T: 3456, Avg. loss: 31864008687352645691637760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3491677508.08, NNZs: 2, Bias: 104953911680.572952, T: 3584, Avg. loss: 543088508333786241433600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 11310828914.29, NNZs: 2, Bias: 104935882952.740372, T: 3712, Avg. loss: 592707759560569472942080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8439738009.18, NNZs: 2, Bias: 104632215196.005692, T: 3840, Avg. loss: 501248107965533227319296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 3112225876.86, NNZs: 2, Bias: 104435417832.620453, T: 3968, Avg. loss: 490597887570938890813440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6869331254.78, NNZs: 2, Bias: 103881393722.126190, T: 4096, Avg. loss: 482096125031221666250752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4294648118.00, NNZs: 2, Bias: 103939197513.230255, T: 4224, Avg. loss: 589440762672141630963712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 801438700.85, NNZs: 2, Bias: 103650044239.039612, T: 4352, Avg. loss: 576201889870029330055168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1512586548.76, NNZs: 2, Bias: 103398189892.453049, T: 4480, Avg. loss: 507899315813379777495040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2492098182.88, NNZs: 2, Bias: 103186482559.280899, T: 4608, Avg. loss: 453715935631480746672128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 7650652937.35, NNZs: 2, Bias: 103304761280.806519, T: 4736, Avg. loss: 423742319887389609164800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5027966636.88, NNZs: 2, Bias: 103209960946.704453, T: 4864, Avg. loss: 462850275361293655343104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2308194992.66, NNZs: 2, Bias: 103353528128.995377, T: 4992, Avg. loss: 544866931171032406425600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 10271965191.56, NNZs: 2, Bias: 103583548049.606613, T: 5120, Avg. loss: 537255506140975077523456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3134599071.13, NNZs: 2, Bias: 103601740319.550659, T: 5248, Avg. loss: 470444418864231921745920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1113261931.20, NNZs: 2, Bias: 103178664687.554138, T: 5376, Avg. loss: 416697017602296946622464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3530322017.86, NNZs: 2, Bias: 102920213742.950684, T: 5504, Avg. loss: 543058170392634806239232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4714845107.08, NNZs: 2, Bias: 102849777918.822205, T: 5632, Avg. loss: 424314982614937192366080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 10614521803.69, NNZs: 2, Bias: 102983948998.349960, T: 5760, Avg. loss: 417261476428622759723008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 5102311086.17, NNZs: 2, Bias: 102791060153.122604, T: 5888, Avg. loss: 556275580189899803852800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2048437280.99, NNZs: 2, Bias: 102591687885.172531, T: 6016, Avg. loss: 574320773596189458169856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1214097520.40, NNZs: 2, Bias: 102558771402.967087, T: 6144, Avg. loss: 1444557811807194185728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1558845325.98, NNZs: 2, Bias: 102518729654.578079, T: 6272, Avg. loss: 1099226594632220803072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1496061795.44, NNZs: 2, Bias: 102481648359.138687, T: 6400, Avg. loss: 1239067860027310866432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1588997757.30, NNZs: 2, Bias: 102446988029.427567, T: 6528, Avg. loss: 1090618868977147576320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1590884412.34, NNZs: 2, Bias: 102410341614.294418, T: 6656, Avg. loss: 1161641553059260399616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1673283621.21, NNZs: 2, Bias: 102373807883.017746, T: 6784, Avg. loss: 1101202916129143390208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1553311246.04, NNZs: 2, Bias: 102340739261.479630, T: 6912, Avg. loss: 1196929838796349374464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1625442086.10, NNZs: 2, Bias: 102304623160.656418, T: 7040, Avg. loss: 1127944157344935706624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1674970210.13, NNZs: 2, Bias: 102270958619.230194, T: 7168, Avg. loss: 1050582703305118973952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1577350682.12, NNZs: 2, Bias: 102234767076.657227, T: 7296, Avg. loss: 1209320275319738073088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1559480142.55, NNZs: 2, Bias: 102199839418.944504, T: 7424, Avg. loss: 1076512260271367389184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1645068532.83, NNZs: 2, Bias: 102163151780.422119, T: 7552, Avg. loss: 1095775477182081925120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1641830189.06, NNZs: 2, Bias: 102126990812.395584, T: 7680, Avg. loss: 1173330897694412374016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1570702594.63, NNZs: 2, Bias: 102092006077.328751, T: 7808, Avg. loss: 1198669382080472809472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1589748986.34, NNZs: 2, Bias: 102084668880.118301, T: 7936, Avg. loss: 909512750764431638528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1624084405.87, NNZs: 2, Bias: 102077263001.781693, T: 8064, Avg. loss: 882857258628956291072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1616837478.74, NNZs: 2, Bias: 102070459732.976242, T: 8192, Avg. loss: 893319624371273728000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1623338929.46, NNZs: 2, Bias: 102063509245.994644, T: 8320, Avg. loss: 882885662892721307648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1626847165.43, NNZs: 2, Bias: 102056491663.055115, T: 8448, Avg. loss: 898030442350649409536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1626443588.71, NNZs: 2, Bias: 102049624333.894211, T: 8576, Avg. loss: 886855865288526266368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1627452107.59, NNZs: 2, Bias: 102042628035.872925, T: 8704, Avg. loss: 901320933740534038528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1630588368.58, NNZs: 2, Bias: 102041203316.890137, T: 8832, Avg. loss: 861617969073920671744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1630679969.69, NNZs: 2, Bias: 102039826405.142853, T: 8960, Avg. loss: 862187379634374443008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1629790499.65, NNZs: 2, Bias: 102038467113.450043, T: 9088, Avg. loss: 860946462432353058816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1628382307.32, NNZs: 2, Bias: 102037115393.451859, T: 9216, Avg. loss: 861549970578839306240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1631698739.72, NNZs: 2, Bias: 102035686958.993652, T: 9344, Avg. loss: 862099321548203753472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1631032254.24, NNZs: 2, Bias: 102034325118.873581, T: 9472, Avg. loss: 860264647620231954432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1629933443.90, NNZs: 2, Bias: 102032967380.419540, T: 9600, Avg. loss: 862140325083293024256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1629960635.55, NNZs: 2, Bias: 102031591855.701035, T: 9728, Avg. loss: 861848251958514810880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1626852847.51, NNZs: 2, Bias: 102030269428.709747, T: 9856, Avg. loss: 860167861998049165312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1628955308.24, NNZs: 2, Bias: 102028859745.388611, T: 9984, Avg. loss: 862531282921894707200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1629953539.25, NNZs: 2, Bias: 102027468672.988586, T: 10112, Avg. loss: 861901151148175917056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1632287875.22, NNZs: 2, Bias: 102026055883.375671, T: 10240, Avg. loss: 862102778061432553472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1638509020.95, NNZs: 2, Bias: 102024587174.766388, T: 10368, Avg. loss: 857834571260012789760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1636617266.13, NNZs: 2, Bias: 102023240212.873856, T: 10496, Avg. loss: 863457240100079140864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 1630918595.11, NNZs: 2, Bias: 102021958272.394806, T: 10624, Avg. loss: 860930778255589638144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 1635703681.62, NNZs: 2, Bias: 102020508805.199600, T: 10752, Avg. loss: 860154574727951155200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 1639345244.91, NNZs: 2, Bias: 102019078642.963364, T: 10880, Avg. loss: 859453726386266701824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 1634772323.54, NNZs: 2, Bias: 102017777479.178131, T: 11008, Avg. loss: 861688916941233717248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 86 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1324608087797.01, NNZs: 2, Bias: -80676844679.137543, T: 128, Avg. loss: 20334105321846390619054800896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2756227001254.31, NNZs: 2, Bias: 39323155320.862457, T: 256, Avg. loss: 20518492613997492283564359680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1686853456390.13, NNZs: 2, Bias: 79323155320.862457, T: 384, Avg. loss: 24406486197210032595772899328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1204253499137.87, NNZs: 2, Bias: 139323155320.862457, T: 512, Avg. loss: 22419735680321635217628463104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1143655039036.32, NNZs: 2, Bias: 183516832728.693665, T: 640, Avg. loss: 20710884385874860227430449152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2269519880222.56, NNZs: 2, Bias: 183516832728.693665, T: 768, Avg. loss: 21755853264617512787291144192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 336538987429.58, NNZs: 2, Bias: 186957833767.167267, T: 896, Avg. loss: 2316436816543515049184985088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 392615958852.99, NNZs: 2, Bias: 197334832501.792267, T: 1024, Avg. loss: 805631185071186888326381568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 27029420549.21, NNZs: 2, Bias: 189141543459.088776, T: 1152, Avg. loss: 869662746292725630655004672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 71658809955.95, NNZs: 2, Bias: 196725651569.780121, T: 1280, Avg. loss: 836796428333043730570280960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 47649859341.61, NNZs: 2, Bias: 183820130538.928711, T: 1408, Avg. loss: 833329367532045357513965568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 391938205062.77, NNZs: 2, Bias: 164829736601.835999, T: 1536, Avg. loss: 804899261376645455799123968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 359101641393.15, NNZs: 2, Bias: 176685623319.862640, T: 1664, Avg. loss: 791036484587985591617978368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 570265395581.74, NNZs: 2, Bias: 178452693326.140045, T: 1792, Avg. loss: 809329508643165798930579456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 167029468400.79, NNZs: 2, Bias: 177657957890.165192, T: 1920, Avg. loss: 819594233585984189509926912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 411865979309.91, NNZs: 2, Bias: 201534109239.750031, T: 2048, Avg. loss: 794664751019623229515890688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 261496108225.92, NNZs: 2, Bias: 204500606997.678375, T: 2176, Avg. loss: 1088517009423102967552147456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 34247559901.65, NNZs: 2, Bias: 188474886328.987762, T: 2304, Avg. loss: 832526621903480903419559936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 83846977878.94, NNZs: 2, Bias: 184943429744.047211, T: 2432, Avg. loss: 30447134508520300129288192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 22657049978.19, NNZs: 2, Bias: 185788790652.210815, T: 2560, Avg. loss: 32950681606834724265787392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 36777364551.73, NNZs: 2, Bias: 188291517710.659882, T: 2688, Avg. loss: 29175369738415513528172544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 42574259020.84, NNZs: 2, Bias: 186230449123.119385, T: 2816, Avg. loss: 29613605733984407748870144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 58707434381.31, NNZs: 2, Bias: 182458282669.358551, T: 2944, Avg. loss: 31059771914779247782133760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 21372320677.73, NNZs: 2, Bias: 181257064100.361938, T: 3072, Avg. loss: 31972055067082914931933184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 47753437763.19, NNZs: 2, Bias: 183474252448.252441, T: 3200, Avg. loss: 29238838223869882543374336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 31797360863.88, NNZs: 2, Bias: 182666669658.979523, T: 3328, Avg. loss: 32965531505923647462178816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2930818332.66, NNZs: 2, Bias: 183305315734.882599, T: 3456, Avg. loss: 601571250644747680743424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2851673744.27, NNZs: 2, Bias: 182934671975.076447, T: 3584, Avg. loss: 670935517366223105949696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 6722791702.36, NNZs: 2, Bias: 182676159473.596375, T: 3712, Avg. loss: 623680631023680331186176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8628002983.17, NNZs: 2, Bias: 182602453330.291321, T: 3840, Avg. loss: 802186241017611533942784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2666769743.79, NNZs: 2, Bias: 182451672765.443939, T: 3968, Avg. loss: 627364930903469637763072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2790926852.54, NNZs: 2, Bias: 181974295460.907806, T: 4096, Avg. loss: 514141134244057502973952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3466765533.00, NNZs: 2, Bias: 181640014765.276703, T: 4224, Avg. loss: 641723223002735777415168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 5355701041.82, NNZs: 2, Bias: 181283577324.618469, T: 4352, Avg. loss: 486768040981367701372928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7535176886.91, NNZs: 2, Bias: 181223794136.094666, T: 4480, Avg. loss: 621398250908138464083968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2111030900.49, NNZs: 2, Bias: 180879002529.771942, T: 4608, Avg. loss: 657401296791118450524160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2034055269.49, NNZs: 2, Bias: 180642062939.815369, T: 4736, Avg. loss: 694131184158767012904960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3946260679.13, NNZs: 2, Bias: 180820758008.233368, T: 4864, Avg. loss: 483483468132563688620032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 7637607144.05, NNZs: 2, Bias: 180499007656.750122, T: 4992, Avg. loss: 467804596166158157086720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 6523494613.54, NNZs: 2, Bias: 180408374682.844666, T: 5120, Avg. loss: 674677236248758538207232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 12154416577.65, NNZs: 2, Bias: 179904294376.024200, T: 5248, Avg. loss: 552292368962125951926272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 8585044260.88, NNZs: 2, Bias: 179979023652.568909, T: 5376, Avg. loss: 623899230336202290757632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 7600352228.71, NNZs: 2, Bias: 179896074812.711639, T: 5504, Avg. loss: 646765881357119338315776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 16766973922.93, NNZs: 2, Bias: 179466481820.084808, T: 5632, Avg. loss: 575209391446069243543552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6189894636.01, NNZs: 2, Bias: 179534183974.384552, T: 5760, Avg. loss: 54934112919917445513216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4784065638.32, NNZs: 2, Bias: 179503562444.179932, T: 5888, Avg. loss: 4229247051398463881216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3990999483.27, NNZs: 2, Bias: 179456801684.820526, T: 6016, Avg. loss: 3801778496791581818880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3531893109.16, NNZs: 2, Bias: 179414017448.164948, T: 6144, Avg. loss: 3026630831915870978048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3345055579.55, NNZs: 2, Bias: 179360528482.060547, T: 6272, Avg. loss: 3154896943136350666752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3382741094.42, NNZs: 2, Bias: 179302977059.830109, T: 6400, Avg. loss: 3083089549967495790592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3062360166.92, NNZs: 2, Bias: 179246842795.284332, T: 6528, Avg. loss: 3570863880799527632896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3094027689.06, NNZs: 2, Bias: 179190505611.452393, T: 6656, Avg. loss: 2972007549554617483264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3175592724.83, NNZs: 2, Bias: 179133204481.373291, T: 6784, Avg. loss: 3036345342681453428736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3102103965.57, NNZs: 2, Bias: 179082219749.514160, T: 6912, Avg. loss: 2769501354558089068544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3290862631.56, NNZs: 2, Bias: 179023302639.604065, T: 7040, Avg. loss: 3065647135960392531968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3114690744.53, NNZs: 2, Bias: 178969616329.481506, T: 7168, Avg. loss: 3149852241339534540800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3222813585.52, NNZs: 2, Bias: 178914631042.809845, T: 7296, Avg. loss: 2797812695472923475968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3342164262.59, NNZs: 2, Bias: 178859252665.784973, T: 7424, Avg. loss: 2874404868067710992384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3195124314.53, NNZs: 2, Bias: 178805591343.945984, T: 7552, Avg. loss: 3173739132335334883328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3238698840.67, NNZs: 2, Bias: 178793397331.741394, T: 7680, Avg. loss: 2572761592392569585664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3203322181.87, NNZs: 2, Bias: 178782801626.368347, T: 7808, Avg. loss: 2536989292855316447232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3220423974.53, NNZs: 2, Bias: 178771332255.482880, T: 7936, Avg. loss: 2516350504719008923648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3170599225.98, NNZs: 2, Bias: 178761035832.334045, T: 8064, Avg. loss: 2527079987020883296256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3182067516.90, NNZs: 2, Bias: 178749669192.444153, T: 8192, Avg. loss: 2515743761781664776192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3173855526.30, NNZs: 2, Bias: 178738551662.144531, T: 8320, Avg. loss: 2543820968472880349184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3153369402.97, NNZs: 2, Bias: 178727680336.145813, T: 8448, Avg. loss: 2535045348138437574656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3118123359.18, NNZs: 2, Bias: 178717086358.769684, T: 8576, Avg. loss: 2532816640908227772416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3153557378.95, NNZs: 2, Bias: 178705253796.385162, T: 8704, Avg. loss: 2525030153315349954560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3175358582.85, NNZs: 2, Bias: 178693723150.144745, T: 8832, Avg. loss: 2509387695643351318528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3137336171.95, NNZs: 2, Bias: 178683043118.575012, T: 8960, Avg. loss: 2565965266920200470528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 3130160328.49, NNZs: 2, Bias: 178671969804.231720, T: 9088, Avg. loss: 2521575124535968530432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 3125758509.69, NNZs: 2, Bias: 178661021827.475250, T: 9216, Avg. loss: 2487438696299273650176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 3132189520.24, NNZs: 2, Bias: 178649600427.182678, T: 9344, Avg. loss: 2548320705971390775296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 3123487826.04, NNZs: 2, Bias: 178638637234.801178, T: 9472, Avg. loss: 2503965254517929279488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 3128268829.54, NNZs: 2, Bias: 178627363345.378662, T: 9600, Avg. loss: 2521533461952017203200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 3123322199.57, NNZs: 2, Bias: 178616221537.607178, T: 9728, Avg. loss: 2533437316730742374400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 3143247056.30, NNZs: 2, Bias: 178604737903.760498, T: 9856, Avg. loss: 2505263630254177517568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 3139545940.98, NNZs: 2, Bias: 178602565218.915436, T: 9984, Avg. loss: 2455192673746465849344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 3130084393.83, NNZs: 2, Bias: 178600500125.589478, T: 10112, Avg. loss: 2448192676356799594496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 3137921287.22, NNZs: 2, Bias: 178598130141.633026, T: 10240, Avg. loss: 2448262512120949112832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 3131603806.95, NNZs: 2, Bias: 178596002767.054688, T: 10368, Avg. loss: 2455455380463142043648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 3139146629.04, NNZs: 2, Bias: 178593643341.679169, T: 10496, Avg. loss: 2442288169464813322240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 3137403358.73, NNZs: 2, Bias: 178591440642.626953, T: 10624, Avg. loss: 2449765750617496616960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 3124726079.36, NNZs: 2, Bias: 178589432187.322784, T: 10752, Avg. loss: 2447459582170882375680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 3128831075.19, NNZs: 2, Bias: 178587123332.177673, T: 10880, Avg. loss: 2453475192031781322752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 3127067915.87, NNZs: 2, Bias: 178584920642.586792, T: 11008, Avg. loss: 2449870149642169614336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 3131220889.07, NNZs: 2, Bias: 178582612606.254242, T: 11136, Avg. loss: 2451503166279979630592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 87 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2139991077371.80, NNZs: 2, Bias: 49854606098.549088, T: 128, Avg. loss: 21306519499278240904583839744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1561390023220.03, NNZs: 2, Bias: -13688572060.146881, T: 256, Avg. loss: 23484749734142415602830016512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1148909035787.38, NNZs: 2, Bias: 26311427939.853119, T: 384, Avg. loss: 23746302884356248662297280512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1302758740232.81, NNZs: 2, Bias: 35597688881.666168, T: 512, Avg. loss: 23347492766708699665193238528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 677400802986.64, NNZs: 2, Bias: 15597688881.666168, T: 640, Avg. loss: 22646150057202696270274101248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2059156165215.93, NNZs: 2, Bias: 115597688881.666168, T: 768, Avg. loss: 21661274620540406179399991296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 232109713794.48, NNZs: 2, Bias: 138788417431.846436, T: 896, Avg. loss: 1659339651046016679776616448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 281098315265.25, NNZs: 2, Bias: 136322695965.914795, T: 1024, Avg. loss: 1009810717815900206383759360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 280555362430.46, NNZs: 2, Bias: 113165281802.276749, T: 1152, Avg. loss: 901057953987917037204144128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 223088697994.35, NNZs: 2, Bias: 113563051374.649139, T: 1280, Avg. loss: 986942630940571083485478912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 291886172508.14, NNZs: 2, Bias: 112994904202.673431, T: 1408, Avg. loss: 902329546839219449551126528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 245507327922.96, NNZs: 2, Bias: 89077946215.980515, T: 1536, Avg. loss: 930342310871020299656101888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 248972563482.07, NNZs: 2, Bias: 95841301693.435944, T: 1664, Avg. loss: 891486105132912523295588352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 158136921436.52, NNZs: 2, Bias: 102456595854.657166, T: 1792, Avg. loss: 912748083126204335575269376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 289103248433.66, NNZs: 2, Bias: 100589542729.330444, T: 1920, Avg. loss: 864154254413325080878645248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 245568482129.70, NNZs: 2, Bias: 101992081144.460388, T: 2048, Avg. loss: 948260727754096069893423104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 276118115254.05, NNZs: 2, Bias: 95672047029.295776, T: 2176, Avg. loss: 912102764491285658897219584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 646210602801.10, NNZs: 2, Bias: 78208728142.098846, T: 2304, Avg. loss: 913242943276099270055297024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 430612586756.19, NNZs: 2, Bias: 75117703820.722275, T: 2432, Avg. loss: 877731446358221228167135232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 375521747430.15, NNZs: 2, Bias: 82476450239.184326, T: 2560, Avg. loss: 932469734860433162573447168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 38234291733.30, NNZs: 2, Bias: 73557578820.529221, T: 2688, Avg. loss: 54326859331911215178842112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 17940807604.51, NNZs: 2, Bias: 75167438669.673813, T: 2816, Avg. loss: 33038747064593463830904832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 32323311831.45, NNZs: 2, Bias: 74250388066.000473, T: 2944, Avg. loss: 32524948133450201543213056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 28600378850.90, NNZs: 2, Bias: 74260919205.061691, T: 3072, Avg. loss: 31579023553500028721954816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 55756754782.51, NNZs: 2, Bias: 76521774805.142258, T: 3200, Avg. loss: 33688371354565975767777280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 44222890150.82, NNZs: 2, Bias: 77519012324.833420, T: 3328, Avg. loss: 31567077915061182380638208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 65083122468.05, NNZs: 2, Bias: 77724951155.119553, T: 3456, Avg. loss: 34968170874181308200779776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 35641784169.10, NNZs: 2, Bias: 79041492168.947159, T: 3584, Avg. loss: 36255190040827191900504064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 75764751878.33, NNZs: 2, Bias: 73711810636.594009, T: 3712, Avg. loss: 35931222617590167463002112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 41448897635.77, NNZs: 2, Bias: 72999041116.657486, T: 3840, Avg. loss: 36028424944722560214368256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 56134825827.64, NNZs: 2, Bias: 69984047909.784851, T: 3968, Avg. loss: 35598672180203296659603456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6592730995.85, NNZs: 2, Bias: 70016200157.713821, T: 4096, Avg. loss: 1408572863242102531686400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2480584022.84, NNZs: 2, Bias: 69972044836.118347, T: 4224, Avg. loss: 598551654509098494328832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 13048080337.43, NNZs: 2, Bias: 70179179874.372757, T: 4352, Avg. loss: 695396318696341946499072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 8250342887.05, NNZs: 2, Bias: 70410199784.241638, T: 4480, Avg. loss: 598503645501341342629888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1170479339.33, NNZs: 2, Bias: 70262832878.675430, T: 4608, Avg. loss: 558946363353852863840256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 7947365480.14, NNZs: 2, Bias: 70481267599.903442, T: 4736, Avg. loss: 644040635953371162869760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 10611890685.90, NNZs: 2, Bias: 70241100681.809937, T: 4864, Avg. loss: 596193695022482043437056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2532692800.13, NNZs: 2, Bias: 69811124695.412689, T: 4992, Avg. loss: 737325349055889483497472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1890184090.15, NNZs: 2, Bias: 69564688540.492874, T: 5120, Avg. loss: 603312041507981677821952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 10382352265.49, NNZs: 2, Bias: 69516545552.358093, T: 5248, Avg. loss: 619573870795780628938752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4719406551.34, NNZs: 2, Bias: 69434930611.199249, T: 5376, Avg. loss: 17698051126351026454528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1955987109.18, NNZs: 2, Bias: 69370701916.303497, T: 5504, Avg. loss: 4156722683280942956544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 521121450.43, NNZs: 2, Bias: 69325165597.808243, T: 5632, Avg. loss: 1438491743900677701632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 582825212.54, NNZs: 2, Bias: 69290602120.576202, T: 5760, Avg. loss: 673365378181104795648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 776708351.59, NNZs: 2, Bias: 69262013867.086685, T: 5888, Avg. loss: 546736546864301539328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1006970607.00, NNZs: 2, Bias: 69235170489.092758, T: 6016, Avg. loss: 493123570379382849536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 978900545.86, NNZs: 2, Bias: 69212235602.515076, T: 6144, Avg. loss: 505045889249155874816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1105242005.40, NNZs: 2, Bias: 69187945621.810715, T: 6272, Avg. loss: 471384903677113794560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1097519145.04, NNZs: 2, Bias: 69165352832.736740, T: 6400, Avg. loss: 499368817799937654784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1139035621.68, NNZs: 2, Bias: 69141137399.879440, T: 6528, Avg. loss: 505326239132447014912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1089280636.58, NNZs: 2, Bias: 69119358814.608978, T: 6656, Avg. loss: 466499543471071559680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1087970427.16, NNZs: 2, Bias: 69095741862.161819, T: 6784, Avg. loss: 518896110526464524288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1078730298.86, NNZs: 2, Bias: 69072004281.810852, T: 6912, Avg. loss: 516279148573567746048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1088886866.94, NNZs: 2, Bias: 69048821713.447861, T: 7040, Avg. loss: 508313639858641633280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1015979396.43, NNZs: 2, Bias: 69025816538.571716, T: 7168, Avg. loss: 530509763541509079040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1102819093.95, NNZs: 2, Bias: 69000656589.224045, T: 7296, Avg. loss: 513862211791130722304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1047124033.25, NNZs: 2, Bias: 68996689004.359314, T: 7424, Avg. loss: 423456995603702743040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1060126301.99, NNZs: 2, Bias: 68991860852.962967, T: 7552, Avg. loss: 402841210636501975040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1061045671.06, NNZs: 2, Bias: 68987250244.163864, T: 7680, Avg. loss: 400043746206358437888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1066867331.52, NNZs: 2, Bias: 68982483571.436127, T: 7808, Avg. loss: 407689043437404815360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1076628790.15, NNZs: 2, Bias: 68977713639.782211, T: 7936, Avg. loss: 401723948592298393600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1071039158.77, NNZs: 2, Bias: 68973155064.589813, T: 8064, Avg. loss: 405030344099102654464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1080822266.05, NNZs: 2, Bias: 68968383654.087906, T: 8192, Avg. loss: 401957953241174507520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1085649436.15, NNZs: 2, Bias: 68963609177.730621, T: 8320, Avg. loss: 409019103737322274816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1080376230.26, NNZs: 2, Bias: 68962765936.401489, T: 8448, Avg. loss: 392413227744336674816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1079814414.09, NNZs: 2, Bias: 68961847366.258087, T: 8576, Avg. loss: 392856329795724378112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1079048832.56, NNZs: 2, Bias: 68960932116.988937, T: 8704, Avg. loss: 392818460821178351616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1082320901.43, NNZs: 2, Bias: 68959955016.920624, T: 8832, Avg. loss: 392125769709512556544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1082267236.29, NNZs: 2, Bias: 68959029245.109116, T: 8960, Avg. loss: 392526844113669652480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1084642740.66, NNZs: 2, Bias: 68958066790.932983, T: 9088, Avg. loss: 391835020638737661952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1080843302.63, NNZs: 2, Bias: 68957197005.712494, T: 9216, Avg. loss: 393805845241864912896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1077876773.90, NNZs: 2, Bias: 68956320690.444763, T: 9344, Avg. loss: 390930010995057491968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1079105521.14, NNZs: 2, Bias: 68955374373.708160, T: 9472, Avg. loss: 392699370728909176832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1084381694.20, NNZs: 2, Bias: 68954368294.019775, T: 9600, Avg. loss: 390940637448758099968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1079194728.80, NNZs: 2, Bias: 68953524190.005051, T: 9728, Avg. loss: 392148629211780546560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1083016127.33, NNZs: 2, Bias: 68952538628.054153, T: 9856, Avg. loss: 391967798092590874624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1082408918.15, NNZs: 2, Bias: 68951620594.150513, T: 9984, Avg. loss: 392894307132257533952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 78 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 823929026433.19, NNZs: 2, Bias: -9008967394.277451, T: 128, Avg. loss: 21547313947536361290716938240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1271672680407.32, NNZs: 2, Bias: -9008967394.277451, T: 256, Avg. loss: 24862463689162837409988083712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1933530290531.92, NNZs: 2, Bias: -22437461340.695499, T: 384, Avg. loss: 22638359981929232053745745920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 887043893413.81, NNZs: 2, Bias: -62437461340.695496, T: 512, Avg. loss: 22638868257646936470964928512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1784673506395.55, NNZs: 2, Bias: -102437461340.695496, T: 640, Avg. loss: 23596269848427504719114534912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2042130235508.01, NNZs: 2, Bias: -128479408115.668976, T: 768, Avg. loss: 25220904194535210340157751296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 90101752506.24, NNZs: 2, Bias: -135259152923.283417, T: 896, Avg. loss: 1889067016754918959595126784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 388514055082.99, NNZs: 2, Bias: -125088163045.763199, T: 1024, Avg. loss: 1016030700833238066042765312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 218269181805.50, NNZs: 2, Bias: -147861565119.937042, T: 1152, Avg. loss: 881507192223413596562915328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 478695731867.14, NNZs: 2, Bias: -147360957482.724396, T: 1280, Avg. loss: 923225764141062309416009728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 171696515951.08, NNZs: 2, Bias: -124378191602.579437, T: 1408, Avg. loss: 983054809969308636968648704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 74910841210.48, NNZs: 2, Bias: -126844804615.121704, T: 1536, Avg. loss: 944538648723499441916477440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11968770225.76, NNZs: 2, Bias: -127268999967.288681, T: 1664, Avg. loss: 1013983147086856328860139520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 370218785249.67, NNZs: 2, Bias: -137422125658.718292, T: 1792, Avg. loss: 922466128938445299884490752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 49649953016.65, NNZs: 2, Bias: -138199659235.014069, T: 1920, Avg. loss: 77474553619101976948113408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 30527500138.84, NNZs: 2, Bias: -138435294266.172974, T: 2048, Avg. loss: 35510196575680564274659328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 106617170560.37, NNZs: 2, Bias: -139066540385.513885, T: 2176, Avg. loss: 35881943654363849428041728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 56014360869.27, NNZs: 2, Bias: -136634959236.689301, T: 2304, Avg. loss: 35584759646829701943525376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 30497704272.38, NNZs: 2, Bias: -136945361070.668060, T: 2432, Avg. loss: 33042336498584130506719232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 18884464115.80, NNZs: 2, Bias: -135461977879.448990, T: 2560, Avg. loss: 33359060614059728450879488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 47774678073.93, NNZs: 2, Bias: -133124261626.274338, T: 2688, Avg. loss: 34132662461849086000627712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4578555782.76, NNZs: 2, Bias: -132919048231.370758, T: 2816, Avg. loss: 30772093060797645650395136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 36676776888.50, NNZs: 2, Bias: -132743145076.550446, T: 2944, Avg. loss: 37207230643543817840492544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 91597597003.50, NNZs: 2, Bias: -130921508119.858047, T: 3072, Avg. loss: 32332105719447985338712064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 45063681004.58, NNZs: 2, Bias: -130853189634.195374, T: 3200, Avg. loss: 39585218477238676371800064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 58394448214.06, NNZs: 2, Bias: -130430880652.386002, T: 3328, Avg. loss: 34124270658958811566440448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 42443201927.17, NNZs: 2, Bias: -134081109217.697235, T: 3456, Avg. loss: 36105111952376504178966528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 6935473964.57, NNZs: 2, Bias: -133572105784.456940, T: 3584, Avg. loss: 983616491608066811232256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 18242263239.63, NNZs: 2, Bias: -133490877865.387314, T: 3712, Avg. loss: 792931902613878416080896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4170065312.39, NNZs: 2, Bias: -133064966597.985458, T: 3840, Avg. loss: 922991954752331501797376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 645041175.96, NNZs: 2, Bias: -132614809406.052002, T: 3968, Avg. loss: 604621487243301228642304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2974997106.62, NNZs: 2, Bias: -132168360852.790466, T: 4096, Avg. loss: 730797204094805417656320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7788860048.50, NNZs: 2, Bias: -131993276854.856415, T: 4224, Avg. loss: 595918235315108384342016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3280921059.03, NNZs: 2, Bias: -132190217444.288742, T: 4352, Avg. loss: 680846031943658916282368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 8931318977.14, NNZs: 2, Bias: -132045802450.139526, T: 4480, Avg. loss: 840125467498860469288960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4618674989.38, NNZs: 2, Bias: -131458485515.415970, T: 4608, Avg. loss: 617359925921640689434624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5984831474.51, NNZs: 2, Bias: -131388693849.852234, T: 4736, Avg. loss: 584426680161587328712704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 10961887541.57, NNZs: 2, Bias: -131261436296.722015, T: 4864, Avg. loss: 790464661852439548264448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 14982961780.56, NNZs: 2, Bias: -131462591477.937119, T: 4992, Avg. loss: 763373612660300250611712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4751999956.88, NNZs: 2, Bias: -131317641877.563232, T: 5120, Avg. loss: 923895355047251338592256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 14932721913.44, NNZs: 2, Bias: -131251433051.891724, T: 5248, Avg. loss: 648589819979836707307520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 7783514896.64, NNZs: 2, Bias: -131224232857.053238, T: 5376, Avg. loss: 734380770420180874428416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3497510993.18, NNZs: 2, Bias: -131140305971.986359, T: 5504, Avg. loss: 10436534073233512595456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1210248964.14, NNZs: 2, Bias: -131066548335.421616, T: 5632, Avg. loss: 4473171577321132392448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 697587149.88, NNZs: 2, Bias: -131011703060.752823, T: 5760, Avg. loss: 2250731911407557410816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1328023533.35, NNZs: 2, Bias: -130964985732.385696, T: 5888, Avg. loss: 1558908164084907638784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1602739711.45, NNZs: 2, Bias: -130922803846.130249, T: 6016, Avg. loss: 1518601423117760069632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1741872297.08, NNZs: 2, Bias: -130883655351.050018, T: 6144, Avg. loss: 1472912312705462304768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1803545299.26, NNZs: 2, Bias: -130843624426.514328, T: 6272, Avg. loss: 1554173510755899932672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1931839474.00, NNZs: 2, Bias: -130803107919.431046, T: 6400, Avg. loss: 1553680958322889981952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1825032701.64, NNZs: 2, Bias: -130768221903.253693, T: 6528, Avg. loss: 1429657514111929679872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1949980595.60, NNZs: 2, Bias: -130727262042.135101, T: 6656, Avg. loss: 1563235389271931092992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1950908651.68, NNZs: 2, Bias: -130688219461.540604, T: 6784, Avg. loss: 1525536560224899170304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1908958312.94, NNZs: 2, Bias: -130649027628.743240, T: 6912, Avg. loss: 1631058484731766898688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2074790378.42, NNZs: 2, Bias: -130609487049.042389, T: 7040, Avg. loss: 1477038761381217173504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1997063665.40, NNZs: 2, Bias: -130570976058.671814, T: 7168, Avg. loss: 1562670880420959617024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2018880482.55, NNZs: 2, Bias: -130562922555.842407, T: 7296, Avg. loss: 1269037373019641085952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2000204102.67, NNZs: 2, Bias: -130555744334.376114, T: 7424, Avg. loss: 1226618993566891638784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1994830590.00, NNZs: 2, Bias: -130548200252.304047, T: 7552, Avg. loss: 1254136970668979781632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1979428505.21, NNZs: 2, Bias: -130540780522.646149, T: 7680, Avg. loss: 1257596257914242727936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1971441506.98, NNZs: 2, Bias: -130533232089.817093, T: 7808, Avg. loss: 1261321553869974798336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1964345589.24, NNZs: 2, Bias: -130525782889.693329, T: 7936, Avg. loss: 1239895747822207893504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1952824694.53, NNZs: 2, Bias: -130518371559.356522, T: 8064, Avg. loss: 1244867260956725739520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1961884572.87, NNZs: 2, Bias: -130516711666.577011, T: 8192, Avg. loss: 1219166886442340974592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1961331532.82, NNZs: 2, Bias: -130515200064.317429, T: 8320, Avg. loss: 1216208413855780962304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1964467014.96, NNZs: 2, Bias: -130513634117.571274, T: 8448, Avg. loss: 1215288551598074888192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1956828458.66, NNZs: 2, Bias: -130512230221.253647, T: 8576, Avg. loss: 1215531527433872736256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1959125795.93, NNZs: 2, Bias: -130510677110.002304, T: 8704, Avg. loss: 1215150585536027295744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1959779062.53, NNZs: 2, Bias: -130509151650.993103, T: 8832, Avg. loss: 1212842075954432180224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1951920084.25, NNZs: 2, Bias: -130507753602.216095, T: 8960, Avg. loss: 1213291796324820189184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1952490632.12, NNZs: 2, Bias: -130506224136.218460, T: 9088, Avg. loss: 1217040288557971800064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1956764149.57, NNZs: 2, Bias: -130504641017.259033, T: 9216, Avg. loss: 1215358605394629099520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1957724546.55, NNZs: 2, Bias: -130503109796.390152, T: 9344, Avg. loss: 1213578315682444476416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1954494735.36, NNZs: 2, Bias: -130501638907.124863, T: 9472, Avg. loss: 1215755447590592708608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 74 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1422595008476.19, NNZs: 2, Bias: -19250248899.419937, T: 128, Avg. loss: 19755022063192745975903944704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 648694683207.43, NNZs: 2, Bias: -99250248899.419937, T: 256, Avg. loss: 19654946382347068700929032192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2257679640854.36, NNZs: 2, Bias: -51459335058.960739, T: 384, Avg. loss: 21586652752504384877689307136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 999807862522.58, NNZs: 2, Bias: -31459335058.960739, T: 512, Avg. loss: 23308912141328295227622948864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 661328561788.31, NNZs: 2, Bias: -17046256237.501572, T: 640, Avg. loss: 23260379703820162996520353792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 338090940293.14, NNZs: 2, Bias: -71858210799.739746, T: 768, Avg. loss: 21439819934228007950781251584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1152187689373.68, NNZs: 2, Bias: 23127583862.413456, T: 896, Avg. loss: 21632079847963563495985774592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 194457864034.37, NNZs: 2, Bias: -777525299.349174, T: 1024, Avg. loss: 1272899890159096408915836928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 176712791036.83, NNZs: 2, Bias: -3965619320.019902, T: 1152, Avg. loss: 768378236934655887867379712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 351735941724.83, NNZs: 2, Bias: -13470273743.628054, T: 1280, Avg. loss: 765298169337051540990459904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 207335560904.13, NNZs: 2, Bias: -9488849123.054760, T: 1408, Avg. loss: 907237487407832244739375104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 206107799821.46, NNZs: 2, Bias: -1434742791.701666, T: 1536, Avg. loss: 813604772026745593098403840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 346742047212.35, NNZs: 2, Bias: 28709377050.905270, T: 1664, Avg. loss: 873366705525296910162722816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 347739166080.83, NNZs: 2, Bias: 30406277216.489674, T: 1792, Avg. loss: 899448611448007787412455424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62636178360.25, NNZs: 2, Bias: 18219542012.138821, T: 1920, Avg. loss: 743096036556246070820077568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 141378031452.84, NNZs: 2, Bias: 12616161486.980598, T: 2048, Avg. loss: 819622576429215436677054464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 131736402261.89, NNZs: 2, Bias: 21309350112.249626, T: 2176, Avg. loss: 767069090930791348489420800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 298377158890.49, NNZs: 2, Bias: 14783112618.121872, T: 2304, Avg. loss: 745785562265237463429545984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 18962045633.22, NNZs: 2, Bias: -6326502287.710938, T: 2432, Avg. loss: 853255883178747826177835008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 438228053201.28, NNZs: 2, Bias: 6631394253.966003, T: 2560, Avg. loss: 922254321785047395403300864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 22259053137.28, NNZs: 2, Bias: 7661528016.349026, T: 2688, Avg. loss: 113256327724425461555527680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 9995835248.41, NNZs: 2, Bias: 8384976699.699461, T: 2816, Avg. loss: 31234184949267558729515008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 70161326026.56, NNZs: 2, Bias: 6635828940.942833, T: 2944, Avg. loss: 32096899579323595232378880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 111451226254.32, NNZs: 2, Bias: 8958270123.061020, T: 3072, Avg. loss: 29928517940803861802385408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 36301934681.04, NNZs: 2, Bias: 12361340329.908285, T: 3200, Avg. loss: 38547136666373738668752896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 6360449888.98, NNZs: 2, Bias: 11518798932.967226, T: 3328, Avg. loss: 32088899169506813619994624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 55815018314.41, NNZs: 2, Bias: 15027874259.430283, T: 3456, Avg. loss: 29584757706034546567282688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 44312394364.62, NNZs: 2, Bias: 15962766430.178768, T: 3584, Avg. loss: 33272536358165351107657728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 109721811326.57, NNZs: 2, Bias: 17777337077.973164, T: 3712, Avg. loss: 29345294986085452065275904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 60699365161.67, NNZs: 2, Bias: 22214328589.393341, T: 3840, Avg. loss: 32299150797601204296744960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 76599818373.52, NNZs: 2, Bias: 23188665231.844574, T: 3968, Avg. loss: 31785396314419746318581760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 41389026711.82, NNZs: 2, Bias: 22923084286.047199, T: 4096, Avg. loss: 33423646416305175608164352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 48414102323.00, NNZs: 2, Bias: 25953513166.140247, T: 4224, Avg. loss: 31436191040269439234736128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 73894239074.95, NNZs: 2, Bias: 24240148407.323490, T: 4352, Avg. loss: 31569434362842354339020800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 14399410132.77, NNZs: 2, Bias: 24863811442.750576, T: 4480, Avg. loss: 2161766894634937111019520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3152222527.66, NNZs: 2, Bias: 24821146951.185966, T: 4608, Avg. loss: 543103833212590202290176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1364329227.83, NNZs: 2, Bias: 25273095746.498932, T: 4736, Avg. loss: 485272767482094071840768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1250432889.81, NNZs: 2, Bias: 25280225982.242874, T: 4864, Avg. loss: 654588987313471279333376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2885803344.52, NNZs: 2, Bias: 25173548828.540695, T: 4992, Avg. loss: 502661222711727434498048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1994486022.00, NNZs: 2, Bias: 25314662761.979313, T: 5120, Avg. loss: 474686288402751674122240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 634093398.38, NNZs: 2, Bias: 24925684132.696564, T: 5248, Avg. loss: 529846113003949076250624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 7214934414.95, NNZs: 2, Bias: 24742352034.092667, T: 5376, Avg. loss: 421970936552244683735040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1719751772.34, NNZs: 2, Bias: 24965846454.085697, T: 5504, Avg. loss: 509568955405125768183808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2963149361.27, NNZs: 2, Bias: 24777837549.157967, T: 5632, Avg. loss: 552447197092308488028160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 5841257268.35, NNZs: 2, Bias: 24723910335.363705, T: 5760, Avg. loss: 599525380545533943218176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3428705198.84, NNZs: 2, Bias: 24898958921.929531, T: 5888, Avg. loss: 704804555511118147092480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 6744999941.47, NNZs: 2, Bias: 24879313392.998024, T: 6016, Avg. loss: 600056349844042149789696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1246337959.12, NNZs: 2, Bias: 24852984414.314892, T: 6144, Avg. loss: 10403837053548617531392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 801406071.75, NNZs: 2, Bias: 24850947869.309742, T: 6272, Avg. loss: 182546009842788401152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 558846876.23, NNZs: 2, Bias: 24845969631.039894, T: 6400, Avg. loss: 98122329632521043968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 487768113.33, NNZs: 2, Bias: 24838384392.425903, T: 6528, Avg. loss: 69471238223354945536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 451370550.40, NNZs: 2, Bias: 24830631150.283268, T: 6656, Avg. loss: 63772467862000033792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 429062559.80, NNZs: 2, Bias: 24822398148.528362, T: 6784, Avg. loss: 66325072302900568064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 433242070.12, NNZs: 2, Bias: 24813576748.405331, T: 6912, Avg. loss: 69605283482623033344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 414742260.77, NNZs: 2, Bias: 24805310626.517933, T: 7040, Avg. loss: 66334549517266649088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 406905875.98, NNZs: 2, Bias: 24796224122.658394, T: 7168, Avg. loss: 69172320353984184320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 411505647.27, NNZs: 2, Bias: 24786996922.015106, T: 7296, Avg. loss: 69640021080470298624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 398305114.34, NNZs: 2, Bias: 24785464003.494457, T: 7424, Avg. loss: 54634023353486286848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 403533954.60, NNZs: 2, Bias: 24783659220.427322, T: 7552, Avg. loss: 53635443127922163712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 398960108.64, NNZs: 2, Bias: 24782012480.641804, T: 7680, Avg. loss: 53637919155190472704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 404479576.75, NNZs: 2, Bias: 24780167212.032402, T: 7808, Avg. loss: 54684707871355412480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 396970849.82, NNZs: 2, Bias: 24778523695.208721, T: 7936, Avg. loss: 55134391621857746944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 401288258.10, NNZs: 2, Bias: 24776745768.620228, T: 8064, Avg. loss: 53025605815266664448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 401501083.73, NNZs: 2, Bias: 24775005874.552387, T: 8192, Avg. loss: 54178091752699420672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 401099281.50, NNZs: 2, Bias: 24773294891.077663, T: 8320, Avg. loss: 53522938826888560640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 399807439.40, NNZs: 2, Bias: 24771553659.073326, T: 8448, Avg. loss: 54974183262324056064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 398041650.46, NNZs: 2, Bias: 24769826747.607376, T: 8576, Avg. loss: 54662033717501763584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 400049001.00, NNZs: 2, Bias: 24768041432.617092, T: 8704, Avg. loss: 54650091940185366528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 398055057.60, NNZs: 2, Bias: 24767723479.511768, T: 8832, Avg. loss: 53177209083060232192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 396430365.18, NNZs: 2, Bias: 24767401669.489410, T: 8960, Avg. loss: 52833872764503293952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 396492147.26, NNZs: 2, Bias: 24767051915.488972, T: 9088, Avg. loss: 52951175614383374336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 395041193.96, NNZs: 2, Bias: 24766729093.845772, T: 9216, Avg. loss: 52545564871918100480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 395398208.18, NNZs: 2, Bias: 24766375085.920979, T: 9344, Avg. loss: 52880550768413278208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 395156545.83, NNZs: 2, Bias: 24766031860.025711, T: 9472, Avg. loss: 52698083991029702656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 396451181.39, NNZs: 2, Bias: 24765661541.474636, T: 9600, Avg. loss: 53074193457018109952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 397135065.69, NNZs: 2, Bias: 24765301843.129398, T: 9728, Avg. loss: 52940898260698112000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 397192623.01, NNZs: 2, Bias: 24764952445.805157, T: 9856, Avg. loss: 52907282600128995328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 77 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 321942323383.22, NNZs: 2, Bias: 70913811310.533112, T: 128, Avg. loss: 17892543880812523377622253568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 747326066700.46, NNZs: 2, Bias: 90913811310.533112, T: 256, Avg. loss: 20105535535665010813603676160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 536634207792.11, NNZs: 2, Bias: 124465311043.638245, T: 384, Avg. loss: 17355990124111783182450294784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1619703019769.06, NNZs: 2, Bias: 87868372858.998688, T: 512, Avg. loss: 21077708370223421466769096704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 475530028639.64, NNZs: 2, Bias: 75777840028.639694, T: 640, Avg. loss: 21364946742203430783265275904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2264019917409.31, NNZs: 2, Bias: 95777840028.639694, T: 768, Avg. loss: 19605253390430970793590521856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1401628235148.16, NNZs: 2, Bias: 95777840028.639694, T: 896, Avg. loss: 19760352473531240048482058240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 613795988304.58, NNZs: 2, Bias: 75777840028.639694, T: 1024, Avg. loss: 18534458222321913083373551616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 221221836904.16, NNZs: 2, Bias: 66245376437.307724, T: 1152, Avg. loss: 842943304667464953004818432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 254588324796.40, NNZs: 2, Bias: 58423173394.754768, T: 1280, Avg. loss: 775522969370565109891465216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 72283239046.84, NNZs: 2, Bias: 51000930499.432541, T: 1408, Avg. loss: 783396149745735840617725952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 370652985665.73, NNZs: 2, Bias: 36792467902.753670, T: 1536, Avg. loss: 776783075596703972590616576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 137997197821.12, NNZs: 2, Bias: 33509042977.991028, T: 1664, Avg. loss: 891629309354711434483728384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 242092285351.31, NNZs: 2, Bias: 19091713903.815273, T: 1792, Avg. loss: 807446315735739582904270848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 500109805763.39, NNZs: 2, Bias: 11421631993.442703, T: 1920, Avg. loss: 750929184991050187818401792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 382623371135.42, NNZs: 2, Bias: 12290681901.455654, T: 2048, Avg. loss: 834077418318570842090373120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 114882729066.63, NNZs: 2, Bias: 31470387193.973682, T: 2176, Avg. loss: 840460830574598054955974656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 219473738307.03, NNZs: 2, Bias: 21537301714.766502, T: 2304, Avg. loss: 839867931613724964997300224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 246983588991.66, NNZs: 2, Bias: 7889302035.656979, T: 2432, Avg. loss: 791875738449653299115196416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 275013473248.47, NNZs: 2, Bias: 3889302035.656979, T: 2560, Avg. loss: 701743827282219377230872576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 113288042464.21, NNZs: 2, Bias: -8464269655.986181, T: 2688, Avg. loss: 750042900187351985239883776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 496698705665.06, NNZs: 2, Bias: -5472773282.408481, T: 2816, Avg. loss: 789618180878047865424838656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 266367943375.29, NNZs: 2, Bias: -8575493332.391468, T: 2944, Avg. loss: 861455001116432814647017472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 287494631402.95, NNZs: 2, Bias: -13002630356.355413, T: 3072, Avg. loss: 735954903292978529858224128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 249299358815.87, NNZs: 2, Bias: -19435988507.150879, T: 3200, Avg. loss: 789061211867365302993944576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 82846085415.08, NNZs: 2, Bias: -19873545301.066891, T: 3328, Avg. loss: 42498050958665398653812736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 37987294199.21, NNZs: 2, Bias: -20912319365.398319, T: 3456, Avg. loss: 30746571395099504886677504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 57911107789.08, NNZs: 2, Bias: -18309005728.726410, T: 3584, Avg. loss: 29023253632309493376221184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 43904252628.51, NNZs: 2, Bias: -16831020261.838287, T: 3712, Avg. loss: 32236165550605795449634816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 37119479415.29, NNZs: 2, Bias: -16885257966.660294, T: 3840, Avg. loss: 29795257964554166229532672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 65919159707.03, NNZs: 2, Bias: -20613885104.586056, T: 3968, Avg. loss: 26937451101626261645033472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 54558359664.37, NNZs: 2, Bias: -18879059475.939350, T: 4096, Avg. loss: 31870153858823678647599104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 40946496133.73, NNZs: 2, Bias: -20599992861.947628, T: 4224, Avg. loss: 30936141157858460500492288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 78496530622.48, NNZs: 2, Bias: -19629545657.967278, T: 4352, Avg. loss: 30732678463761502980538368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 22234731350.50, NNZs: 2, Bias: -18954855020.713619, T: 4480, Avg. loss: 34209918225146367289851904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 58420729800.18, NNZs: 2, Bias: -17468134838.384731, T: 4608, Avg. loss: 30893888431475613954473984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8651936156.89, NNZs: 2, Bias: -17944115124.224716, T: 4736, Avg. loss: 1239909035963585885372416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1907620096.51, NNZs: 2, Bias: -17746362300.801807, T: 4864, Avg. loss: 338925171855367497318400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1768744315.49, NNZs: 2, Bias: -17685887001.624371, T: 4992, Avg. loss: 551192303225313911898112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3978299155.48, NNZs: 2, Bias: -17767805522.712551, T: 5120, Avg. loss: 381468563192760019976192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1853865411.88, NNZs: 2, Bias: -17856606193.595028, T: 5248, Avg. loss: 501344915974227448823808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4110005162.07, NNZs: 2, Bias: -17687746748.282593, T: 5376, Avg. loss: 604464657814283920343040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2276013697.65, NNZs: 2, Bias: -17685498896.682724, T: 5504, Avg. loss: 373302266620447530418176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1273122845.85, NNZs: 2, Bias: -17694123135.057262, T: 5632, Avg. loss: 527222441777804869632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 809961041.42, NNZs: 2, Bias: -17695426702.811497, T: 5760, Avg. loss: 145568722617340739584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 527733456.76, NNZs: 2, Bias: -17694093189.547306, T: 5888, Avg. loss: 73158384660113424384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 403006046.13, NNZs: 2, Bias: -17689954129.424774, T: 6016, Avg. loss: 44258177258060382208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 336701438.10, NNZs: 2, Bias: -17684948387.425690, T: 6144, Avg. loss: 35574124915484434432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 301502744.72, NNZs: 2, Bias: -17679316938.656315, T: 6272, Avg. loss: 34543622710112755712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 293813315.16, NNZs: 2, Bias: -17673349722.573570, T: 6400, Avg. loss: 34736235787368787968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 296693652.62, NNZs: 2, Bias: -17667456685.195549, T: 6528, Avg. loss: 31325002899011239936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 281372342.47, NNZs: 2, Bias: -17661316328.498787, T: 6656, Avg. loss: 34964069235645255680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 281568631.87, NNZs: 2, Bias: -17655144280.764030, T: 6784, Avg. loss: 33612920377894207488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 299709731.24, NNZs: 2, Bias: -17649273474.815987, T: 6912, Avg. loss: 31194261426984660992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 284900098.18, NNZs: 2, Bias: -17643484772.964645, T: 7040, Avg. loss: 33066108239271403520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 273128822.46, NNZs: 2, Bias: -17637739612.874443, T: 7168, Avg. loss: 32394616931054907392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 285459681.53, NNZs: 2, Bias: -17631719478.422958, T: 7296, Avg. loss: 30982998280475103232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 276647962.41, NNZs: 2, Bias: -17625939623.178822, T: 7424, Avg. loss: 32046804814348521472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 278398045.72, NNZs: 2, Bias: -17619854659.162239, T: 7552, Avg. loss: 32704530488884162560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 270064308.76, NNZs: 2, Bias: -17613932697.423607, T: 7680, Avg. loss: 33108093640829419520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 290392435.36, NNZs: 2, Bias: -17607716081.193970, T: 7808, Avg. loss: 32336194100006379520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 279915325.41, NNZs: 2, Bias: -17601999170.473679, T: 7936, Avg. loss: 31878253270928805888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 281974954.96, NNZs: 2, Bias: -17600778591.766380, T: 8064, Avg. loss: 26365289520418930688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 280959842.86, NNZs: 2, Bias: -17599606386.257427, T: 8192, Avg. loss: 26404795484482629632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 283701320.02, NNZs: 2, Bias: -17598364032.496635, T: 8320, Avg. loss: 26593426636218556416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 279842640.77, NNZs: 2, Bias: -17597224104.585011, T: 8448, Avg. loss: 26725050211518074880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 281425585.29, NNZs: 2, Bias: -17596017196.749065, T: 8576, Avg. loss: 26189813472959541248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 282355201.93, NNZs: 2, Bias: -17594867081.235851, T: 8704, Avg. loss: 25279111720833142784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 286405813.79, NNZs: 2, Bias: -17593628809.775127, T: 8832, Avg. loss: 25990132986613985280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 285628028.89, NNZs: 2, Bias: -17592460017.661510, T: 8960, Avg. loss: 26207575537667895296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 281548386.91, NNZs: 2, Bias: -17591314486.507458, T: 9088, Avg. loss: 26932564976025796608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 285267615.74, NNZs: 2, Bias: -17590091242.488274, T: 9216, Avg. loss: 25786682142204309504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 279958024.32, NNZs: 2, Bias: -17588982435.846737, T: 9344, Avg. loss: 26561610599398387712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 281117539.92, NNZs: 2, Bias: -17588728342.659874, T: 9472, Avg. loss: 25404085414138580992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 281448220.28, NNZs: 2, Bias: -17588485738.704285, T: 9600, Avg. loss: 25599938397031849984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 281242231.91, NNZs: 2, Bias: -17588251748.359657, T: 9728, Avg. loss: 25603199627795845120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 281231403.84, NNZs: 2, Bias: -17588014359.537292, T: 9856, Avg. loss: 25627002184659775488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 281890961.98, NNZs: 2, Bias: -17587766334.478924, T: 9984, Avg. loss: 25615333213085814784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 78 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1073018834513.84, NNZs: 2, Bias: 80268121623.780151, T: 128, Avg. loss: 20138073644182147052662161408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 449869618591.21, NNZs: 2, Bias: 53837917384.172363, T: 256, Avg. loss: 21794826784147461391383527424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1414750974577.10, NNZs: 2, Bias: 44855719165.980522, T: 384, Avg. loss: 18911154762123011503696117760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 904933780733.69, NNZs: 2, Bias: -15144280834.019478, T: 512, Avg. loss: 21809748044320216302978334720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1216662492269.90, NNZs: 2, Bias: 23511093029.819641, T: 640, Avg. loss: 19036093063887115634050334720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1942732936569.57, NNZs: 2, Bias: -6363455106.560867, T: 768, Avg. loss: 21153810100530878006519922688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1473146294449.49, NNZs: 2, Bias: -71443785901.831100, T: 896, Avg. loss: 21260296424412254543886155776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1128906625553.80, NNZs: 2, Bias: -51443785901.831100, T: 1024, Avg. loss: 21813648731021489397148155904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 242682587809.84, NNZs: 2, Bias: -45868338737.549957, T: 1152, Avg. loss: 1030284172872037458644041728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 128886368488.20, NNZs: 2, Bias: -42339764028.719322, T: 1280, Avg. loss: 777445356511499378726273024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 529483957566.45, NNZs: 2, Bias: -32546460703.859894, T: 1408, Avg. loss: 811450535581109963364237312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 158111713621.13, NNZs: 2, Bias: -48545305832.568962, T: 1536, Avg. loss: 826653849294559025582571520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 255581072224.18, NNZs: 2, Bias: -42054705514.355011, T: 1664, Avg. loss: 855231367734917155858153472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 284959370597.78, NNZs: 2, Bias: -46575435795.917953, T: 1792, Avg. loss: 815080893255472591717531648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 282061046873.01, NNZs: 2, Bias: -53289141374.548538, T: 1920, Avg. loss: 903307671264386914063482880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 69616836418.83, NNZs: 2, Bias: -52168303783.530556, T: 2048, Avg. loss: 44549584353460810615357440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 56339498666.85, NNZs: 2, Bias: -54390538896.982704, T: 2176, Avg. loss: 30188303621427868125364224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 90924672430.45, NNZs: 2, Bias: -53594982326.698563, T: 2304, Avg. loss: 28574264796019714988965888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 32372502408.08, NNZs: 2, Bias: -52226205002.654854, T: 2432, Avg. loss: 32011877080895008362463232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 54073179356.64, NNZs: 2, Bias: -48868334082.049736, T: 2560, Avg. loss: 29016173249483318933585920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 38047475707.19, NNZs: 2, Bias: -47059680168.467422, T: 2688, Avg. loss: 30603397397382289153851392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 52118690293.55, NNZs: 2, Bias: -43358576929.366371, T: 2816, Avg. loss: 33701240171264976472768512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 59306685045.88, NNZs: 2, Bias: -42825625697.334869, T: 2944, Avg. loss: 31652056252468399204990976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 3372976406.64, NNZs: 2, Bias: -43186867897.060913, T: 3072, Avg. loss: 1779844384561949606674432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 12757368352.00, NNZs: 2, Bias: -42936414680.482140, T: 3200, Avg. loss: 537237602252015796224000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8747590844.49, NNZs: 2, Bias: -42827336380.474022, T: 3328, Avg. loss: 550104960209278375821312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 12782303806.37, NNZs: 2, Bias: -42796711446.248055, T: 3456, Avg. loss: 463891507020362548248576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1342038632.55, NNZs: 2, Bias: -42655986278.716805, T: 3584, Avg. loss: 556085804852065624653824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 10837004254.37, NNZs: 2, Bias: -42573778907.782310, T: 3712, Avg. loss: 336612140429480864776192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3534429482.99, NNZs: 2, Bias: -42561301066.679970, T: 3840, Avg. loss: 612066712894254631354368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6515662408.42, NNZs: 2, Bias: -42662021641.962128, T: 3968, Avg. loss: 524884754362351266824192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4889953223.48, NNZs: 2, Bias: -42447253178.055382, T: 4096, Avg. loss: 552583439753528018468864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1985270284.68, NNZs: 2, Bias: -42493198363.087830, T: 4224, Avg. loss: 546338146727131915223040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1003437724.92, NNZs: 2, Bias: -42562459138.515358, T: 4352, Avg. loss: 437824121457416519811072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 134504748.67, NNZs: 2, Bias: -42540560497.376793, T: 4480, Avg. loss: 421165995359999492096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 392057162.17, NNZs: 2, Bias: -42521025912.168823, T: 4608, Avg. loss: 215362778256059203584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 560986590.61, NNZs: 2, Bias: -42504334893.648415, T: 4736, Avg. loss: 183437483711143149568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 618321270.10, NNZs: 2, Bias: -42488780326.801315, T: 4864, Avg. loss: 187389793992436809728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 693446786.56, NNZs: 2, Bias: -42474690026.650352, T: 4992, Avg. loss: 161316215047642513408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 745417003.63, NNZs: 2, Bias: -42460866022.284828, T: 5120, Avg. loss: 165021387238937264128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 709389595.18, NNZs: 2, Bias: -42448705903.657730, T: 5248, Avg. loss: 167646371619149447168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 735019531.27, NNZs: 2, Bias: -42434547529.940208, T: 5376, Avg. loss: 172653635263234310144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 720346142.68, NNZs: 2, Bias: -42421827721.174202, T: 5504, Avg. loss: 168343458178124054528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 729682737.19, NNZs: 2, Bias: -42408646748.378906, T: 5632, Avg. loss: 164511572704386088960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 717605646.98, NNZs: 2, Bias: -42406189909.127617, T: 5760, Avg. loss: 142475470737801412608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 723454528.35, NNZs: 2, Bias: -42403411701.694588, T: 5888, Avg. loss: 142935423650461499392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 727706408.82, NNZs: 2, Bias: -42400676308.730873, T: 6016, Avg. loss: 142180550850004320256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 735387419.34, NNZs: 2, Bias: -42397928094.335587, T: 6144, Avg. loss: 139439819084926746624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 727387224.28, NNZs: 2, Bias: -42395376204.869621, T: 6272, Avg. loss: 143791527232666697728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 729785612.45, NNZs: 2, Bias: -42392685619.671295, T: 6400, Avg. loss: 141351342612063649792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 729768362.60, NNZs: 2, Bias: -42389992800.727203, T: 6528, Avg. loss: 143698715876413816832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 730549919.84, NNZs: 2, Bias: -42387287785.750427, T: 6656, Avg. loss: 143816524037708414976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 731774652.97, NNZs: 2, Bias: -42384688877.589073, T: 6784, Avg. loss: 137489307625215950848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 721385594.95, NNZs: 2, Bias: -42382294196.776253, T: 6912, Avg. loss: 136994383507191496704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 723815893.29, NNZs: 2, Bias: -42379552230.125900, T: 7040, Avg. loss: 144122294444083773440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 732446703.51, NNZs: 2, Bias: -42376780062.779877, T: 7168, Avg. loss: 139982902304474857472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 730475242.72, NNZs: 2, Bias: -42374151073.371048, T: 7296, Avg. loss: 142251284278623076352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 729831702.37, NNZs: 2, Bias: -42371471239.914330, T: 7424, Avg. loss: 143478302464143605760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 730781553.71, NNZs: 2, Bias: -42368833726.933014, T: 7552, Avg. loss: 139943155160408145920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 731739554.40, NNZs: 2, Bias: -42368285993.791702, T: 7680, Avg. loss: 137934789766659211264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 731207969.52, NNZs: 2, Bias: -42367763669.061874, T: 7808, Avg. loss: 138032467607910432768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 732910307.81, NNZs: 2, Bias: -42367203575.687759, T: 7936, Avg. loss: 137802988818220941312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 732100244.86, NNZs: 2, Bias: -42366686236.937332, T: 8064, Avg. loss: 137995378070371958784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 730455424.40, NNZs: 2, Bias: -42366184109.894745, T: 8192, Avg. loss: 137801047398864715776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 64 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1969556467213.95, NNZs: 2, Bias: 72561495512.258514, T: 128, Avg. loss: 23299871571915737112439160832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 575730363822.43, NNZs: 2, Bias: 108917232127.612946, T: 256, Avg. loss: 23836206911951684469425963008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 556192808293.40, NNZs: 2, Bias: 29568497965.428520, T: 384, Avg. loss: 23144894749862114132603437056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1705087885007.07, NNZs: 2, Bias: -30431502034.571480, T: 512, Avg. loss: 22284681313360589376282689536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1226924153251.50, NNZs: 2, Bias: -75946343095.843048, T: 640, Avg. loss: 24700570715359001746929090560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 742485621253.56, NNZs: 2, Bias: -41034587703.382690, T: 768, Avg. loss: 24897676473679521520400990208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 936603451804.14, NNZs: 2, Bias: -62847634146.323685, T: 896, Avg. loss: 21673696428063111948523274240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 345573807173.12, NNZs: 2, Bias: -54716143186.734116, T: 1024, Avg. loss: 24526152489961187990581542912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1301725132136.22, NNZs: 2, Bias: -91648722615.265167, T: 1152, Avg. loss: 23123638565322872386389803008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 589356359187.53, NNZs: 2, Bias: -114738791435.194824, T: 1280, Avg. loss: 22948627077804036716629065728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1294211290077.37, NNZs: 2, Bias: -127007126907.760803, T: 1408, Avg. loss: 22772590306310833472115048448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2943100416390.09, NNZs: 2, Bias: -167007126907.760803, T: 1536, Avg. loss: 21898412103339068184223285248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 255530953717.17, NNZs: 2, Bias: -140587616983.945831, T: 1664, Avg. loss: 4350503346737311682438103040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 461389985495.86, NNZs: 2, Bias: -139287954554.320099, T: 1792, Avg. loss: 918109232132942437004869632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 64781506426.61, NNZs: 2, Bias: -123287954554.320099, T: 1920, Avg. loss: 931357896662913110325067776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 164044704276.30, NNZs: 2, Bias: -130230478700.221436, T: 2048, Avg. loss: 826872917467136043184553984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 211342021279.06, NNZs: 2, Bias: -126402305968.648163, T: 2176, Avg. loss: 868404752763983332596776960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 167148740956.33, NNZs: 2, Bias: -129957135384.080582, T: 2304, Avg. loss: 811940909823373938798886912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 320583258245.87, NNZs: 2, Bias: -132778966949.632080, T: 2432, Avg. loss: 855128618501868345366675456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 69104441688.39, NNZs: 2, Bias: -115214445148.110031, T: 2560, Avg. loss: 886708274848845997373652992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 450289234216.67, NNZs: 2, Bias: -104123075176.250183, T: 2688, Avg. loss: 809130281827217300107821056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 314553727628.91, NNZs: 2, Bias: -112011120053.715332, T: 2816, Avg. loss: 862140927207712980725661696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 85867503119.15, NNZs: 2, Bias: -127239986273.744934, T: 2944, Avg. loss: 890746674926029879222730752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 90792633117.73, NNZs: 2, Bias: -124755045920.535080, T: 3072, Avg. loss: 995733400165780666353451008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 265450732731.77, NNZs: 2, Bias: -120187467792.510498, T: 3200, Avg. loss: 908917710080790878557831168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 130669547129.95, NNZs: 2, Bias: -113025686505.804337, T: 3328, Avg. loss: 979181491419539865178472448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 61522034418.81, NNZs: 2, Bias: -116371714919.224472, T: 3456, Avg. loss: 35043240473587187386941440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 53842017382.78, NNZs: 2, Bias: -118978946728.305847, T: 3584, Avg. loss: 33736896631426787405987840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 82760599164.02, NNZs: 2, Bias: -117533159369.864685, T: 3712, Avg. loss: 37760629729896025976471552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 22436410600.82, NNZs: 2, Bias: -120074857426.168015, T: 3840, Avg. loss: 34837739539525599194251264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 51086623116.21, NNZs: 2, Bias: -119452535421.630707, T: 3968, Avg. loss: 31815367058279093220933632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 20573492903.41, NNZs: 2, Bias: -119518013413.656708, T: 4096, Avg. loss: 32509655348970215750762496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 56836666501.00, NNZs: 2, Bias: -119364920627.881851, T: 4224, Avg. loss: 34462627269179726039613440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 100688013304.58, NNZs: 2, Bias: -121731632170.786240, T: 4352, Avg. loss: 31904504727204031874727936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 27144849872.98, NNZs: 2, Bias: -121198024661.786102, T: 4480, Avg. loss: 35707392203269827807150080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 27988327608.94, NNZs: 2, Bias: -122607654689.754227, T: 4608, Avg. loss: 36242406097279619566665728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5957579365.51, NNZs: 2, Bias: -121853941085.480530, T: 4736, Avg. loss: 786523162299900283060224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9726607078.67, NNZs: 2, Bias: -121498221512.618820, T: 4864, Avg. loss: 581997710620123818098688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 15022956297.85, NNZs: 2, Bias: -121408247974.186752, T: 4992, Avg. loss: 514010786929284078370816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 16730191839.44, NNZs: 2, Bias: -120933521795.996368, T: 5120, Avg. loss: 543453020741566690492416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 6339136294.14, NNZs: 2, Bias: -120986144870.178238, T: 5248, Avg. loss: 658294894011131996667904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1600426175.15, NNZs: 2, Bias: -121028696670.480637, T: 5376, Avg. loss: 623736015784124956540928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1496973286.23, NNZs: 2, Bias: -121173972685.051025, T: 5504, Avg. loss: 648677600942285731659776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5577797894.22, NNZs: 2, Bias: -121028527728.336487, T: 5632, Avg. loss: 538532050516860343418880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3730500077.22, NNZs: 2, Bias: -121018216747.143265, T: 5760, Avg. loss: 3291137668558437744640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2757245738.36, NNZs: 2, Bias: -120989156864.847046, T: 5888, Avg. loss: 2349257322604892258304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2442796473.47, NNZs: 2, Bias: -120956293156.423019, T: 6016, Avg. loss: 1499633641627822325760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2213833749.36, NNZs: 2, Bias: -120921252029.357162, T: 6144, Avg. loss: 1506557897389995196416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2102346015.84, NNZs: 2, Bias: -120881612108.797806, T: 6272, Avg. loss: 1557692251774343970816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1985909142.51, NNZs: 2, Bias: -120842555524.281204, T: 6400, Avg. loss: 1515911394717088612352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1837174193.68, NNZs: 2, Bias: -120802437023.016418, T: 6528, Avg. loss: 1622367430073204080640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1838671567.08, NNZs: 2, Bias: -120764971063.271057, T: 6656, Avg. loss: 1374313344492853788672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1945167166.90, NNZs: 2, Bias: -120722992749.334625, T: 6784, Avg. loss: 1569463242704894296064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2055526763.62, NNZs: 2, Bias: -120683948976.460312, T: 6912, Avg. loss: 1320203646545760354304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1926872591.64, NNZs: 2, Bias: -120645528066.689972, T: 7040, Avg. loss: 1599380649840137994240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2005564218.30, NNZs: 2, Bias: -120606355268.864746, T: 7168, Avg. loss: 1383070875387128446976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1819275692.26, NNZs: 2, Bias: -120567366220.185089, T: 7296, Avg. loss: 1679854589733354602496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1855980796.76, NNZs: 2, Bias: -120528198777.301971, T: 7424, Avg. loss: 1447152668917531148288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1858263825.32, NNZs: 2, Bias: -120488037097.094650, T: 7552, Avg. loss: 1499772433143278862336.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1883235055.97, NNZs: 2, Bias: -120479514229.392731, T: 7680, Avg. loss: 1236299341715427819520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1871314978.30, NNZs: 2, Bias: -120471583672.972931, T: 7808, Avg. loss: 1233641865527378313216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1884617040.36, NNZs: 2, Bias: -120463254400.806168, T: 7936, Avg. loss: 1234042070430484791296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1858167106.30, NNZs: 2, Bias: -120455591024.199387, T: 8064, Avg. loss: 1229488095432179187712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1878408593.87, NNZs: 2, Bias: -120447076857.609924, T: 8192, Avg. loss: 1243415354543598731264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1878762170.98, NNZs: 2, Bias: -120439136640.763214, T: 8320, Avg. loss: 1203790282417443700736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1883492481.60, NNZs: 2, Bias: -120430873378.751556, T: 8448, Avg. loss: 1246444927027609862144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1875410260.06, NNZs: 2, Bias: -120422905605.470810, T: 8576, Avg. loss: 1228417397561058918400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1912685089.21, NNZs: 2, Bias: -120414276509.507050, T: 8704, Avg. loss: 1217678131708873932800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1870416548.15, NNZs: 2, Bias: -120406817180.856613, T: 8832, Avg. loss: 1235891777745509941248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1858876841.67, NNZs: 2, Bias: -120398956487.098541, T: 8960, Avg. loss: 1220696572554408886272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1875957677.58, NNZs: 2, Bias: -120397058819.358871, T: 9088, Avg. loss: 1204927896135020314624.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1878662334.55, NNZs: 2, Bias: -120395396928.538956, T: 9216, Avg. loss: 1195920098631506460672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1882056632.10, NNZs: 2, Bias: -120393726761.756973, T: 9344, Avg. loss: 1194070964983305863168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1875439804.24, NNZs: 2, Bias: -120392209043.941925, T: 9472, Avg. loss: 1197345438218587734016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1877046144.93, NNZs: 2, Bias: -120390563467.399658, T: 9600, Avg. loss: 1196693742888007761920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1877031005.15, NNZs: 2, Bias: -120388944215.750519, T: 9728, Avg. loss: 1195930210950184435712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1872952389.56, NNZs: 2, Bias: -120387388681.126862, T: 9856, Avg. loss: 1195665883353413058560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1871735457.63, NNZs: 2, Bias: -120385788560.726166, T: 9984, Avg. loss: 1195581952528565141504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 78 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1034396268837.92, NNZs: 2, Bias: -25878977343.570450, T: 128, Avg. loss: 22633633990208870015542755328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 340270901059.81, NNZs: 2, Bias: 54121022656.429550, T: 256, Avg. loss: 24605270277223827169062420480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2553372581768.88, NNZs: 2, Bias: 94121022656.429550, T: 384, Avg. loss: 20840418494951160859248820224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1379580757030.89, NNZs: 2, Bias: 64495867525.174591, T: 512, Avg. loss: 25849064831693993418755670016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1559730338931.40, NNZs: 2, Bias: 98785765279.054047, T: 640, Avg. loss: 22883116353439193043667255296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1017141624783.99, NNZs: 2, Bias: 118785765279.054047, T: 768, Avg. loss: 22163555424384131909195661312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1175442007066.79, NNZs: 2, Bias: 58785765279.054047, T: 896, Avg. loss: 23292836935819821330827575296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1431729209514.24, NNZs: 2, Bias: 83782581122.857025, T: 1024, Avg. loss: 23424835530994055950612037632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 60849669386.47, NNZs: 2, Bias: 65695263786.375885, T: 1152, Avg. loss: 1135524033483585859495133184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 281820741936.27, NNZs: 2, Bias: 68708351666.355972, T: 1280, Avg. loss: 907831591138165771389108224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 193006899708.61, NNZs: 2, Bias: 65775405372.948944, T: 1408, Avg. loss: 945206708619072860592275456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 284594881377.05, NNZs: 2, Bias: 61940777558.508270, T: 1536, Avg. loss: 933249242294517703427227648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 187932485608.46, NNZs: 2, Bias: 50272883272.629150, T: 1664, Avg. loss: 938914335929705539622141952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 64938240340.75, NNZs: 2, Bias: 53264198023.492577, T: 1792, Avg. loss: 944681040398617559458381824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 418447546406.69, NNZs: 2, Bias: 66790089699.194595, T: 1920, Avg. loss: 948032873904149466053607424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 124204346125.03, NNZs: 2, Bias: 59400633151.516342, T: 2048, Avg. loss: 47753015846677274559512576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 102459219242.74, NNZs: 2, Bias: 57113681059.416130, T: 2176, Avg. loss: 34871578035117513336946688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 79224492317.23, NNZs: 2, Bias: 55195502321.330872, T: 2304, Avg. loss: 32456050158889710779367424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 23521676932.98, NNZs: 2, Bias: 55035646131.766563, T: 2432, Avg. loss: 35978983415269305706610688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 32988795553.10, NNZs: 2, Bias: 55496424153.913498, T: 2560, Avg. loss: 35734209917571182509424640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 90657321435.45, NNZs: 2, Bias: 57322798266.037354, T: 2688, Avg. loss: 38601518032973751348363264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 77191086841.35, NNZs: 2, Bias: 57522551563.178070, T: 2816, Avg. loss: 36359904184312800888225792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 26341393592.01, NNZs: 2, Bias: 54590086391.158722, T: 2944, Avg. loss: 33750438422853096501673984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 7429105230.29, NNZs: 2, Bias: 54187400374.189713, T: 3072, Avg. loss: 686186581229282300788736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 922142211.69, NNZs: 2, Bias: 54507255630.018593, T: 3200, Avg. loss: 747610170869621943435264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1154384755.42, NNZs: 2, Bias: 54782372421.022232, T: 3328, Avg. loss: 724636061980484188504064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 11029774060.72, NNZs: 2, Bias: 54491471081.456329, T: 3456, Avg. loss: 575345059848379439251456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9015698481.21, NNZs: 2, Bias: 54509089425.662155, T: 3584, Avg. loss: 858231294161235430342656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2291654028.05, NNZs: 2, Bias: 54420392791.369682, T: 3712, Avg. loss: 592721244081679610413056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 6226222960.68, NNZs: 2, Bias: 54275048917.738716, T: 3840, Avg. loss: 732715876179906163376128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 3032503355.61, NNZs: 2, Bias: 53985488131.231583, T: 3968, Avg. loss: 686378422637445328666624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 7777850504.58, NNZs: 2, Bias: 54092126019.287437, T: 4096, Avg. loss: 743425112842639192883200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1386097584.29, NNZs: 2, Bias: 54012637417.120186, T: 4224, Avg. loss: 14011750178936288444416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 523822575.44, NNZs: 2, Bias: 53982779159.487877, T: 4352, Avg. loss: 702424815892952383488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 308559634.03, NNZs: 2, Bias: 53961346058.683090, T: 4480, Avg. loss: 354776357666547499008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 476698181.24, NNZs: 2, Bias: 53942444239.891800, T: 4608, Avg. loss: 275792669736252440576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 657340874.54, NNZs: 2, Bias: 53924606247.963409, T: 4736, Avg. loss: 255199683969764851712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 721132874.57, NNZs: 2, Bias: 53907742210.414452, T: 4864, Avg. loss: 258044456900806344704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 755967071.08, NNZs: 2, Bias: 53891517221.234383, T: 4992, Avg. loss: 262580866269632200704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 764405380.01, NNZs: 2, Bias: 53875448121.642426, T: 5120, Avg. loss: 261682595050406150144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 854606710.96, NNZs: 2, Bias: 53859844586.713676, T: 5248, Avg. loss: 227548292862977179648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 821700240.04, NNZs: 2, Bias: 53845743694.857918, T: 5376, Avg. loss: 239440631303900037120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 774866517.31, NNZs: 2, Bias: 53830650540.104736, T: 5504, Avg. loss: 266773495403063181312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 801622239.68, NNZs: 2, Bias: 53814680814.415382, T: 5632, Avg. loss: 253711362361707495424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 791978921.86, NNZs: 2, Bias: 53799500262.228203, T: 5760, Avg. loss: 260102273667325722624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 796137235.20, NNZs: 2, Bias: 53783944785.914230, T: 5888, Avg. loss: 255014090167941758976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 805790624.38, NNZs: 2, Bias: 53780650963.838242, T: 6016, Avg. loss: 213123243254811721728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 802740822.02, NNZs: 2, Bias: 53777560563.227493, T: 6144, Avg. loss: 212321136587110318080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 796972972.69, NNZs: 2, Bias: 53774544795.265427, T: 6272, Avg. loss: 210336476514936258560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 795354284.48, NNZs: 2, Bias: 53771408641.770493, T: 6400, Avg. loss: 214354981053345792000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 791583126.57, NNZs: 2, Bias: 53768338032.069427, T: 6528, Avg. loss: 211845681736876163072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 796423326.65, NNZs: 2, Bias: 53765106618.153618, T: 6656, Avg. loss: 213811528697854754816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 794076860.67, NNZs: 2, Bias: 53761988796.626595, T: 6784, Avg. loss: 213762862247400833024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 802702334.64, NNZs: 2, Bias: 53758738316.384651, T: 6912, Avg. loss: 211311073178770833408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 794131823.22, NNZs: 2, Bias: 53758232502.060387, T: 7040, Avg. loss: 208886626056721760256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 793986874.66, NNZs: 2, Bias: 53757608474.227577, T: 7168, Avg. loss: 206436682286520696832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 793729430.27, NNZs: 2, Bias: 53756986070.698715, T: 7296, Avg. loss: 206446113194427318272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 794001256.93, NNZs: 2, Bias: 53756356747.334702, T: 7424, Avg. loss: 206123895965227646976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 792528996.25, NNZs: 2, Bias: 53755752905.387260, T: 7552, Avg. loss: 206250869170805899264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 792869286.67, NNZs: 2, Bias: 53755121642.911522, T: 7680, Avg. loss: 206441756016988291072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 794321859.49, NNZs: 2, Bias: 53754474776.639648, T: 7808, Avg. loss: 206141525968563863552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 792586605.56, NNZs: 2, Bias: 53753875917.880592, T: 7936, Avg. loss: 205881792254546444288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 794116914.88, NNZs: 2, Bias: 53753228291.341110, T: 8064, Avg. loss: 206005026402830057472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 793193266.47, NNZs: 2, Bias: 53752615587.333832, T: 8192, Avg. loss: 206485767285715435520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 795193824.14, NNZs: 2, Bias: 53751960965.911743, T: 8320, Avg. loss: 206020711849676505088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 793825985.48, NNZs: 2, Bias: 53751354839.629639, T: 8448, Avg. loss: 206479623524876812288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 792621991.16, NNZs: 2, Bias: 53750746321.706635, T: 8576, Avg. loss: 206470710285816528896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 67 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 709449888297.63, NNZs: 2, Bias: -40096828411.364182, T: 128, Avg. loss: 20101984678328135090459115520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 576296980751.99, NNZs: 2, Bias: -40096828411.364182, T: 256, Avg. loss: 22537518259275869849053560832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1083297154461.51, NNZs: 2, Bias: 23122500717.300415, T: 384, Avg. loss: 20785347474529752100292788224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 965218324253.39, NNZs: 2, Bias: 43122500717.300415, T: 512, Avg. loss: 21704519711357834315417255936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1668513683959.29, NNZs: 2, Bias: 15398332831.523590, T: 640, Avg. loss: 24460768298993686452067368960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1589363896724.52, NNZs: 2, Bias: -97746021928.893433, T: 768, Avg. loss: 21231042116439845016579342336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 281075179894.43, NNZs: 2, Bias: -87560185858.559326, T: 896, Avg. loss: 1571008820833331793501356032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 319128071573.78, NNZs: 2, Bias: -103322743600.262222, T: 1024, Avg. loss: 825686587418688705385201664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 100073780202.25, NNZs: 2, Bias: -116940298837.018707, T: 1152, Avg. loss: 954209334934103189620785152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 245754267687.21, NNZs: 2, Bias: -106728554361.025360, T: 1280, Avg. loss: 845129077638449452835405824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 152117417729.59, NNZs: 2, Bias: -93741538149.319229, T: 1408, Avg. loss: 851970009220881042842320896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 186542100976.81, NNZs: 2, Bias: -96103814566.464157, T: 1536, Avg. loss: 808234894719883642293714944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 214328985487.80, NNZs: 2, Bias: -100766776166.486679, T: 1664, Avg. loss: 870775978578292351434752000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 427472747595.39, NNZs: 2, Bias: -120913115157.127563, T: 1792, Avg. loss: 754904259518971684361076736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 141464300337.53, NNZs: 2, Bias: -126412117776.820786, T: 1920, Avg. loss: 909961297203883151575744512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 174581293137.46, NNZs: 2, Bias: -137932010144.830780, T: 2048, Avg. loss: 782514347796188329869836288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 300158397056.34, NNZs: 2, Bias: -136838767213.724472, T: 2176, Avg. loss: 812915031968042375396196352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 210712921530.69, NNZs: 2, Bias: -152741867849.361450, T: 2304, Avg. loss: 914586086792417537695940608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 322968942678.90, NNZs: 2, Bias: -145049533807.136749, T: 2432, Avg. loss: 821226288731535046866894848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 49371646735.51, NNZs: 2, Bias: -144679714539.834656, T: 2560, Avg. loss: 58405977406434844692447232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 26417304672.42, NNZs: 2, Bias: -139450947275.857941, T: 2688, Avg. loss: 29886191891687666723323904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 24977319196.95, NNZs: 2, Bias: -138248442213.526062, T: 2816, Avg. loss: 30851052278437039300411392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 15318878323.98, NNZs: 2, Bias: -138116431694.390106, T: 2944, Avg. loss: 34178072452008322843803648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 31864370205.78, NNZs: 2, Bias: -137987222469.875153, T: 3072, Avg. loss: 31168256274594439169572864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 60683457665.20, NNZs: 2, Bias: -136937160398.599289, T: 3200, Avg. loss: 31501055466457413648908288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100413639013.33, NNZs: 2, Bias: -138966906343.242371, T: 3328, Avg. loss: 28426754390319338918772736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 27274589661.18, NNZs: 2, Bias: -139768666193.497009, T: 3456, Avg. loss: 32337772291425204852228096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 104894472699.48, NNZs: 2, Bias: -139471405194.230225, T: 3584, Avg. loss: 32521865699431477942419456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 43421032060.85, NNZs: 2, Bias: -139208649970.078217, T: 3712, Avg. loss: 33939776056397255342555136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 105125789958.32, NNZs: 2, Bias: -135811454889.267136, T: 3840, Avg. loss: 27062097204495756786925568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 46008851299.93, NNZs: 2, Bias: -133583030267.878937, T: 3968, Avg. loss: 33313100461616529416388608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 62313427861.40, NNZs: 2, Bias: -133847156948.007828, T: 4096, Avg. loss: 33448541490032025503006720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 60738179481.99, NNZs: 2, Bias: -132592297255.062881, T: 4224, Avg. loss: 32191148050757292157566976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 93846872778.43, NNZs: 2, Bias: -130169530218.274551, T: 4352, Avg. loss: 28829489345236539591884800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 22752656422.80, NNZs: 2, Bias: -129337757837.838120, T: 4480, Avg. loss: 30747556869913688292720640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1307982282.49, NNZs: 2, Bias: -129391027503.276535, T: 4608, Avg. loss: 906178341165403985674240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6573609808.56, NNZs: 2, Bias: -129181494862.454742, T: 4736, Avg. loss: 462767100251497801187328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5217598454.65, NNZs: 2, Bias: -129262136977.270523, T: 4864, Avg. loss: 658250490423876046028800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 8373316652.59, NNZs: 2, Bias: -128783258772.663177, T: 4992, Avg. loss: 735209618404043726520320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9312741659.42, NNZs: 2, Bias: -128933913482.451431, T: 5120, Avg. loss: 642317207913521012015104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 13229728358.42, NNZs: 2, Bias: -128533537402.637970, T: 5248, Avg. loss: 758683571712477422944256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2322058312.00, NNZs: 2, Bias: -128119728623.781937, T: 5376, Avg. loss: 629972345459368121073664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2128238428.26, NNZs: 2, Bias: -128073872793.695053, T: 5504, Avg. loss: 2085059570343197802496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2178695405.31, NNZs: 2, Bias: -128029068603.014618, T: 5632, Avg. loss: 1716855215690836869120.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1969331193.35, NNZs: 2, Bias: -127986473140.043198, T: 5760, Avg. loss: 1793015218263794384896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2017325686.01, NNZs: 2, Bias: -127938597089.549194, T: 5888, Avg. loss: 1854836059791865937920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1943813125.15, NNZs: 2, Bias: -127894641031.752014, T: 6016, Avg. loss: 1707707962664032665600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2113972182.99, NNZs: 2, Bias: -127849057146.104019, T: 6144, Avg. loss: 1648959765775879766016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1948422979.80, NNZs: 2, Bias: -127805190154.594803, T: 6272, Avg. loss: 1788976065451045683200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1995673886.60, NNZs: 2, Bias: -127758856914.486557, T: 6400, Avg. loss: 1781416607652410032128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2060094392.16, NNZs: 2, Bias: -127712666753.766129, T: 6528, Avg. loss: 1714262383851818713088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2025292593.22, NNZs: 2, Bias: -127669363180.857254, T: 6656, Avg. loss: 1673960232238228701184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2040228845.31, NNZs: 2, Bias: -127625295853.141724, T: 6784, Avg. loss: 1714732923756742180864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2034830562.94, NNZs: 2, Bias: -127616374698.905502, T: 6912, Avg. loss: 1446516255994646626304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2035124374.01, NNZs: 2, Bias: -127607443515.194366, T: 7040, Avg. loss: 1434614995671098327040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2012637872.52, NNZs: 2, Bias: -127599031112.925339, T: 7168, Avg. loss: 1407742678726422560768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2042880696.52, NNZs: 2, Bias: -127589493612.180603, T: 7296, Avg. loss: 1452313673634387853312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2044743032.28, NNZs: 2, Bias: -127580652223.625580, T: 7424, Avg. loss: 1413086063655619395584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2045368963.49, NNZs: 2, Bias: -127571770889.518661, T: 7552, Avg. loss: 1422049426627437264896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2039006685.52, NNZs: 2, Bias: -127563253758.236771, T: 7680, Avg. loss: 1384181750572604456960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2022709783.60, NNZs: 2, Bias: -127554981363.140472, T: 7808, Avg. loss: 1368666104863231836160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2055999486.77, NNZs: 2, Bias: -127545523400.453125, T: 7936, Avg. loss: 1427808410672967712768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2059160458.12, NNZs: 2, Bias: -127536397170.209732, T: 8064, Avg. loss: 1458088666554616512512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2061616237.12, NNZs: 2, Bias: -127527333316.724854, T: 8192, Avg. loss: 1447034261019976269824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2032367522.55, NNZs: 2, Bias: -127518958135.815414, T: 8320, Avg. loss: 1416000760530573197312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2047689444.36, NNZs: 2, Bias: -127509633045.871674, T: 8448, Avg. loss: 1457156908351792611328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2040493975.34, NNZs: 2, Bias: -127507953847.139572, T: 8576, Avg. loss: 1403486027123057754112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2049268297.68, NNZs: 2, Bias: -127506032980.450333, T: 8704, Avg. loss: 1391325987465775022080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2037897617.94, NNZs: 2, Bias: -127504428596.199265, T: 8832, Avg. loss: 1397357578991731736576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2044103158.83, NNZs: 2, Bias: -127502536359.992020, T: 8960, Avg. loss: 1401445333728585056256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2038541329.85, NNZs: 2, Bias: -127500833388.230179, T: 9088, Avg. loss: 1401404176796175040512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 71 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1607529929102.17, NNZs: 2, Bias: 25870207435.680481, T: 128, Avg. loss: 19223316159985596346623066112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1252809359028.04, NNZs: 2, Bias: -24069830939.289906, T: 256, Avg. loss: 19644813705414816659283116032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1981929575509.74, NNZs: 2, Bias: -74145585803.049805, T: 384, Avg. loss: 20377299512511431107642654720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 940934136753.65, NNZs: 2, Bias: -34145585803.049805, T: 512, Avg. loss: 19978220684460930234360791040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 945098477038.66, NNZs: 2, Bias: -109724333994.011749, T: 640, Avg. loss: 19840868784196793524723646464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2061953969621.35, NNZs: 2, Bias: -129724333994.011749, T: 768, Avg. loss: 21063253433604746905288441856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 298685743252.18, NNZs: 2, Bias: -101035704505.608841, T: 896, Avg. loss: 2081481649917532126530502656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 125490733995.70, NNZs: 2, Bias: -96663124927.261597, T: 1024, Avg. loss: 745616152321745738488872960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 215859949305.64, NNZs: 2, Bias: -103004819407.450745, T: 1152, Avg. loss: 878913987060275968229769216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 348939512876.58, NNZs: 2, Bias: -113049166829.870453, T: 1280, Avg. loss: 780247029343811469299417088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 143488018891.35, NNZs: 2, Bias: -121763298818.804321, T: 1408, Avg. loss: 779267711666135348663025664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 412852013015.94, NNZs: 2, Bias: -126763145220.074280, T: 1536, Avg. loss: 766835469911487380365246464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 628279888016.31, NNZs: 2, Bias: -141342787754.282410, T: 1664, Avg. loss: 735035732567075727714811904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 157211513049.47, NNZs: 2, Bias: -127554602981.796997, T: 1792, Avg. loss: 734798105050901138169135104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 154214489523.93, NNZs: 2, Bias: -139390893900.804565, T: 1920, Avg. loss: 861012238823567046184271872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 329069606083.51, NNZs: 2, Bias: -142223031120.671875, T: 2048, Avg. loss: 864592752744827533752532992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1410221738.57, NNZs: 2, Bias: -147017241922.896637, T: 2176, Avg. loss: 799726021083376329324232704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 82542924354.24, NNZs: 2, Bias: -148445424083.953308, T: 2304, Avg. loss: 804642047627822918975619072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 276229772734.05, NNZs: 2, Bias: -157324979594.386017, T: 2432, Avg. loss: 826477047893074449803509760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 80818420351.93, NNZs: 2, Bias: -166396522963.416016, T: 2560, Avg. loss: 34377258396678734462582784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 81182656212.71, NNZs: 2, Bias: -164196461293.439941, T: 2688, Avg. loss: 30798790126431238388449280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 63913494780.04, NNZs: 2, Bias: -163624467199.441772, T: 2816, Avg. loss: 29231058280070358994255872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 48384600707.42, NNZs: 2, Bias: -162139194574.276917, T: 2944, Avg. loss: 27236423125131180084559872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 5102155465.55, NNZs: 2, Bias: -163283068893.177002, T: 3072, Avg. loss: 28005040377415886966882304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 43210297297.81, NNZs: 2, Bias: -161449813679.695221, T: 3200, Avg. loss: 30394284618641105567612928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 32566649621.54, NNZs: 2, Bias: -162957321416.564087, T: 3328, Avg. loss: 27533234199935638931767296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 69327891645.48, NNZs: 2, Bias: -163997544284.549011, T: 3456, Avg. loss: 27461716848995256156291072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 99979396216.00, NNZs: 2, Bias: -167111466605.586060, T: 3584, Avg. loss: 27215575587230572095733760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 17773157088.09, NNZs: 2, Bias: -167029526375.034119, T: 3712, Avg. loss: 30009258012898412170575872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 19635014441.48, NNZs: 2, Bias: -168257399007.037567, T: 3840, Avg. loss: 30048255907460059114766336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 74217731161.49, NNZs: 2, Bias: -167097796339.468109, T: 3968, Avg. loss: 27398699171018587705966592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 47293392529.26, NNZs: 2, Bias: -166631064788.033203, T: 4096, Avg. loss: 30343470515462654090280960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 30201637302.37, NNZs: 2, Bias: -167404563978.675537, T: 4224, Avg. loss: 27446698900082126112161792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6139904510.44, NNZs: 2, Bias: -167012910765.179108, T: 4352, Avg. loss: 561563042754978912403456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11665592157.94, NNZs: 2, Bias: -166642284517.120209, T: 4480, Avg. loss: 569258914574689892302848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5768954479.83, NNZs: 2, Bias: -166296320891.057098, T: 4608, Avg. loss: 625436234308146448826368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5326377862.64, NNZs: 2, Bias: -165800585338.462799, T: 4736, Avg. loss: 601633984938571974311936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7739580788.20, NNZs: 2, Bias: -165579023264.212311, T: 4864, Avg. loss: 606384959021605961334784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3597563592.37, NNZs: 2, Bias: -165587553300.566772, T: 4992, Avg. loss: 407755980938285263355904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1043073575.54, NNZs: 2, Bias: -165461181413.087341, T: 5120, Avg. loss: 287971023405122429386752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3211696837.16, NNZs: 2, Bias: -165020867618.092834, T: 5248, Avg. loss: 486458697259604179419136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 5545735485.83, NNZs: 2, Bias: -164651435019.758636, T: 5376, Avg. loss: 526200518471569549295616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2948778702.04, NNZs: 2, Bias: -164624135978.192169, T: 5504, Avg. loss: 551900097640625290084352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 10232757425.71, NNZs: 2, Bias: -164043113001.506531, T: 5632, Avg. loss: 634533267582930703613952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 8834623546.60, NNZs: 2, Bias: -163788879381.160309, T: 5760, Avg. loss: 558456545749790401495040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2995262790.87, NNZs: 2, Bias: -163694796504.720367, T: 5888, Avg. loss: 25341892983830110797824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2911802046.30, NNZs: 2, Bias: -163639978777.700348, T: 6016, Avg. loss: 2926826214634043736064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2750952075.33, NNZs: 2, Bias: -163592888908.060516, T: 6144, Avg. loss: 2446273264551518535680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2704767659.07, NNZs: 2, Bias: -163539562050.777557, T: 6272, Avg. loss: 2703418199818786308096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2606346055.51, NNZs: 2, Bias: -163485506764.393250, T: 6400, Avg. loss: 2799904278864548331520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2750293813.69, NNZs: 2, Bias: -163425671651.049164, T: 6528, Avg. loss: 2931005136509152526336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2896280686.63, NNZs: 2, Bias: -163373000591.185638, T: 6656, Avg. loss: 2412452241238507126784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2685564003.97, NNZs: 2, Bias: -163323986444.864044, T: 6784, Avg. loss: 2633884215305668919296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2693000245.17, NNZs: 2, Bias: -163269177211.583496, T: 6912, Avg. loss: 2737392780948570898432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2489011034.82, NNZs: 2, Bias: -163215134128.676788, T: 7040, Avg. loss: 2867522960861204316160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2567895781.73, NNZs: 2, Bias: -163155632362.697113, T: 7168, Avg. loss: 2912063503436392955904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2644511954.86, NNZs: 2, Bias: -163099393798.986115, T: 7296, Avg. loss: 2763115266321288790016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2651544769.39, NNZs: 2, Bias: -163088142415.296631, T: 7424, Avg. loss: 2293528142295201480704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2668011522.60, NNZs: 2, Bias: -163076808397.829803, T: 7552, Avg. loss: 2276499918294570237952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2653550904.43, NNZs: 2, Bias: -163065933402.181793, T: 7680, Avg. loss: 2287579160428184076288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2667295889.15, NNZs: 2, Bias: -163054661696.664032, T: 7808, Avg. loss: 2274549498998538895360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2644104389.45, NNZs: 2, Bias: -163043985887.392609, T: 7936, Avg. loss: 2274174746057664102400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2620631216.87, NNZs: 2, Bias: -163033273918.187744, T: 8064, Avg. loss: 2285461611696310976512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2627383557.02, NNZs: 2, Bias: -163022056737.950439, T: 8192, Avg. loss: 2287967686324191756288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2613410962.01, NNZs: 2, Bias: -163011114436.506439, T: 8320, Avg. loss: 2300073326825264644096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2598430580.51, NNZs: 2, Bias: -163000394431.143341, T: 8448, Avg. loss: 2254967622194470322176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2675971785.10, NNZs: 2, Bias: -162988483223.694519, T: 8576, Avg. loss: 2184551693085095231488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2654754190.09, NNZs: 2, Bias: -162977835806.211792, T: 8704, Avg. loss: 2261459011320681594880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2620137172.05, NNZs: 2, Bias: -162967331876.217957, T: 8832, Avg. loss: 2279271037475794976768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2633191134.00, NNZs: 2, Bias: -162956044103.679810, T: 8960, Avg. loss: 2278738699389997154304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2588475422.54, NNZs: 2, Bias: -162945639888.724426, T: 9088, Avg. loss: 2289277908860344467456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2587253786.61, NNZs: 2, Bias: -162934639114.692810, T: 9216, Avg. loss: 2263262529060808949760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2612053499.20, NNZs: 2, Bias: -162932043330.176270, T: 9344, Avg. loss: 2197800482821749080064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2609816898.80, NNZs: 2, Bias: -162929881553.723053, T: 9472, Avg. loss: 2196957460187663826944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2616327819.83, NNZs: 2, Bias: -162927579402.135498, T: 9600, Avg. loss: 2196361922885770280960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2611674378.10, NNZs: 2, Bias: -162925458856.011261, T: 9728, Avg. loss: 2194576570425158664192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2609427030.52, NNZs: 2, Bias: -162923301472.661896, T: 9856, Avg. loss: 2192686437689327616000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 77 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 956425302216.76, NNZs: 2, Bias: 38989201199.661728, T: 128, Avg. loss: 21661407784738578977364377600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1217069125497.87, NNZs: 2, Bias: 91795449175.108551, T: 256, Avg. loss: 19832746965215853231409725440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1879962682927.26, NNZs: 2, Bias: 111795449175.108551, T: 384, Avg. loss: 19598937378752131802507247616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2121868643607.66, NNZs: 2, Bias: 51795449175.108551, T: 512, Avg. loss: 21613807443966249010284462080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 881230355043.15, NNZs: 2, Bias: 46059591352.285622, T: 640, Avg. loss: 19663034875787038919093125120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 287341483987.49, NNZs: 2, Bias: 82413814850.235458, T: 768, Avg. loss: 22345915882320742199112761344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 153609749196.40, NNZs: 2, Bias: 122284241075.222412, T: 896, Avg. loss: 20947910754172845095856898048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1479404684957.05, NNZs: 2, Bias: 140116123264.628296, T: 1024, Avg. loss: 21758273925218552400238870528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 432647558155.84, NNZs: 2, Bias: 136372454028.194702, T: 1152, Avg. loss: 1521087959187673886173954048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 539470974941.39, NNZs: 2, Bias: 139750020985.256836, T: 1280, Avg. loss: 751285026495897735085948928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 271165339543.29, NNZs: 2, Bias: 147663555939.971802, T: 1408, Avg. loss: 884220834750191687228719104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 228717738787.17, NNZs: 2, Bias: 147469947221.994171, T: 1536, Avg. loss: 839408819478476510958977024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 100862020641.66, NNZs: 2, Bias: 149948837130.325562, T: 1664, Avg. loss: 868939063585864241035345920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 331989590054.16, NNZs: 2, Bias: 154920065460.272980, T: 1792, Avg. loss: 824276650083029374677811200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 298746438594.37, NNZs: 2, Bias: 152769110229.722504, T: 1920, Avg. loss: 828131548730001332111409152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 89816498623.03, NNZs: 2, Bias: 146591181005.625610, T: 2048, Avg. loss: 47850177476466635924570112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 97326394105.08, NNZs: 2, Bias: 144098556228.897552, T: 2176, Avg. loss: 28492899339558197596782592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4394395752.03, NNZs: 2, Bias: 142947274041.182495, T: 2304, Avg. loss: 32337364405822409450455040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 44006954639.69, NNZs: 2, Bias: 141481732817.058167, T: 2432, Avg. loss: 29609211619644600586600448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 34317194442.43, NNZs: 2, Bias: 139020131474.909302, T: 2560, Avg. loss: 29744282458715333559582720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 45483775747.02, NNZs: 2, Bias: 138951663439.986389, T: 2688, Avg. loss: 28103773281509015948361728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 42792036059.06, NNZs: 2, Bias: 141764815556.898773, T: 2816, Avg. loss: 29418226896230960871768064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 16176887186.68, NNZs: 2, Bias: 140596009103.407074, T: 2944, Avg. loss: 34761967824786559552454656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 114210070904.71, NNZs: 2, Bias: 139503088608.392700, T: 3072, Avg. loss: 29098944730897787398389760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 12210176614.52, NNZs: 2, Bias: 141433729950.157684, T: 3200, Avg. loss: 28073297745667790905278464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 79885299340.23, NNZs: 2, Bias: 142889053876.984619, T: 3328, Avg. loss: 33321424910303324031418368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 115284863796.73, NNZs: 2, Bias: 144392959444.988281, T: 3456, Avg. loss: 30230711668318769277566976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 56807190949.85, NNZs: 2, Bias: 146693122185.442139, T: 3584, Avg. loss: 31260266477007848830140416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 80570818456.29, NNZs: 2, Bias: 147886814729.125153, T: 3712, Avg. loss: 29414444156172919709368320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 33278329974.17, NNZs: 2, Bias: 145247978674.030701, T: 3840, Avg. loss: 36112141964583880544485376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 12030405953.44, NNZs: 2, Bias: 145678041178.719086, T: 3968, Avg. loss: 785699101584195126820864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5266791557.03, NNZs: 2, Bias: 145635397984.113129, T: 4096, Avg. loss: 586664757239184369909760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5710155708.90, NNZs: 2, Bias: 145872646484.000763, T: 4224, Avg. loss: 701808796869501617438720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2766911578.22, NNZs: 2, Bias: 145487099439.657410, T: 4352, Avg. loss: 547358356947900527804416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2081216168.10, NNZs: 2, Bias: 145277834410.940735, T: 4480, Avg. loss: 570886385592909449658368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 16662367123.15, NNZs: 2, Bias: 144799069438.607941, T: 4608, Avg. loss: 523709144307356441509888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 7018560734.64, NNZs: 2, Bias: 144573964335.202606, T: 4736, Avg. loss: 600746717386850583969792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1564136311.75, NNZs: 2, Bias: 144291637749.893829, T: 4864, Avg. loss: 564477058620031632408576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2956064190.38, NNZs: 2, Bias: 144026717284.682831, T: 4992, Avg. loss: 587954618905659374043136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 5560300529.21, NNZs: 2, Bias: 143756184832.083252, T: 5120, Avg. loss: 617306902655680435453952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 7624661530.60, NNZs: 2, Bias: 143679275156.837097, T: 5248, Avg. loss: 512964662866569683009536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4815318739.91, NNZs: 2, Bias: 143571354118.443817, T: 5376, Avg. loss: 634706621283265448771584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9280744685.10, NNZs: 2, Bias: 143337462929.102814, T: 5504, Avg. loss: 640643315963838569906176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4821981535.72, NNZs: 2, Bias: 143231902022.486023, T: 5632, Avg. loss: 394805607671608425578496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1373143078.14, NNZs: 2, Bias: 142935284286.714569, T: 5760, Avg. loss: 545344538109982533484544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 11246906218.70, NNZs: 2, Bias: 142773482408.727142, T: 5888, Avg. loss: 522435133452048993878016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3633632901.26, NNZs: 2, Bias: 142918374275.667572, T: 6016, Avg. loss: 757893558752780400721920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2844408878.63, NNZs: 2, Bias: 142696043444.038696, T: 6144, Avg. loss: 641491006355750931922944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3461740469.75, NNZs: 2, Bias: 142658673986.002075, T: 6272, Avg. loss: 505040828199601302405120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2326498826.85, NNZs: 2, Bias: 142598080751.655731, T: 6400, Avg. loss: 3851428223910431162368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2371870832.09, NNZs: 2, Bias: 142553023836.365570, T: 6528, Avg. loss: 1904437674044856467456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2508636157.94, NNZs: 2, Bias: 142506917492.709015, T: 6656, Avg. loss: 1831141954748353609728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2448635142.87, NNZs: 2, Bias: 142462194278.871185, T: 6784, Avg. loss: 2017672179777984004096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2415693629.56, NNZs: 2, Bias: 142419598567.477325, T: 6912, Avg. loss: 1921836649187302965248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2573595800.04, NNZs: 2, Bias: 142373587889.628510, T: 7040, Avg. loss: 2020531822137953484800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2574466080.50, NNZs: 2, Bias: 142329301593.891754, T: 7168, Avg. loss: 1904239475711010930688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2431541636.37, NNZs: 2, Bias: 142285571116.576874, T: 7296, Avg. loss: 2031801315924700561408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2471279936.96, NNZs: 2, Bias: 142275874866.073364, T: 7424, Avg. loss: 1612944768482793750528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2503909125.64, NNZs: 2, Bias: 142266430927.525116, T: 7552, Avg. loss: 1587598530592393658368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2480076985.23, NNZs: 2, Bias: 142257795569.255188, T: 7680, Avg. loss: 1623592059548038070272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2454423716.50, NNZs: 2, Bias: 142249347102.184937, T: 7808, Avg. loss: 1596539162769556504576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2460707260.72, NNZs: 2, Bias: 142240241868.948151, T: 7936, Avg. loss: 1612627498227159269376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2467767273.30, NNZs: 2, Bias: 142231484866.628723, T: 8064, Avg. loss: 1546470597326538014720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2449496449.82, NNZs: 2, Bias: 142222991320.335205, T: 8192, Avg. loss: 1577585712788084359168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2479447301.35, NNZs: 2, Bias: 142213575800.783508, T: 8320, Avg. loss: 1590850446209165295616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2483882095.93, NNZs: 2, Bias: 142204674436.150909, T: 8448, Avg. loss: 1579206094155717541888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2482228793.66, NNZs: 2, Bias: 142195943762.261597, T: 8576, Avg. loss: 1566064166964092731392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2463798245.11, NNZs: 2, Bias: 142187255543.206512, T: 8704, Avg. loss: 1612827251447673913344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2471333352.37, NNZs: 2, Bias: 142185337738.264618, T: 8832, Avg. loss: 1557619585993807233024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2468485231.77, NNZs: 2, Bias: 142183604598.247009, T: 8960, Avg. loss: 1554225408219009515520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2473735551.12, NNZs: 2, Bias: 142181731831.600525, T: 9088, Avg. loss: 1552802496852593475584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2468052921.66, NNZs: 2, Bias: 142180050117.204407, T: 9216, Avg. loss: 1552570351196222783488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2470080479.71, NNZs: 2, Bias: 142178240791.645508, T: 9344, Avg. loss: 1546440219378605621248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2477264473.19, NNZs: 2, Bias: 142176340311.141144, T: 9472, Avg. loss: 1547532329966025048064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2472399550.37, NNZs: 2, Bias: 142174642789.066040, T: 9600, Avg. loss: 1553894389012036845568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2475415381.69, NNZs: 2, Bias: 142172810621.076324, T: 9728, Avg. loss: 1551223201071547285504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2477258433.73, NNZs: 2, Bias: 142171003211.184357, T: 9856, Avg. loss: 1547542427609258000384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2464792172.59, NNZs: 2, Bias: 142169454180.998047, T: 9984, Avg. loss: 1539741954570203693056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2472673707.41, NNZs: 2, Bias: 142167538016.778259, T: 10112, Avg. loss: 1550639636201555623936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2475438529.89, NNZs: 2, Bias: 142165713182.791718, T: 10240, Avg. loss: 1548511724665148538880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 2473331383.36, NNZs: 2, Bias: 142163968097.095947, T: 10368, Avg. loss: 1553343256381894426624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 2471019822.94, NNZs: 2, Bias: 142162223884.824127, T: 10496, Avg. loss: 1555538535582684676096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 2465540979.82, NNZs: 2, Bias: 142160537941.366943, T: 10624, Avg. loss: 1552758883217111515136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 83 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 56496268835.03, NNZs: 2, Bias: 15622972369.215279, T: 128, Avg. loss: 20626512938495536875169644544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2562173030640.43, NNZs: 2, Bias: 28688639603.074432, T: 256, Avg. loss: 22616842030506115221619212288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 859752614130.05, NNZs: 2, Bias: 71471971630.639938, T: 384, Avg. loss: 24773600343746346620546973696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 409536945805.90, NNZs: 2, Bias: 131471971630.639954, T: 512, Avg. loss: 24257801599493748071887536128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1206422052803.54, NNZs: 2, Bias: 135882578168.703094, T: 640, Avg. loss: 26388938009661042152397864960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1157472836210.46, NNZs: 2, Bias: 155882578168.703094, T: 768, Avg. loss: 22765751567603927970593374208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 223301302092.60, NNZs: 2, Bias: 164738226467.169708, T: 896, Avg. loss: 1132569106155512231469514752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 64617262169.39, NNZs: 2, Bias: 168728680497.703064, T: 1024, Avg. loss: 973548826120822139129954304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 285164682336.59, NNZs: 2, Bias: 156385084365.438782, T: 1152, Avg. loss: 853143652007891061220311040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 416539742759.42, NNZs: 2, Bias: 159328262385.060028, T: 1280, Avg. loss: 874861815974187130706460672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 98869970987.70, NNZs: 2, Bias: 159713080604.690582, T: 1408, Avg. loss: 909075995908266971147272192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 390173675655.49, NNZs: 2, Bias: 160900154787.165253, T: 1536, Avg. loss: 807858133971601348586635264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 337983365878.82, NNZs: 2, Bias: 150498317370.296692, T: 1664, Avg. loss: 968376055089621464546017280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 113196607395.36, NNZs: 2, Bias: 156676105112.341553, T: 1792, Avg. loss: 876406550216430567685095424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 90962624320.93, NNZs: 2, Bias: 162777745405.561676, T: 1920, Avg. loss: 907044629270069510815088640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 406482035152.12, NNZs: 2, Bias: 143398734290.552094, T: 2048, Avg. loss: 890350462862452521988784128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 156020751185.69, NNZs: 2, Bias: 156542561722.886902, T: 2176, Avg. loss: 909934991351633697442889728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 87481809809.17, NNZs: 2, Bias: 157264732187.610992, T: 2304, Avg. loss: 37942668246392016337895424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28462227308.34, NNZs: 2, Bias: 156757624685.210175, T: 2432, Avg. loss: 37958458508614494618386432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 48205701530.34, NNZs: 2, Bias: 154521530988.359589, T: 2560, Avg. loss: 34828691862758078524948480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 38084296961.35, NNZs: 2, Bias: 152471113339.429260, T: 2688, Avg. loss: 33032039732982477043531776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 45640689796.94, NNZs: 2, Bias: 152874572206.166962, T: 2816, Avg. loss: 35917904231143154508627968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 58476145008.58, NNZs: 2, Bias: 154658406766.969666, T: 2944, Avg. loss: 37777269241078709644951552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 61522903261.49, NNZs: 2, Bias: 157538793969.162140, T: 3072, Avg. loss: 31751664019088351831261184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 12235317399.95, NNZs: 2, Bias: 161240040964.859741, T: 3200, Avg. loss: 32504858984991506972016640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 53785352428.31, NNZs: 2, Bias: 164125493691.272308, T: 3328, Avg. loss: 34012923348472105676046336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 30489623187.15, NNZs: 2, Bias: 160749783385.723907, T: 3456, Avg. loss: 31835372073649730358345728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 56286452738.39, NNZs: 2, Bias: 164329162102.158691, T: 3584, Avg. loss: 32019784630391581687414784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 38685756916.60, NNZs: 2, Bias: 162635051727.078430, T: 3712, Avg. loss: 33165313287643937435025408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 12755947696.30, NNZs: 2, Bias: 162537933800.373047, T: 3840, Avg. loss: 1192494258578422371450880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 9018023357.46, NNZs: 2, Bias: 162651822643.840912, T: 3968, Avg. loss: 563603668741573811634176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2511674416.27, NNZs: 2, Bias: 162710023144.228516, T: 4096, Avg. loss: 727333690174440826994688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6860137803.77, NNZs: 2, Bias: 162672219605.907349, T: 4224, Avg. loss: 777504254061532160196608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9717786275.99, NNZs: 2, Bias: 162763490420.246857, T: 4352, Avg. loss: 742996504507815934558208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2060660876.81, NNZs: 2, Bias: 162872232606.512207, T: 4480, Avg. loss: 730734162104786018631680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6404360062.52, NNZs: 2, Bias: 162606138358.205414, T: 4608, Avg. loss: 606706696804727550640128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3980562341.68, NNZs: 2, Bias: 162583087640.620880, T: 4736, Avg. loss: 6471886136639710298112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3270466571.80, NNZs: 2, Bias: 162541139993.218506, T: 4864, Avg. loss: 3050001029186267381760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2976075459.23, NNZs: 2, Bias: 162494920896.949921, T: 4992, Avg. loss: 2866570211106503000064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2815563063.77, NNZs: 2, Bias: 162443634102.142029, T: 5120, Avg. loss: 2807691579100203319296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2661561030.49, NNZs: 2, Bias: 162389886468.601593, T: 5248, Avg. loss: 2824074739049287385088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2506848671.37, NNZs: 2, Bias: 162338254166.456573, T: 5376, Avg. loss: 2842464775995211644928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2628697993.43, NNZs: 2, Bias: 162281844361.397339, T: 5504, Avg. loss: 2755019436709720883200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2450556719.99, NNZs: 2, Bias: 162231405005.156097, T: 5632, Avg. loss: 2758309195832356765696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2520054890.93, NNZs: 2, Bias: 162176508653.373993, T: 5760, Avg. loss: 2824099213280168378368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2525795604.19, NNZs: 2, Bias: 162125004662.395355, T: 5888, Avg. loss: 2699964434250121871360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2391411345.94, NNZs: 2, Bias: 162070134093.576599, T: 6016, Avg. loss: 2938972512092995715072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2496621544.20, NNZs: 2, Bias: 162011029564.236572, T: 6144, Avg. loss: 2879800984181438676992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2539038377.62, NNZs: 2, Bias: 161956292287.195984, T: 6272, Avg. loss: 2756174444462001881088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2591157562.87, NNZs: 2, Bias: 161900438373.250214, T: 6400, Avg. loss: 2801894936476236906496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2543323274.36, NNZs: 2, Bias: 161846705889.851776, T: 6528, Avg. loss: 2722058288774900613120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2558075004.22, NNZs: 2, Bias: 161835440567.443695, T: 6656, Avg. loss: 2253309318217201090560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2604629137.95, NNZs: 2, Bias: 161823800075.974060, T: 6784, Avg. loss: 2221068190448460234752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2557029802.46, NNZs: 2, Bias: 161813666105.916504, T: 6912, Avg. loss: 2225615484640502218752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2584526469.82, NNZs: 2, Bias: 161802374267.197418, T: 7040, Avg. loss: 2212334793893365415936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2560251498.29, NNZs: 2, Bias: 161791894602.897766, T: 7168, Avg. loss: 2220558897598597693440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2592466240.94, NNZs: 2, Bias: 161780655814.236267, T: 7296, Avg. loss: 2182638951105117552640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2597658835.82, NNZs: 2, Bias: 161769606117.788177, T: 7424, Avg. loss: 2239256984861078192128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2545277594.11, NNZs: 2, Bias: 161759378202.846863, T: 7552, Avg. loss: 2260538111394684862464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2529180452.98, NNZs: 2, Bias: 161748768857.183838, T: 7680, Avg. loss: 2217239406733695647744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2551415744.84, NNZs: 2, Bias: 161737360740.063690, T: 7808, Avg. loss: 2253329731028439531520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2520065766.61, NNZs: 2, Bias: 161726963188.343567, T: 7936, Avg. loss: 2221511408461685456896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2548103935.30, NNZs: 2, Bias: 161724321052.599365, T: 8064, Avg. loss: 2183974440917774630912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2545146923.29, NNZs: 2, Bias: 161722191654.191681, T: 8192, Avg. loss: 2159072575804276211712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2556072468.71, NNZs: 2, Bias: 161719842901.080414, T: 8320, Avg. loss: 2158851535037877452800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2551293626.33, NNZs: 2, Bias: 161717741600.597107, T: 8448, Avg. loss: 2160008230588679716864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2545647882.28, NNZs: 2, Bias: 161715657887.081665, T: 8576, Avg. loss: 2156021411004232761344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2540991853.63, NNZs: 2, Bias: 161713560009.114380, T: 8704, Avg. loss: 2154223444477197156352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2551272033.49, NNZs: 2, Bias: 161711224574.607666, T: 8832, Avg. loss: 2155761170656844316672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2538590309.26, NNZs: 2, Bias: 161709259164.243347, T: 8960, Avg. loss: 2148727899928827789312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2537935066.51, NNZs: 2, Bias: 161707100310.899811, T: 9088, Avg. loss: 2151682460185937575936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2536349698.82, NNZs: 2, Bias: 161704950843.123505, T: 9216, Avg. loss: 2157190287212931973120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2550462667.10, NNZs: 2, Bias: 161702548595.028137, T: 9344, Avg. loss: 2161997623439366553600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2545055949.25, NNZs: 2, Bias: 161700459293.668030, T: 9472, Avg. loss: 2157608487099836923904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2554451470.38, NNZs: 2, Bias: 161698140268.082642, T: 9600, Avg. loss: 2153011147447346921472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1349342067937.94, NNZs: 2, Bias: 70601597808.074478, T: 128, Avg. loss: 21082958691291609722863484928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2542204035624.00, NNZs: 2, Bias: 90601597808.074478, T: 256, Avg. loss: 24665367501019910791002849280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 841116856037.33, NNZs: 2, Bias: 68405196976.178864, T: 384, Avg. loss: 22507184440056929578876141568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 903083085558.20, NNZs: 2, Bias: 98359771277.829849, T: 512, Avg. loss: 24614328836251238571135991808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1386940131790.99, NNZs: 2, Bias: 20459386215.439697, T: 640, Avg. loss: 23915567196097085109220409344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1369526881775.29, NNZs: 2, Bias: 99866749429.485535, T: 768, Avg. loss: 24049244555706903214128365568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 242039028932.58, NNZs: 2, Bias: 125337545164.941147, T: 896, Avg. loss: 1168747639117562540619464704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 71353127278.14, NNZs: 2, Bias: 143354420303.035156, T: 1024, Avg. loss: 947654530165741783521165312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 267855223836.55, NNZs: 2, Bias: 162221585916.673523, T: 1152, Avg. loss: 880550582674564246568697856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 304741026929.91, NNZs: 2, Bias: 159710869755.447845, T: 1280, Avg. loss: 886127689214822469435654144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 342552002437.73, NNZs: 2, Bias: 159167020324.100250, T: 1408, Avg. loss: 975072905977293310194089984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 277133008996.29, NNZs: 2, Bias: 145293468504.435089, T: 1536, Avg. loss: 940838183409042727049887744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 342331265381.15, NNZs: 2, Bias: 133993861819.329483, T: 1664, Avg. loss: 906621597231405905020452864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 280294995422.70, NNZs: 2, Bias: 124958217032.298798, T: 1792, Avg. loss: 968496257241506478511095808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 47578956616.55, NNZs: 2, Bias: 124855411738.469955, T: 1920, Avg. loss: 56730858806936982106669056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 65616642208.92, NNZs: 2, Bias: 125541184858.168060, T: 2048, Avg. loss: 38049256068016227806609408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41378658123.68, NNZs: 2, Bias: 123954520248.334885, T: 2176, Avg. loss: 34277054111298332617867264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 68133449411.25, NNZs: 2, Bias: 123222648048.895340, T: 2304, Avg. loss: 32190990246561622704259072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 6316212462.79, NNZs: 2, Bias: 119534367835.815918, T: 2432, Avg. loss: 34915448603447547832303616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42384065231.45, NNZs: 2, Bias: 117929843869.679443, T: 2560, Avg. loss: 32588394929933996276056064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 82143700275.46, NNZs: 2, Bias: 112966833586.742310, T: 2688, Avg. loss: 35233540687975958668378112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 91917116909.15, NNZs: 2, Bias: 114498849792.101334, T: 2816, Avg. loss: 38842637282495754540154880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 66732020769.20, NNZs: 2, Bias: 112095511839.913940, T: 2944, Avg. loss: 34545567936273269292793856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 9932665032.59, NNZs: 2, Bias: 112535147475.445145, T: 3072, Avg. loss: 1673032200024596284440576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10739328938.83, NNZs: 2, Bias: 112370951258.901413, T: 3200, Avg. loss: 742706908578942036213760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8669827168.61, NNZs: 2, Bias: 112248641674.516739, T: 3328, Avg. loss: 671844539794452432027648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 9284832565.56, NNZs: 2, Bias: 112166429996.189651, T: 3456, Avg. loss: 682945129891129102172160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2507822410.10, NNZs: 2, Bias: 112155608611.187485, T: 3584, Avg. loss: 550037159221434010042368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3412376906.67, NNZs: 2, Bias: 112172154007.104233, T: 3712, Avg. loss: 573918221548245594669056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4781483674.85, NNZs: 2, Bias: 112165256342.315094, T: 3840, Avg. loss: 748615775205898422583296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6713320941.72, NNZs: 2, Bias: 111992145850.502975, T: 3968, Avg. loss: 860821520009304905613312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 13085430824.88, NNZs: 2, Bias: 111612529697.084351, T: 4096, Avg. loss: 632815162751668803600384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7223498456.90, NNZs: 2, Bias: 111996929505.857147, T: 4224, Avg. loss: 821022275615076177149952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4529341629.18, NNZs: 2, Bias: 111999172024.157471, T: 4352, Avg. loss: 5549981728720114679808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3239270825.19, NNZs: 2, Bias: 111983858131.272629, T: 4480, Avg. loss: 2292609758450018156544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2661880770.36, NNZs: 2, Bias: 111959368642.750885, T: 4608, Avg. loss: 1452336578495119097856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2219758221.35, NNZs: 2, Bias: 111932133518.696213, T: 4736, Avg. loss: 1323647728572885630976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1897202817.49, NNZs: 2, Bias: 111905994669.856979, T: 4864, Avg. loss: 1154931305374578638848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1744348467.66, NNZs: 2, Bias: 111875630429.927139, T: 4992, Avg. loss: 1162381088044910379008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1686022925.50, NNZs: 2, Bias: 111844001487.792145, T: 5120, Avg. loss: 1088592080587797954560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1704547090.35, NNZs: 2, Bias: 111810285711.378601, T: 5248, Avg. loss: 1131308624391128743936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1559743802.31, NNZs: 2, Bias: 111780080623.780289, T: 5376, Avg. loss: 1118413712520052604928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1647106666.40, NNZs: 2, Bias: 111746628737.320938, T: 5504, Avg. loss: 1087091668988316876800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1701441575.28, NNZs: 2, Bias: 111712685256.198196, T: 5632, Avg. loss: 1134630717278976475136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1703127739.04, NNZs: 2, Bias: 111680231890.841003, T: 5760, Avg. loss: 1075986180258390999040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1725891052.05, NNZs: 2, Bias: 111646941531.518112, T: 5888, Avg. loss: 1119345491724748324864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1765175241.09, NNZs: 2, Bias: 111616520272.744553, T: 6016, Avg. loss: 1030625074656145833984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1755744485.44, NNZs: 2, Bias: 111584510163.725784, T: 6144, Avg. loss: 1078825250095181070336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1767007708.83, NNZs: 2, Bias: 111551665053.221359, T: 6272, Avg. loss: 1114532922332796026880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1614376726.57, NNZs: 2, Bias: 111519866438.828369, T: 6400, Avg. loss: 1194498870490365165568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1647655785.55, NNZs: 2, Bias: 111486245002.033356, T: 6528, Avg. loss: 1128657935869941252096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1743170694.51, NNZs: 2, Bias: 111453001839.958374, T: 6656, Avg. loss: 1055472425068974309376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1762912464.42, NNZs: 2, Bias: 111446029803.115295, T: 6784, Avg. loss: 936243084257435582464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1768437921.31, NNZs: 2, Bias: 111439514009.636124, T: 6912, Avg. loss: 902945980262986547200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1757410404.24, NNZs: 2, Bias: 111433160403.101349, T: 7040, Avg. loss: 917570133583682994176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1770452591.92, NNZs: 2, Bias: 111426458209.577057, T: 7168, Avg. loss: 913322699035618705408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1748808469.05, NNZs: 2, Bias: 111420280274.137009, T: 7296, Avg. loss: 919090588659830095872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1714168444.72, NNZs: 2, Bias: 111414329945.798309, T: 7424, Avg. loss: 912673658328244420608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1711967297.43, NNZs: 2, Bias: 111407845590.255936, T: 7552, Avg. loss: 914245159163680129024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1721440752.72, NNZs: 2, Bias: 111406388952.606094, T: 7680, Avg. loss: 896444584870697762816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1723591637.46, NNZs: 2, Bias: 111405058067.783905, T: 7808, Avg. loss: 887733815155771703296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1726074500.17, NNZs: 2, Bias: 111403724219.629608, T: 7936, Avg. loss: 886136417765880627200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1724536756.79, NNZs: 2, Bias: 111402451875.929321, T: 8064, Avg. loss: 886754399193776914432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1721600184.72, NNZs: 2, Bias: 111401202461.651291, T: 8192, Avg. loss: 885936501760710934528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1719922014.38, NNZs: 2, Bias: 111399936190.571976, T: 8320, Avg. loss: 883986339617212071936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1721834306.96, NNZs: 2, Bias: 111398610915.823822, T: 8448, Avg. loss: 886366903811760979968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1723421680.22, NNZs: 2, Bias: 111397291541.210007, T: 8576, Avg. loss: 885752587631354314752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1720799151.10, NNZs: 2, Bias: 111396046686.735321, T: 8704, Avg. loss: 879175871850218520576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1717391339.75, NNZs: 2, Bias: 111394804691.320969, T: 8832, Avg. loss: 885669459883504697344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1720365127.18, NNZs: 2, Bias: 111393463490.890198, T: 8960, Avg. loss: 885964011804488761344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1720032958.67, NNZs: 2, Bias: 111392173311.642166, T: 9088, Avg. loss: 886099987624321351680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1722034018.89, NNZs: 2, Bias: 111390848148.957733, T: 9216, Avg. loss: 885231478639044198400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1715562166.11, NNZs: 2, Bias: 111389654095.051620, T: 9344, Avg. loss: 885259732699252785152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 73 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1594038193077.82, NNZs: 2, Bias: 18135676204.336739, T: 128, Avg. loss: 21274130514576273257686630400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 322106180424.25, NNZs: 2, Bias: 38135676204.336731, T: 256, Avg. loss: 20332884296081267184094937088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2169280259510.26, NNZs: 2, Bias: 74117345912.613403, T: 384, Avg. loss: 20391158993246138121595125760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 284579942435.65, NNZs: 2, Bias: -11600156220.494339, T: 512, Avg. loss: 23013946826176293062506971136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1319511586237.43, NNZs: 2, Bias: 50185658744.479355, T: 640, Avg. loss: 21846632740167778780456157184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 449880018268.28, NNZs: 2, Bias: 131592874605.002625, T: 768, Avg. loss: 21506153994551779459638231040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 252745273948.94, NNZs: 2, Bias: 131592874605.002625, T: 896, Avg. loss: 22249621660752412822994944000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 514313167129.64, NNZs: 2, Bias: 123147364251.148773, T: 1024, Avg. loss: 861918860759339595896717312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 150384253073.07, NNZs: 2, Bias: 126648109057.532181, T: 1152, Avg. loss: 923371503263360647157514240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 524366594868.29, NNZs: 2, Bias: 126907420002.352142, T: 1280, Avg. loss: 771041889107084474694238208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 82318024304.41, NNZs: 2, Bias: 144529003521.884827, T: 1408, Avg. loss: 891865790327835699204587520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 434659367317.64, NNZs: 2, Bias: 149634839903.187683, T: 1536, Avg. loss: 825659819191579419477016576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 313073949906.75, NNZs: 2, Bias: 142353562717.132416, T: 1664, Avg. loss: 857814221998145858281930752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 197121866315.58, NNZs: 2, Bias: 154711491606.477844, T: 1792, Avg. loss: 884863018098236574140465152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 77436866869.28, NNZs: 2, Bias: 170997877287.314972, T: 1920, Avg. loss: 807533885286755240796749824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 34033855030.95, NNZs: 2, Bias: 172644152117.923096, T: 2048, Avg. loss: 32749978514625966574141440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 14295561730.16, NNZs: 2, Bias: 171593703411.817352, T: 2176, Avg. loss: 33615295445530270005985280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 10776160864.98, NNZs: 2, Bias: 169498852661.305328, T: 2304, Avg. loss: 34311937328712545246117888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 9642054079.10, NNZs: 2, Bias: 171172520246.766541, T: 2432, Avg. loss: 31383237300418722257698816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43759726946.11, NNZs: 2, Bias: 169198230419.273132, T: 2560, Avg. loss: 30226842893271503160213504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 9940150643.09, NNZs: 2, Bias: 167289173624.804901, T: 2688, Avg. loss: 30697773625661447626293248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10688935257.45, NNZs: 2, Bias: 167270555660.478088, T: 2816, Avg. loss: 34092583489581047479271424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 27207303879.00, NNZs: 2, Bias: 167050235740.554596, T: 2944, Avg. loss: 32153796682929303661314048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 99953326277.52, NNZs: 2, Bias: 168599429676.748413, T: 3072, Avg. loss: 31850915544312746122149888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 65396916860.48, NNZs: 2, Bias: 167206039929.294983, T: 3200, Avg. loss: 34629818184312374358441984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1034537233.40, NNZs: 2, Bias: 167046389462.847931, T: 3328, Avg. loss: 1836618358470381991362560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 819564251.00, NNZs: 2, Bias: 166668009429.079773, T: 3456, Avg. loss: 739261567433808935911424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 10685171584.68, NNZs: 2, Bias: 166379120755.773987, T: 3584, Avg. loss: 449767766791083161288704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4867367361.61, NNZs: 2, Bias: 166565447746.873993, T: 3712, Avg. loss: 593717681368939506958336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3690858014.99, NNZs: 2, Bias: 166615841996.616272, T: 3840, Avg. loss: 561284834128446529470464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11038356848.71, NNZs: 2, Bias: 166394802816.358307, T: 3968, Avg. loss: 666350311148123286667264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6155070370.85, NNZs: 2, Bias: 166205871163.638885, T: 4096, Avg. loss: 708074591613407301992448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7486554812.71, NNZs: 2, Bias: 165781120797.092804, T: 4224, Avg. loss: 697462386474503903379456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2216179429.69, NNZs: 2, Bias: 165675143000.244507, T: 4352, Avg. loss: 20068398179839106875392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2577351738.01, NNZs: 2, Bias: 165613327982.231506, T: 4480, Avg. loss: 2873738655104299433984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2687363814.82, NNZs: 2, Bias: 165550666922.887543, T: 4608, Avg. loss: 3034474322730709680128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2650988436.87, NNZs: 2, Bias: 165494822517.323486, T: 4736, Avg. loss: 2911555062341249794048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2629145400.26, NNZs: 2, Bias: 165439006125.846771, T: 4864, Avg. loss: 2820466816479516950528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2838188550.66, NNZs: 2, Bias: 165378397415.961731, T: 4992, Avg. loss: 2878929838478500823040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2776581450.32, NNZs: 2, Bias: 165319871446.446259, T: 5120, Avg. loss: 3049433302458150944768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2713691734.08, NNZs: 2, Bias: 165261661585.446655, T: 5248, Avg. loss: 3028178043495459586048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2788784924.12, NNZs: 2, Bias: 165205436212.559052, T: 5376, Avg. loss: 2786550842869239250944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2693437013.22, NNZs: 2, Bias: 165150467151.299042, T: 5504, Avg. loss: 2785206613498981777408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2555683315.88, NNZs: 2, Bias: 165093148868.593292, T: 5632, Avg. loss: 3010215902034982338560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2743609654.30, NNZs: 2, Bias: 165035447847.017853, T: 5760, Avg. loss: 2771740656509086859264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2739543608.05, NNZs: 2, Bias: 164975435615.821869, T: 5888, Avg. loss: 2961255106015916982272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2779940183.46, NNZs: 2, Bias: 164919587123.908264, T: 6016, Avg. loss: 2776468561214501289984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2808090328.21, NNZs: 2, Bias: 164862378966.564667, T: 6144, Avg. loss: 2782507731315768950784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2605772734.08, NNZs: 2, Bias: 164805486413.770264, T: 6272, Avg. loss: 2952428724591430991872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2555329514.40, NNZs: 2, Bias: 164750393528.498077, T: 6400, Avg. loss: 2746838844143535390720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2644116677.50, NNZs: 2, Bias: 164691782381.982452, T: 6528, Avg. loss: 2920014910604651790336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2435683249.17, NNZs: 2, Bias: 164633992165.905090, T: 6656, Avg. loss: 3244513894848637960192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2500565039.64, NNZs: 2, Bias: 164577492219.294006, T: 6784, Avg. loss: 2951143053550855651328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2601863806.72, NNZs: 2, Bias: 164514907397.741943, T: 6912, Avg. loss: 3059975319642393018368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2615503848.97, NNZs: 2, Bias: 164455162950.387512, T: 7040, Avg. loss: 3049289357961979232256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2588110973.32, NNZs: 2, Bias: 164444164163.406769, T: 7168, Avg. loss: 2367474317294812266496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2597932763.21, NNZs: 2, Bias: 164432471142.341461, T: 7296, Avg. loss: 2387393418975828770816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2645578010.04, NNZs: 2, Bias: 164420104787.651886, T: 7424, Avg. loss: 2403909551545618792448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2613585648.22, NNZs: 2, Bias: 164408994783.576599, T: 7552, Avg. loss: 2406310562190845280256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2651164495.48, NNZs: 2, Bias: 164396738067.221222, T: 7680, Avg. loss: 2411516026410013556736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2676645435.50, NNZs: 2, Bias: 164384819197.315979, T: 7808, Avg. loss: 2376788826788994220032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2664483055.53, NNZs: 2, Bias: 164382688290.431885, T: 7936, Avg. loss: 2351037819689006530560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2650398203.66, NNZs: 2, Bias: 164380608427.840973, T: 8064, Avg. loss: 2329619082239119196160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2648673370.24, NNZs: 2, Bias: 164378325863.776337, T: 8192, Avg. loss: 2331908481369028952064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2653780300.73, NNZs: 2, Bias: 164375935317.309784, T: 8320, Avg. loss: 2328887560601897795584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2658948036.25, NNZs: 2, Bias: 164373549225.112122, T: 8448, Avg. loss: 2323458772028514893824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2657720816.02, NNZs: 2, Bias: 164371262560.860077, T: 8576, Avg. loss: 2327887005176203313152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2657989310.73, NNZs: 2, Bias: 164368947950.565979, T: 8704, Avg. loss: 2331381626231640555520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2666553930.08, NNZs: 2, Bias: 164366511438.441437, T: 8832, Avg. loss: 2317944076291297509376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2659075431.69, NNZs: 2, Bias: 164364319544.650085, T: 8960, Avg. loss: 2334856563966343380992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2657929093.18, NNZs: 2, Bias: 164362030047.894226, T: 9088, Avg. loss: 2329394052065254178816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2660428805.64, NNZs: 2, Bias: 164359680071.171234, T: 9216, Avg. loss: 2330561740359064616960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2659406604.06, NNZs: 2, Bias: 164357388150.913208, T: 9344, Avg. loss: 2329501714578521718784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2653410458.18, NNZs: 2, Bias: 164355178831.100281, T: 9472, Avg. loss: 2327721927640109547520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 74 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1114100114134.01, NNZs: 2, Bias: -51910726165.861023, T: 128, Avg. loss: 20325686758531681372946300928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 959422994198.48, NNZs: 2, Bias: 12630194141.017136, T: 256, Avg. loss: 19761818865226624521591586816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 865725229299.17, NNZs: 2, Bias: 32630194141.017136, T: 384, Avg. loss: 19636804730222182043903590400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1143535164456.19, NNZs: 2, Bias: 52630194141.017136, T: 512, Avg. loss: 20060305978803000247240884224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 941966522460.97, NNZs: 2, Bias: 32630194141.017136, T: 640, Avg. loss: 19684525315556157961225109504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 959332312057.54, NNZs: 2, Bias: 32630194141.017136, T: 768, Avg. loss: 19814949970762397696173015040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1137176501560.38, NNZs: 2, Bias: 22410590213.888046, T: 896, Avg. loss: 19828801624543313639795326976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2796707027097.45, NNZs: 2, Bias: -37589409786.111954, T: 1024, Avg. loss: 18262928278578479619387686912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 787635007128.33, NNZs: 2, Bias: -25058048264.757324, T: 1152, Avg. loss: 20213934889917959977434087424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1380983830039.99, NNZs: 2, Bias: -65058048264.757324, T: 1280, Avg. loss: 19145689841792397300526481408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 521748484565.22, NNZs: 2, Bias: -5058048264.757324, T: 1408, Avg. loss: 22203651772074061331481755648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 807077138232.45, NNZs: 2, Bias: 78706026658.994965, T: 1536, Avg. loss: 19447423448620509622815424512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1610761276816.29, NNZs: 2, Bias: 98706026658.994965, T: 1664, Avg. loss: 20000446554939422441755115520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 183041996738.48, NNZs: 2, Bias: 122357781340.684814, T: 1792, Avg. loss: 1378838864574055122544361472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 182608719222.80, NNZs: 2, Bias: 139393155921.583527, T: 1920, Avg. loss: 759042057857025337102172160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 247659551345.94, NNZs: 2, Bias: 147376071224.923767, T: 2048, Avg. loss: 766599421069379639284072448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 330299546597.78, NNZs: 2, Bias: 143280964002.966797, T: 2176, Avg. loss: 883620438961666018687057920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 164668495109.26, NNZs: 2, Bias: 163416853816.021851, T: 2304, Avg. loss: 767330780427407209254617088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 198855972257.18, NNZs: 2, Bias: 158043257586.784332, T: 2432, Avg. loss: 875512752515869079181983744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 274583310590.54, NNZs: 2, Bias: 156685051982.112091, T: 2560, Avg. loss: 779604382685511801810976768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 72381106603.95, NNZs: 2, Bias: 160357820080.941071, T: 2688, Avg. loss: 41479390494584754164203520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 52831210982.36, NNZs: 2, Bias: 157523787769.783447, T: 2816, Avg. loss: 30813831548830784270893056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 43741173766.31, NNZs: 2, Bias: 157076710117.776306, T: 2944, Avg. loss: 28734879601804999259062272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 75591482915.66, NNZs: 2, Bias: 154354079148.651947, T: 3072, Avg. loss: 28196632331532767707791360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 35648826850.39, NNZs: 2, Bias: 154052940676.622925, T: 3200, Avg. loss: 29984210920967744490831872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 33768544646.90, NNZs: 2, Bias: 154179943774.284760, T: 3328, Avg. loss: 29400009632045789660315648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 36434267966.26, NNZs: 2, Bias: 151980836124.561920, T: 3456, Avg. loss: 27553669761562111813615616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 25944420897.66, NNZs: 2, Bias: 151938540513.168732, T: 3584, Avg. loss: 29065140595144356943364096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 21811882228.16, NNZs: 2, Bias: 152690733780.408051, T: 3712, Avg. loss: 32040415372100932997218304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 27588784725.22, NNZs: 2, Bias: 154696944579.432129, T: 3840, Avg. loss: 29870843352489426153373696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 16863518624.56, NNZs: 2, Bias: 151634823048.581879, T: 3968, Avg. loss: 29247166985769629886971904.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 37917891862.03, NNZs: 2, Bias: 155644749156.506195, T: 4096, Avg. loss: 26603445520991053353582592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 25799873272.97, NNZs: 2, Bias: 156034377711.936798, T: 4224, Avg. loss: 29208195721194593371291648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 24919520380.06, NNZs: 2, Bias: 153788943443.126923, T: 4352, Avg. loss: 30469410079377632171917312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 36237098213.26, NNZs: 2, Bias: 153254752583.820648, T: 4480, Avg. loss: 26941050264762235188412416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 36143562780.09, NNZs: 2, Bias: 152369691079.089447, T: 4608, Avg. loss: 28945450902275963563802624.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 78204996803.13, NNZs: 2, Bias: 153599941872.639771, T: 4736, Avg. loss: 25940486002781171908345856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 66301322599.68, NNZs: 2, Bias: 150759453730.833344, T: 4864, Avg. loss: 28465046996446830598815744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 80136280043.05, NNZs: 2, Bias: 147621323743.369537, T: 4992, Avg. loss: 31820742723628602287456256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 61010033465.61, NNZs: 2, Bias: 150084940201.803406, T: 5120, Avg. loss: 28572664765738379603083264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 33191642918.59, NNZs: 2, Bias: 148083159397.928162, T: 5248, Avg. loss: 30076699594682490299613184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 63991076675.72, NNZs: 2, Bias: 143234052273.016968, T: 5376, Avg. loss: 29337877506209038481752064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 8553736734.81, NNZs: 2, Bias: 144000636276.210175, T: 5504, Avg. loss: 1331844189767214066302976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5568258952.08, NNZs: 2, Bias: 143795961953.172577, T: 5632, Avg. loss: 697892104221392096985088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 5875020421.96, NNZs: 2, Bias: 143415545596.288605, T: 5760, Avg. loss: 437775578458617764904960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3178668920.01, NNZs: 2, Bias: 143084477355.276886, T: 5888, Avg. loss: 521523124717034571563008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 13908553523.88, NNZs: 2, Bias: 142781738371.974182, T: 6016, Avg. loss: 421186489447596410535936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3071057526.58, NNZs: 2, Bias: 142736827199.440369, T: 6144, Avg. loss: 683039629637764914348032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3139823408.50, NNZs: 2, Bias: 142632491202.120331, T: 6272, Avg. loss: 607865075797975455760384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 11690259522.74, NNZs: 2, Bias: 142433758755.737915, T: 6400, Avg. loss: 533930469067075778248704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 5918211654.36, NNZs: 2, Bias: 142359628061.151215, T: 6528, Avg. loss: 470144124851102762926080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3676063824.64, NNZs: 2, Bias: 142318946020.736542, T: 6656, Avg. loss: 490254718549297121460224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3161851592.14, NNZs: 2, Bias: 142276789448.378937, T: 6784, Avg. loss: 2581779777873735319552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2905564253.10, NNZs: 2, Bias: 142235825825.354279, T: 6912, Avg. loss: 2168860973518281506816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2689121294.80, NNZs: 2, Bias: 142190141114.121368, T: 7040, Avg. loss: 2270651046040950276096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2527404284.80, NNZs: 2, Bias: 142146849331.095947, T: 7168, Avg. loss: 2003741220917124005888.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2453923550.93, NNZs: 2, Bias: 142099941111.896759, T: 7296, Avg. loss: 2105432686558540464128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2355416532.89, NNZs: 2, Bias: 142055714863.459381, T: 7424, Avg. loss: 2045915054494710497280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2448337629.28, NNZs: 2, Bias: 142005728612.919250, T: 7552, Avg. loss: 2053644383107816882176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2296116333.82, NNZs: 2, Bias: 141964492794.403625, T: 7680, Avg. loss: 1888724504237274300416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2438122404.34, NNZs: 2, Bias: 141913391797.604279, T: 7808, Avg. loss: 2159366308193533165568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2468612611.80, NNZs: 2, Bias: 141863587714.353790, T: 7936, Avg. loss: 2220439160336682319872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2350958725.58, NNZs: 2, Bias: 141819438622.327942, T: 8064, Avg. loss: 2073881859737905266688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2467404055.16, NNZs: 2, Bias: 141771013129.123474, T: 8192, Avg. loss: 1950857432009394618368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2262103623.26, NNZs: 2, Bias: 141724722742.486084, T: 8320, Avg. loss: 2172237900575894929408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2356606381.29, NNZs: 2, Bias: 141713396215.208008, T: 8448, Avg. loss: 1752208688215070081024.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2343934699.56, NNZs: 2, Bias: 141703946160.457367, T: 8576, Avg. loss: 1730251216341437251584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2355283102.54, NNZs: 2, Bias: 141694103218.883331, T: 8704, Avg. loss: 1727566011820209078272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2342594135.25, NNZs: 2, Bias: 141684573128.459839, T: 8832, Avg. loss: 1744695941730639020032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2358332471.66, NNZs: 2, Bias: 141674716190.268188, T: 8960, Avg. loss: 1716502845081149767680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2349055716.05, NNZs: 2, Bias: 141665301702.612335, T: 9088, Avg. loss: 1715375145354766319616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2364358686.49, NNZs: 2, Bias: 141655470404.759766, T: 9216, Avg. loss: 1709604309302183985152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2356040111.00, NNZs: 2, Bias: 141646238434.814148, T: 9344, Avg. loss: 1678276788121177948160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2388014008.50, NNZs: 2, Bias: 141636182062.015106, T: 9472, Avg. loss: 1700140715434060808192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2363583409.12, NNZs: 2, Bias: 141626983335.282715, T: 9600, Avg. loss: 1722198496362147086336.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2366802521.18, NNZs: 2, Bias: 141617239129.431000, T: 9728, Avg. loss: 1733160855512974098432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2356582832.53, NNZs: 2, Bias: 141607802549.813385, T: 9856, Avg. loss: 1720293848372774436864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2371314954.89, NNZs: 2, Bias: 141598022316.730682, T: 9984, Avg. loss: 1705728024642892595200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2377754024.66, NNZs: 2, Bias: 141596002156.513336, T: 10112, Avg. loss: 1663072520201508225024.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2382981795.83, NNZs: 2, Bias: 141594005540.240601, T: 10240, Avg. loss: 1660017310192920428544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 2376921213.16, NNZs: 2, Bias: 141592201414.455200, T: 10368, Avg. loss: 1658234107349437513728.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 2385096408.24, NNZs: 2, Bias: 141590156697.061676, T: 10496, Avg. loss: 1658589037111332306944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 2373127216.09, NNZs: 2, Bias: 141588464250.043762, T: 10624, Avg. loss: 1647736397805758709760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 2372216290.85, NNZs: 2, Bias: 141586580667.113464, T: 10752, Avg. loss: 1651866156913893048320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 2377887724.61, NNZs: 2, Bias: 141584575372.329102, T: 10880, Avg. loss: 1661170444796906438656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 2382732101.99, NNZs: 2, Bias: 141582588041.869202, T: 11008, Avg. loss: 1657413848356685611008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 2378668941.17, NNZs: 2, Bias: 141580750030.441498, T: 11136, Avg. loss: 1658352198653718822912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 2388873985.70, NNZs: 2, Bias: 141578677471.103180, T: 11264, Avg. loss: 1652683085891202187264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 88 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1057130777552.50, NNZs: 2, Bias: 131040239428.431335, T: 128, Avg. loss: 19812530298027752740152672256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1459276025189.24, NNZs: 2, Bias: 104217037077.722046, T: 256, Avg. loss: 20914214073456818709738815488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2447275288682.40, NNZs: 2, Bias: 48565679176.519302, T: 384, Avg. loss: 21412062387514093222508888064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 470816180343.71, NNZs: 2, Bias: 68565679176.519302, T: 512, Avg. loss: 21632702015845026621602922496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 155739735617.88, NNZs: 2, Bias: 48565679176.519302, T: 640, Avg. loss: 21631515082501930007230676992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1168771533037.31, NNZs: 2, Bias: -11434320823.480698, T: 768, Avg. loss: 21099228252564663029716746240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39935620131.16, NNZs: 2, Bias: -9145692824.739285, T: 896, Avg. loss: 1039567243053708289425539072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 378033344838.93, NNZs: 2, Bias: -32760840087.349968, T: 1024, Avg. loss: 853577652660523421791158272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 317695915416.16, NNZs: 2, Bias: -57052212412.567650, T: 1152, Avg. loss: 795502618372325390738784256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 156566902091.61, NNZs: 2, Bias: -46820523144.627579, T: 1280, Avg. loss: 876559290329825486577860608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 29585104659.71, NNZs: 2, Bias: -44999321923.013893, T: 1408, Avg. loss: 867294999557819253571715072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 161877948728.12, NNZs: 2, Bias: -65022987122.964157, T: 1536, Avg. loss: 782375374033930029197426688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 336743656228.51, NNZs: 2, Bias: -57306763336.423035, T: 1664, Avg. loss: 809829845837231567604285440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 498579935923.40, NNZs: 2, Bias: -62079689008.544510, T: 1792, Avg. loss: 811129653145663694717321216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 132072024834.24, NNZs: 2, Bias: -60015119282.718353, T: 1920, Avg. loss: 874893219740508362018652160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 80757394918.79, NNZs: 2, Bias: -63653098553.573227, T: 2048, Avg. loss: 857258950987884562260951040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 101394458227.16, NNZs: 2, Bias: -58552552071.867393, T: 2176, Avg. loss: 817983693527548716436684800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 35325282219.42, NNZs: 2, Bias: -55077099104.830185, T: 2304, Avg. loss: 32326807063527439820914688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 95849170972.47, NNZs: 2, Bias: -58370591796.565125, T: 2432, Avg. loss: 27826588918642575883108352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 32301783511.37, NNZs: 2, Bias: -58521506281.182121, T: 2560, Avg. loss: 30731564771285226177429504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 49986977385.84, NNZs: 2, Bias: -57884528735.657524, T: 2688, Avg. loss: 31510360059164456980054016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 44686356782.67, NNZs: 2, Bias: -60564055195.713417, T: 2816, Avg. loss: 33059474034068028500475904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 41976797554.80, NNZs: 2, Bias: -61203666987.508888, T: 2944, Avg. loss: 28848009891919189852028928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 63167606719.51, NNZs: 2, Bias: -59428877207.883888, T: 3072, Avg. loss: 32602501742274977458028544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1151336730.45, NNZs: 2, Bias: -59208010312.782738, T: 3200, Avg. loss: 1320969374661681109532672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 9404340620.82, NNZs: 2, Bias: -59120106582.251503, T: 3328, Avg. loss: 452550950275466586488832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2019191594.41, NNZs: 2, Bias: -58953170491.483284, T: 3456, Avg. loss: 460196355337880592187392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3494414579.62, NNZs: 2, Bias: -59204160523.325783, T: 3584, Avg. loss: 595356604376546271035392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2458627206.91, NNZs: 2, Bias: -58837918774.213699, T: 3712, Avg. loss: 641845241982452787838976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1826583969.68, NNZs: 2, Bias: -58639862539.861206, T: 3840, Avg. loss: 473948005933021719953408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2616070979.34, NNZs: 2, Bias: -58675597099.803520, T: 3968, Avg. loss: 426769431747554898345984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 21260954175.49, NNZs: 2, Bias: -58386818611.137825, T: 4096, Avg. loss: 418032092106650999062528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 15949089715.15, NNZs: 2, Bias: -58291839861.195831, T: 4224, Avg. loss: 515766128602718459133952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4455515071.50, NNZs: 2, Bias: -58441968173.217285, T: 4352, Avg. loss: 550272340359643689648128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2443335442.72, NNZs: 2, Bias: -58325691914.320847, T: 4480, Avg. loss: 508091680772556415041536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3919946193.93, NNZs: 2, Bias: -58068447899.277725, T: 4608, Avg. loss: 508783537726895016640512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1405713916.42, NNZs: 2, Bias: -57928379777.313255, T: 4736, Avg. loss: 534503996035687562346496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1277779828.88, NNZs: 2, Bias: -57911530681.238098, T: 4864, Avg. loss: 371914831435232903168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1180032601.57, NNZs: 2, Bias: -57895672970.255188, T: 4992, Avg. loss: 317929454081802240000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1132670961.18, NNZs: 2, Bias: -57877547497.500938, T: 5120, Avg. loss: 339821267305413345280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1109941459.81, NNZs: 2, Bias: -57859241476.590363, T: 5248, Avg. loss: 336075716846596980736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1108900351.40, NNZs: 2, Bias: -57840877912.549294, T: 5376, Avg. loss: 327320556234144874496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1135077114.44, NNZs: 2, Bias: -57821925821.458046, T: 5504, Avg. loss: 330386936221883826176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1081069829.68, NNZs: 2, Bias: -57804927038.860458, T: 5632, Avg. loss: 320107225718921363456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1080039801.71, NNZs: 2, Bias: -57801272447.323196, T: 5760, Avg. loss: 268290548941585350656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1077783806.15, NNZs: 2, Bias: -57797726733.969299, T: 5888, Avg. loss: 261524301085441097728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1077604023.12, NNZs: 2, Bias: -57794139474.755424, T: 6016, Avg. loss: 261981087928155602944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1073465010.67, NNZs: 2, Bias: -57790702887.770485, T: 6144, Avg. loss: 255467542680512593920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1083592693.25, NNZs: 2, Bias: -57786840023.405884, T: 6272, Avg. loss: 267921570494310055936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1088452955.04, NNZs: 2, Bias: -57783074440.632896, T: 6400, Avg. loss: 267637190236168388608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1084114464.51, NNZs: 2, Bias: -57779501813.182396, T: 6528, Avg. loss: 266605886607741222912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1076153872.12, NNZs: 2, Bias: -57775986315.375435, T: 6656, Avg. loss: 267597335168211386368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1073018515.06, NNZs: 2, Bias: -57772428141.873886, T: 6784, Avg. loss: 263895577699730423808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1085737092.19, NNZs: 2, Bias: -57771460974.931595, T: 6912, Avg. loss: 258528798035018842112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1083742834.21, NNZs: 2, Bias: -57770775321.491592, T: 7040, Avg. loss: 256603347182645411840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1081938621.33, NNZs: 2, Bias: -57770090804.854294, T: 7168, Avg. loss: 254879823829299888128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1084986688.18, NNZs: 2, Bias: -57769309274.044502, T: 7296, Avg. loss: 256930499383956242432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1084945231.37, NNZs: 2, Bias: -57768587854.857773, T: 7424, Avg. loss: 256228367120943611904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1083290547.29, NNZs: 2, Bias: -57767896560.934845, T: 7552, Avg. loss: 256341211236459577344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1084689428.59, NNZs: 2, Bias: -57767146536.135666, T: 7680, Avg. loss: 256754069480756543488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1084023303.62, NNZs: 2, Bias: -57766436394.665977, T: 7808, Avg. loss: 256399407231144165376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 61 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1801366347674.52, NNZs: 2, Bias: -4540394997.779816, T: 128, Avg. loss: 21379702263179216040943943680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1014025504839.76, NNZs: 2, Bias: -4540394997.779816, T: 256, Avg. loss: 25118571919249858793308160000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 874975575026.09, NNZs: 2, Bias: 49289419837.571693, T: 384, Avg. loss: 21128278273069090816196083712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 637960318261.00, NNZs: 2, Bias: 49289419837.571686, T: 512, Avg. loss: 22188264851830545789713645568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2849680999466.26, NNZs: 2, Bias: 13883660295.868126, T: 640, Avg. loss: 21018264567094287890879873024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1340202490095.05, NNZs: 2, Bias: 80161237592.320190, T: 768, Avg. loss: 23549482882343957375007850496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 765923846646.60, NNZs: 2, Bias: 68265454641.220245, T: 896, Avg. loss: 20922607624464584710356467712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2136738584732.43, NNZs: 2, Bias: 108265454641.220245, T: 1024, Avg. loss: 22090532368595449069841678336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 371613478399.85, NNZs: 2, Bias: 32525892306.247330, T: 1152, Avg. loss: 25210964353637967755464409088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2659765033700.75, NNZs: 2, Bias: 52525892306.247330, T: 1280, Avg. loss: 21560573785746579842190540800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1331765696207.46, NNZs: 2, Bias: 52525892306.247330, T: 1408, Avg. loss: 22368352557189929876137705472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1913853205804.45, NNZs: 2, Bias: 44704265293.494904, T: 1536, Avg. loss: 21988888619217126220330172416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 147770266879.87, NNZs: 2, Bias: 42796578761.652374, T: 1664, Avg. loss: 2341946080186066683801108480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 564325448495.54, NNZs: 2, Bias: 24486874174.326767, T: 1792, Avg. loss: 929653067445738634058137600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 72277619963.94, NNZs: 2, Bias: 22369943971.369331, T: 1920, Avg. loss: 1006499172147660751911256064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 171598975483.67, NNZs: 2, Bias: 29081350642.972809, T: 2048, Avg. loss: 884959994324774994990596096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 286056199310.77, NNZs: 2, Bias: 25477417172.260483, T: 2176, Avg. loss: 855533512007963573705768960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 177791925783.74, NNZs: 2, Bias: 30560770435.236320, T: 2304, Avg. loss: 874917609096358934234529792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 122574683745.65, NNZs: 2, Bias: 18216723454.443855, T: 2432, Avg. loss: 861096221183426570712252416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 123789734152.64, NNZs: 2, Bias: 15848784272.224117, T: 2560, Avg. loss: 848377927863029537464909824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 120211377161.20, NNZs: 2, Bias: 18028640071.026871, T: 2688, Avg. loss: 798708606246983306355671040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 109227665366.59, NNZs: 2, Bias: 39780390274.503456, T: 2816, Avg. loss: 941831603761325414354518016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 47179924854.74, NNZs: 2, Bias: 22485892400.614346, T: 2944, Avg. loss: 835850554951159911597211648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 458731111828.86, NNZs: 2, Bias: 3056269295.389549, T: 3072, Avg. loss: 888347179874869199048278016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 561990670273.60, NNZs: 2, Bias: 29181463016.904915, T: 3200, Avg. loss: 856902130051312851523469312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 241999630376.10, NNZs: 2, Bias: 18889021643.714542, T: 3328, Avg. loss: 975609394850852956805267456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 69420131433.39, NNZs: 2, Bias: 19864777334.959816, T: 3456, Avg. loss: 48053427654091721475620864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 20898937812.19, NNZs: 2, Bias: 21456116141.496876, T: 3584, Avg. loss: 33214020892260541000581120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 32120488998.66, NNZs: 2, Bias: 20471678211.118103, T: 3712, Avg. loss: 34250084538877646498430976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 21997132935.33, NNZs: 2, Bias: 21728130806.298649, T: 3840, Avg. loss: 31649074328755616215990272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 40369218612.89, NNZs: 2, Bias: 20657010924.354931, T: 3968, Avg. loss: 31031615994799150063419392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 98445118674.99, NNZs: 2, Bias: 18834950476.623379, T: 4096, Avg. loss: 32981222756457130582081536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 53874958018.10, NNZs: 2, Bias: 18802570870.322170, T: 4224, Avg. loss: 34154486401929352790933504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 59932536297.62, NNZs: 2, Bias: 15873940749.182299, T: 4352, Avg. loss: 30478315062741790565072896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 49242343093.84, NNZs: 2, Bias: 15569412392.796839, T: 4480, Avg. loss: 32512652912461920681852928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11893808094.49, NNZs: 2, Bias: 14384732120.260736, T: 4608, Avg. loss: 36248916297696023423221760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 94267403118.24, NNZs: 2, Bias: 12297192232.303703, T: 4736, Avg. loss: 30054153545862035753926656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 61837009114.51, NNZs: 2, Bias: 8523209743.544487, T: 4864, Avg. loss: 34649552397281873383915520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 12260599145.52, NNZs: 2, Bias: 11110953132.157944, T: 4992, Avg. loss: 31426356857080610750988288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 8380528123.78, NNZs: 2, Bias: 10248770786.527166, T: 5120, Avg. loss: 30166675207247712994983936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 44801844004.87, NNZs: 2, Bias: 11082861267.599535, T: 5248, Avg. loss: 34966770234524679480016896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 34237066421.02, NNZs: 2, Bias: 9101388183.340595, T: 5376, Avg. loss: 34575566733620385228521472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 19497666125.39, NNZs: 2, Bias: 9756529228.603205, T: 5504, Avg. loss: 911138437053761881899008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1659247984.64, NNZs: 2, Bias: 9480217437.725508, T: 5632, Avg. loss: 578809315873082956578816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 18433403583.38, NNZs: 2, Bias: 9597999696.098560, T: 5760, Avg. loss: 649658889573013733244928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3668758677.25, NNZs: 2, Bias: 9479362503.065538, T: 5888, Avg. loss: 592389698650619527561216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 11238028273.50, NNZs: 2, Bias: 9695849809.273109, T: 6016, Avg. loss: 621987070089379763453952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4325538095.29, NNZs: 2, Bias: 9966118301.232758, T: 6144, Avg. loss: 549699613663487848349696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 5078424914.92, NNZs: 2, Bias: 9699504159.504719, T: 6272, Avg. loss: 720742356248994254946304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3641313344.27, NNZs: 2, Bias: 9706616373.910252, T: 6400, Avg. loss: 713922741907922324815872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 12300390440.95, NNZs: 2, Bias: 9655120950.345942, T: 6528, Avg. loss: 523362472064164021927936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4221293223.21, NNZs: 2, Bias: 9838255693.005220, T: 6656, Avg. loss: 617789554762459700527104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 798275860.12, NNZs: 2, Bias: 9841117118.871431, T: 6784, Avg. loss: 835057803108401824137216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1599197833.89, NNZs: 2, Bias: 9664266745.334444, T: 6912, Avg. loss: 542800497033479930773504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1770559387.15, NNZs: 2, Bias: 9608421132.774742, T: 7040, Avg. loss: 586972779939130268188672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2331050658.19, NNZs: 2, Bias: 9348216819.884443, T: 7168, Avg. loss: 518850616723666565595136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 5539277624.45, NNZs: 2, Bias: 9392880002.641508, T: 7296, Avg. loss: 596801117913558282141696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1470741690.34, NNZs: 2, Bias: 9360477494.069603, T: 7424, Avg. loss: 693106658519462658965504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 17893192473.73, NNZs: 2, Bias: 9374957095.950033, T: 7552, Avg. loss: 571900919464584280014848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 7413805975.02, NNZs: 2, Bias: 9275447198.027222, T: 7680, Avg. loss: 579261971180337997283328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4009890445.34, NNZs: 2, Bias: 9235923849.531843, T: 7808, Avg. loss: 486010071513874168807424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3066760842.18, NNZs: 2, Bias: 8945137168.211195, T: 7936, Avg. loss: 663201383202757841780736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8051297880.32, NNZs: 2, Bias: 9143264299.545078, T: 8064, Avg. loss: 610251488278016946077696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1592493482.36, NNZs: 2, Bias: 9240649858.451544, T: 8192, Avg. loss: 640535618873266823757824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1632839920.01, NNZs: 2, Bias: 9021214417.491192, T: 8320, Avg. loss: 611771486614732849283072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 13249049451.56, NNZs: 2, Bias: 8883396001.695126, T: 8448, Avg. loss: 524887298487938180972544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2048364312.18, NNZs: 2, Bias: 8921022614.026566, T: 8576, Avg. loss: 64497535680983146168320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1227247714.29, NNZs: 2, Bias: 8902629062.645407, T: 8704, Avg. loss: 454815874314627776512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 876659668.57, NNZs: 2, Bias: 8890406764.503983, T: 8832, Avg. loss: 145033846415111012352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 779899197.06, NNZs: 2, Bias: 8883267763.965599, T: 8960, Avg. loss: 40987660142587772928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 763456492.85, NNZs: 2, Bias: 8878103078.323071, T: 9088, Avg. loss: 16467485988954828800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 763943286.95, NNZs: 2, Bias: 8874266195.343916, T: 9216, Avg. loss: 9731081137942630400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 768329060.67, NNZs: 2, Bias: 8870493212.407328, T: 9344, Avg. loss: 8745417299430474752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 771357071.23, NNZs: 2, Bias: 8867281177.275448, T: 9472, Avg. loss: 7818155415098875904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 773001593.44, NNZs: 2, Bias: 8864137870.660885, T: 9600, Avg. loss: 8435962964686511104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 773117757.00, NNZs: 2, Bias: 8861219950.730639, T: 9728, Avg. loss: 7807898557793223680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 774955000.61, NNZs: 2, Bias: 8858134038.980387, T: 9856, Avg. loss: 7900005765482418176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 776160974.21, NNZs: 2, Bias: 8855284368.231976, T: 9984, Avg. loss: 7641682773149925376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 775422040.19, NNZs: 2, Bias: 8852493617.414711, T: 10112, Avg. loss: 7928357290503577600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 774161053.36, NNZs: 2, Bias: 8849524594.091198, T: 10240, Avg. loss: 8412824605388128256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 775648290.37, NNZs: 2, Bias: 8846338924.559870, T: 10368, Avg. loss: 8184512097980385280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 773999000.75, NNZs: 2, Bias: 8843474326.774086, T: 10496, Avg. loss: 8490508636329867264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 773698319.58, NNZs: 2, Bias: 8840607996.052422, T: 10624, Avg. loss: 7909178485592808448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 774133686.03, NNZs: 2, Bias: 8839969308.669716, T: 10752, Avg. loss: 6694639147264871424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 773858560.09, NNZs: 2, Bias: 8839402453.027733, T: 10880, Avg. loss: 6591396807855127552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 774004314.86, NNZs: 2, Bias: 8838803792.423721, T: 11008, Avg. loss: 6530027002197294080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 773728109.80, NNZs: 2, Bias: 8838241888.868624, T: 11136, Avg. loss: 6533981528860616704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 774184006.43, NNZs: 2, Bias: 8837611243.853743, T: 11264, Avg. loss: 6579400210375415808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 773842791.98, NNZs: 2, Bias: 8837048620.064335, T: 11392, Avg. loss: 6613609603280053248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 774101173.29, NNZs: 2, Bias: 8836434248.007650, T: 11520, Avg. loss: 6592099039169820672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 773885372.56, NNZs: 2, Bias: 8835855085.559177, T: 11648, Avg. loss: 6680255332189037568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 774112739.36, NNZs: 2, Bias: 8835715603.927185, T: 11776, Avg. loss: 6485352148035868672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 773996514.34, NNZs: 2, Bias: 8835607948.856783, T: 11904, Avg. loss: 6396848946655588352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 774088804.46, NNZs: 2, Bias: 8835480681.242960, T: 12032, Avg. loss: 6466697824171116544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 774156556.30, NNZs: 2, Bias: 8835355975.008715, T: 12160, Avg. loss: 6444756063657285632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 774067304.94, NNZs: 2, Bias: 8835245162.336468, T: 12288, Avg. loss: 6440470762293525504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 774112730.42, NNZs: 2, Bias: 8835122447.458780, T: 12416, Avg. loss: 6443351024163877888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 774123184.79, NNZs: 2, Bias: 8835002630.345985, T: 12544, Avg. loss: 6452759707447918592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 98 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 889559732829.52, NNZs: 2, Bias: 29372922663.167130, T: 128, Avg. loss: 22246718867350677160753889280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 312409228424.88, NNZs: 2, Bias: 15367050624.492088, T: 256, Avg. loss: 24165307294895128381711450112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1477722427972.14, NNZs: 2, Bias: -26106991797.522545, T: 384, Avg. loss: 23510213867522656212122337280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1665910377482.68, NNZs: 2, Bias: -44467178176.133301, T: 512, Avg. loss: 21334894433558387097591611392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1535799277480.34, NNZs: 2, Bias: -4467178176.133301, T: 640, Avg. loss: 26070073364241078884814028800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1210170069550.84, NNZs: 2, Bias: -97380683556.625320, T: 768, Avg. loss: 23564238928590422130579996672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 661153690985.59, NNZs: 2, Bias: -96147849539.954041, T: 896, Avg. loss: 26537591376747381685582036992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 824760926400.67, NNZs: 2, Bias: -116147849539.954041, T: 1024, Avg. loss: 25206958758886809372731637760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 482910937758.65, NNZs: 2, Bias: -154535487016.279114, T: 1152, Avg. loss: 23857713982366979366192152576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 277591783500.60, NNZs: 2, Bias: -158113585034.979828, T: 1280, Avg. loss: 922321961883859355449688064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 352721316677.18, NNZs: 2, Bias: -153685912523.128784, T: 1408, Avg. loss: 945903396558223794929401856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 521885863022.74, NNZs: 2, Bias: -163794419587.976929, T: 1536, Avg. loss: 861505238436610087627784192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 339920089734.56, NNZs: 2, Bias: -175336174402.681763, T: 1664, Avg. loss: 923691766195721684339654656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 101943971254.82, NNZs: 2, Bias: -175990308271.156158, T: 1792, Avg. loss: 913592378333395757566001152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 477297717011.00, NNZs: 2, Bias: -176098632670.860352, T: 1920, Avg. loss: 917778707136718431630393344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 122796164132.27, NNZs: 2, Bias: -171488903478.794525, T: 2048, Avg. loss: 955985041876234132242038784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 349609408517.17, NNZs: 2, Bias: -172970289595.909302, T: 2176, Avg. loss: 957631811435835491927195648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 13134332321.01, NNZs: 2, Bias: -169094383035.504395, T: 2304, Avg. loss: 55939121740700416422707200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 52277912198.14, NNZs: 2, Bias: -168808011787.366669, T: 2432, Avg. loss: 34525034754304635654111232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 52485128591.17, NNZs: 2, Bias: -169277002379.332977, T: 2560, Avg. loss: 33047059871714417011851264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8261314633.00, NNZs: 2, Bias: -167973823745.173370, T: 2688, Avg. loss: 35716606215408518835470336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 73520032387.46, NNZs: 2, Bias: -169447380371.388885, T: 2816, Avg. loss: 33289004268157066132062208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 35645146997.41, NNZs: 2, Bias: -165493268806.874542, T: 2944, Avg. loss: 38451386465891850844635136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 61587907379.71, NNZs: 2, Bias: -163565982410.269226, T: 3072, Avg. loss: 33588964549231877587730432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 19619776056.80, NNZs: 2, Bias: -163344586382.853577, T: 3200, Avg. loss: 33135867124310646944956416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 14191863821.72, NNZs: 2, Bias: -162678978708.841858, T: 3328, Avg. loss: 865467195281241416925184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 5046530275.43, NNZs: 2, Bias: -162400149786.237549, T: 3456, Avg. loss: 894795809024420419207168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 834569625.74, NNZs: 2, Bias: -162136523181.640594, T: 3584, Avg. loss: 795179088918744339054592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8020060323.24, NNZs: 2, Bias: -162005842368.159363, T: 3712, Avg. loss: 721017452004510978277376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4116257377.93, NNZs: 2, Bias: -161723902430.196167, T: 3840, Avg. loss: 592333432279363093528576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 12493354907.73, NNZs: 2, Bias: -161465576743.110382, T: 3968, Avg. loss: 760004975231700188528640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6495082231.53, NNZs: 2, Bias: -161021846528.221100, T: 4096, Avg. loss: 804836504483237241815040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6187833598.82, NNZs: 2, Bias: -160978515654.967499, T: 4224, Avg. loss: 510827634300925635461120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2436443622.65, NNZs: 2, Bias: -160797030624.164337, T: 4352, Avg. loss: 784089265924296872558592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 17482185443.57, NNZs: 2, Bias: -160518386040.690277, T: 4480, Avg. loss: 604228934416592856416256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 10396123932.84, NNZs: 2, Bias: -160424262563.340485, T: 4608, Avg. loss: 822710569644003329835008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6265299700.27, NNZs: 2, Bias: -160664022029.136658, T: 4736, Avg. loss: 752287421107412140032000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3612162139.58, NNZs: 2, Bias: -160163559866.741974, T: 4864, Avg. loss: 797947887147536374300672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2119003872.55, NNZs: 2, Bias: -160126224269.421387, T: 4992, Avg. loss: 3338536513423573778432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2163483914.55, NNZs: 2, Bias: -160078472521.052032, T: 5120, Avg. loss: 2223284251098208796672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2257771255.55, NNZs: 2, Bias: -160028521653.977783, T: 5248, Avg. loss: 2305479713903978479616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2162923650.02, NNZs: 2, Bias: -159982338653.260223, T: 5376, Avg. loss: 2283748935618837086208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2317389302.36, NNZs: 2, Bias: -159935730800.493805, T: 5504, Avg. loss: 2068271191946458038272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2226303210.02, NNZs: 2, Bias: -159889860459.971344, T: 5632, Avg. loss: 2286622891523969646592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2379273400.44, NNZs: 2, Bias: -159843083710.563110, T: 5760, Avg. loss: 2025854645511600472064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2363680689.05, NNZs: 2, Bias: -159794729672.367065, T: 5888, Avg. loss: 2295113488334803697664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2412846455.39, NNZs: 2, Bias: -159746892847.941467, T: 6016, Avg. loss: 2224710877255080083456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2352719951.20, NNZs: 2, Bias: -159701661879.328308, T: 6144, Avg. loss: 2126102183990789668864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2371397896.25, NNZs: 2, Bias: -159654415995.808777, T: 6272, Avg. loss: 2216217781887950389248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2377075035.13, NNZs: 2, Bias: -159605946893.944122, T: 6400, Avg. loss: 2333983235842633367552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2326850990.92, NNZs: 2, Bias: -159597278547.515717, T: 6528, Avg. loss: 1866964213484185714688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2320389632.31, NNZs: 2, Bias: -159587899538.772888, T: 6656, Avg. loss: 1877485566888981299200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2321368380.46, NNZs: 2, Bias: -159578491386.539062, T: 6784, Avg. loss: 1860009676600719441920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2306388672.67, NNZs: 2, Bias: -159569386397.851562, T: 6912, Avg. loss: 1844318027269570297856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2318903040.14, NNZs: 2, Bias: -159559722850.664246, T: 7040, Avg. loss: 1879410015027858243584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2327861056.64, NNZs: 2, Bias: -159550192092.915558, T: 7168, Avg. loss: 1866002930615551000576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2302287446.80, NNZs: 2, Bias: -159541125133.545807, T: 7296, Avg. loss: 1870066927558595182592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2296856732.70, NNZs: 2, Bias: -159531675439.097839, T: 7424, Avg. loss: 1887878559827471106048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2296483721.61, NNZs: 2, Bias: -159522197811.542450, T: 7552, Avg. loss: 1880147409300234436608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2297398417.19, NNZs: 2, Bias: -159520301789.577454, T: 7680, Avg. loss: 1817557306945793949696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2299191202.22, NNZs: 2, Bias: -159518395216.185425, T: 7808, Avg. loss: 1815375272220679995392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2309893764.57, NNZs: 2, Bias: -159516363061.803253, T: 7936, Avg. loss: 1811862355327020957696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2303352494.15, NNZs: 2, Bias: -159514575556.876862, T: 8064, Avg. loss: 1816824699701606744064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2292464712.74, NNZs: 2, Bias: -159512863383.585480, T: 8192, Avg. loss: 1804378326254126891008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2315430804.81, NNZs: 2, Bias: -159510667743.427338, T: 8320, Avg. loss: 1797873977304855609344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2298225452.09, NNZs: 2, Bias: -159509034504.558502, T: 8448, Avg. loss: 1817086099683230351360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2292560700.05, NNZs: 2, Bias: -159507238905.177460, T: 8576, Avg. loss: 1811876044708289183744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2304761611.67, NNZs: 2, Bias: -159505181785.868134, T: 8704, Avg. loss: 1815420297631037915136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2314835262.30, NNZs: 2, Bias: -159503164141.577881, T: 8832, Avg. loss: 1806059276435122028544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2308378631.10, NNZs: 2, Bias: -159501370884.644012, T: 8960, Avg. loss: 1821481325611488903168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 70 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 506480563800.09, NNZs: 2, Bias: -27636258975.685165, T: 128, Avg. loss: 18792291183271326711476649984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1043934271562.43, NNZs: 2, Bias: -7636258975.685165, T: 256, Avg. loss: 23545819030391350885477253120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1195671663371.05, NNZs: 2, Bias: -27636258975.685165, T: 384, Avg. loss: 22379730558200195929054642176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 568513047893.44, NNZs: 2, Bias: -68119634001.469818, T: 512, Avg. loss: 23961899770289567672207147008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1934644036925.19, NNZs: 2, Bias: -68119634001.469818, T: 640, Avg. loss: 21778179385743436214236610560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 921742990569.53, NNZs: 2, Bias: -67665216127.236984, T: 768, Avg. loss: 22128386390923965700994236416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 586406471314.62, NNZs: 2, Bias: -47491093183.315849, T: 896, Avg. loss: 885609835245381243363131392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 190305756313.88, NNZs: 2, Bias: -53338924117.671310, T: 1024, Avg. loss: 870455391119113098998317056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 150124387470.20, NNZs: 2, Bias: -51568658197.822464, T: 1152, Avg. loss: 934958607773017102790688768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 35032398019.13, NNZs: 2, Bias: -39341421639.644569, T: 1280, Avg. loss: 842199453457780795213086720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 289320137788.47, NNZs: 2, Bias: -40977188178.069855, T: 1408, Avg. loss: 810873736434293053375643648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 75771091120.15, NNZs: 2, Bias: -44886543297.211983, T: 1536, Avg. loss: 781829583831771645934043136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 458398359483.78, NNZs: 2, Bias: -34850903865.967323, T: 1664, Avg. loss: 765758446640471051155275776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 348126208874.66, NNZs: 2, Bias: -45458076906.753983, T: 1792, Avg. loss: 882063522852972422708068352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 469814098673.47, NNZs: 2, Bias: -41751975035.788094, T: 1920, Avg. loss: 932987792332031151302508544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 184602163429.98, NNZs: 2, Bias: -42744956936.216087, T: 2048, Avg. loss: 913535972138595781420515328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 184080424323.39, NNZs: 2, Bias: -44268611239.248016, T: 2176, Avg. loss: 819852341612101486281490432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 255995408383.32, NNZs: 2, Bias: -57391478122.682579, T: 2304, Avg. loss: 915355262776445048992038912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 53472726405.77, NNZs: 2, Bias: -58585871145.866249, T: 2432, Avg. loss: 45797947204440204448366592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 62809983597.74, NNZs: 2, Bias: -56443455113.346718, T: 2560, Avg. loss: 31352592298381386631348224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 22513439645.75, NNZs: 2, Bias: -55221143571.551140, T: 2688, Avg. loss: 33575471386684621164904448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 21722924255.07, NNZs: 2, Bias: -57275216676.563377, T: 2816, Avg. loss: 31331217520836354974416896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 14684387408.18, NNZs: 2, Bias: -54907796168.906624, T: 2944, Avg. loss: 29532890362266864238723072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 74926745142.19, NNZs: 2, Bias: -55217201325.167542, T: 3072, Avg. loss: 30997590950532583927054336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 59455258785.73, NNZs: 2, Bias: -56893496593.127174, T: 3200, Avg. loss: 32234587957683254493970432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 91419114598.86, NNZs: 2, Bias: -55359743864.369469, T: 3328, Avg. loss: 31771179137568596962574336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 45540617471.25, NNZs: 2, Bias: -54911597285.245522, T: 3456, Avg. loss: 31444672073878952178876416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 73673582519.41, NNZs: 2, Bias: -55093436493.765503, T: 3584, Avg. loss: 33788719557494266258259968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 10099380723.82, NNZs: 2, Bias: -55091025599.529579, T: 3712, Avg. loss: 2064776452499069032464384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5531474570.70, NNZs: 2, Bias: -54990860225.661377, T: 3840, Avg. loss: 459925240187066104414208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5614801345.25, NNZs: 2, Bias: -54905112573.670509, T: 3968, Avg. loss: 606161252590252522995712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11050650668.13, NNZs: 2, Bias: -54930961989.242554, T: 4096, Avg. loss: 715120056855405095026688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2511193454.10, NNZs: 2, Bias: -54741904849.411110, T: 4224, Avg. loss: 504444558949945480052736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3098450504.09, NNZs: 2, Bias: -54568463584.369637, T: 4352, Avg. loss: 515532313987944913305600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1518193449.55, NNZs: 2, Bias: -54922774306.130455, T: 4480, Avg. loss: 564461025991568379609088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 471609427.55, NNZs: 2, Bias: -54887025607.668365, T: 4608, Avg. loss: 852513975657743777792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 267209126.57, NNZs: 2, Bias: -54860430514.911064, T: 4736, Avg. loss: 439195276835022569472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 546746808.99, NNZs: 2, Bias: -54836122108.682640, T: 4864, Avg. loss: 354022681901017923584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 732402058.81, NNZs: 2, Bias: -54814469183.670563, T: 4992, Avg. loss: 305593724695134404608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 792850262.55, NNZs: 2, Bias: -54793465130.005173, T: 5120, Avg. loss: 322791126340099506176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 859713980.13, NNZs: 2, Bias: -54773348598.050621, T: 5248, Avg. loss: 299576951650187149312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 782425237.52, NNZs: 2, Bias: -54754319111.005188, T: 5376, Avg. loss: 331716215283162546176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 844607040.15, NNZs: 2, Bias: -54733723856.038925, T: 5504, Avg. loss: 324034096738351710208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 805978225.36, NNZs: 2, Bias: -54713574737.209541, T: 5632, Avg. loss: 339436663294895456256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 891110056.50, NNZs: 2, Bias: -54693465667.054260, T: 5760, Avg. loss: 294749549049433489408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 945462578.91, NNZs: 2, Bias: -54674528608.379555, T: 5888, Avg. loss: 290445575714319728640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 916097108.97, NNZs: 2, Bias: -54655950324.014030, T: 6016, Avg. loss: 313724268831168004096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 885264113.78, NNZs: 2, Bias: -54637058671.627625, T: 6144, Avg. loss: 313561671273461776384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 836795698.96, NNZs: 2, Bias: -54618074077.903702, T: 6272, Avg. loss: 337900706175457034240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 861533638.86, NNZs: 2, Bias: -54598010946.928520, T: 6400, Avg. loss: 319909894394011582464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 837658146.87, NNZs: 2, Bias: -54578544689.015953, T: 6528, Avg. loss: 319789717329373364224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 853371821.70, NNZs: 2, Bias: -54574368247.836121, T: 6656, Avg. loss: 266005019870798774272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 849281285.03, NNZs: 2, Bias: -54570586611.464691, T: 6784, Avg. loss: 260468524875000643584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 839734824.34, NNZs: 2, Bias: -54566845248.982231, T: 6912, Avg. loss: 263747554807022288896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 843338145.98, NNZs: 2, Bias: -54562857615.403679, T: 7040, Avg. loss: 266943989181149347840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 850210963.55, NNZs: 2, Bias: -54558837391.802628, T: 7168, Avg. loss: 265023135379658571776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 861990707.77, NNZs: 2, Bias: -54554763227.440742, T: 7296, Avg. loss: 263034098076422668288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 838191304.12, NNZs: 2, Bias: -54551219137.710503, T: 7424, Avg. loss: 266200270874188480512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 844183127.98, NNZs: 2, Bias: -54550342448.285690, T: 7552, Avg. loss: 258957832349153853440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 846421075.54, NNZs: 2, Bias: -54549528744.574120, T: 7680, Avg. loss: 257236792026973011968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 845708067.90, NNZs: 2, Bias: -54548763206.919685, T: 7808, Avg. loss: 256467185942450700288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 845909988.73, NNZs: 2, Bias: -54547982787.324554, T: 7936, Avg. loss: 256666905200024027136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 850539738.17, NNZs: 2, Bias: -54547135535.286064, T: 8064, Avg. loss: 255906995550480793600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 847048721.69, NNZs: 2, Bias: -54546411782.073257, T: 8192, Avg. loss: 257001488757078458368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 848308537.58, NNZs: 2, Bias: -54545614257.541626, T: 8320, Avg. loss: 256841155187632537600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 846421566.14, NNZs: 2, Bias: -54544867724.122246, T: 8448, Avg. loss: 256216901665344815104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 849331157.60, NNZs: 2, Bias: -54544045579.202393, T: 8576, Avg. loss: 256462668645166874624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 848544905.94, NNZs: 2, Bias: -54543280654.245392, T: 8704, Avg. loss: 256649102311956316160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 68 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 221501348140.43, NNZs: 2, Bias: -13471747340.672913, T: 128, Avg. loss: 18127011782962175525561303040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 505602294440.96, NNZs: 2, Bias: -2168451782.768471, T: 256, Avg. loss: 21856626005819410018260221952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1427994144575.69, NNZs: 2, Bias: 137831548217.231537, T: 384, Avg. loss: 21549195590831536052558102528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 376828829999.16, NNZs: 2, Bias: 179584529282.696686, T: 512, Avg. loss: 20216908617710893563549581312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 923255025920.60, NNZs: 2, Bias: 172718206717.951111, T: 640, Avg. loss: 18940204722579456719700623360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1392132689530.01, NNZs: 2, Bias: 117417396121.079163, T: 768, Avg. loss: 21219400626665964559608578048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 10398214905.18, NNZs: 2, Bias: 146569118610.768127, T: 896, Avg. loss: 1182416085101174870792732672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 289533792128.22, NNZs: 2, Bias: 135019529911.126770, T: 1024, Avg. loss: 773672682415495774128308224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 144266927460.98, NNZs: 2, Bias: 141778103251.371735, T: 1152, Avg. loss: 781365809104356097839333376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 467463878416.22, NNZs: 2, Bias: 151322786044.161591, T: 1280, Avg. loss: 794107942912959640179310592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 481241012411.79, NNZs: 2, Bias: 147802766399.950195, T: 1408, Avg. loss: 771667357774284887118839808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 225938507483.62, NNZs: 2, Bias: 133638622671.613892, T: 1536, Avg. loss: 809693406355007974009733120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 99333516140.04, NNZs: 2, Bias: 144243849816.416077, T: 1664, Avg. loss: 800900280478124998404341760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 169665760427.94, NNZs: 2, Bias: 156257434055.031464, T: 1792, Avg. loss: 742725553556443641814188032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 428409495923.91, NNZs: 2, Bias: 159781165038.348846, T: 1920, Avg. loss: 792666748251689909537996800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 93505051582.72, NNZs: 2, Bias: 168824991618.814941, T: 2048, Avg. loss: 778334797808601725126311936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 95229392895.25, NNZs: 2, Bias: 170843860497.690491, T: 2176, Avg. loss: 773810987809935037447536640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 198077745977.38, NNZs: 2, Bias: 162309284364.744904, T: 2304, Avg. loss: 755424489212184762003750912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 413416273739.92, NNZs: 2, Bias: 161235326423.827972, T: 2432, Avg. loss: 833601010176987952654057472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 13584124195.12, NNZs: 2, Bias: 154681789354.839508, T: 2560, Avg. loss: 90130679275823870781685760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 29776674369.27, NNZs: 2, Bias: 152363693241.923767, T: 2688, Avg. loss: 29042674041407365361696768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 38638606442.47, NNZs: 2, Bias: 151107611203.486755, T: 2816, Avg. loss: 27370674510404161942585344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 79080364153.77, NNZs: 2, Bias: 149169330731.909485, T: 2944, Avg. loss: 29648803253625013693054976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 26012459500.23, NNZs: 2, Bias: 152959550857.828766, T: 3072, Avg. loss: 32416361596744104994144256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 19264184819.59, NNZs: 2, Bias: 149498317552.108368, T: 3200, Avg. loss: 26291386457010827796938752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 35299938439.99, NNZs: 2, Bias: 150999373421.737213, T: 3328, Avg. loss: 28539396648476074106159104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 41936833389.79, NNZs: 2, Bias: 151476816626.305542, T: 3456, Avg. loss: 33531100233347321613516800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 48582114789.40, NNZs: 2, Bias: 147077996385.733490, T: 3584, Avg. loss: 31696885651745784773738496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 38553388700.42, NNZs: 2, Bias: 146805218553.578339, T: 3712, Avg. loss: 30294949439027686972325888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 60025025180.26, NNZs: 2, Bias: 146361029452.054840, T: 3840, Avg. loss: 27623219561487667566739456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1497483593.47, NNZs: 2, Bias: 145968540159.427124, T: 3968, Avg. loss: 1621749887324613788041216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1206528882.25, NNZs: 2, Bias: 145932349269.954254, T: 4096, Avg. loss: 562906226963732035010560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 16340616284.33, NNZs: 2, Bias: 145693116074.824524, T: 4224, Avg. loss: 549375972174672389210112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 13794058250.84, NNZs: 2, Bias: 145570091397.623962, T: 4352, Avg. loss: 569725641599244560236544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3910059390.46, NNZs: 2, Bias: 145293807961.493256, T: 4480, Avg. loss: 453138675942455605460992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 13960996096.81, NNZs: 2, Bias: 145351031257.008850, T: 4608, Avg. loss: 487957326369705282240512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6533691985.38, NNZs: 2, Bias: 145410578325.604279, T: 4736, Avg. loss: 596210655297550294188032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6123623666.51, NNZs: 2, Bias: 145154217363.624298, T: 4864, Avg. loss: 363493631874480612573184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6245790583.12, NNZs: 2, Bias: 144907508727.589264, T: 4992, Avg. loss: 467163039223543706419200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3442332859.17, NNZs: 2, Bias: 144807970402.304199, T: 5120, Avg. loss: 688549455558724305289216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 5797380647.57, NNZs: 2, Bias: 144267919165.976257, T: 5248, Avg. loss: 539331206216706384986112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4914165956.24, NNZs: 2, Bias: 144318132597.836761, T: 5376, Avg. loss: 520391826230785584660480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9895612174.20, NNZs: 2, Bias: 143847016304.334290, T: 5504, Avg. loss: 546335504870799386345472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3284087600.24, NNZs: 2, Bias: 143850424831.381134, T: 5632, Avg. loss: 26575416300139525963776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2663491625.53, NNZs: 2, Bias: 143807839595.622070, T: 5760, Avg. loss: 2529308179791468298240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2573858379.28, NNZs: 2, Bias: 143761667938.868469, T: 5888, Avg. loss: 2196591854242089926656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2430666055.96, NNZs: 2, Bias: 143714749318.338806, T: 6016, Avg. loss: 2289859194694441893888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2327476633.57, NNZs: 2, Bias: 143667645210.907074, T: 6144, Avg. loss: 2087272277603335798784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2269379263.19, NNZs: 2, Bias: 143621278608.527252, T: 6272, Avg. loss: 2121445962442415013888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2260438225.30, NNZs: 2, Bias: 143568011541.867462, T: 6400, Avg. loss: 2359489424889660047360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2119834173.52, NNZs: 2, Bias: 143519813317.161774, T: 6528, Avg. loss: 2273375250006620504064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2220515820.14, NNZs: 2, Bias: 143469075495.644409, T: 6656, Avg. loss: 2178411145203154419712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2379730239.74, NNZs: 2, Bias: 143418198283.825775, T: 6784, Avg. loss: 2087379985242673643520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2354544497.63, NNZs: 2, Bias: 143408829108.324585, T: 6912, Avg. loss: 1744125047830912958464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2289948459.95, NNZs: 2, Bias: 143399810279.767151, T: 7040, Avg. loss: 1803321579101159948288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2282415487.00, NNZs: 2, Bias: 143390274554.599426, T: 7168, Avg. loss: 1721085615634353750016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2269538219.72, NNZs: 2, Bias: 143380657803.252502, T: 7296, Avg. loss: 1754440384466081546240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2220767243.35, NNZs: 2, Bias: 143371923023.588287, T: 7424, Avg. loss: 1692221004998990626816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2255203944.64, NNZs: 2, Bias: 143361479113.983398, T: 7552, Avg. loss: 1772903448720800743424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2285197127.96, NNZs: 2, Bias: 143351188730.194397, T: 7680, Avg. loss: 1746363157586470240256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2283711260.17, NNZs: 2, Bias: 143341375042.275635, T: 7808, Avg. loss: 1753269463878445301760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2266218623.88, NNZs: 2, Bias: 143331736453.141266, T: 7936, Avg. loss: 1769597061257859956736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2263335388.40, NNZs: 2, Bias: 143321791665.367920, T: 8064, Avg. loss: 1781025616817884758016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2250311926.00, NNZs: 2, Bias: 143320029712.010254, T: 8192, Avg. loss: 1707237485748132773888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2242763664.70, NNZs: 2, Bias: 143318190385.538727, T: 8320, Avg. loss: 1698271288680072609792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2248711497.75, NNZs: 2, Bias: 143316134806.208954, T: 8448, Avg. loss: 1702073815421384654848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2249976078.96, NNZs: 2, Bias: 143314152246.035767, T: 8576, Avg. loss: 1702414870658079784960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2254921507.35, NNZs: 2, Bias: 143312118181.428650, T: 8704, Avg. loss: 1696558006882104508416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 68 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1493061385370.08, NNZs: 2, Bias: 31771731199.613998, T: 128, Avg. loss: 18420657097258214777195331584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 999339586744.58, NNZs: 2, Bias: 56174322912.353455, T: 256, Avg. loss: 20351453713387397451480039424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 655194406882.81, NNZs: 2, Bias: 76174322912.353455, T: 384, Avg. loss: 19401692651217661010347294720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2121711323591.32, NNZs: 2, Bias: 96174322912.353455, T: 512, Avg. loss: 21412504187954729896393048064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1006991970053.33, NNZs: 2, Bias: 89008200743.908356, T: 640, Avg. loss: 19462581629986234604193841152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 532969660580.29, NNZs: 2, Bias: 109008200743.908356, T: 768, Avg. loss: 20719071567461361737088892928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 151399640708.20, NNZs: 2, Bias: 103620637108.478348, T: 896, Avg. loss: 866455435451560016339795968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 249383889373.68, NNZs: 2, Bias: 107106392202.567413, T: 1024, Avg. loss: 833840421664667502202847232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 122657653137.47, NNZs: 2, Bias: 112146204116.904266, T: 1152, Avg. loss: 830302314488341664484032512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 80396911647.95, NNZs: 2, Bias: 109508988207.733353, T: 1280, Avg. loss: 876134810311896105142452224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 244090477712.84, NNZs: 2, Bias: 102914648560.603638, T: 1408, Avg. loss: 760609739748117157106417664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 226397271257.91, NNZs: 2, Bias: 112155096918.240463, T: 1536, Avg. loss: 885074943945465145874972672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 399319742462.79, NNZs: 2, Bias: 96099108468.399887, T: 1664, Avg. loss: 823316959379819903250857984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59498331932.54, NNZs: 2, Bias: 96127923695.689896, T: 1792, Avg. loss: 818180707799623317678194688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 223381666224.11, NNZs: 2, Bias: 89929420286.634644, T: 1920, Avg. loss: 836538109113765686881026048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 231308037809.89, NNZs: 2, Bias: 81938864682.544067, T: 2048, Avg. loss: 737764114207655821414760448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 483302616679.68, NNZs: 2, Bias: 82727228413.072906, T: 2176, Avg. loss: 819094182315428055447764992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 177000543342.53, NNZs: 2, Bias: 85390247414.925751, T: 2304, Avg. loss: 938480793433915036096528384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 179154103322.71, NNZs: 2, Bias: 104078500789.671249, T: 2432, Avg. loss: 788399541220063256676139008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 150396953189.74, NNZs: 2, Bias: 105691797083.370850, T: 2560, Avg. loss: 780801644821443534179532800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 146935588942.32, NNZs: 2, Bias: 99425329088.713181, T: 2688, Avg. loss: 872127626361720611629170688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 20906096237.69, NNZs: 2, Bias: 97311296122.530380, T: 2816, Avg. loss: 33985427085301273696665600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 90459689894.89, NNZs: 2, Bias: 98693472591.866913, T: 2944, Avg. loss: 29608158931262068056129536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 81007929008.12, NNZs: 2, Bias: 95800787308.262268, T: 3072, Avg. loss: 32826737062163443919880192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 20014642910.91, NNZs: 2, Bias: 92510615374.279388, T: 3200, Avg. loss: 30282585723507403235786752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 37752182552.69, NNZs: 2, Bias: 89948053101.851974, T: 3328, Avg. loss: 29625047881766052311334912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 33480751402.71, NNZs: 2, Bias: 88698076454.974350, T: 3456, Avg. loss: 31697475138878453785296896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 30923605418.38, NNZs: 2, Bias: 86093268414.290298, T: 3584, Avg. loss: 32718248441882527605456896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 6346463869.31, NNZs: 2, Bias: 86302552252.351776, T: 3712, Avg. loss: 655106454961666484338688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1225635715.32, NNZs: 2, Bias: 85941659114.332748, T: 3840, Avg. loss: 585908575416684906545152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 850181601.95, NNZs: 2, Bias: 85747676496.204102, T: 3968, Avg. loss: 479863133492926708973568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1491905405.26, NNZs: 2, Bias: 85675643374.626190, T: 4096, Avg. loss: 619739285976211647365120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4608679303.34, NNZs: 2, Bias: 85534606467.513443, T: 4224, Avg. loss: 589604320581546990895104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6231263116.91, NNZs: 2, Bias: 85623489618.122314, T: 4352, Avg. loss: 569866210166709814296576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6811642308.46, NNZs: 2, Bias: 85310625012.518234, T: 4480, Avg. loss: 541666048477074775080960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1414175087.69, NNZs: 2, Bias: 85490148451.910141, T: 4608, Avg. loss: 556555081092033228570624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1189552479.44, NNZs: 2, Bias: 85449560956.865906, T: 4736, Avg. loss: 1251978186816260407296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1286125903.82, NNZs: 2, Bias: 85419757477.153488, T: 4864, Avg. loss: 732198559554589818880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1311796707.75, NNZs: 2, Bias: 85392987884.830307, T: 4992, Avg. loss: 681543787988241481728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1377024037.59, NNZs: 2, Bias: 85365427953.658615, T: 5120, Avg. loss: 682562345523942785024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1459396721.52, NNZs: 2, Bias: 85337558128.731522, T: 5248, Avg. loss: 680373183807982534656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1513893523.02, NNZs: 2, Bias: 85310532783.445099, T: 5376, Avg. loss: 649312021157393072128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1550718771.34, NNZs: 2, Bias: 85285983423.849503, T: 5504, Avg. loss: 589766830892599476224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1541064697.21, NNZs: 2, Bias: 85259250529.418030, T: 5632, Avg. loss: 665591744551786119168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1402937266.01, NNZs: 2, Bias: 85234048246.156677, T: 5760, Avg. loss: 723077564628582006784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1460242865.89, NNZs: 2, Bias: 85205148389.129517, T: 5888, Avg. loss: 703373207678476746752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1483364237.86, NNZs: 2, Bias: 85178638044.647659, T: 6016, Avg. loss: 679893047452478078976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1509689455.14, NNZs: 2, Bias: 85151010546.726151, T: 6144, Avg. loss: 707188913725487448064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1527314243.38, NNZs: 2, Bias: 85145203241.326920, T: 6272, Avg. loss: 577100162489992871936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1516982441.87, NNZs: 2, Bias: 85139897337.109222, T: 6400, Avg. loss: 578841853328283402240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1507031174.36, NNZs: 2, Bias: 85134642848.597412, T: 6528, Avg. loss: 572123745332639563776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1501352500.37, NNZs: 2, Bias: 85129327894.963715, T: 6656, Avg. loss: 570940318387982368768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1477795975.00, NNZs: 2, Bias: 85124246423.962799, T: 6784, Avg. loss: 578877157094055739392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1477708225.08, NNZs: 2, Bias: 85118789935.318146, T: 6912, Avg. loss: 574101630949568610304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1477702555.03, NNZs: 2, Bias: 85113299585.300095, T: 7040, Avg. loss: 578103109111740039168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1469071040.01, NNZs: 2, Bias: 85108068460.444885, T: 7168, Avg. loss: 566913986424644960256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1475986057.08, NNZs: 2, Bias: 85102444759.413589, T: 7296, Avg. loss: 579422138329179226112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1456755372.49, NNZs: 2, Bias: 85097247566.246796, T: 7424, Avg. loss: 583312530834634113024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1441474092.88, NNZs: 2, Bias: 85092017168.052505, T: 7552, Avg. loss: 578608684558464319488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1445095665.40, NNZs: 2, Bias: 85086500946.973358, T: 7680, Avg. loss: 573817981587373490176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1453543642.10, NNZs: 2, Bias: 85080995681.061111, T: 7808, Avg. loss: 563694880656303783936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1460204861.36, NNZs: 2, Bias: 85075491225.963882, T: 7936, Avg. loss: 566561993034407542784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1460631469.98, NNZs: 2, Bias: 85070102921.725494, T: 8064, Avg. loss: 566939040163964256256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1446742017.95, NNZs: 2, Bias: 85064808372.346252, T: 8192, Avg. loss: 582739478936396824576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1451040153.14, NNZs: 2, Bias: 85059431497.169678, T: 8320, Avg. loss: 559237857631552012288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1456470065.87, NNZs: 2, Bias: 85053885130.991745, T: 8448, Avg. loss: 574845410976672382976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1434687707.39, NNZs: 2, Bias: 85048976006.852814, T: 8576, Avg. loss: 555519249245803708416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1438696102.67, NNZs: 2, Bias: 85043440982.146149, T: 8704, Avg. loss: 574814991600965976064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1443982407.06, NNZs: 2, Bias: 85037820015.270416, T: 8832, Avg. loss: 581750889686971645952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1460302978.47, NNZs: 2, Bias: 85032197725.270386, T: 8960, Avg. loss: 562236669268414038016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1453865509.43, NNZs: 2, Bias: 85026884190.032501, T: 9088, Avg. loss: 570353478456194957312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1448670169.81, NNZs: 2, Bias: 85021539655.916626, T: 9216, Avg. loss: 571574734634097442816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1437067686.15, NNZs: 2, Bias: 85020644715.206741, T: 9344, Avg. loss: 559956187664133193728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1439001236.80, NNZs: 2, Bias: 85019529311.920349, T: 9472, Avg. loss: 554846241863909900288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1436182519.72, NNZs: 2, Bias: 85018493630.302429, T: 9600, Avg. loss: 555318544871029997568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1437359064.47, NNZs: 2, Bias: 85017390942.611130, T: 9728, Avg. loss: 554865724251627585536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1440373218.73, NNZs: 2, Bias: 85016262438.347534, T: 9856, Avg. loss: 552076003667159089152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1440180354.93, NNZs: 2, Bias: 85015183191.246750, T: 9984, Avg. loss: 554748838080188973056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1441015071.89, NNZs: 2, Bias: 85014086490.225143, T: 10112, Avg. loss: 554747878620642869248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1436763657.60, NNZs: 2, Bias: 85013075048.069855, T: 10240, Avg. loss: 555362054654337810432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1438845105.84, NNZs: 2, Bias: 85011955789.667130, T: 10368, Avg. loss: 555477907122902204416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1434536365.70, NNZs: 2, Bias: 85010945315.826996, T: 10496, Avg. loss: 555289798322350850048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 82 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1100238611080.86, NNZs: 2, Bias: 68294322125.201431, T: 128, Avg. loss: 22485974353508928761905545216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1243214234032.32, NNZs: 2, Bias: 58605025108.895752, T: 256, Avg. loss: 22866992478780187853958676480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 592134582196.99, NNZs: 2, Bias: 18605025108.895752, T: 384, Avg. loss: 20986478231252602274013249536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 611853224690.13, NNZs: 2, Bias: 38057209541.684891, T: 512, Avg. loss: 23768218982003784521072246784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1011685271229.96, NNZs: 2, Bias: 31368121837.550835, T: 640, Avg. loss: 21699167345553214849767440384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1065845908767.73, NNZs: 2, Bias: 31368121837.550835, T: 768, Avg. loss: 24396576412478793741034848256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 381543247453.61, NNZs: 2, Bias: 37462003070.028946, T: 896, Avg. loss: 23936056320951471013806211072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1985481102121.32, NNZs: 2, Bias: -20296186611.640793, T: 1024, Avg. loss: 23177911424969449892097294336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 66792907929.12, NNZs: 2, Bias: -37537522505.374084, T: 1152, Avg. loss: 1924406357999481059845079040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 138341606933.74, NNZs: 2, Bias: -34504729273.930832, T: 1280, Avg. loss: 1006639683721076334282145792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 215012375578.39, NNZs: 2, Bias: -35856188330.819473, T: 1408, Avg. loss: 972142015051661483295375360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 125252554510.34, NNZs: 2, Bias: -36822144547.326035, T: 1536, Avg. loss: 913676462024229168305143808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 85326667147.79, NNZs: 2, Bias: -45732670100.145699, T: 1664, Avg. loss: 883097414570081916781854720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 51769968337.84, NNZs: 2, Bias: -35845103253.825043, T: 1792, Avg. loss: 1004366263526242583035510784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 269042638618.23, NNZs: 2, Bias: -51014148069.644119, T: 1920, Avg. loss: 909906839539219794583617536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 297883879487.25, NNZs: 2, Bias: -56038092230.767929, T: 2048, Avg. loss: 963704178813936489551888384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 253993944568.00, NNZs: 2, Bias: -50027937207.343124, T: 2176, Avg. loss: 948475085293061755417657344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 331151964701.89, NNZs: 2, Bias: -62025218505.175514, T: 2304, Avg. loss: 941338683804969469355229184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 52482122768.00, NNZs: 2, Bias: -57481293020.596901, T: 2432, Avg. loss: 69103878486725961659187200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 58712678792.22, NNZs: 2, Bias: -59071098401.497078, T: 2560, Avg. loss: 31235952445266868786167808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 27148980430.24, NNZs: 2, Bias: -59920545282.873947, T: 2688, Avg. loss: 34180189698946525890084864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 56262401499.81, NNZs: 2, Bias: -60949192017.595955, T: 2816, Avg. loss: 31655583444898463816351744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4948328980.69, NNZs: 2, Bias: -58958965166.340675, T: 2944, Avg. loss: 31541808142371722157359104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 23597641424.79, NNZs: 2, Bias: -61421082716.519081, T: 3072, Avg. loss: 33777494616355443084099584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 41743800193.62, NNZs: 2, Bias: -59147232233.382652, T: 3200, Avg. loss: 34524506392918954472374272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 11133990323.57, NNZs: 2, Bias: -58809614967.498596, T: 3328, Avg. loss: 1140507845526523282980864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2048784928.94, NNZs: 2, Bias: -58641780305.201622, T: 3456, Avg. loss: 583911355069169802412032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 11926146475.04, NNZs: 2, Bias: -58533286677.539139, T: 3584, Avg. loss: 448947660415337519644672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 6698342238.70, NNZs: 2, Bias: -58692270939.698097, T: 3712, Avg. loss: 832985849242883385720832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3131966333.92, NNZs: 2, Bias: -58969449819.035217, T: 3840, Avg. loss: 793088266151328370130944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 3221777003.24, NNZs: 2, Bias: -58680925954.176010, T: 3968, Avg. loss: 805045978728453296357376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8102659231.44, NNZs: 2, Bias: -58668896615.656059, T: 4096, Avg. loss: 635731763919033661915136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4031419210.26, NNZs: 2, Bias: -58774512298.883568, T: 4224, Avg. loss: 538290917830032720134144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2244481637.35, NNZs: 2, Bias: -58764029199.421844, T: 4352, Avg. loss: 2786089648943857139712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1559637029.61, NNZs: 2, Bias: -58755242909.858429, T: 4480, Avg. loss: 609781907551829229568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1256535558.07, NNZs: 2, Bias: -58741294195.263321, T: 4608, Avg. loss: 380680353263527788544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1114511614.31, NNZs: 2, Bias: -58725349634.168877, T: 4736, Avg. loss: 341456618183261224960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1021114681.14, NNZs: 2, Bias: -58706160546.696365, T: 4864, Avg. loss: 368712668125065445376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1025614616.52, NNZs: 2, Bias: -58685785416.501625, T: 4992, Avg. loss: 350289228115201359872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 971366513.93, NNZs: 2, Bias: -58666510262.204971, T: 5120, Avg. loss: 368013254680014422016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 905000690.91, NNZs: 2, Bias: -58646765253.802139, T: 5248, Avg. loss: 392606217840221093888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 910361920.93, NNZs: 2, Bias: -58626603999.654404, T: 5376, Avg. loss: 371812132247555342336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 885774494.40, NNZs: 2, Bias: -58622935643.438072, T: 5504, Avg. loss: 296600083611191869440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 885573011.44, NNZs: 2, Bias: -58618913827.183243, T: 5632, Avg. loss: 293745125302236971008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 882137289.71, NNZs: 2, Bias: -58614964538.272957, T: 5760, Avg. loss: 291942706104624185344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 902423789.76, NNZs: 2, Bias: -58610644673.495628, T: 5888, Avg. loss: 292391430366486003712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 886112301.74, NNZs: 2, Bias: -58606871535.627342, T: 6016, Avg. loss: 293751886859479810048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 907204752.65, NNZs: 2, Bias: -58602611741.151726, T: 6144, Avg. loss: 286049408230421233664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 913316837.09, NNZs: 2, Bias: -58598542284.086769, T: 6272, Avg. loss: 289660977360556294144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 902593222.93, NNZs: 2, Bias: -58594725875.963875, T: 6400, Avg. loss: 290459198102726868992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 905073300.62, NNZs: 2, Bias: -58590767953.075539, T: 6528, Avg. loss: 286119465878633414656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 891799373.23, NNZs: 2, Bias: -58586936275.770149, T: 6656, Avg. loss: 295264044812499025920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 902488594.44, NNZs: 2, Bias: -58582763599.025772, T: 6784, Avg. loss: 292090585286655377408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 894307186.63, NNZs: 2, Bias: -58582083441.732986, T: 6912, Avg. loss: 286056833782337568768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 892183665.35, NNZs: 2, Bias: -58581317001.610931, T: 7040, Avg. loss: 283492253009808064512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 892639381.26, NNZs: 2, Bias: -58580512363.028732, T: 7168, Avg. loss: 283000014039611932672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 895255042.19, NNZs: 2, Bias: -58579676089.385086, T: 7296, Avg. loss: 282463786723282092032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 896043103.06, NNZs: 2, Bias: -58578866568.868111, T: 7424, Avg. loss: 282920844572551970816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 891657727.36, NNZs: 2, Bias: -58578134712.780579, T: 7552, Avg. loss: 283450102504394752000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 894019123.99, NNZs: 2, Bias: -58577298883.634422, T: 7680, Avg. loss: 283710242660153851904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 894731213.67, NNZs: 2, Bias: -58576490597.165634, T: 7808, Avg. loss: 282868383323097694208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 895094584.34, NNZs: 2, Bias: -58575687319.443359, T: 7936, Avg. loss: 282995346295517151232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 62 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1129500219399.12, NNZs: 2, Bias: -3808555337.018658, T: 128, Avg. loss: 24099488790814728006053920768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 611807188870.81, NNZs: 2, Bias: 36352431881.799377, T: 256, Avg. loss: 24539914619266826310783074304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 807401710699.71, NNZs: 2, Bias: 95503334736.373413, T: 384, Avg. loss: 21911248799074176326854246400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 596202113127.08, NNZs: 2, Bias: 75503334736.373413, T: 512, Avg. loss: 23149885697773616428893601792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1317174511248.39, NNZs: 2, Bias: 115503334736.373413, T: 640, Avg. loss: 22572411849431643344699654144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 438279832064.24, NNZs: 2, Bias: 215503334736.373413, T: 768, Avg. loss: 23391114021060108910774452224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 620555100024.74, NNZs: 2, Bias: 234122174600.711151, T: 896, Avg. loss: 24957701593600101343360450560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1831912084697.54, NNZs: 2, Bias: 234122174600.711151, T: 1024, Avg. loss: 24602713664331645049903251456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 99268396943.43, NNZs: 2, Bias: 232557582236.606812, T: 1152, Avg. loss: 1991112638492309991853129728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 189417501468.46, NNZs: 2, Bias: 226779238805.055542, T: 1280, Avg. loss: 1038246569685572069508513792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 154470617113.37, NNZs: 2, Bias: 217809643842.961365, T: 1408, Avg. loss: 970025136913259272735817728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 267219571049.98, NNZs: 2, Bias: 212011085168.818756, T: 1536, Avg. loss: 1005302755872122571424006144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 224961023728.08, NNZs: 2, Bias: 217846460531.042236, T: 1664, Avg. loss: 950065420298143505934450688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 171878150451.94, NNZs: 2, Bias: 200638418700.077759, T: 1792, Avg. loss: 966805121920663774935646208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 335169763896.19, NNZs: 2, Bias: 209739920571.599579, T: 1920, Avg. loss: 1005653164007747497574268928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 156145902205.28, NNZs: 2, Bias: 206019930443.692688, T: 2048, Avg. loss: 860120124605891730965790720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 197669144155.81, NNZs: 2, Bias: 201504407326.930878, T: 2176, Avg. loss: 973711160793596007163101184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 445959867378.22, NNZs: 2, Bias: 199777762103.913757, T: 2304, Avg. loss: 953920720283459478408396800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 251354127793.36, NNZs: 2, Bias: 191809050327.493835, T: 2432, Avg. loss: 1046311628136820444162424832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 240205793029.59, NNZs: 2, Bias: 185352618835.708893, T: 2560, Avg. loss: 973792869274211272680800256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 570245392532.05, NNZs: 2, Bias: 197182719578.731934, T: 2688, Avg. loss: 946180310504866833579900928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 47641643840.70, NNZs: 2, Bias: 190861628727.974670, T: 2816, Avg. loss: 118548642880396386967224320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 24046592684.85, NNZs: 2, Bias: 192704146043.182892, T: 2944, Avg. loss: 37219475987946603951423488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 85966992532.25, NNZs: 2, Bias: 193343013282.873779, T: 3072, Avg. loss: 31531035853395548486762496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 89281613521.92, NNZs: 2, Bias: 195457706035.301117, T: 3200, Avg. loss: 33473511766568244554498048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 42192720125.35, NNZs: 2, Bias: 193884996341.804443, T: 3328, Avg. loss: 34290230436548013782466560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 84251797798.89, NNZs: 2, Bias: 193600095135.451721, T: 3456, Avg. loss: 34445005103047562753998848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 45776369446.82, NNZs: 2, Bias: 198490463023.498138, T: 3584, Avg. loss: 36093102723691882412507136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 29587138708.68, NNZs: 2, Bias: 199220293482.788788, T: 3712, Avg. loss: 36793533685503195483209728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8426363057.30, NNZs: 2, Bias: 199050862590.364685, T: 3840, Avg. loss: 794556472069614181810176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 7091919592.48, NNZs: 2, Bias: 198745181748.551544, T: 3968, Avg. loss: 710330574417844957609984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1606300162.29, NNZs: 2, Bias: 198577072280.614258, T: 4096, Avg. loss: 714714604109796216930304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1788739197.37, NNZs: 2, Bias: 198314856649.081268, T: 4224, Avg. loss: 784133932020373116682240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 11831188064.65, NNZs: 2, Bias: 197881695942.792511, T: 4352, Avg. loss: 686765977906625986428928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6088635365.73, NNZs: 2, Bias: 197670747944.386993, T: 4480, Avg. loss: 691525282192191790252032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 8164347459.39, NNZs: 2, Bias: 197659134990.510498, T: 4608, Avg. loss: 761550381668551423426560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4713323330.00, NNZs: 2, Bias: 197363686966.748779, T: 4736, Avg. loss: 745063001506800134520832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5752863822.88, NNZs: 2, Bias: 197149678670.981842, T: 4864, Avg. loss: 815383999042421784576000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9611431245.88, NNZs: 2, Bias: 197198167305.228760, T: 4992, Avg. loss: 709268594957116912959488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4184203712.29, NNZs: 2, Bias: 197196517658.051819, T: 5120, Avg. loss: 15561209509576504770560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3465485056.61, NNZs: 2, Bias: 197146254323.446198, T: 5248, Avg. loss: 4003719080591741157376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3158121669.26, NNZs: 2, Bias: 197091990330.602570, T: 5376, Avg. loss: 3772213948488928460800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3022200740.95, NNZs: 2, Bias: 197033619968.064026, T: 5504, Avg. loss: 3814106892487367327744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3034464644.71, NNZs: 2, Bias: 196977652227.580200, T: 5632, Avg. loss: 3194335160532227588096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2816093380.31, NNZs: 2, Bias: 196924622092.540558, T: 5760, Avg. loss: 3387735883556460167168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2960090277.29, NNZs: 2, Bias: 196864591407.611877, T: 5888, Avg. loss: 3344746622336998309888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2846685599.08, NNZs: 2, Bias: 196808986158.368134, T: 6016, Avg. loss: 3501150273942284402688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2928315481.71, NNZs: 2, Bias: 196748298527.748352, T: 6144, Avg. loss: 3485687333712292216832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2813577601.17, NNZs: 2, Bias: 196693287989.670135, T: 6272, Avg. loss: 3353417065140295041024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2841994729.91, NNZs: 2, Bias: 196681266034.436432, T: 6400, Avg. loss: 2837791777219147726848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2869133411.29, NNZs: 2, Bias: 196669139727.603271, T: 6528, Avg. loss: 2869929238583322869760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2796607162.78, NNZs: 2, Bias: 196658673006.314575, T: 6656, Avg. loss: 2819598396217306382336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2815602930.05, NNZs: 2, Bias: 196646757082.925171, T: 6784, Avg. loss: 2845691164902183927808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2884181545.47, NNZs: 2, Bias: 196634129434.635986, T: 6912, Avg. loss: 2840302827143514030080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2839588307.65, NNZs: 2, Bias: 196623199493.891693, T: 7040, Avg. loss: 2833750864504016076800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2817794402.11, NNZs: 2, Bias: 196612026517.946899, T: 7168, Avg. loss: 2806032430692883759104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2834005016.32, NNZs: 2, Bias: 196600159630.563904, T: 7296, Avg. loss: 2850591418202139918336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2839198638.22, NNZs: 2, Bias: 196588467956.125366, T: 7424, Avg. loss: 2837670472985812140032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2821309351.32, NNZs: 2, Bias: 196577282130.233246, T: 7552, Avg. loss: 2796785486293494661120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2840735851.88, NNZs: 2, Bias: 196565290778.323242, T: 7680, Avg. loss: 2864192592093963091968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2828675426.05, NNZs: 2, Bias: 196553766836.049957, T: 7808, Avg. loss: 2862307671947826167808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2838279891.82, NNZs: 2, Bias: 196541896037.803589, T: 7936, Avg. loss: 2873240959001135939584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2860103025.59, NNZs: 2, Bias: 196530095941.937927, T: 8064, Avg. loss: 2808578989781899804672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2838154922.13, NNZs: 2, Bias: 196518820430.263428, T: 8192, Avg. loss: 2830627558539392450560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2851233815.97, NNZs: 2, Bias: 196516329001.930939, T: 8320, Avg. loss: 2742426375724151078912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2848815681.71, NNZs: 2, Bias: 196514051122.653625, T: 8448, Avg. loss: 2756476287811053420544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2841475934.75, NNZs: 2, Bias: 196511852172.640808, T: 8576, Avg. loss: 2747179846137028280320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2839417006.80, NNZs: 2, Bias: 196509569306.757507, T: 8704, Avg. loss: 2756086570689305772032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2840839017.68, NNZs: 2, Bias: 196507232402.740662, T: 8832, Avg. loss: 2760240631088910172160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2831017734.53, NNZs: 2, Bias: 196505065543.324982, T: 8960, Avg. loss: 2751298842338999140352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 70 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 527137650099.71, NNZs: 2, Bias: 10275761224.800453, T: 128, Avg. loss: 21949820547107042333359603712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2582631167589.82, NNZs: 2, Bias: -29110911906.958740, T: 256, Avg. loss: 22126671773479193228636848128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 768212390208.84, NNZs: 2, Bias: 8436103491.208015, T: 384, Avg. loss: 23239986855399657694858051584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 134030833015.22, NNZs: 2, Bias: 68436103491.208008, T: 512, Avg. loss: 19685009404571075524698308608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1743070278486.72, NNZs: 2, Bias: 128436103491.208008, T: 640, Avg. loss: 22052227320761090168091312128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 681290375107.58, NNZs: 2, Bias: 133879118543.734039, T: 768, Avg. loss: 22610289074075272822535487488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2215690349314.80, NNZs: 2, Bias: 128377318137.981659, T: 896, Avg. loss: 21504188239814500773003264000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 722789437978.65, NNZs: 2, Bias: 189326576781.545593, T: 1024, Avg. loss: 22282420429440478995149750272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 905929118112.08, NNZs: 2, Bias: 189326576781.545593, T: 1152, Avg. loss: 21600541272061621056739213312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 91336814754.15, NNZs: 2, Bias: 169788738239.419037, T: 1280, Avg. loss: 982685249117499198023925760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 215688184061.10, NNZs: 2, Bias: 166982100835.046112, T: 1408, Avg. loss: 812797744096685008474865664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 57335913031.17, NNZs: 2, Bias: 183939599982.079803, T: 1536, Avg. loss: 942276790890026071069032448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 360588559259.19, NNZs: 2, Bias: 180280001210.978973, T: 1664, Avg. loss: 868490625165529630111694848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 102631778252.61, NNZs: 2, Bias: 180109597406.347412, T: 1792, Avg. loss: 832197881630145014726131712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 569532966635.65, NNZs: 2, Bias: 196773691526.622864, T: 1920, Avg. loss: 798428639923784540271673344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 328535441029.15, NNZs: 2, Bias: 185130819553.647614, T: 2048, Avg. loss: 859937637144701096400257024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 100058367934.35, NNZs: 2, Bias: 185172096657.279694, T: 2176, Avg. loss: 862197760256932634322534400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 274336812698.82, NNZs: 2, Bias: 196698245539.697388, T: 2304, Avg. loss: 932497573247396021771698176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 308566945155.29, NNZs: 2, Bias: 177953012381.247833, T: 2432, Avg. loss: 789250864433233481896558592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 63588005014.96, NNZs: 2, Bias: 187418949334.587067, T: 2560, Avg. loss: 821613815110538072986484736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 144432400229.79, NNZs: 2, Bias: 198071401841.733612, T: 2688, Avg. loss: 815087586119119855448752128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 278773621945.18, NNZs: 2, Bias: 189184019487.318207, T: 2816, Avg. loss: 803552248414765669492457472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 122431303496.38, NNZs: 2, Bias: 191249927386.073853, T: 2944, Avg. loss: 882384155650331402435559424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 106202196022.32, NNZs: 2, Bias: 193556024841.816223, T: 3072, Avg. loss: 851111758903579568982982656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 26836106546.37, NNZs: 2, Bias: 194175397561.969574, T: 3200, Avg. loss: 29320564152953112782438400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 93253383838.11, NNZs: 2, Bias: 196266890872.279510, T: 3328, Avg. loss: 29967426143705397867839488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 44851619042.35, NNZs: 2, Bias: 193360185911.513031, T: 3456, Avg. loss: 32550936105432047826239488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 57212050466.38, NNZs: 2, Bias: 193512292107.506104, T: 3584, Avg. loss: 30718173491640966255214592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 47187794014.23, NNZs: 2, Bias: 191868799202.907593, T: 3712, Avg. loss: 34105160322552712600223744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 33391236883.12, NNZs: 2, Bias: 190331846755.248718, T: 3840, Avg. loss: 33937259228643846944456704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11133239510.09, NNZs: 2, Bias: 189713984939.411835, T: 3968, Avg. loss: 801999659552024549130240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 13284631517.60, NNZs: 2, Bias: 189446414035.295319, T: 4096, Avg. loss: 657082648064744801435648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9296165915.02, NNZs: 2, Bias: 189341303170.704865, T: 4224, Avg. loss: 660872252881550417330176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8901323083.30, NNZs: 2, Bias: 188308891979.238617, T: 4352, Avg. loss: 641951921209585524801536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 5432663774.31, NNZs: 2, Bias: 188589542100.258270, T: 4480, Avg. loss: 784475580432756705853440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3323772746.46, NNZs: 2, Bias: 188442172692.269470, T: 4608, Avg. loss: 639764480901623358423040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 17704807215.63, NNZs: 2, Bias: 188113511309.675751, T: 4736, Avg. loss: 582322253325556848263168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8807840837.39, NNZs: 2, Bias: 187508237189.863800, T: 4864, Avg. loss: 729476390890428560310272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 7004493274.45, NNZs: 2, Bias: 186916637845.474243, T: 4992, Avg. loss: 540440099190361907265536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4443429957.95, NNZs: 2, Bias: 186493174086.141602, T: 5120, Avg. loss: 459195428004060993683456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 10996678893.46, NNZs: 2, Bias: 185490220486.808075, T: 5248, Avg. loss: 543982990888712508801024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 10445231769.79, NNZs: 2, Bias: 185355993475.561096, T: 5376, Avg. loss: 425905966309724567633920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3932067390.40, NNZs: 2, Bias: 184888195334.948029, T: 5504, Avg. loss: 750561233672600140382208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5815279792.07, NNZs: 2, Bias: 184622731196.985596, T: 5632, Avg. loss: 691010174655369014411264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2779686089.01, NNZs: 2, Bias: 184402256972.863007, T: 5760, Avg. loss: 655890638385244679438336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4539530082.60, NNZs: 2, Bias: 184504947890.797302, T: 5888, Avg. loss: 682359649821232396763136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 11413649751.60, NNZs: 2, Bias: 184314347200.417358, T: 6016, Avg. loss: 620876255375044070342656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3193578854.27, NNZs: 2, Bias: 184182249358.338043, T: 6144, Avg. loss: 36403110183928439242752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3133159006.49, NNZs: 2, Bias: 184118634619.092926, T: 6272, Avg. loss: 3592934205362253332480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2891615486.54, NNZs: 2, Bias: 184059742681.408112, T: 6400, Avg. loss: 3503739861231986016256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2935540425.91, NNZs: 2, Bias: 183994286234.911774, T: 6528, Avg. loss: 3647359566630736101376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2939036217.63, NNZs: 2, Bias: 183927269320.216858, T: 6656, Avg. loss: 3645348461095886520320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2883120403.83, NNZs: 2, Bias: 183859829711.142029, T: 6784, Avg. loss: 3825388170842885586944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2831806764.60, NNZs: 2, Bias: 183797075248.760254, T: 6912, Avg. loss: 3542154416043333779456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2981513225.73, NNZs: 2, Bias: 183731526687.254700, T: 7040, Avg. loss: 3479788525889376485376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3036893936.52, NNZs: 2, Bias: 183665722643.950104, T: 7168, Avg. loss: 3503825525991467384832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2949474093.14, NNZs: 2, Bias: 183601326518.467682, T: 7296, Avg. loss: 3623905386374054281216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2855747394.49, NNZs: 2, Bias: 183537345800.987305, T: 7424, Avg. loss: 3804241964872297873408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2656873937.98, NNZs: 2, Bias: 183479120768.601532, T: 7552, Avg. loss: 3394206178474061725696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2772550894.60, NNZs: 2, Bias: 183411526279.114624, T: 7680, Avg. loss: 3578739708966759563264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2706222978.56, NNZs: 2, Bias: 183347493026.392090, T: 7808, Avg. loss: 3607282154485882290176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2917639825.86, NNZs: 2, Bias: 183279216953.137756, T: 7936, Avg. loss: 3506129793998376140800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2785657179.61, NNZs: 2, Bias: 183212912826.552094, T: 8064, Avg. loss: 3774269135553234468864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2802027280.44, NNZs: 2, Bias: 183146390335.124634, T: 8192, Avg. loss: 3626263031707566342144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2933803219.90, NNZs: 2, Bias: 183130932118.114288, T: 8320, Avg. loss: 3038325716524535382016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2875310889.86, NNZs: 2, Bias: 183118996169.821198, T: 8448, Avg. loss: 2930085049956814553088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2919659336.72, NNZs: 2, Bias: 183105382432.524414, T: 8576, Avg. loss: 2932599992229246795776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2896286110.80, NNZs: 2, Bias: 183092591023.390686, T: 8704, Avg. loss: 3000415249405425745920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2911610147.72, NNZs: 2, Bias: 183079184676.153778, T: 8832, Avg. loss: 2997300514931846152192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2910056334.01, NNZs: 2, Bias: 183066274370.582367, T: 8960, Avg. loss: 2942706546458436829184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2922695675.25, NNZs: 2, Bias: 183052959548.520935, T: 9088, Avg. loss: 2985612463029040971776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2901548149.76, NNZs: 2, Bias: 183050689305.399078, T: 9216, Avg. loss: 2894743889467212300288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2902295822.05, NNZs: 2, Bias: 183048072954.055054, T: 9344, Avg. loss: 2890576106369481441280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2906656347.07, NNZs: 2, Bias: 183045398331.969543, T: 9472, Avg. loss: 2891861894126712127488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2893073379.08, NNZs: 2, Bias: 183043018027.285278, T: 9600, Avg. loss: 2881267046419191037952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2912060281.37, NNZs: 2, Bias: 183040126223.511993, T: 9728, Avg. loss: 2873920392334551810048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2913423939.17, NNZs: 2, Bias: 183037502930.239685, T: 9856, Avg. loss: 2887248473729001324544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2908743007.37, NNZs: 2, Bias: 183034972876.667542, T: 9984, Avg. loss: 2890708038431368282112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2893824193.49, NNZs: 2, Bias: 183032616603.843018, T: 10112, Avg. loss: 2878522856319130009600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2891984936.90, NNZs: 2, Bias: 183030045440.768951, T: 10240, Avg. loss: 2886084838885437734912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 2900953279.08, NNZs: 2, Bias: 183027296066.803925, T: 10368, Avg. loss: 2893494137214684626944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 81 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 532348890181.77, NNZs: 2, Bias: 29043982865.131660, T: 128, Avg. loss: 17907718726249551309746208768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 825913144537.72, NNZs: 2, Bias: 82434699025.852570, T: 256, Avg. loss: 20196309310272005897508093952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 392193509174.41, NNZs: 2, Bias: 82434699025.852570, T: 384, Avg. loss: 21111103435703936026559905792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 433455367198.60, NNZs: 2, Bias: 102434699025.852570, T: 512, Avg. loss: 19157608840191168036816814080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 408964028912.03, NNZs: 2, Bias: 214495161344.029419, T: 640, Avg. loss: 20307405431933326792268447744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1629969813853.13, NNZs: 2, Bias: 249266282037.980225, T: 768, Avg. loss: 20377567054602292843365007360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 238395042731.21, NNZs: 2, Bias: 263527616957.757050, T: 896, Avg. loss: 1037434364724641682679660544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 263629318153.53, NNZs: 2, Bias: 255937088735.216766, T: 1024, Avg. loss: 802598674302137930673553408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 336966395600.67, NNZs: 2, Bias: 258915845784.002106, T: 1152, Avg. loss: 756458914658473688059346944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 455434380522.70, NNZs: 2, Bias: 256016916562.309174, T: 1280, Avg. loss: 869073472755954734346534912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 269448196560.03, NNZs: 2, Bias: 264030722462.162750, T: 1408, Avg. loss: 831194526285922697677373440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 40897854725.49, NNZs: 2, Bias: 251633841880.785126, T: 1536, Avg. loss: 828435465284892666561036288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 128068223754.27, NNZs: 2, Bias: 234656306736.066559, T: 1664, Avg. loss: 860187220522270813499424768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 135085185360.43, NNZs: 2, Bias: 233406048058.918976, T: 1792, Avg. loss: 796525713480016645886836736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 14330840261.97, NNZs: 2, Bias: 233257627224.184418, T: 1920, Avg. loss: 31262291587027339873091584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 96324306971.22, NNZs: 2, Bias: 233617446102.676392, T: 2048, Avg. loss: 29617344432238706598871040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 49013760405.24, NNZs: 2, Bias: 233752521721.356384, T: 2176, Avg. loss: 29659758528566833436426240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 27910334343.78, NNZs: 2, Bias: 236503643096.900085, T: 2304, Avg. loss: 29277123384232165683232768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 9903567909.92, NNZs: 2, Bias: 235735289671.729187, T: 2432, Avg. loss: 28425984561608559503081472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 7210377458.06, NNZs: 2, Bias: 232954945725.625458, T: 2560, Avg. loss: 31262063221316995300458496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 93221905764.96, NNZs: 2, Bias: 234894109050.408112, T: 2688, Avg. loss: 27994564105836231173079040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 66535965790.47, NNZs: 2, Bias: 236464738436.294556, T: 2816, Avg. loss: 25868463146973225520463872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 59082439347.61, NNZs: 2, Bias: 235217297693.543884, T: 2944, Avg. loss: 30247969349903807575752704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10914469911.66, NNZs: 2, Bias: 232454125682.184906, T: 3072, Avg. loss: 29262758306658840800657408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 35058411022.64, NNZs: 2, Bias: 232715987237.428314, T: 3200, Avg. loss: 31107482721630137046007808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 47340591230.09, NNZs: 2, Bias: 232749792112.479340, T: 3328, Avg. loss: 28364776168037535046434816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 62444677937.97, NNZs: 2, Bias: 234426217895.401489, T: 3456, Avg. loss: 31315557335702457970327552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 5870335734.15, NNZs: 2, Bias: 234839928709.611511, T: 3584, Avg. loss: 1254010453619005435412480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 13035646513.73, NNZs: 2, Bias: 234400678346.158691, T: 3712, Avg. loss: 586768087753786260455424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5130991674.28, NNZs: 2, Bias: 234026704517.684692, T: 3840, Avg. loss: 537931950888007323615232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5294154701.51, NNZs: 2, Bias: 233951642304.278717, T: 3968, Avg. loss: 544310243379079861501952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6248614749.19, NNZs: 2, Bias: 233575320575.135620, T: 4096, Avg. loss: 533791562936238364164096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4606912858.61, NNZs: 2, Bias: 233701573738.149445, T: 4224, Avg. loss: 595141466467576693391360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 5712863170.16, NNZs: 2, Bias: 233298959585.892914, T: 4352, Avg. loss: 475652062015662174765056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 20248605110.72, NNZs: 2, Bias: 232906327617.718170, T: 4480, Avg. loss: 693765423318786147090432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6482792121.44, NNZs: 2, Bias: 232566925528.187317, T: 4608, Avg. loss: 691889480869855291768832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 7128749985.02, NNZs: 2, Bias: 232309396372.937866, T: 4736, Avg. loss: 611876508741826684911616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 15197311503.51, NNZs: 2, Bias: 231941034942.442657, T: 4864, Avg. loss: 520100243338133707423744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1313968406.11, NNZs: 2, Bias: 231902540537.118927, T: 4992, Avg. loss: 619541767431253204664320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2504201767.14, NNZs: 2, Bias: 231800719578.981842, T: 5120, Avg. loss: 6397405440767239913472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3282461564.59, NNZs: 2, Bias: 231711828528.308167, T: 5248, Avg. loss: 5355749712970318348288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3744763155.17, NNZs: 2, Bias: 231625168639.361328, T: 5376, Avg. loss: 5552525417920847675392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3686333119.21, NNZs: 2, Bias: 231542879277.401978, T: 5504, Avg. loss: 5858600618117240455168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3714654976.79, NNZs: 2, Bias: 231465383142.428955, T: 5632, Avg. loss: 5269783236198569869312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3559936174.46, NNZs: 2, Bias: 231386285945.036346, T: 5760, Avg. loss: 5850248893586515951616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3618756694.82, NNZs: 2, Bias: 231304112036.777924, T: 5888, Avg. loss: 5808501127452265807872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3735149886.83, NNZs: 2, Bias: 231223700136.994202, T: 6016, Avg. loss: 5331622818970181042176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3718863189.64, NNZs: 2, Bias: 231145737555.808075, T: 6144, Avg. loss: 5561503116868597055488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3745347956.38, NNZs: 2, Bias: 231062418774.424774, T: 6272, Avg. loss: 5861299285602220376064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3695949948.99, NNZs: 2, Bias: 231047379788.379303, T: 6400, Avg. loss: 4566570980104046903296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3675333106.55, NNZs: 2, Bias: 231031771249.362732, T: 6528, Avg. loss: 4592184049394000592896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3628677434.47, NNZs: 2, Bias: 231017089740.115570, T: 6656, Avg. loss: 4441316727262912970752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3680878960.90, NNZs: 2, Bias: 231000127365.376495, T: 6784, Avg. loss: 4649280046230523084800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3627196350.61, NNZs: 2, Bias: 230985488832.564178, T: 6912, Avg. loss: 4467411702203619475456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3717675465.83, NNZs: 2, Bias: 230968228815.568787, T: 7040, Avg. loss: 4552283608238888321024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3684416789.50, NNZs: 2, Bias: 230952802190.911469, T: 7168, Avg. loss: 4599841192386239660032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3609392841.29, NNZs: 2, Bias: 230938112997.607086, T: 7296, Avg. loss: 4586541002659786653696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3641730845.80, NNZs: 2, Bias: 230934421341.745483, T: 7424, Avg. loss: 4457664108454427492352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3644476779.14, NNZs: 2, Bias: 230931223809.409393, T: 7552, Avg. loss: 4417616267973126258688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3636578985.21, NNZs: 2, Bias: 230928198851.508331, T: 7680, Avg. loss: 4411766040746933092352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3633583485.17, NNZs: 2, Bias: 230925094164.935516, T: 7808, Avg. loss: 4414791930423645569024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3642601228.73, NNZs: 2, Bias: 230921793975.171265, T: 7936, Avg. loss: 4422560266797191266304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3651743153.00, NNZs: 2, Bias: 230918499065.382690, T: 8064, Avg. loss: 4411671842533704990720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3639171785.92, NNZs: 2, Bias: 230915546972.358856, T: 8192, Avg. loss: 4413656982205534568448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3627673710.76, NNZs: 2, Bias: 230912602955.962067, T: 8320, Avg. loss: 4376819983210745692160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3633282145.03, NNZs: 2, Bias: 230909351248.243652, T: 8448, Avg. loss: 4430196790822109184000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3638252621.68, NNZs: 2, Bias: 230906116972.213989, T: 8576, Avg. loss: 4419482380171482234880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3647690253.43, NNZs: 2, Bias: 230902814570.690826, T: 8704, Avg. loss: 4415392076978607620096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3659471012.20, NNZs: 2, Bias: 230899487884.855347, T: 8832, Avg. loss: 4396067566623643402240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3644512304.47, NNZs: 2, Bias: 230896569440.895905, T: 8960, Avg. loss: 4419531516380999319552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 70 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1607495264486.30, NNZs: 2, Bias: 12791279145.757519, T: 128, Avg. loss: 20333584553439519512509546496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1760990858174.08, NNZs: 2, Bias: -47208720854.242477, T: 256, Avg. loss: 19837484910721796215599529984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 294644025175.37, NNZs: 2, Bias: -45410375445.045120, T: 384, Avg. loss: 22747499009041280465874452480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 435167120579.38, NNZs: 2, Bias: -96357028762.340057, T: 512, Avg. loss: 22627356754294423333015388160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1996647832767.51, NNZs: 2, Bias: -73486115349.701721, T: 640, Avg. loss: 20521473136714803057459724288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 208308372477.28, NNZs: 2, Bias: -61978354361.345566, T: 768, Avg. loss: 21413881240253320075197546496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1148046271047.90, NNZs: 2, Bias: -64409149393.399902, T: 896, Avg. loss: 22126614768177978242236416000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 291000635225.48, NNZs: 2, Bias: -58621769453.676773, T: 1024, Avg. loss: 1106417686448053755307884544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 146894857113.04, NNZs: 2, Bias: -46819851277.659378, T: 1152, Avg. loss: 816069328650702437451038720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 215987922302.79, NNZs: 2, Bias: -67589363148.413971, T: 1280, Avg. loss: 835777496561379467887378432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 266697708681.85, NNZs: 2, Bias: -67611059589.453888, T: 1408, Avg. loss: 912281014023208963531603968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 93229295334.61, NNZs: 2, Bias: -65041639398.711578, T: 1536, Avg. loss: 801856964286851418976944128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 123249142368.29, NNZs: 2, Bias: -75017764961.661591, T: 1664, Avg. loss: 873777557108734630719127552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 218881432070.18, NNZs: 2, Bias: -92019919367.914505, T: 1792, Avg. loss: 788332090444694895963668480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 372686538062.52, NNZs: 2, Bias: -105985739664.638062, T: 1920, Avg. loss: 765507184500850797999816704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 137313832065.81, NNZs: 2, Bias: -102753647773.346405, T: 2048, Avg. loss: 864819051315876286288625664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 302642078362.13, NNZs: 2, Bias: -111432478305.812073, T: 2176, Avg. loss: 886380902412073037440483328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 104412944697.51, NNZs: 2, Bias: -109045903016.770401, T: 2304, Avg. loss: 857546937960796053403860992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 150082085000.98, NNZs: 2, Bias: -118140113141.594894, T: 2432, Avg. loss: 805120050812504104755003392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 359764757796.12, NNZs: 2, Bias: -110945983002.633255, T: 2560, Avg. loss: 836331602325436130608021504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 44466272535.07, NNZs: 2, Bias: -109801719856.526230, T: 2688, Avg. loss: 77477669734134955949162496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 31904467084.49, NNZs: 2, Bias: -108336507066.752777, T: 2816, Avg. loss: 28993513571106759519502336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 82269667912.83, NNZs: 2, Bias: -108075413288.975220, T: 2944, Avg. loss: 29667246652876646655197184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 12639227705.75, NNZs: 2, Bias: -105642071551.330948, T: 3072, Avg. loss: 35977110728588951063363584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 29086477391.53, NNZs: 2, Bias: -104876428882.920105, T: 3200, Avg. loss: 31109609619851176988114944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 14099711543.09, NNZs: 2, Bias: -105831797299.736313, T: 3328, Avg. loss: 30909004299856217072730112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 3940669102.29, NNZs: 2, Bias: -106103721578.311951, T: 3456, Avg. loss: 29711309124545764057415680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 10045600945.72, NNZs: 2, Bias: -105753083828.314697, T: 3584, Avg. loss: 525758482163505412702208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 6399756338.55, NNZs: 2, Bias: -105405843927.304825, T: 3712, Avg. loss: 605023583473588559151104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8995971027.11, NNZs: 2, Bias: -105345013264.215561, T: 3840, Avg. loss: 664960356701930765942784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6512829886.48, NNZs: 2, Bias: -105386514297.478012, T: 3968, Avg. loss: 560535584638442177298432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 14033794193.90, NNZs: 2, Bias: -105092141180.713394, T: 4096, Avg. loss: 506568722172184065212416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7791979452.64, NNZs: 2, Bias: -105168734580.973083, T: 4224, Avg. loss: 645361479586708025507840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6368835802.88, NNZs: 2, Bias: -105214169958.866074, T: 4352, Avg. loss: 321489838387755713822720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 14832921522.89, NNZs: 2, Bias: -105094164268.930695, T: 4480, Avg. loss: 437108921538019825025024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3850871727.66, NNZs: 2, Bias: -105161288540.546829, T: 4608, Avg. loss: 597654483814721890811904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2871614555.16, NNZs: 2, Bias: -105196134760.069763, T: 4736, Avg. loss: 562808299727546409287680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9865313913.49, NNZs: 2, Bias: -105080645322.284943, T: 4864, Avg. loss: 569252523043302638878720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4140015609.81, NNZs: 2, Bias: -104725238504.543152, T: 4992, Avg. loss: 716728534023238022332416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2982635435.28, NNZs: 2, Bias: -104710914082.411072, T: 5120, Avg. loss: 1871983995241773662208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2476487073.02, NNZs: 2, Bias: -104684515815.930038, T: 5248, Avg. loss: 1287667797417832218624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2088355668.68, NNZs: 2, Bias: -104656186775.594711, T: 5376, Avg. loss: 1220654064464575332352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1948923170.69, NNZs: 2, Bias: -104625022894.357529, T: 5504, Avg. loss: 1070956317201200971776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1840171365.93, NNZs: 2, Bias: -104592616529.609879, T: 5632, Avg. loss: 1101650861782902636544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1811319901.42, NNZs: 2, Bias: -104559345626.864029, T: 5760, Avg. loss: 1016170126848058327040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1698283624.62, NNZs: 2, Bias: -104527381524.122849, T: 5888, Avg. loss: 1077697719820221939712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1711633300.47, NNZs: 2, Bias: -104494008612.983673, T: 6016, Avg. loss: 1014771368123463237632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1780066460.54, NNZs: 2, Bias: -104461657095.425476, T: 6144, Avg. loss: 1006843564079634841600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1719956513.07, NNZs: 2, Bias: -104429919843.460358, T: 6272, Avg. loss: 1072170191944785592320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1663126728.55, NNZs: 2, Bias: -104398398123.206726, T: 6400, Avg. loss: 1041646198697810853888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1655182582.96, NNZs: 2, Bias: -104364075107.061935, T: 6528, Avg. loss: 1092257493392938631168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1693166912.30, NNZs: 2, Bias: -104329563962.546936, T: 6656, Avg. loss: 1094096087947942952960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1741386583.22, NNZs: 2, Bias: -104296161152.244583, T: 6784, Avg. loss: 993982550870585245696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1707556882.35, NNZs: 2, Bias: -104264381575.082611, T: 6912, Avg. loss: 1017259135083371167744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1822804703.63, NNZs: 2, Bias: -104229687803.292999, T: 7040, Avg. loss: 982964330382124515328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1729349112.36, NNZs: 2, Bias: -104197588420.574249, T: 7168, Avg. loss: 1087406844602379534336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1910194420.14, NNZs: 2, Bias: -104162347023.480881, T: 7296, Avg. loss: 988893468794233159680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1829140654.24, NNZs: 2, Bias: -104129884355.967728, T: 7424, Avg. loss: 1064878502833899044864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1773709911.00, NNZs: 2, Bias: -104096775078.551437, T: 7552, Avg. loss: 1060243315824581279744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1755139971.60, NNZs: 2, Bias: -104064732614.248108, T: 7680, Avg. loss: 1019481097670612746240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1755097317.13, NNZs: 2, Bias: -104058147108.380905, T: 7808, Avg. loss: 848886460650690314240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1777888905.94, NNZs: 2, Bias: -104051119379.113266, T: 7936, Avg. loss: 855987813574547603456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1770660909.67, NNZs: 2, Bias: -104044618855.757751, T: 8064, Avg. loss: 855866584186222411776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1775790571.58, NNZs: 2, Bias: -104037831443.089172, T: 8192, Avg. loss: 865571596084302446592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1750920889.98, NNZs: 2, Bias: -104031778612.930328, T: 8320, Avg. loss: 835646319636891828224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1763800737.33, NNZs: 2, Bias: -104024994287.025833, T: 8448, Avg. loss: 846446269009174069248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1756830888.59, NNZs: 2, Bias: -104018419289.599304, T: 8576, Avg. loss: 864214422026384703488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1764039517.11, NNZs: 2, Bias: -104011694808.987534, T: 8704, Avg. loss: 850587790539441831936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1749079372.25, NNZs: 2, Bias: -104005364113.238846, T: 8832, Avg. loss: 851599520172497698816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1780864735.11, NNZs: 2, Bias: -103998295722.251816, T: 8960, Avg. loss: 840023735932780019712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1767169360.25, NNZs: 2, Bias: -103997190368.394958, T: 9088, Avg. loss: 842386987035928166400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1765660244.61, NNZs: 2, Bias: -103995891438.886734, T: 9216, Avg. loss: 832724112976005169152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1763886509.45, NNZs: 2, Bias: -103994597479.404831, T: 9344, Avg. loss: 832406023615788613632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1761253267.23, NNZs: 2, Bias: -103993319989.871902, T: 9472, Avg. loss: 831114758034609668096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1763909920.18, NNZs: 2, Bias: -103991952279.064087, T: 9600, Avg. loss: 831316109697348796416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1765795691.30, NNZs: 2, Bias: -103990598692.650543, T: 9728, Avg. loss: 830540696218137264128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1762594474.50, NNZs: 2, Bias: -103989330426.852890, T: 9856, Avg. loss: 831383020374130425856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1762375969.31, NNZs: 2, Bias: -103988014881.163025, T: 9984, Avg. loss: 829139291349923921920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1763635926.21, NNZs: 2, Bias: -103986674117.228928, T: 10112, Avg. loss: 829207518110995185664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1760118060.56, NNZs: 2, Bias: -103985412806.845459, T: 10240, Avg. loss: 830350552451343056896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1762638426.54, NNZs: 2, Bias: -103984046622.001938, T: 10368, Avg. loss: 831745057049479217152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1762079003.37, NNZs: 2, Bias: -103982733199.756866, T: 10496, Avg. loss: 831463778049898971136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 1766777738.50, NNZs: 2, Bias: -103981336259.490585, T: 10624, Avg. loss: 827630771876556177408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 1764491106.45, NNZs: 2, Bias: -103980052355.871567, T: 10752, Avg. loss: 831433925771354439680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 1761275943.42, NNZs: 2, Bias: -103978785069.483322, T: 10880, Avg. loss: 830831676703637897216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 1764337978.56, NNZs: 2, Bias: -103977413785.323380, T: 11008, Avg. loss: 828996212517379244032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 1763072820.79, NNZs: 2, Bias: -103976115482.177963, T: 11136, Avg. loss: 829440259539427917824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 1762555703.87, NNZs: 2, Bias: -103974802470.111069, T: 11264, Avg. loss: 830603505869370818560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 88 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 868289905250.45, NNZs: 2, Bias: 86171300595.907837, T: 128, Avg. loss: 22233372677539158563433218048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2041152382641.88, NNZs: 2, Bias: 106876197886.793320, T: 256, Avg. loss: 21174053282950542783305220096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 522445829022.07, NNZs: 2, Bias: 146876197886.793335, T: 384, Avg. loss: 23042687630166733707213275136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 864313674589.09, NNZs: 2, Bias: 111454685888.567535, T: 512, Avg. loss: 23519203284441394066122342400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1006353871415.80, NNZs: 2, Bias: 125396126098.423996, T: 640, Avg. loss: 21180364161343913591832576000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1481018321780.82, NNZs: 2, Bias: 125396126098.424011, T: 768, Avg. loss: 22831186116154648762192494592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 937813183934.80, NNZs: 2, Bias: 65396126098.424011, T: 896, Avg. loss: 21065683093107563566077050880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 456632147406.12, NNZs: 2, Bias: 67847682410.207001, T: 1024, Avg. loss: 23730990886391263350751232000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 537583664883.64, NNZs: 2, Bias: 27847682410.207001, T: 1152, Avg. loss: 23738987406203500567988273152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1140929854229.92, NNZs: 2, Bias: 87847682410.207001, T: 1280, Avg. loss: 25201645388871424152497553408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1096614965799.05, NNZs: 2, Bias: 107847682410.207001, T: 1408, Avg. loss: 24766160236445862930346409984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 991473417111.57, NNZs: 2, Bias: 83716628504.495773, T: 1536, Avg. loss: 24463125210395792880198221824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 347351684266.88, NNZs: 2, Bias: 79167162730.943069, T: 1664, Avg. loss: 1001603600628118908498345984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 138937797783.04, NNZs: 2, Bias: 72107172446.429504, T: 1792, Avg. loss: 927225936796966715392000000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 241193000014.80, NNZs: 2, Bias: 78205810479.674545, T: 1920, Avg. loss: 888128903141011089688363008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 475183576556.67, NNZs: 2, Bias: 77750785167.853271, T: 2048, Avg. loss: 923407829102380623738175488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 284365627588.62, NNZs: 2, Bias: 83049500234.145935, T: 2176, Avg. loss: 923716259004967935040028672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 202373727638.51, NNZs: 2, Bias: 92237308987.079559, T: 2304, Avg. loss: 924974837260551096845205504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 98993638012.11, NNZs: 2, Bias: 86109227083.660370, T: 2432, Avg. loss: 917053680727382340715675648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 509873905182.47, NNZs: 2, Bias: 88095536125.443832, T: 2560, Avg. loss: 886409866278515606202351616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 86776529417.91, NNZs: 2, Bias: 83846230067.254700, T: 2688, Avg. loss: 924828430727760628991131648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 225978819175.29, NNZs: 2, Bias: 94035825144.256699, T: 2816, Avg. loss: 851572711420987052793004032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 175213274602.83, NNZs: 2, Bias: 110682522986.328735, T: 2944, Avg. loss: 944432098422417457642733568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 191578825169.64, NNZs: 2, Bias: 100794903572.801849, T: 3072, Avg. loss: 907518190846711776359219200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 571872607483.10, NNZs: 2, Bias: 94045040881.965210, T: 3200, Avg. loss: 913489373741832711348158464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 377000738522.49, NNZs: 2, Bias: 115826564541.278610, T: 3328, Avg. loss: 978554498332224858009632768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 543626734288.86, NNZs: 2, Bias: 128694798716.525101, T: 3456, Avg. loss: 832365327451717153161478144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 315347106298.34, NNZs: 2, Bias: 114142894300.878174, T: 3584, Avg. loss: 981865948101440431443673088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 265736134100.14, NNZs: 2, Bias: 134107598734.873871, T: 3712, Avg. loss: 871414023372309064635645952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 44991447258.42, NNZs: 2, Bias: 134560993745.924225, T: 3840, Avg. loss: 887472422646345087573819392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 209564961245.08, NNZs: 2, Bias: 134006762850.165039, T: 3968, Avg. loss: 921510094899700604333981696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 30570675530.14, NNZs: 2, Bias: 135161746470.555206, T: 4096, Avg. loss: 958319005475352329444130816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 92690914649.80, NNZs: 2, Bias: 133355706478.901581, T: 4224, Avg. loss: 36881587662370652653879296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 44169813185.16, NNZs: 2, Bias: 132167333580.690536, T: 4352, Avg. loss: 32266152214308745543417856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 50946756037.75, NNZs: 2, Bias: 131402342719.697754, T: 4480, Avg. loss: 34490776515202145274822656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 33683929643.91, NNZs: 2, Bias: 132167125486.005112, T: 4608, Avg. loss: 35740995968819934191943680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 22426722537.88, NNZs: 2, Bias: 130265644428.849503, T: 4736, Avg. loss: 36369158639440035978412032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 47337698500.77, NNZs: 2, Bias: 132110239934.041840, T: 4864, Avg. loss: 32143989085488364111527936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 104484183635.11, NNZs: 2, Bias: 132377819001.305740, T: 4992, Avg. loss: 32653110828592676007313408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 110968414118.41, NNZs: 2, Bias: 132083980583.822495, T: 5120, Avg. loss: 32706955985937211137720320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 29503250963.91, NNZs: 2, Bias: 131539386768.765869, T: 5248, Avg. loss: 33463050368238190510211072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 75675307991.91, NNZs: 2, Bias: 131510168020.197845, T: 5376, Avg. loss: 31827748118132247519821824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 47378153262.73, NNZs: 2, Bias: 132776334834.488800, T: 5504, Avg. loss: 37105756913259589704613888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 29658134459.04, NNZs: 2, Bias: 131415873043.671021, T: 5632, Avg. loss: 36750987344936871315636224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 54414333382.63, NNZs: 2, Bias: 128187359677.494781, T: 5760, Avg. loss: 34254885043438461957177344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 33182139352.57, NNZs: 2, Bias: 125187892555.297821, T: 5888, Avg. loss: 35893792614079887858204672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 51486910556.26, NNZs: 2, Bias: 127617416350.957794, T: 6016, Avg. loss: 34677340221266662988447744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 6187167426.73, NNZs: 2, Bias: 127965306668.260574, T: 6144, Avg. loss: 1339678940740997645074432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 6981455336.36, NNZs: 2, Bias: 127956790702.612122, T: 6272, Avg. loss: 774980789423577285787648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 5886441169.09, NNZs: 2, Bias: 127682656714.515976, T: 6400, Avg. loss: 831770639480066620260352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1417332736.41, NNZs: 2, Bias: 127234062420.023346, T: 6528, Avg. loss: 609047356867363376988160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 13013710317.39, NNZs: 2, Bias: 126800994656.295822, T: 6656, Avg. loss: 562669660615082814472192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4277441981.43, NNZs: 2, Bias: 126674564705.850662, T: 6784, Avg. loss: 556724988159807136464896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4259301515.59, NNZs: 2, Bias: 126580587248.958954, T: 6912, Avg. loss: 834740937537225836462080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 19077009828.78, NNZs: 2, Bias: 126309015732.089935, T: 7040, Avg. loss: 491507981527810668756992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 8069598279.60, NNZs: 2, Bias: 126133742420.948105, T: 7168, Avg. loss: 801679664364868616585216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 7995686342.11, NNZs: 2, Bias: 126320666389.185822, T: 7296, Avg. loss: 675245379154265755353088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 7455920813.58, NNZs: 2, Bias: 126777930530.409470, T: 7424, Avg. loss: 728848749730701259046912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 10912749136.79, NNZs: 2, Bias: 126669214831.643387, T: 7552, Avg. loss: 780277017729601397325824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4072179445.50, NNZs: 2, Bias: 126585893927.881424, T: 7680, Avg. loss: 674001607012992891748352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1342965831.90, NNZs: 2, Bias: 126514741067.182053, T: 7808, Avg. loss: 5591815388283209252864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1704228602.12, NNZs: 2, Bias: 126465128903.285233, T: 7936, Avg. loss: 1706916888875539365888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1781892717.43, NNZs: 2, Bias: 126421135226.554199, T: 8064, Avg. loss: 1669747757893669093376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1903746208.86, NNZs: 2, Bias: 126377103710.484985, T: 8192, Avg. loss: 1569069929829990137856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1940102198.11, NNZs: 2, Bias: 126335805947.128647, T: 8320, Avg. loss: 1557005724228389175296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1879419159.64, NNZs: 2, Bias: 126294568657.700089, T: 8448, Avg. loss: 1646861552719542616064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1851148523.73, NNZs: 2, Bias: 126249223355.231964, T: 8576, Avg. loss: 1758272386454633054208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1779279055.52, NNZs: 2, Bias: 126205098999.456955, T: 8704, Avg. loss: 1782917849058548383744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1969315060.97, NNZs: 2, Bias: 126157992866.291687, T: 8832, Avg. loss: 1689686964340558135296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1881475601.78, NNZs: 2, Bias: 126115138487.787491, T: 8960, Avg. loss: 1656524921692230254592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1913769226.63, NNZs: 2, Bias: 126106054913.226135, T: 9088, Avg. loss: 1347626928730841284608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1891182133.12, NNZs: 2, Bias: 126097757940.498764, T: 9216, Avg. loss: 1359514590198468182016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1924520481.20, NNZs: 2, Bias: 126088639306.206696, T: 9344, Avg. loss: 1353001972451774562304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1886780716.65, NNZs: 2, Bias: 126080751831.058212, T: 9472, Avg. loss: 1332178681361865375744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1929533534.87, NNZs: 2, Bias: 126071453802.987015, T: 9600, Avg. loss: 1358375874157923532800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1913800774.89, NNZs: 2, Bias: 126063092623.034775, T: 9728, Avg. loss: 1355722260098801205248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1910014320.57, NNZs: 2, Bias: 126054586815.783340, T: 9856, Avg. loss: 1345632939450623066112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1910422746.20, NNZs: 2, Bias: 126045940213.381088, T: 9984, Avg. loss: 1358708466325893939200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1895015558.21, NNZs: 2, Bias: 126037549258.861343, T: 10112, Avg. loss: 1355078070021362286592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1920883934.82, NNZs: 2, Bias: 126035418527.251846, T: 10240, Avg. loss: 1329722075568425664512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1926909398.95, NNZs: 2, Bias: 126033613450.697388, T: 10368, Avg. loss: 1310148982186193453056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1918226522.06, NNZs: 2, Bias: 126032032364.606323, T: 10496, Avg. loss: 1311038880502296870912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 1926088390.15, NNZs: 2, Bias: 126030201705.935745, T: 10624, Avg. loss: 1308137298059056381952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 1918196075.80, NNZs: 2, Bias: 126028607270.300537, T: 10752, Avg. loss: 1311906943493927075840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 1919480007.60, NNZs: 2, Bias: 126026871415.508621, T: 10880, Avg. loss: 1312770454690089402368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 1916306378.79, NNZs: 2, Bias: 126025208001.487366, T: 11008, Avg. loss: 1309240990267516387328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 1926071007.28, NNZs: 2, Bias: 126023349899.560272, T: 11136, Avg. loss: 1306898051822800338944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 1923012197.23, NNZs: 2, Bias: 126021679329.867477, T: 11264, Avg. loss: 1313619635970928017408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 1915533755.20, NNZs: 2, Bias: 126020084045.608688, T: 11392, Avg. loss: 1307432914560774045696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 1919359220.00, NNZs: 2, Bias: 126018312249.896835, T: 11520, Avg. loss: 1310313848687462973440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 1918007538.69, NNZs: 2, Bias: 126016618906.451767, T: 11648, Avg. loss: 1310830875474870665216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 1923029720.08, NNZs: 2, Bias: 126014827108.613129, T: 11776, Avg. loss: 1311698131377697062912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 92 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 975477695640.20, NNZs: 2, Bias: -41400081418.290588, T: 128, Avg. loss: 20310965480565452179312214016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1609143314586.04, NNZs: 2, Bias: -123852171918.734512, T: 256, Avg. loss: 25035634062151853570013528064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2391314207688.23, NNZs: 2, Bias: -83852171918.734512, T: 384, Avg. loss: 24086925895250451614224351232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 956230136503.08, NNZs: 2, Bias: -151868341908.106262, T: 512, Avg. loss: 24118389092904623769844187136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1353126374442.17, NNZs: 2, Bias: -151868341908.106262, T: 640, Avg. loss: 23479875700426926454852288512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 619379097220.15, NNZs: 2, Bias: -111868341908.106262, T: 768, Avg. loss: 24525860114587119687112327168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 21574504779.46, NNZs: 2, Bias: -113425626825.941742, T: 896, Avg. loss: 966143818591540821658435584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 43314512615.93, NNZs: 2, Bias: -98190731431.315277, T: 1024, Avg. loss: 882897600595756811684937728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 167810950917.88, NNZs: 2, Bias: -103431432408.300293, T: 1152, Avg. loss: 902835973048972120646746112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 460285727524.72, NNZs: 2, Bias: -122687429681.928513, T: 1280, Avg. loss: 940658761782761646651867136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 105733229907.62, NNZs: 2, Bias: -118817828430.254242, T: 1408, Avg. loss: 1034573354747591915789615104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 115873174787.50, NNZs: 2, Bias: -127703270095.309860, T: 1536, Avg. loss: 985698539087845400286068736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 483471957605.39, NNZs: 2, Bias: -128211620835.286118, T: 1664, Avg. loss: 986087283913780101522653184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 49457151962.68, NNZs: 2, Bias: -120125195167.652145, T: 1792, Avg. loss: 75121187068784555512037376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61019504076.34, NNZs: 2, Bias: -119139870850.096481, T: 1920, Avg. loss: 35444155659757638052216832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 30327864607.87, NNZs: 2, Bias: -117768806892.096436, T: 2048, Avg. loss: 36066796065878362241892352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 24108486629.70, NNZs: 2, Bias: -117869678325.843246, T: 2176, Avg. loss: 35444525237612917798469632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 52717916621.22, NNZs: 2, Bias: -117201201211.573105, T: 2304, Avg. loss: 34245076679660444950986752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 57180799401.27, NNZs: 2, Bias: -114889141306.277100, T: 2432, Avg. loss: 34030446841567341942145024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 65044786518.57, NNZs: 2, Bias: -116682084705.908447, T: 2560, Avg. loss: 34207010341700120812191744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 77876031004.86, NNZs: 2, Bias: -114701505302.542542, T: 2688, Avg. loss: 33384394019258653472718848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 49395715004.69, NNZs: 2, Bias: -114566514670.560394, T: 2816, Avg. loss: 35228597633272635589656576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 55362430141.42, NNZs: 2, Bias: -115131159897.791412, T: 2944, Avg. loss: 34026683876293950023139328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 39021706624.69, NNZs: 2, Bias: -114768571433.069977, T: 3072, Avg. loss: 37814590777120211626622976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 23455785711.56, NNZs: 2, Bias: -117212948650.275604, T: 3200, Avg. loss: 33798142709809867976081408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 38595653498.22, NNZs: 2, Bias: -115040459908.775589, T: 3328, Avg. loss: 34895413156400049751588864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 7400289520.86, NNZs: 2, Bias: -115241251039.330460, T: 3456, Avg. loss: 937937010753193711239168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 6704440860.11, NNZs: 2, Bias: -115038784335.113297, T: 3584, Avg. loss: 696661241403772709634048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3243142424.64, NNZs: 2, Bias: -114854242845.880753, T: 3712, Avg. loss: 835714262805436761636864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 7314934689.73, NNZs: 2, Bias: -114720332664.659439, T: 3840, Avg. loss: 708151881263857866375168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2529233323.01, NNZs: 2, Bias: -114806104476.906326, T: 3968, Avg. loss: 760924836750076441264128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4662729147.50, NNZs: 2, Bias: -114448383091.835510, T: 4096, Avg. loss: 759507267188894633820160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8113573190.06, NNZs: 2, Bias: -114169737337.196457, T: 4224, Avg. loss: 731361932397840110190592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4399805834.19, NNZs: 2, Bias: -114186941127.383026, T: 4352, Avg. loss: 8234075919505347837952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3224670487.10, NNZs: 2, Bias: -114171717479.428223, T: 4480, Avg. loss: 2135214265488574251008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2550209215.72, NNZs: 2, Bias: -114148165674.030594, T: 4608, Avg. loss: 1694702392719657140224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2333902529.16, NNZs: 2, Bias: -114117663469.822266, T: 4736, Avg. loss: 1274990089549662388224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2265603516.15, NNZs: 2, Bias: -114088138235.912460, T: 4864, Avg. loss: 1061525019457932361728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2172864607.04, NNZs: 2, Bias: -114056634595.820755, T: 4992, Avg. loss: 1213867867518805999616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2137115431.41, NNZs: 2, Bias: -114023769920.241547, T: 5120, Avg. loss: 1140910092088400412672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2048718853.86, NNZs: 2, Bias: -113991293826.099670, T: 5248, Avg. loss: 1193501801594034847744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2059005180.84, NNZs: 2, Bias: -113957111433.369690, T: 5376, Avg. loss: 1177070818794239688704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2185291251.32, NNZs: 2, Bias: -113922038044.751709, T: 5504, Avg. loss: 1083076672025622216704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2122505511.68, NNZs: 2, Bias: -113916378339.870361, T: 5632, Avg. loss: 987008800860649291776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2115561849.74, NNZs: 2, Bias: -113909883904.182938, T: 5760, Avg. loss: 952093298575495921664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2115004922.51, NNZs: 2, Bias: -113903213489.449158, T: 5888, Avg. loss: 959477326082023620608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2121682620.36, NNZs: 2, Bias: -113896400281.656448, T: 6016, Avg. loss: 960672187180182405120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2118369322.07, NNZs: 2, Bias: -113889781370.329529, T: 6144, Avg. loss: 958797872194646310912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2115773391.70, NNZs: 2, Bias: -113883168069.376633, T: 6272, Avg. loss: 956964158075295236096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2126709524.63, NNZs: 2, Bias: -113876349481.304367, T: 6400, Avg. loss: 949189560748182208512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2090061996.05, NNZs: 2, Bias: -113870352288.793243, T: 6528, Avg. loss: 959342225460539817984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2111179116.13, NNZs: 2, Bias: -113863396366.944870, T: 6656, Avg. loss: 941570186816303923200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2122794201.51, NNZs: 2, Bias: -113856579093.508713, T: 6784, Avg. loss: 947342857924733304832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2113392611.56, NNZs: 2, Bias: -113850112070.395386, T: 6912, Avg. loss: 954259519256634195968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2090760006.76, NNZs: 2, Bias: -113843905125.968033, T: 7040, Avg. loss: 952622418204005105664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2104288942.92, NNZs: 2, Bias: -113836981556.776199, T: 7168, Avg. loss: 957926816437275328512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2101759924.54, NNZs: 2, Bias: -113830340164.984985, T: 7296, Avg. loss: 960440086317864452096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2092778499.18, NNZs: 2, Bias: -113829180980.266647, T: 7424, Avg. loss: 926379241654649880576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2091438710.84, NNZs: 2, Bias: -113827884328.171295, T: 7552, Avg. loss: 923599243199220416512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2095851196.84, NNZs: 2, Bias: -113826478768.075195, T: 7680, Avg. loss: 925487792393715318784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2093889819.48, NNZs: 2, Bias: -113825192945.700897, T: 7808, Avg. loss: 924072250112588120064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2097455577.78, NNZs: 2, Bias: -113823804575.371735, T: 7936, Avg. loss: 924381080845186105344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2095469770.84, NNZs: 2, Bias: -113822516908.813629, T: 8064, Avg. loss: 925624533328909041664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2097564047.64, NNZs: 2, Bias: -113821158689.097214, T: 8192, Avg. loss: 922316904848903897088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2093170317.81, NNZs: 2, Bias: -113819924391.610168, T: 8320, Avg. loss: 919360417442474491904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2101408234.57, NNZs: 2, Bias: -113818453809.941040, T: 8448, Avg. loss: 921422287861744402432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2099455606.09, NNZs: 2, Bias: -113817164663.957855, T: 8576, Avg. loss: 926271630942701092864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2096458646.10, NNZs: 2, Bias: -113815898693.190811, T: 8704, Avg. loss: 923504460922450214912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2101977752.54, NNZs: 2, Bias: -113814478512.984955, T: 8832, Avg. loss: 921146605323354374144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2096868669.77, NNZs: 2, Bias: -113813252833.286301, T: 8960, Avg. loss: 922666648020231127040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 70 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 409011492732.52, NNZs: 2, Bias: 63147544333.597198, T: 128, Avg. loss: 21129946114162606850351038464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1444136026659.53, NNZs: 2, Bias: 43147544333.597198, T: 256, Avg. loss: 21482954918308008382540283904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 922728168733.65, NNZs: 2, Bias: 20742731859.357048, T: 384, Avg. loss: 19945444887622528796435939328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1847799248331.40, NNZs: 2, Bias: 32524700892.720367, T: 512, Avg. loss: 21659387323731985021811032064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1593974944883.42, NNZs: 2, Bias: -7475299107.279633, T: 640, Avg. loss: 22263674435974449232869326848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2081997311195.31, NNZs: 2, Bias: -87475299107.279633, T: 768, Avg. loss: 20339188884716669256014495744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1563236059517.67, NNZs: 2, Bias: -227080234957.001190, T: 896, Avg. loss: 20731109682592738847645237248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 805043685903.78, NNZs: 2, Bias: -200430912306.216492, T: 1024, Avg. loss: 19809366257288992654108917760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 217447761718.99, NNZs: 2, Bias: -115005379655.452820, T: 1152, Avg. loss: 22096826535454326745370460160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1389753737511.26, NNZs: 2, Bias: -194559272517.608429, T: 1280, Avg. loss: 19541921725533377104535617536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 427795117643.84, NNZs: 2, Bias: -172007559520.530731, T: 1408, Avg. loss: 22877938858348060931790995456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1019402360957.10, NNZs: 2, Bias: -152007559520.530731, T: 1536, Avg. loss: 23061998489378138933000404992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1506105882136.67, NNZs: 2, Bias: -101403225602.290375, T: 1664, Avg. loss: 20246338970418464148219232256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1075554287672.13, NNZs: 2, Bias: -121403225602.290375, T: 1792, Avg. loss: 20573338232241185902328545280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 469952360849.87, NNZs: 2, Bias: 2693417341.241142, T: 1920, Avg. loss: 20581607016809487442013847552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 110149679727.97, NNZs: 2, Bias: -1146414855.096039, T: 2048, Avg. loss: 873371935812046219506614272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 398481584674.49, NNZs: 2, Bias: -8384768220.660608, T: 2176, Avg. loss: 771649847578511255145545728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 292724526910.09, NNZs: 2, Bias: 5519577511.733935, T: 2304, Avg. loss: 914904908692415280014426112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 463241659401.80, NNZs: 2, Bias: 5134952423.264008, T: 2432, Avg. loss: 813083769661579611158347776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 86969458455.13, NNZs: 2, Bias: -2277195526.225458, T: 2560, Avg. loss: 904016946430182279369195520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 57075852736.57, NNZs: 2, Bias: 3718625026.018437, T: 2688, Avg. loss: 921925235760750135512924160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 340547882235.11, NNZs: 2, Bias: -2793541476.353196, T: 2816, Avg. loss: 856863306490793017143721984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4734658411.69, NNZs: 2, Bias: -8124994105.611433, T: 2944, Avg. loss: 70707455371838845091840000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 5867359862.47, NNZs: 2, Bias: -9463369068.885468, T: 3072, Avg. loss: 33549544371500257686585344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 35714337000.65, NNZs: 2, Bias: -11450089434.528549, T: 3200, Avg. loss: 30169020093713360688775168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 83870664258.37, NNZs: 2, Bias: -14760916740.362347, T: 3328, Avg. loss: 33845995466881850702561280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 24032543130.40, NNZs: 2, Bias: -13310156184.180475, T: 3456, Avg. loss: 32727679159868108824379392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 10139752437.70, NNZs: 2, Bias: -13694630066.136477, T: 3584, Avg. loss: 31019129662703616716177408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 24959775775.01, NNZs: 2, Bias: -14074013801.588104, T: 3712, Avg. loss: 30346699793913736119451648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 42962699918.75, NNZs: 2, Bias: -10945260159.658371, T: 3840, Avg. loss: 32997313780447312871424000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4668312515.47, NNZs: 2, Bias: -10532827305.439619, T: 3968, Avg. loss: 915441376707736040898560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3626257840.75, NNZs: 2, Bias: -10411472828.954435, T: 4096, Avg. loss: 468949007230608812802048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2603435604.49, NNZs: 2, Bias: -10558192857.367470, T: 4224, Avg. loss: 485558679129502599086080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2978796710.27, NNZs: 2, Bias: -10590679288.717733, T: 4352, Avg. loss: 620017323386014219108352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2735633920.96, NNZs: 2, Bias: -10591366994.795046, T: 4480, Avg. loss: 540206278511524774412288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 13487192407.51, NNZs: 2, Bias: -10700675811.447231, T: 4608, Avg. loss: 608308431246546515787776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3288813709.04, NNZs: 2, Bias: -10962871551.560499, T: 4736, Avg. loss: 616810884504119087726592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2736537925.56, NNZs: 2, Bias: -10946842101.251720, T: 4864, Avg. loss: 585804612461570359296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2605520653.04, NNZs: 2, Bias: -10935380694.983593, T: 4992, Avg. loss: 150219855261610672128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2584410321.09, NNZs: 2, Bias: -10927482520.828979, T: 5120, Avg. loss: 39922370408205230080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2583860287.51, NNZs: 2, Bias: -10921613673.464905, T: 5248, Avg. loss: 18742218850718715904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2586429762.79, NNZs: 2, Bias: -10916840221.203018, T: 5376, Avg. loss: 12941029278360977408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2587276246.21, NNZs: 2, Bias: -10912626382.366400, T: 5504, Avg. loss: 13277806267448684544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2587883501.47, NNZs: 2, Bias: -10908475701.443687, T: 5632, Avg. loss: 13861556876207017984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2588289272.73, NNZs: 2, Bias: -10904448335.985022, T: 5760, Avg. loss: 12948361508087250944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2588800082.55, NNZs: 2, Bias: -10900360746.063633, T: 5888, Avg. loss: 13736765896754300928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2589004509.99, NNZs: 2, Bias: -10896647173.933674, T: 6016, Avg. loss: 12282432018987857920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2589048890.10, NNZs: 2, Bias: -10892729580.203812, T: 6144, Avg. loss: 13283912515554125824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2588871699.60, NNZs: 2, Bias: -10889103090.701906, T: 6272, Avg. loss: 12050911660293498880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2589063414.72, NNZs: 2, Bias: -10885379373.543530, T: 6400, Avg. loss: 12617657621533478912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2589425718.58, NNZs: 2, Bias: -10881498769.451485, T: 6528, Avg. loss: 12989359358566117376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2587959267.93, NNZs: 2, Bias: -10877845745.837156, T: 6656, Avg. loss: 14158799670152953856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2588241261.25, NNZs: 2, Bias: -10873917811.696968, T: 6784, Avg. loss: 12245466749158111232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2588661324.27, NNZs: 2, Bias: -10869830440.515879, T: 6912, Avg. loss: 13279019136875960320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2588262776.24, NNZs: 2, Bias: -10869152844.576324, T: 7040, Avg. loss: 10586741056214349824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2588244298.81, NNZs: 2, Bias: -10868380590.028814, T: 7168, Avg. loss: 10628419974277419008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2588398299.15, NNZs: 2, Bias: -10867577462.708235, T: 7296, Avg. loss: 10468151383815903232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2588261811.86, NNZs: 2, Bias: -10866842352.624767, T: 7424, Avg. loss: 10492463529405050880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2588462937.49, NNZs: 2, Bias: -10866034132.259745, T: 7552, Avg. loss: 10383803566325633024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2588516660.55, NNZs: 2, Bias: -10865251664.011415, T: 7680, Avg. loss: 10530205253585602560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2588372871.70, NNZs: 2, Bias: -10864525444.950371, T: 7808, Avg. loss: 10395880888196038656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2588646808.08, NNZs: 2, Bias: -10863686277.325096, T: 7936, Avg. loss: 10565133519395352576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2588541064.29, NNZs: 2, Bias: -10862941181.887011, T: 8064, Avg. loss: 10532178929423423488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2588600293.56, NNZs: 2, Bias: -10862158824.415668, T: 8192, Avg. loss: 10517246306317570048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2588572420.25, NNZs: 2, Bias: -10862013127.536137, T: 8320, Avg. loss: 10161328783151726592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2588616650.29, NNZs: 2, Bias: -10861850462.652405, T: 8448, Avg. loss: 10141070458621550592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2588594008.55, NNZs: 2, Bias: -10861703285.960535, T: 8576, Avg. loss: 10175231188247851008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2588627256.65, NNZs: 2, Bias: -10861542929.663700, T: 8704, Avg. loss: 10161971243950536704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2588620034.54, NNZs: 2, Bias: -10861391987.721624, T: 8832, Avg. loss: 10181128843942608896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2588633360.69, NNZs: 2, Bias: -10861236151.178146, T: 8960, Avg. loss: 10179145855141326848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2588643505.85, NNZs: 2, Bias: -10861081444.929535, T: 9088, Avg. loss: 10153491755970336768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 71 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 85215746075.41, NNZs: 2, Bias: -80965320288.533905, T: 128, Avg. loss: 19777731603150170263631429632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 467208274881.34, NNZs: 2, Bias: -20965320288.533905, T: 256, Avg. loss: 20196813477938845678879899648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2864487255484.84, NNZs: 2, Bias: 15059299732.237839, T: 384, Avg. loss: 19346178435139322919197343744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2004559342612.78, NNZs: 2, Bias: -32534203422.827301, T: 512, Avg. loss: 20110674705511855023535947776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 255056325819.45, NNZs: 2, Bias: -63752019360.376205, T: 640, Avg. loss: 21637188219847317434560151552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 826816068579.92, NNZs: 2, Bias: -83752019360.376205, T: 768, Avg. loss: 19153871132518594120198914048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1970654717936.55, NNZs: 2, Bias: 2918499783.745869, T: 896, Avg. loss: 19762806293025039796989329408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1137145506242.61, NNZs: 2, Bias: -37081500216.254135, T: 1024, Avg. loss: 20165396105053265089515225088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1972002170707.70, NNZs: 2, Bias: -88860723360.349258, T: 1152, Avg. loss: 19170032546831657156409819136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 331654527860.89, NNZs: 2, Bias: -68395804463.558670, T: 1280, Avg. loss: 19579984091098144174963163136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2035274271583.47, NNZs: 2, Bias: -87414156313.534714, T: 1408, Avg. loss: 18195953971406673824807124992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 874283933899.31, NNZs: 2, Bias: -52441274354.268051, T: 1536, Avg. loss: 20066922340037401796073750528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2158077584348.79, NNZs: 2, Bias: -7498237326.388672, T: 1664, Avg. loss: 19189811845112934357421522944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1276482332815.44, NNZs: 2, Bias: -41121757675.620407, T: 1792, Avg. loss: 21213475312494718874298613760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 624232985437.74, NNZs: 2, Bias: -58568226742.320953, T: 1920, Avg. loss: 22274750738582693690296238080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 726788039463.17, NNZs: 2, Bias: -58568226742.320953, T: 2048, Avg. loss: 19232601638368519867972190208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 166602345232.41, NNZs: 2, Bias: -61297117849.460503, T: 2176, Avg. loss: 866399583597828786601590784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 356237897207.61, NNZs: 2, Bias: -49782931302.115700, T: 2304, Avg. loss: 778418317973991281261543424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 125816446185.23, NNZs: 2, Bias: -52840040509.614769, T: 2432, Avg. loss: 741856626687529281986232320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 436009012199.75, NNZs: 2, Bias: -49227007872.106110, T: 2560, Avg. loss: 751664906196530268240609280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 387892373183.13, NNZs: 2, Bias: -48220407347.320564, T: 2688, Avg. loss: 900947208228280086361538560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 182808353555.02, NNZs: 2, Bias: -58218274879.291977, T: 2816, Avg. loss: 839713761686953766898630656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 546175084102.15, NNZs: 2, Bias: -42793304072.968735, T: 2944, Avg. loss: 853682141836753501184589824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 516090682488.13, NNZs: 2, Bias: -31106907373.276363, T: 3072, Avg. loss: 823795371156550911415812096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 108417109036.95, NNZs: 2, Bias: -34380531653.990234, T: 3200, Avg. loss: 85527048449595840221151232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 28586305383.22, NNZs: 2, Bias: -38949073718.418251, T: 3328, Avg. loss: 29827581371755260914171904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 47935515163.03, NNZs: 2, Bias: -42535241884.161453, T: 3456, Avg. loss: 29930148590440837497749504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 38968365697.28, NNZs: 2, Bias: -40254217508.807655, T: 3584, Avg. loss: 31373794488545232598073344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 74559425053.19, NNZs: 2, Bias: -43089053668.503304, T: 3712, Avg. loss: 28528201908996300819398656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 11166677945.32, NNZs: 2, Bias: -43658076743.171219, T: 3840, Avg. loss: 33082873331624136310521856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 98998205452.22, NNZs: 2, Bias: -44146385639.531677, T: 3968, Avg. loss: 29984587901217253590302720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 48327645070.73, NNZs: 2, Bias: -45803928752.260307, T: 4096, Avg. loss: 30066085955975109914132480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 53739877988.46, NNZs: 2, Bias: -47791095355.331993, T: 4224, Avg. loss: 30338597107421980395569152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 46474773867.62, NNZs: 2, Bias: -48597232543.814407, T: 4352, Avg. loss: 29695696920002354135171072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6418167800.88, NNZs: 2, Bias: -49143437556.491913, T: 4480, Avg. loss: 867771053377292356026368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2833892303.85, NNZs: 2, Bias: -48873704898.736732, T: 4608, Avg. loss: 468332297844278356344832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 15502137498.74, NNZs: 2, Bias: -48739725335.684715, T: 4736, Avg. loss: 512213113107799487807488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6895297983.13, NNZs: 2, Bias: -48637960718.917114, T: 4864, Avg. loss: 344229033218143921635328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 7071142219.52, NNZs: 2, Bias: -48791922595.544495, T: 4992, Avg. loss: 575654794318382259765248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7954806759.29, NNZs: 2, Bias: -48869537849.794189, T: 5120, Avg. loss: 415805790467679938674688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3611048911.39, NNZs: 2, Bias: -48490581284.851494, T: 5248, Avg. loss: 405962601100020008615936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2909196621.23, NNZs: 2, Bias: -48477751344.462959, T: 5376, Avg. loss: 367885862871649780498432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9087649512.19, NNZs: 2, Bias: -48717046349.125023, T: 5504, Avg. loss: 355241092174465793523712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4747783663.54, NNZs: 2, Bias: -48725111987.707726, T: 5632, Avg. loss: 10058828057525784412160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3599676378.15, NNZs: 2, Bias: -48730913556.366745, T: 5760, Avg. loss: 1565592703535893970944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3156675075.24, NNZs: 2, Bias: -48725977696.906731, T: 5888, Avg. loss: 601841376195812786176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2975918625.97, NNZs: 2, Bias: -48716050475.820633, T: 6016, Avg. loss: 342434404515216031744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2933745484.04, NNZs: 2, Bias: -48702406185.523460, T: 6144, Avg. loss: 255333020187894743040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2882051894.87, NNZs: 2, Bias: -48687370907.128677, T: 6272, Avg. loss: 289889520945284251648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2884861317.53, NNZs: 2, Bias: -48671416501.541130, T: 6400, Avg. loss: 240718372269322797056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2870193631.04, NNZs: 2, Bias: -48656503265.103622, T: 6528, Avg. loss: 240432347495514669056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2864111141.03, NNZs: 2, Bias: -48639940436.595039, T: 6656, Avg. loss: 250960774457281150976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2859872471.12, NNZs: 2, Bias: -48623584659.286613, T: 6784, Avg. loss: 248547226975817564160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2855752629.78, NNZs: 2, Bias: -48608091979.364182, T: 6912, Avg. loss: 238684664173235732480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2863110277.56, NNZs: 2, Bias: -48591973475.382431, T: 7040, Avg. loss: 249957253995476942848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2860416220.84, NNZs: 2, Bias: -48575639967.887695, T: 7168, Avg. loss: 243934754691879993344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2855149238.39, NNZs: 2, Bias: -48559807410.040604, T: 7296, Avg. loss: 248871417640453242880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2867837912.53, NNZs: 2, Bias: -48542556752.746887, T: 7424, Avg. loss: 246705276482234515456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2874419690.98, NNZs: 2, Bias: -48526318969.502457, T: 7552, Avg. loss: 250019793027802202112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2863316770.72, NNZs: 2, Bias: -48523581945.990303, T: 7680, Avg. loss: 209690664132587945984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2865801367.98, NNZs: 2, Bias: -48520198356.851425, T: 7808, Avg. loss: 198215280227187818496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2865491146.19, NNZs: 2, Bias: -48516967300.979706, T: 7936, Avg. loss: 199144668939875975168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2862561266.76, NNZs: 2, Bias: -48513830860.052353, T: 8064, Avg. loss: 203324413569952022528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2865667264.12, NNZs: 2, Bias: -48510477724.375137, T: 8192, Avg. loss: 193840891933410066432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2857614621.68, NNZs: 2, Bias: -48507682996.666992, T: 8320, Avg. loss: 200891278285834485760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2861104010.94, NNZs: 2, Bias: -48504160157.181923, T: 8448, Avg. loss: 203071525469106733056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2863791015.61, NNZs: 2, Bias: -48500750155.355232, T: 8576, Avg. loss: 199035369604773675008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2859944438.97, NNZs: 2, Bias: -48497707994.615486, T: 8704, Avg. loss: 200725337326176665600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2857381172.50, NNZs: 2, Bias: -48494631757.201653, T: 8832, Avg. loss: 198691794704553017344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2859669141.09, NNZs: 2, Bias: -48493837642.594826, T: 8960, Avg. loss: 196276285661232529408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2860506376.52, NNZs: 2, Bias: -48493138948.121910, T: 9088, Avg. loss: 193373720764630532096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2859828762.24, NNZs: 2, Bias: -48492524319.517059, T: 9216, Avg. loss: 195094649242482835456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2859849930.35, NNZs: 2, Bias: -48491869212.272484, T: 9344, Avg. loss: 194798452906667606016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2860008807.86, NNZs: 2, Bias: -48491207446.602852, T: 9472, Avg. loss: 194343883272726446080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2859274392.67, NNZs: 2, Bias: -48490598154.930473, T: 9600, Avg. loss: 194479267600180445184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2860149633.38, NNZs: 2, Bias: -48489894731.569450, T: 9728, Avg. loss: 194119139876849516544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 76 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 413377601870.95, NNZs: 2, Bias: -3378807709.682922, T: 128, Avg. loss: 19595679588862301578855448576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2575075594670.75, NNZs: 2, Bias: 110816334245.713013, T: 256, Avg. loss: 19991938083247737937957224448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 934545639226.47, NNZs: 2, Bias: 50816334245.713013, T: 384, Avg. loss: 22205574937549715412392869888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 926554426212.81, NNZs: 2, Bias: -72241796779.953308, T: 512, Avg. loss: 22433907023084111157562179584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 883518220327.98, NNZs: 2, Bias: -62091490481.164673, T: 640, Avg. loss: 19390967892933064329143517184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1083345009878.48, NNZs: 2, Bias: -2091490481.164673, T: 768, Avg. loss: 21684937663633089537209532416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 891253248513.67, NNZs: 2, Bias: 26920091089.600204, T: 896, Avg. loss: 19300548363729858787190767616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 691235218770.86, NNZs: 2, Bias: 134843687110.356369, T: 1024, Avg. loss: 19396917342861054071384571904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1803676144266.69, NNZs: 2, Bias: 47360981489.032745, T: 1152, Avg. loss: 21707016060151209529954009088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1058985116640.09, NNZs: 2, Bias: 107360981489.032745, T: 1280, Avg. loss: 21942036832112766905596510208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 234427320131.65, NNZs: 2, Bias: 151472855089.974091, T: 1408, Avg. loss: 21130107116100213034442555392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 346348004729.46, NNZs: 2, Bias: 171472855089.974091, T: 1536, Avg. loss: 20485324090077739274192551936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 275783934693.51, NNZs: 2, Bias: 162741572231.927826, T: 1664, Avg. loss: 912041071599176724200292352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 210758223260.70, NNZs: 2, Bias: 167003906049.071350, T: 1792, Avg. loss: 779266333827591806637834240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 239227039400.12, NNZs: 2, Bias: 151003906049.071350, T: 1920, Avg. loss: 798196696317499610155188224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 330049514317.48, NNZs: 2, Bias: 139847147916.899750, T: 2048, Avg. loss: 844478293418474799569567744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 225274300383.45, NNZs: 2, Bias: 158912827438.965698, T: 2176, Avg. loss: 854016294316611626397073408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 227537534954.50, NNZs: 2, Bias: 150711861986.443268, T: 2304, Avg. loss: 799847241807284708730470400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 132305416231.99, NNZs: 2, Bias: 132293814423.074860, T: 2432, Avg. loss: 748711053001017385912631296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 187668345615.23, NNZs: 2, Bias: 129484376877.043854, T: 2560, Avg. loss: 818061499939673003488444416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 165075780647.80, NNZs: 2, Bias: 133792668953.315704, T: 2688, Avg. loss: 789890110290722302852071424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 415189214493.86, NNZs: 2, Bias: 147235393369.132477, T: 2816, Avg. loss: 825330666332710301710942208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 100158038505.60, NNZs: 2, Bias: 140961330297.844116, T: 2944, Avg. loss: 803815379569643880817098752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 13899110414.12, NNZs: 2, Bias: 132968948580.148895, T: 3072, Avg. loss: 939809760155103556901273600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 20244417155.91, NNZs: 2, Bias: 131537528578.649292, T: 3200, Avg. loss: 29762454254019755817041920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 49490668246.04, NNZs: 2, Bias: 130482163470.224380, T: 3328, Avg. loss: 28437292312013145232113664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 85160036968.52, NNZs: 2, Bias: 129641199243.251297, T: 3456, Avg. loss: 28231061369960200549695488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 50451543189.23, NNZs: 2, Bias: 132982137854.818787, T: 3584, Avg. loss: 29795571803383519934152704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 28588746885.91, NNZs: 2, Bias: 130420020619.434479, T: 3712, Avg. loss: 31994010999275301149605888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 44092280288.37, NNZs: 2, Bias: 128997302439.903351, T: 3840, Avg. loss: 30041305004340558579105792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 75439847208.03, NNZs: 2, Bias: 125978980346.782364, T: 3968, Avg. loss: 30725854701383029675261952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 35746568620.97, NNZs: 2, Bias: 122892045663.125565, T: 4096, Avg. loss: 30682567176603851007459328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 11445635492.48, NNZs: 2, Bias: 123029753086.818420, T: 4224, Avg. loss: 916903294246666108928000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2964039821.01, NNZs: 2, Bias: 122776973809.231979, T: 4352, Avg. loss: 615174356558480295329792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7259375747.62, NNZs: 2, Bias: 122636421418.246338, T: 4480, Avg. loss: 646555769707778300444672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5611171529.52, NNZs: 2, Bias: 122344091982.275909, T: 4608, Avg. loss: 597786774666660859084800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2484513243.85, NNZs: 2, Bias: 122429671591.387680, T: 4736, Avg. loss: 699511657623736475975680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 19121215435.06, NNZs: 2, Bias: 121972668571.664810, T: 4864, Avg. loss: 318954053191003998781440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4156004411.95, NNZs: 2, Bias: 121711274491.266464, T: 4992, Avg. loss: 605848209299042979545088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 6519807365.37, NNZs: 2, Bias: 121464887230.060150, T: 5120, Avg. loss: 649928426696051250954240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9339717371.17, NNZs: 2, Bias: 121267118332.156433, T: 5248, Avg. loss: 644130934085398722248704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6670212951.63, NNZs: 2, Bias: 120975514803.541031, T: 5376, Avg. loss: 628792679976904263991296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2618447892.91, NNZs: 2, Bias: 120898285676.557175, T: 5504, Avg. loss: 557403224856765407428608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2664710563.01, NNZs: 2, Bias: 120853423996.724014, T: 5632, Avg. loss: 1597649705793587773440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2877048796.44, NNZs: 2, Bias: 120809147515.547668, T: 5760, Avg. loss: 1421926538254594342912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2991545261.49, NNZs: 2, Bias: 120767077080.402039, T: 5888, Avg. loss: 1452554565301168504832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2983157709.19, NNZs: 2, Bias: 120729545274.291000, T: 6016, Avg. loss: 1373269821587601752064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3040383552.74, NNZs: 2, Bias: 120690358471.410492, T: 6144, Avg. loss: 1342752512565952380928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3067909680.34, NNZs: 2, Bias: 120649383810.453049, T: 6272, Avg. loss: 1490375956097476067328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3049970635.27, NNZs: 2, Bias: 120611859674.303085, T: 6400, Avg. loss: 1424717086159090221056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3045085564.58, NNZs: 2, Bias: 120573591206.274902, T: 6528, Avg. loss: 1462409445782257664000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3112600866.51, NNZs: 2, Bias: 120534631843.591751, T: 6656, Avg. loss: 1371246230415680733184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3125731551.81, NNZs: 2, Bias: 120496710868.097000, T: 6784, Avg. loss: 1367624674982213976064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3140192844.31, NNZs: 2, Bias: 120488538716.742538, T: 6912, Avg. loss: 1185747995367298564096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3121866062.00, NNZs: 2, Bias: 120481378349.662613, T: 7040, Avg. loss: 1162592120308981825536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3125835354.57, NNZs: 2, Bias: 120473724994.554214, T: 7168, Avg. loss: 1147845702833345789952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3128975500.82, NNZs: 2, Bias: 120466003200.428696, T: 7296, Avg. loss: 1162682358494956355584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3119906289.09, NNZs: 2, Bias: 120458674344.843414, T: 7424, Avg. loss: 1150664053833591291904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3100602607.21, NNZs: 2, Bias: 120451639488.823944, T: 7552, Avg. loss: 1143827403422781538304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3096870096.96, NNZs: 2, Bias: 120444188006.136169, T: 7680, Avg. loss: 1149892546819546677248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3101878950.47, NNZs: 2, Bias: 120436441598.530701, T: 7808, Avg. loss: 1157038692544759726080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3111566549.68, NNZs: 2, Bias: 120428691246.130386, T: 7936, Avg. loss: 1140688800702797053952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3102637724.95, NNZs: 2, Bias: 120421286962.697159, T: 8064, Avg. loss: 1160636604478448992256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3133658233.55, NNZs: 2, Bias: 120413177503.633530, T: 8192, Avg. loss: 1106255182441308880896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3102400723.40, NNZs: 2, Bias: 120406305140.758347, T: 8320, Avg. loss: 1168952231593469280256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3098525538.92, NNZs: 2, Bias: 120399053634.641235, T: 8448, Avg. loss: 1115519819483199307776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3111812326.91, NNZs: 2, Bias: 120391195185.307846, T: 8576, Avg. loss: 1138752682756712169472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3110354928.91, NNZs: 2, Bias: 120383706195.269547, T: 8704, Avg. loss: 1144345169660470755328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3095497014.71, NNZs: 2, Bias: 120376457966.652695, T: 8832, Avg. loss: 1161803790986712317952.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3091485965.45, NNZs: 2, Bias: 120375068877.416611, T: 8960, Avg. loss: 1103171742720497156096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 3095729429.50, NNZs: 2, Bias: 120373455562.195114, T: 9088, Avg. loss: 1111895381395815792640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 3099025357.60, NNZs: 2, Bias: 120371870658.784592, T: 9216, Avg. loss: 1108803599719985446912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 3094696406.97, NNZs: 2, Bias: 120370472499.023682, T: 9344, Avg. loss: 1116324917412969447424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 3091334389.42, NNZs: 2, Bias: 120369055174.780746, T: 9472, Avg. loss: 1111844644007234502656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 3094608624.33, NNZs: 2, Bias: 120367463603.910034, T: 9600, Avg. loss: 1114221454340777181184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 75 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2437047538004.77, NNZs: 2, Bias: 6127505197.489273, T: 128, Avg. loss: 20419766762536796415701549056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2467117047795.33, NNZs: 2, Bias: 86127505197.489273, T: 256, Avg. loss: 21468566824178260356930469888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 541733091202.43, NNZs: 2, Bias: 46127505197.489273, T: 384, Avg. loss: 24163083071530351641847922688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 448089699564.64, NNZs: 2, Bias: 87129826428.618866, T: 512, Avg. loss: 23151886048544572567101374464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1974208911347.24, NNZs: 2, Bias: 49694428994.743362, T: 640, Avg. loss: 22614125149006074414268153856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1936189422449.81, NNZs: 2, Bias: 89694428994.743362, T: 768, Avg. loss: 25321057362146069008191848448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 452178895239.25, NNZs: 2, Bias: 77510827645.015701, T: 896, Avg. loss: 1821934521394420538555760640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 260821074985.36, NNZs: 2, Bias: 57527224398.108208, T: 1024, Avg. loss: 900319125765782828415451136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 313685791813.92, NNZs: 2, Bias: 49199321574.316048, T: 1152, Avg. loss: 883318853511653708951191552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 202010436738.42, NNZs: 2, Bias: 57841157428.138855, T: 1280, Avg. loss: 939430166970466242880602112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 141117929546.60, NNZs: 2, Bias: 55986033721.409660, T: 1408, Avg. loss: 858013377545125446515949568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 363333798590.84, NNZs: 2, Bias: 51445516155.570328, T: 1536, Avg. loss: 909991938772325413744017408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 316162104098.09, NNZs: 2, Bias: 67220463250.855103, T: 1664, Avg. loss: 892401411582962729578659840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 264534778366.75, NNZs: 2, Bias: 70097285172.326019, T: 1792, Avg. loss: 846195160238060711763247104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 78009708026.78, NNZs: 2, Bias: 81494072193.745163, T: 1920, Avg. loss: 886084294300184084043792384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 164062139048.55, NNZs: 2, Bias: 90997144324.536621, T: 2048, Avg. loss: 878977557933513787431714816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 381894846867.18, NNZs: 2, Bias: 103570650441.212921, T: 2176, Avg. loss: 844166868639592233002074112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 108837531690.40, NNZs: 2, Bias: 121148026993.984085, T: 2304, Avg. loss: 905245990950062788035215360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 123589316883.28, NNZs: 2, Bias: 124591684157.749878, T: 2432, Avg. loss: 845723353241873273778601984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 282156404057.33, NNZs: 2, Bias: 133576494015.288986, T: 2560, Avg. loss: 806697114227831434026942464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 569250595473.12, NNZs: 2, Bias: 125392670821.360382, T: 2688, Avg. loss: 902884973923336341753430016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 131751008557.88, NNZs: 2, Bias: 135836395569.830109, T: 2816, Avg. loss: 863804735820189295022440448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 161196950873.57, NNZs: 2, Bias: 135344020717.613617, T: 2944, Avg. loss: 911414013856770807352524800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 275566262660.79, NNZs: 2, Bias: 130264471970.611923, T: 3072, Avg. loss: 911748239272590786647031808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 414978641610.34, NNZs: 2, Bias: 129817368212.277954, T: 3200, Avg. loss: 914606737956219824799481856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 67732530777.02, NNZs: 2, Bias: 128105830056.463959, T: 3328, Avg. loss: 60506423265545598621712384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 17841003061.33, NNZs: 2, Bias: 128937257100.151794, T: 3456, Avg. loss: 30984083226100359130775552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 49228490328.49, NNZs: 2, Bias: 129564536109.915131, T: 3584, Avg. loss: 30415522467305476673503232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 46178981805.24, NNZs: 2, Bias: 128873575584.863998, T: 3712, Avg. loss: 32639826789761743558017024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 31495071764.02, NNZs: 2, Bias: 128433737832.670349, T: 3840, Avg. loss: 34451272243955158438903808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 35939261173.89, NNZs: 2, Bias: 124736731756.251389, T: 3968, Avg. loss: 32691577106703204048961536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 48138183562.48, NNZs: 2, Bias: 123298937992.581436, T: 4096, Avg. loss: 36204047434064630141419520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 37642468930.26, NNZs: 2, Bias: 122650127750.801193, T: 4224, Avg. loss: 35676991835387821301956608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6935955094.12, NNZs: 2, Bias: 123038954622.714905, T: 4352, Avg. loss: 981383990367271086194688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2135427097.42, NNZs: 2, Bias: 122670080636.998123, T: 4480, Avg. loss: 617664773449812354793472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3741916954.94, NNZs: 2, Bias: 122313094989.779831, T: 4608, Avg. loss: 601115448108057033179136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4334172938.08, NNZs: 2, Bias: 122133408966.595703, T: 4736, Avg. loss: 697609777231772994502656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 12483827070.73, NNZs: 2, Bias: 121705271183.265182, T: 4864, Avg. loss: 765343996460121332908032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 11461086089.09, NNZs: 2, Bias: 122124173160.884171, T: 4992, Avg. loss: 693184670036168213004288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 19596468271.88, NNZs: 2, Bias: 121505578670.796829, T: 5120, Avg. loss: 649996091459246101626880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3471984175.96, NNZs: 2, Bias: 121504747693.222626, T: 5248, Avg. loss: 663286737485389663043584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2941057071.57, NNZs: 2, Bias: 121472549529.111252, T: 5376, Avg. loss: 1812000516449237729280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2645957189.46, NNZs: 2, Bias: 121435047373.288620, T: 5504, Avg. loss: 1832226785084549365760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2560582667.46, NNZs: 2, Bias: 121397640089.876495, T: 5632, Avg. loss: 1447357003699281199104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2467855670.30, NNZs: 2, Bias: 121356541627.186172, T: 5760, Avg. loss: 1608053287279354707968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2416493935.20, NNZs: 2, Bias: 121317325462.983673, T: 5888, Avg. loss: 1613270036610932801536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2523760737.32, NNZs: 2, Bias: 121276073168.486649, T: 6016, Avg. loss: 1453889250586537492480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2548417438.45, NNZs: 2, Bias: 121235079239.882248, T: 6144, Avg. loss: 1583044315207957741568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2544676140.75, NNZs: 2, Bias: 121194006255.647003, T: 6272, Avg. loss: 1575941513757651369984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2509812829.90, NNZs: 2, Bias: 121186405370.789917, T: 6400, Avg. loss: 1280205713679412363264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2512436315.33, NNZs: 2, Bias: 121178261691.109146, T: 6528, Avg. loss: 1237556255802294272000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2508303894.65, NNZs: 2, Bias: 121170374671.004303, T: 6656, Avg. loss: 1221423009470054137856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2506417637.25, NNZs: 2, Bias: 121162175576.645599, T: 6784, Avg. loss: 1262115728082832195584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2497936520.24, NNZs: 2, Bias: 121154216056.001694, T: 6912, Avg. loss: 1247638394989009698816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2497526032.42, NNZs: 2, Bias: 121146043581.390182, T: 7040, Avg. loss: 1250762579192823676928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2490941148.17, NNZs: 2, Bias: 121138029867.699295, T: 7168, Avg. loss: 1247669557838470447104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2491590381.16, NNZs: 2, Bias: 121129804999.197586, T: 7296, Avg. loss: 1258128283717892308992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2480935845.21, NNZs: 2, Bias: 121128392584.978104, T: 7424, Avg. loss: 1214307898786608840704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2474809143.78, NNZs: 2, Bias: 121126905338.072723, T: 7552, Avg. loss: 1200294508555393564672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2484055202.11, NNZs: 2, Bias: 121125090796.073425, T: 7680, Avg. loss: 1208703822983329742848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2477959635.28, NNZs: 2, Bias: 121123589054.601395, T: 7808, Avg. loss: 1210680089118936137728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2479511445.27, NNZs: 2, Bias: 121121926268.862549, T: 7936, Avg. loss: 1213522871545627410432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2480149553.60, NNZs: 2, Bias: 121120285002.588638, T: 8064, Avg. loss: 1211544457232416243712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2479933687.36, NNZs: 2, Bias: 121118659484.193283, T: 8192, Avg. loss: 1212810826215296335872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 64 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2986145508845.81, NNZs: 2, Bias: -5402607599.430003, T: 128, Avg. loss: 47843697052749495394451324928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1900400484108.55, NNZs: 2, Bias: -5402607599.430003, T: 256, Avg. loss: 53518683629984243488565231616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1217875198860.70, NNZs: 2, Bias: -5402607599.430003, T: 384, Avg. loss: 51689909000160846147158540288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1068805407920.45, NNZs: 2, Bias: -5402607599.430003, T: 512, Avg. loss: 48446347081885349342544396288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1379095718215.38, NNZs: 2, Bias: -5402607599.430003, T: 640, Avg. loss: 52558398234366607777601683456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2310958459167.97, NNZs: 2, Bias: -5402607599.430003, T: 768, Avg. loss: 52631665680437704262210813952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 274951182089.24, NNZs: 2, Bias: 14256413924.007301, T: 896, Avg. loss: 2176664117278686420075020288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 132254639099.00, NNZs: 2, Bias: 17375581604.159424, T: 1024, Avg. loss: 943786417875341009890574336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 334317108767.49, NNZs: 2, Bias: 26149395918.982128, T: 1152, Avg. loss: 1017093300089549386793615360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 443474779199.71, NNZs: 2, Bias: 21938514913.503902, T: 1280, Avg. loss: 971956513703889754199687168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 447146479360.22, NNZs: 2, Bias: 27779402558.068615, T: 1408, Avg. loss: 1076190407415109057062633472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 432903700496.10, NNZs: 2, Bias: 16277029373.498608, T: 1536, Avg. loss: 1029554993933449258988470272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 143632851774.51, NNZs: 2, Bias: 6774531537.238438, T: 1664, Avg. loss: 921540981001630600361148416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 261234689656.18, NNZs: 2, Bias: 9906940884.097748, T: 1792, Avg. loss: 1015030418186413053594042368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 101890592738.76, NNZs: 2, Bias: 17298452906.441139, T: 1920, Avg. loss: 940821546434114364259696640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 230969181908.99, NNZs: 2, Bias: 11249735223.903316, T: 2048, Avg. loss: 966813600212689796194107392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 140571797572.25, NNZs: 2, Bias: -2219686295.097172, T: 2176, Avg. loss: 999804773374731606332276736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 87114861304.61, NNZs: 2, Bias: -3899645940.885325, T: 2304, Avg. loss: 1014694021602076616013381632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 83999351664.94, NNZs: 2, Bias: -2881393859.044202, T: 2432, Avg. loss: 32154120640795426007547904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 79741310334.72, NNZs: 2, Bias: -3920131286.340799, T: 2560, Avg. loss: 36414427361342587085520896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 38641454209.80, NNZs: 2, Bias: -3713646284.752562, T: 2688, Avg. loss: 33573103881983695863676928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 16165942110.56, NNZs: 2, Bias: -4442639400.369850, T: 2816, Avg. loss: 36100661304523399823884288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 30659503892.92, NNZs: 2, Bias: -3465585891.937942, T: 2944, Avg. loss: 35154075026656757580562432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 71227484754.00, NNZs: 2, Bias: -7353237638.230932, T: 3072, Avg. loss: 36650646822217705953689600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 5590912128.36, NNZs: 2, Bias: -6629797554.053123, T: 3200, Avg. loss: 1557704600567020385206272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 6327369733.07, NNZs: 2, Bias: -6728656795.489571, T: 3328, Avg. loss: 491376339068509986226176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 9625418013.60, NNZs: 2, Bias: -6628933065.518054, T: 3456, Avg. loss: 721821433136491240882176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 17945790908.88, NNZs: 2, Bias: -6736225747.562231, T: 3584, Avg. loss: 725062719268718943141888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 13246765584.59, NNZs: 2, Bias: -7147989584.062700, T: 3712, Avg. loss: 729642800021944016044032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2893627144.27, NNZs: 2, Bias: -7139387878.239332, T: 3840, Avg. loss: 615501193515209064448000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1044156789.16, NNZs: 2, Bias: -6835807765.058023, T: 3968, Avg. loss: 698506828190864354836480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 493808786.76, NNZs: 2, Bias: -6839004487.557628, T: 4096, Avg. loss: 97748422653095264256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 245992559.62, NNZs: 2, Bias: -6838977536.507066, T: 4224, Avg. loss: 23338336722592374784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 147667081.06, NNZs: 2, Bias: -6837714267.339364, T: 4352, Avg. loss: 6888479425092870144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 109148204.63, NNZs: 2, Bias: -6835857701.498782, T: 4480, Avg. loss: 4575118671227682816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 88697384.14, NNZs: 2, Bias: -6833790553.177298, T: 4608, Avg. loss: 4188011904556753920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 78714089.58, NNZs: 2, Bias: -6831642123.864949, T: 4736, Avg. loss: 4270353080418571264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 83282022.79, NNZs: 2, Bias: -6829371747.709167, T: 4864, Avg. loss: 4071300317706607616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 79289069.84, NNZs: 2, Bias: -6827121140.592866, T: 4992, Avg. loss: 4406602866564263936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 79732350.92, NNZs: 2, Bias: -6824853811.478336, T: 5120, Avg. loss: 4277041575577752064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 79170983.89, NNZs: 2, Bias: -6822807858.468032, T: 5248, Avg. loss: 3699151473537463296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 78008006.83, NNZs: 2, Bias: -6820723163.206691, T: 5376, Avg. loss: 3795273931752224768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 82172987.46, NNZs: 2, Bias: -6818431264.172575, T: 5504, Avg. loss: 4138986464262256128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 83280844.99, NNZs: 2, Bias: -6816135995.174538, T: 5632, Avg. loss: 4258009863102327296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 77140880.15, NNZs: 2, Bias: -6814023406.631723, T: 5760, Avg. loss: 4141650879276676096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 79088319.04, NNZs: 2, Bias: -6811773273.030616, T: 5888, Avg. loss: 4111701987152096768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 78590816.07, NNZs: 2, Bias: -6811331413.170083, T: 6016, Avg. loss: 3516139069483822592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 77930962.40, NNZs: 2, Bias: -6810900892.835500, T: 6144, Avg. loss: 3423397530475295744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 77904673.09, NNZs: 2, Bias: -6810457697.318614, T: 6272, Avg. loss: 3474877698699644416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 79831007.78, NNZs: 2, Bias: -6809987336.378200, T: 6400, Avg. loss: 3507595263245862912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 78504362.18, NNZs: 2, Bias: -6809556348.719296, T: 6528, Avg. loss: 3494023369857110528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 79070180.25, NNZs: 2, Bias: -6809105130.058801, T: 6656, Avg. loss: 3476194667099529216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 79342581.59, NNZs: 2, Bias: -6808655106.764938, T: 6784, Avg. loss: 3493909327573938176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 79048412.06, NNZs: 2, Bias: -6808569775.812841, T: 6912, Avg. loss: 3392502949981673984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 78952976.64, NNZs: 2, Bias: -6808482158.051450, T: 7040, Avg. loss: 3392928312137637888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 78897985.63, NNZs: 2, Bias: -6808394079.959920, T: 7168, Avg. loss: 3391864362492017664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 78834065.08, NNZs: 2, Bias: -6808306119.145429, T: 7296, Avg. loss: 3391759695779293696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 78865264.64, NNZs: 2, Bias: -6808217051.785425, T: 7424, Avg. loss: 3390959798096331776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 78917638.01, NNZs: 2, Bias: -6808127807.680924, T: 7552, Avg. loss: 3387912474228985856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 79080551.13, NNZs: 2, Bias: -6808037221.845862, T: 7680, Avg. loss: 3391826701030689792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 78990763.56, NNZs: 2, Bias: -6807949782.572944, T: 7808, Avg. loss: 3380400247446338048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 79249993.49, NNZs: 2, Bias: -6807858161.931984, T: 7936, Avg. loss: 3386682219019992064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 78502109.46, NNZs: 2, Bias: -6807778612.949815, T: 8064, Avg. loss: 3369115999793795072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 78910137.68, NNZs: 2, Bias: -6807685055.579194, T: 8192, Avg. loss: 3397180845768296960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 79121567.55, NNZs: 2, Bias: -6807593926.342072, T: 8320, Avg. loss: 3390240411918918144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 78969076.62, NNZs: 2, Bias: -6807507020.552714, T: 8448, Avg. loss: 3389427363014910976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 78781592.01, NNZs: 2, Bias: -6807420664.990450, T: 8576, Avg. loss: 3382812708029970944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 78893320.91, NNZs: 2, Bias: -6807330665.606846, T: 8704, Avg. loss: 3389978360343162880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 68 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 534000936328.77, NNZs: 2, Bias: -605082229.993511, T: 128, Avg. loss: 43398451312087791371426988032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 131061054474.62, NNZs: 2, Bias: -605082229.993511, T: 256, Avg. loss: 47681652956152301979959296000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 496678970764.82, NNZs: 2, Bias: -605082229.993511, T: 384, Avg. loss: 47666639925410903515667103744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 501977091110.74, NNZs: 2, Bias: -605082229.993511, T: 512, Avg. loss: 43441392518390900474509262848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 176819116613.56, NNZs: 2, Bias: -605082229.993511, T: 640, Avg. loss: 45790531413223155482226589696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1162552794500.10, NNZs: 2, Bias: -605082229.993511, T: 768, Avg. loss: 47955545944734264454700597248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 303502437337.17, NNZs: 2, Bias: 3570079461.068460, T: 896, Avg. loss: 1037099323722620042150412288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 134329370648.17, NNZs: 2, Bias: 8055595757.478317, T: 1024, Avg. loss: 861884408431657759493062656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 66837925885.36, NNZs: 2, Bias: 19215823407.604412, T: 1152, Avg. loss: 805558338363898381845135360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 212224788974.40, NNZs: 2, Bias: 24935862669.398560, T: 1280, Avg. loss: 874358498045121927323844608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 128448950166.43, NNZs: 2, Bias: 22280040249.705257, T: 1408, Avg. loss: 832400208624837687215390720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 100197240510.28, NNZs: 2, Bias: 30249373799.669659, T: 1536, Avg. loss: 891028295072639400630288384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 127550507210.05, NNZs: 2, Bias: 16026188592.449375, T: 1664, Avg. loss: 808085264566136906358718464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 343673514458.64, NNZs: 2, Bias: 27944106985.321308, T: 1792, Avg. loss: 878191049113314009133613056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 33438592590.68, NNZs: 2, Bias: 31746367280.982323, T: 1920, Avg. loss: 52006666317628502165159936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 23434269798.27, NNZs: 2, Bias: 30770243100.631329, T: 2048, Avg. loss: 32899804804181010837143552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 31336746547.79, NNZs: 2, Bias: 30323067730.884251, T: 2176, Avg. loss: 32685013183651885369786368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 21415471279.88, NNZs: 2, Bias: 31836810006.531898, T: 2304, Avg. loss: 32074561286426454246031360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10298678670.09, NNZs: 2, Bias: 30946700484.450523, T: 2432, Avg. loss: 31922633960176226368749568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 26346959796.31, NNZs: 2, Bias: 29605115658.690479, T: 2560, Avg. loss: 31321188613163173820760064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 23091584485.32, NNZs: 2, Bias: 29755909785.652184, T: 2688, Avg. loss: 32077255677993363328466944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 16843664332.15, NNZs: 2, Bias: 30412236559.419781, T: 2816, Avg. loss: 29113552325547498250698752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 78802184610.96, NNZs: 2, Bias: 31086617124.419395, T: 2944, Avg. loss: 32000781671886267837579264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 40568520332.43, NNZs: 2, Bias: 26466170150.137562, T: 3072, Avg. loss: 30087589545754649610420224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 25469996368.21, NNZs: 2, Bias: 27016346773.642830, T: 3200, Avg. loss: 31728422752297836454346752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 25587826694.86, NNZs: 2, Bias: 28479649037.554886, T: 3328, Avg. loss: 30709787621364248709431296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 35506846175.92, NNZs: 2, Bias: 28219780568.618397, T: 3456, Avg. loss: 34159386546392819931545600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 7799541881.30, NNZs: 2, Bias: 28000104726.037224, T: 3584, Avg. loss: 702036062448560262610944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3271724418.81, NNZs: 2, Bias: 27938711845.337379, T: 3712, Avg. loss: 554216205745911909842944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1269957420.79, NNZs: 2, Bias: 27815501756.441273, T: 3840, Avg. loss: 500997985076555833933824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 3032444690.32, NNZs: 2, Bias: 27969486233.509441, T: 3968, Avg. loss: 542514993902451490291712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2472457843.83, NNZs: 2, Bias: 28228993216.783497, T: 4096, Avg. loss: 568934913311769498746880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 493353904.98, NNZs: 2, Bias: 28117097540.707893, T: 4224, Avg. loss: 391605022152541153001472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2357995551.49, NNZs: 2, Bias: 27770599699.757053, T: 4352, Avg. loss: 568779954332953783304192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 12613355870.95, NNZs: 2, Bias: 27769800909.689865, T: 4480, Avg. loss: 663075747240429553188864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 265442917.74, NNZs: 2, Bias: 27700198061.923664, T: 4608, Avg. loss: 620483278341273861226496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8296687107.99, NNZs: 2, Bias: 27414203280.962048, T: 4736, Avg. loss: 255408736923671817355264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 12428888615.02, NNZs: 2, Bias: 27288998214.262127, T: 4864, Avg. loss: 437512573895904417808384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4083395182.02, NNZs: 2, Bias: 27091087815.254292, T: 4992, Avg. loss: 612491030658839484563456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 5479965438.65, NNZs: 2, Bias: 27003726823.211403, T: 5120, Avg. loss: 638443023618452161036288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 12895939052.22, NNZs: 2, Bias: 27072666133.310024, T: 5248, Avg. loss: 462193931100833399701504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9100209505.38, NNZs: 2, Bias: 26784428302.543472, T: 5376, Avg. loss: 593990009909827076096000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1616679947.12, NNZs: 2, Bias: 26837573085.615040, T: 5504, Avg. loss: 24444240636049956536320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 818880729.85, NNZs: 2, Bias: 26835344709.506172, T: 5632, Avg. loss: 252439850571159011328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 557441995.10, NNZs: 2, Bias: 26827842185.733303, T: 5760, Avg. loss: 90080146347418714112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 429347209.32, NNZs: 2, Bias: 26819278488.748367, T: 5888, Avg. loss: 77815218562928181248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 381663434.65, NNZs: 2, Bias: 26808989733.235550, T: 6016, Avg. loss: 77376139504424157184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 316122364.27, NNZs: 2, Bias: 26799268152.186676, T: 6144, Avg. loss: 74328066682017939456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 312529717.11, NNZs: 2, Bias: 26788720955.874035, T: 6272, Avg. loss: 75964413716736163840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 338853917.15, NNZs: 2, Bias: 26778051402.551849, T: 6400, Avg. loss: 73940423170388017152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 328969648.94, NNZs: 2, Bias: 26767731520.428570, T: 6528, Avg. loss: 74379183173427642368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 339963952.29, NNZs: 2, Bias: 26756837368.731480, T: 6656, Avg. loss: 78946715714098003968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 358463580.05, NNZs: 2, Bias: 26745673016.636372, T: 6784, Avg. loss: 79525016402730958848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 347718274.75, NNZs: 2, Bias: 26735155453.714928, T: 6912, Avg. loss: 76376265838504607744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 369245512.02, NNZs: 2, Bias: 26724167113.789791, T: 7040, Avg. loss: 78506686508989743104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 337327452.79, NNZs: 2, Bias: 26722414608.375854, T: 7168, Avg. loss: 67251462600403140608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 340940114.78, NNZs: 2, Bias: 26720258433.494606, T: 7296, Avg. loss: 64590245400893161472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 341078934.75, NNZs: 2, Bias: 26718150768.980381, T: 7424, Avg. loss: 64619962114392793088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 341593773.20, NNZs: 2, Bias: 26716037161.222656, T: 7552, Avg. loss: 64418434557405659136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 345467309.53, NNZs: 2, Bias: 26713891000.344730, T: 7680, Avg. loss: 64193707507523788800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 338568957.00, NNZs: 2, Bias: 26711900765.591629, T: 7808, Avg. loss: 63511263632930725888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 347930560.33, NNZs: 2, Bias: 26709687838.465603, T: 7936, Avg. loss: 63923167098202333184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 343677232.21, NNZs: 2, Bias: 26707640271.498566, T: 8064, Avg. loss: 64394706840081342464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 340109099.04, NNZs: 2, Bias: 26705590568.852230, T: 8192, Avg. loss: 64106066469876867072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 339948928.68, NNZs: 2, Bias: 26703496529.484642, T: 8320, Avg. loss: 64155127301737226240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 335725349.66, NNZs: 2, Bias: 26701438505.971581, T: 8448, Avg. loss: 64784201737242656768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 341128139.62, NNZs: 2, Bias: 26700946451.083874, T: 8576, Avg. loss: 63545636256670334976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 342909869.13, NNZs: 2, Bias: 26700505050.071205, T: 8704, Avg. loss: 62676017971961053184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 342388063.04, NNZs: 2, Bias: 26700091708.058762, T: 8832, Avg. loss: 62930606476214091776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 342222985.01, NNZs: 2, Bias: 26699674473.481682, T: 8960, Avg. loss: 62802958796836093952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 342336456.85, NNZs: 2, Bias: 26699253338.103302, T: 9088, Avg. loss: 62858734150868385792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 341584292.14, NNZs: 2, Bias: 26698843642.910351, T: 9216, Avg. loss: 62793755538340298752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 341288771.21, NNZs: 2, Bias: 26698427547.573490, T: 9344, Avg. loss: 62885348402804031488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 73 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2949037978731.37, NNZs: 2, Bias: -7647544370.796085, T: 128, Avg. loss: 36701403489460450272466698240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1399325909143.40, NNZs: 2, Bias: -7647544370.796085, T: 256, Avg. loss: 38630258311953699346225037312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1658223748473.05, NNZs: 2, Bias: -7647544370.796085, T: 384, Avg. loss: 37295565370894470308551458816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1068805407920.45, NNZs: 2, Bias: -7647544370.796085, T: 512, Avg. loss: 38353635392686190239051415552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2106098763116.30, NNZs: 2, Bias: -7647544370.796085, T: 640, Avg. loss: 41036635043099530918734331904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 919083238885.36, NNZs: 2, Bias: -7647544370.796085, T: 768, Avg. loss: 40945522285702431606801694720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 199132935473.17, NNZs: 2, Bias: 9274652224.461437, T: 896, Avg. loss: 807055399890199131421933568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 149330359439.02, NNZs: 2, Bias: 586264203.944778, T: 1024, Avg. loss: 959432754766539268116447232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 252302636545.17, NNZs: 2, Bias: -4777831023.230541, T: 1152, Avg. loss: 834885180824609244561014784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 356103214422.68, NNZs: 2, Bias: -13659329983.760181, T: 1280, Avg. loss: 782952563607754026529062912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 351532270563.27, NNZs: 2, Bias: -25957862229.977383, T: 1408, Avg. loss: 856742987768332970329374720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 333260518057.04, NNZs: 2, Bias: -17638657495.637482, T: 1536, Avg. loss: 803081386617994263541055488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 243089613728.08, NNZs: 2, Bias: -3715339319.052048, T: 1664, Avg. loss: 861941046690379975721222144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 47564927730.02, NNZs: 2, Bias: -25409061450.334148, T: 1792, Avg. loss: 816597809824601571556589568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 276912515878.08, NNZs: 2, Bias: -21329893594.011692, T: 1920, Avg. loss: 740176274661570135172579328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 156375130441.26, NNZs: 2, Bias: -23758682541.535774, T: 2048, Avg. loss: 866029131648269223167262720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 84066165472.24, NNZs: 2, Bias: -8830907165.195965, T: 2176, Avg. loss: 780767126425948292303028224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 162462828405.87, NNZs: 2, Bias: -10844273620.270948, T: 2304, Avg. loss: 803411587368988417508507648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 102828535850.80, NNZs: 2, Bias: -10796049408.006134, T: 2432, Avg. loss: 903828300199603454917738496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 79710015805.18, NNZs: 2, Bias: -9076727325.531124, T: 2560, Avg. loss: 822108994450537203894321152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 33628568167.67, NNZs: 2, Bias: -10671034621.973793, T: 2688, Avg. loss: 30059707182101861136072704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 30235564930.72, NNZs: 2, Bias: -8104517485.079289, T: 2816, Avg. loss: 28687661321326095971123200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 7028017597.81, NNZs: 2, Bias: -6308337314.583068, T: 2944, Avg. loss: 30705062747587344058023936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 98645560738.05, NNZs: 2, Bias: -4365923286.461866, T: 3072, Avg. loss: 27763345524176139327635456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 12482806990.40, NNZs: 2, Bias: -9257209432.315128, T: 3200, Avg. loss: 27318539362689539987472384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 33020144687.93, NNZs: 2, Bias: -10952513090.192192, T: 3328, Avg. loss: 31107261744468851150553088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 54829217943.19, NNZs: 2, Bias: -9914660501.326710, T: 3456, Avg. loss: 27998803200486097276633088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 81109638384.71, NNZs: 2, Bias: -9830071520.043226, T: 3584, Avg. loss: 29281460759529307829698560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 21952295561.83, NNZs: 2, Bias: -10969838550.248142, T: 3712, Avg. loss: 29882338477618482670206976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 7889074303.79, NNZs: 2, Bias: -8502351719.918398, T: 3840, Avg. loss: 30686242295885314964586496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11802559102.44, NNZs: 2, Bias: -9001636732.481930, T: 3968, Avg. loss: 530715407181274410909696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 271855004.58, NNZs: 2, Bias: -8832276753.297262, T: 4096, Avg. loss: 460416631234250212900864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 12676473986.20, NNZs: 2, Bias: -8993391403.141754, T: 4224, Avg. loss: 305110652622893752516608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8857755709.81, NNZs: 2, Bias: -8972096550.847717, T: 4352, Avg. loss: 276270290660827110309888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7187452111.43, NNZs: 2, Bias: -8792061220.119066, T: 4480, Avg. loss: 378169514876218025967616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2405481577.12, NNZs: 2, Bias: -8824039211.050482, T: 4608, Avg. loss: 515138495853647506702336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1152878839.55, NNZs: 2, Bias: -8775018520.154215, T: 4736, Avg. loss: 344341551083035098611712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 415444175.79, NNZs: 2, Bias: -8937306807.843300, T: 4864, Avg. loss: 334130394235373149487104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 11377842244.18, NNZs: 2, Bias: -9085663952.885460, T: 4992, Avg. loss: 479509792020393355116544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 486808915.06, NNZs: 2, Bias: -9013291542.645767, T: 5120, Avg. loss: 43248299833613011124224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 138486949.47, NNZs: 2, Bias: -9005403442.162062, T: 5248, Avg. loss: 46561521051978506240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 50401868.61, NNZs: 2, Bias: -9000100422.985870, T: 5376, Avg. loss: 15763225907370127360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 82606414.29, NNZs: 2, Bias: -8996017677.467678, T: 5504, Avg. loss: 10312272793901647872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 97687308.94, NNZs: 2, Bias: -8992393625.102293, T: 5632, Avg. loss: 9025636557601270784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 109368464.53, NNZs: 2, Bias: -8988833661.544703, T: 5760, Avg. loss: 8731461111724335104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 108663891.34, NNZs: 2, Bias: -8985270526.006092, T: 5888, Avg. loss: 9154851336970505216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 115539454.45, NNZs: 2, Bias: -8981742732.533030, T: 6016, Avg. loss: 8587669478260715520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 116943451.48, NNZs: 2, Bias: -8978233105.794224, T: 6144, Avg. loss: 8573270396241857536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 107038034.69, NNZs: 2, Bias: -8974877375.294956, T: 6272, Avg. loss: 8765677413083985920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 112414396.56, NNZs: 2, Bias: -8971492105.668577, T: 6400, Avg. loss: 8232150973885435904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 123857290.53, NNZs: 2, Bias: -8967924513.975330, T: 6528, Avg. loss: 8086150443319497728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 114133682.39, NNZs: 2, Bias: -8964709454.380482, T: 6656, Avg. loss: 8342950851818917888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 120600258.96, NNZs: 2, Bias: -8961340892.316109, T: 6784, Avg. loss: 8125940180925913088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 121750215.81, NNZs: 2, Bias: -8957955462.557791, T: 6912, Avg. loss: 8181388519588974592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 113903927.20, NNZs: 2, Bias: -8954572999.378096, T: 7040, Avg. loss: 8492097378689624064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 119615375.03, NNZs: 2, Bias: -8951347073.313454, T: 7168, Avg. loss: 7554990713582422016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 114949038.71, NNZs: 2, Bias: -8947974084.852234, T: 7296, Avg. loss: 8394070572622999552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 124729093.03, NNZs: 2, Bias: -8944607438.248722, T: 7424, Avg. loss: 8083585019961649152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 112494689.49, NNZs: 2, Bias: -8941375955.832241, T: 7552, Avg. loss: 8501383051694777344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 111388845.13, NNZs: 2, Bias: -8938147491.859186, T: 7680, Avg. loss: 7585344655297053696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 111260734.08, NNZs: 2, Bias: -8934884762.596930, T: 7808, Avg. loss: 7989414432793244672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 110059459.39, NNZs: 2, Bias: -8934215451.949091, T: 7936, Avg. loss: 7078921326125729792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 109990050.00, NNZs: 2, Bias: -8933532678.713041, T: 8064, Avg. loss: 7049034251640052736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 109815566.88, NNZs: 2, Bias: -8932855966.046568, T: 8192, Avg. loss: 6997488102207953920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 113856229.78, NNZs: 2, Bias: -8932137216.082163, T: 8320, Avg. loss: 6850599000575106048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 112274931.31, NNZs: 2, Bias: -8931474631.235737, T: 8448, Avg. loss: 7016055664270829568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 112705454.63, NNZs: 2, Bias: -8930791344.592968, T: 8576, Avg. loss: 6964095993659172864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 113475478.64, NNZs: 2, Bias: -8930097797.891417, T: 8704, Avg. loss: 7017571425445273600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 113091892.70, NNZs: 2, Bias: -8929423723.520792, T: 8832, Avg. loss: 6960902222530217984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 112442822.52, NNZs: 2, Bias: -8928751362.686756, T: 8960, Avg. loss: 6974622994832531456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 113436243.64, NNZs: 2, Bias: -8928602687.286806, T: 9088, Avg. loss: 6813327306127471616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 113640090.40, NNZs: 2, Bias: -8928464738.708843, T: 9216, Avg. loss: 6769988280622307328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 114320037.16, NNZs: 2, Bias: -8928321319.087685, T: 9344, Avg. loss: 6734230659902552064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 113967887.42, NNZs: 2, Bias: -8928190359.091923, T: 9472, Avg. loss: 6775575621952153600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 113921084.61, NNZs: 2, Bias: -8928055754.348196, T: 9600, Avg. loss: 6758224690570403840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 113900882.43, NNZs: 2, Bias: -8927920727.666016, T: 9728, Avg. loss: 6762442120527875072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 113519742.08, NNZs: 2, Bias: -8927790755.513767, T: 9856, Avg. loss: 6736003932415833088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 113440235.87, NNZs: 2, Bias: -8927656456.925756, T: 9984, Avg. loss: 6761556632808488960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 78 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 416433668187.38, NNZs: 2, Bias: -885250345.276217, T: 128, Avg. loss: 39603824836335104116847017984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2289246600958.49, NNZs: 2, Bias: -885250345.276217, T: 256, Avg. loss: 43465305694001687052706381824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2663519476181.84, NNZs: 2, Bias: -885250345.276217, T: 384, Avg. loss: 46099206286260746136967970816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 635613876500.51, NNZs: 2, Bias: 3321382707.439995, T: 512, Avg. loss: 44155984629292269628163096576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2240128567738.91, NNZs: 2, Bias: 1804168880.381596, T: 640, Avg. loss: 43274143950681986622061281280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 466514737173.44, NNZs: 2, Bias: 1804168880.381596, T: 768, Avg. loss: 44771493591338393459889274880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 459892095559.03, NNZs: 2, Bias: 10334493869.862640, T: 896, Avg. loss: 857990782023341548532400128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 228934132675.98, NNZs: 2, Bias: 2087635765.971370, T: 1024, Avg. loss: 811994899121214850735276032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 250486412281.30, NNZs: 2, Bias: 21011229178.283104, T: 1152, Avg. loss: 801549019982443254919462912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 53324837475.69, NNZs: 2, Bias: 9260606811.379234, T: 1280, Avg. loss: 877260052943915869043425280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 394779205163.81, NNZs: 2, Bias: 14628932301.415823, T: 1408, Avg. loss: 785782142240756352040304640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 157473863856.84, NNZs: 2, Bias: 27074104530.035648, T: 1536, Avg. loss: 877655117251947108073734144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 75613773866.72, NNZs: 2, Bias: 34114219031.793030, T: 1664, Avg. loss: 930708971792815321109233664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 157544027023.36, NNZs: 2, Bias: 52678383342.498451, T: 1792, Avg. loss: 852441946619725878176776192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 532545510876.43, NNZs: 2, Bias: 41356825546.392082, T: 1920, Avg. loss: 777007873903236516138713088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 78857330446.45, NNZs: 2, Bias: 48661997221.889267, T: 2048, Avg. loss: 940822215204205536114376704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 119062124902.31, NNZs: 2, Bias: 43588847083.000114, T: 2176, Avg. loss: 848660308008136194234777600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 196347052623.64, NNZs: 2, Bias: 44739193495.979523, T: 2304, Avg. loss: 886185084488770731364057088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 43637794823.26, NNZs: 2, Bias: 50782807760.614471, T: 2432, Avg. loss: 974766894505457395569786880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 229308515678.37, NNZs: 2, Bias: 45717670084.072166, T: 2560, Avg. loss: 776631525062314589367042048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 371953656203.47, NNZs: 2, Bias: 48294778928.663269, T: 2688, Avg. loss: 874591400258114571579949056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 375525876809.08, NNZs: 2, Bias: 40168794061.183533, T: 2816, Avg. loss: 876310460367165349764792320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 109378633043.65, NNZs: 2, Bias: 60512649397.740059, T: 2944, Avg. loss: 893994423370008002541125632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 322038104042.85, NNZs: 2, Bias: 48878828452.894958, T: 3072, Avg. loss: 837327434206378742519955456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 163271195830.40, NNZs: 2, Bias: 51881608959.151291, T: 3200, Avg. loss: 860849270191456333158416384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 36716026361.72, NNZs: 2, Bias: 48650996885.902206, T: 3328, Avg. loss: 31419363742425468838608896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 12151594369.97, NNZs: 2, Bias: 46892279533.046158, T: 3456, Avg. loss: 31376995344391591522467840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 44307886310.16, NNZs: 2, Bias: 43941300320.434296, T: 3584, Avg. loss: 28764159893201005525860352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 38184266847.29, NNZs: 2, Bias: 44189638281.896889, T: 3712, Avg. loss: 33335156045997316971167744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 59586201263.93, NNZs: 2, Bias: 44537289097.008759, T: 3840, Avg. loss: 31285580610136437308784640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6582435131.96, NNZs: 2, Bias: 44132447743.002983, T: 3968, Avg. loss: 32839263106549975120609280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 56880243122.65, NNZs: 2, Bias: 48821120216.594574, T: 4096, Avg. loss: 30685310270964726753132544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 73428524907.08, NNZs: 2, Bias: 49961911352.348122, T: 4224, Avg. loss: 31442597442626353432100864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6288526288.17, NNZs: 2, Bias: 50428777766.794899, T: 4352, Avg. loss: 1631375597407985054253056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 5967583743.32, NNZs: 2, Bias: 50331368389.069916, T: 4480, Avg. loss: 396101225292302179631104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1580534193.66, NNZs: 2, Bias: 50120136543.300049, T: 4608, Avg. loss: 401795756671710162583552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 15164717735.61, NNZs: 2, Bias: 50109321178.153267, T: 4736, Avg. loss: 507095122165798226886656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6203962920.77, NNZs: 2, Bias: 50237102589.146988, T: 4864, Avg. loss: 505941862547451218493440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3210954720.27, NNZs: 2, Bias: 50037858328.572128, T: 4992, Avg. loss: 627976880658953587916800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 5729064800.43, NNZs: 2, Bias: 49976330722.464355, T: 5120, Avg. loss: 396568397956525301170176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 305822995.48, NNZs: 2, Bias: 49980804060.974762, T: 5248, Avg. loss: 5741074915236780179456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 521032049.09, NNZs: 2, Bias: 49958841605.395363, T: 5376, Avg. loss: 288614904300805718016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 604439003.11, NNZs: 2, Bias: 49939708770.817825, T: 5504, Avg. loss: 243278764690374328320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 639843346.87, NNZs: 2, Bias: 49920637865.542343, T: 5632, Avg. loss: 250453951763074547712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 629406856.25, NNZs: 2, Bias: 49902836423.325859, T: 5760, Avg. loss: 238124768555716870144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 685014054.46, NNZs: 2, Bias: 49884168630.614113, T: 5888, Avg. loss: 235284350607717302272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 664995077.84, NNZs: 2, Bias: 49866533731.352036, T: 6016, Avg. loss: 241409218915063726080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 661786229.38, NNZs: 2, Bias: 49849187020.436050, T: 6144, Avg. loss: 229759730331667759104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 661145168.11, NNZs: 2, Bias: 49831098220.013489, T: 6272, Avg. loss: 243975498970432667648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 682207546.89, NNZs: 2, Bias: 49812100436.548233, T: 6400, Avg. loss: 254336069954106130432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 675260463.98, NNZs: 2, Bias: 49795047630.186958, T: 6528, Avg. loss: 232910771749199609856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 698509920.87, NNZs: 2, Bias: 49776561836.354004, T: 6656, Avg. loss: 248518711833729400832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 686002097.17, NNZs: 2, Bias: 49758220748.404076, T: 6784, Avg. loss: 253652931153421467648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 679169855.59, NNZs: 2, Bias: 49754706201.137505, T: 6912, Avg. loss: 202149054196764377088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 664788198.46, NNZs: 2, Bias: 49751279445.970146, T: 7040, Avg. loss: 203262606838899671040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 676260143.45, NNZs: 2, Bias: 49747520396.317513, T: 7168, Avg. loss: 202041024836197908480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 680160193.18, NNZs: 2, Bias: 49743899337.927361, T: 7296, Avg. loss: 199751030631830618112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 670583903.05, NNZs: 2, Bias: 49740407495.905205, T: 7424, Avg. loss: 203135458723017097216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 676281920.76, NNZs: 2, Bias: 49736759327.320724, T: 7552, Avg. loss: 199380680924142600192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 685725178.64, NNZs: 2, Bias: 49733073311.717865, T: 7680, Avg. loss: 198527898655143723008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 677540795.43, NNZs: 2, Bias: 49729568747.505905, T: 7808, Avg. loss: 202861414494264197120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 681872471.34, NNZs: 2, Bias: 49725957210.256607, T: 7936, Avg. loss: 197901732242773147648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 674889688.19, NNZs: 2, Bias: 49722486046.490753, T: 8064, Avg. loss: 198853139267210346496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 688331181.00, NNZs: 2, Bias: 49718700006.469986, T: 8192, Avg. loss: 201348749927574077440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 668653852.26, NNZs: 2, Bias: 49715423736.926033, T: 8320, Avg. loss: 197628548762926153728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 672602023.10, NNZs: 2, Bias: 49711804122.250000, T: 8448, Avg. loss: 199346523682168471552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 676222103.26, NNZs: 2, Bias: 49708147752.113617, T: 8576, Avg. loss: 201793330054400049152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 675456539.28, NNZs: 2, Bias: 49704575343.688362, T: 8704, Avg. loss: 200298536548438507520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 668652487.58, NNZs: 2, Bias: 49701066802.732910, T: 8832, Avg. loss: 201394080635039318016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 672829914.49, NNZs: 2, Bias: 49697435156.733192, T: 8960, Avg. loss: 199915891387937193984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 674242406.62, NNZs: 2, Bias: 49696697628.191032, T: 9088, Avg. loss: 196220060616412299264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 674490104.43, NNZs: 2, Bias: 49695976544.997444, T: 9216, Avg. loss: 195879652736823394304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 678293510.31, NNZs: 2, Bias: 49695213306.698402, T: 9344, Avg. loss: 194073266584725127168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 676241461.21, NNZs: 2, Bias: 49694525807.078987, T: 9472, Avg. loss: 195234665607572783104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 674289432.80, NNZs: 2, Bias: 49693835729.099541, T: 9600, Avg. loss: 195543166275643670528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 675078579.42, NNZs: 2, Bias: 49693107556.521156, T: 9728, Avg. loss: 195912194435101196288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 673200324.84, NNZs: 2, Bias: 49692416392.825943, T: 9856, Avg. loss: 195593300303459221504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 677061721.42, NNZs: 2, Bias: 49691648525.298836, T: 9984, Avg. loss: 195299090962286608384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 78 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2629232967996.56, NNZs: 2, Bias: -9158678637.206444, T: 128, Avg. loss: 45470598169503031200072073216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1403128646988.58, NNZs: 2, Bias: -9158678637.206444, T: 256, Avg. loss: 50822113575584138897479696384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 928769616212.76, NNZs: 2, Bias: -9158678637.206444, T: 384, Avg. loss: 47502224637660358632225636352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 811045004916.50, NNZs: 2, Bias: -9158678637.206444, T: 512, Avg. loss: 45303666813309273628081127424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2704700537952.40, NNZs: 2, Bias: -9158678637.206444, T: 640, Avg. loss: 45792063266532695531235311616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1438190877456.81, NNZs: 2, Bias: -9158678637.206444, T: 768, Avg. loss: 48249326328848806805808087040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2406800781120.03, NNZs: 2, Bias: -9158678637.206444, T: 896, Avg. loss: 46430332068910599676123676672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 762685387299.38, NNZs: 2, Bias: -9158678637.206444, T: 1024, Avg. loss: 48642746054134013041412407296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2229854031097.10, NNZs: 2, Bias: -9158678637.206444, T: 1152, Avg. loss: 46851852493886783193962512384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 64042143873.43, NNZs: 2, Bias: 12075716429.102823, T: 1280, Avg. loss: 1271322080381291869218275328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 234056954284.74, NNZs: 2, Bias: 9530164771.904324, T: 1408, Avg. loss: 1050340034081792608757088256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 448179942183.47, NNZs: 2, Bias: 15273392036.412170, T: 1536, Avg. loss: 938234985118429031069384704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 206316466611.80, NNZs: 2, Bias: 18218540809.423668, T: 1664, Avg. loss: 996483756367580464968368128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 155356798296.01, NNZs: 2, Bias: 11858735864.040224, T: 1792, Avg. loss: 973739256281557551871426560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 136091899463.19, NNZs: 2, Bias: 6465341097.062702, T: 1920, Avg. loss: 959934543976068184272797696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 497210255414.62, NNZs: 2, Bias: 10873110937.394091, T: 2048, Avg. loss: 843972667908437536839565312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 66069704169.05, NNZs: 2, Bias: 10057731249.251245, T: 2176, Avg. loss: 1003826390295523131339571200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 370999105751.69, NNZs: 2, Bias: 2617929787.678724, T: 2304, Avg. loss: 1028623972492954481176084480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 23291332552.66, NNZs: 2, Bias: 10095407339.115101, T: 2432, Avg. loss: 933656005636804731360772096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 354009075292.90, NNZs: 2, Bias: 361733853.146538, T: 2560, Avg. loss: 1013464555000299284112343040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 24745110836.39, NNZs: 2, Bias: 4761363207.289381, T: 2688, Avg. loss: 935790623299863241836986368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 33810837782.41, NNZs: 2, Bias: 4591588053.373127, T: 2816, Avg. loss: 33440553742474823359004672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 82593935659.68, NNZs: 2, Bias: 5206855943.676429, T: 2944, Avg. loss: 33877028748409902316126208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 32517229329.02, NNZs: 2, Bias: 5646907785.305348, T: 3072, Avg. loss: 36890769616313159264501760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 50669476206.00, NNZs: 2, Bias: 7266751596.328157, T: 3200, Avg. loss: 36109075874296163662299136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 26529952146.22, NNZs: 2, Bias: 5574958496.573459, T: 3328, Avg. loss: 35460700503061351427473408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 63462242627.67, NNZs: 2, Bias: 7011831403.201399, T: 3456, Avg. loss: 31892440776709428167573504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 42213541368.11, NNZs: 2, Bias: 7561152368.696217, T: 3584, Avg. loss: 33797680035558594824896512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 40948149737.74, NNZs: 2, Bias: 9313591238.565657, T: 3712, Avg. loss: 34494087511687552223412224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 43486533000.23, NNZs: 2, Bias: 11654975984.906023, T: 3840, Avg. loss: 33926293413046091685822464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 58242681270.54, NNZs: 2, Bias: 12797999891.160618, T: 3968, Avg. loss: 33009054733356612475420672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 13427048725.92, NNZs: 2, Bias: 12220582317.952171, T: 4096, Avg. loss: 36293028840739132005154816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9804647865.35, NNZs: 2, Bias: 12104944644.961424, T: 4224, Avg. loss: 625880575752004108812288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 11890922143.80, NNZs: 2, Bias: 12168679219.892927, T: 4352, Avg. loss: 607966421707942627639296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 949990363.74, NNZs: 2, Bias: 12395411332.920321, T: 4480, Avg. loss: 620280923353825302020096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1263585357.04, NNZs: 2, Bias: 12284875046.636938, T: 4608, Avg. loss: 442976961089656391204864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 384443196.55, NNZs: 2, Bias: 12286398721.843733, T: 4736, Avg. loss: 526891531852146651693056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7164717835.01, NNZs: 2, Bias: 12145189238.102432, T: 4864, Avg. loss: 527255433891526834388992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4845189547.12, NNZs: 2, Bias: 12183596587.590038, T: 4992, Avg. loss: 639189430324142597472256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9917479665.53, NNZs: 2, Bias: 12199483988.398870, T: 5120, Avg. loss: 532476425683119179300864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 8270984017.61, NNZs: 2, Bias: 12270532330.840572, T: 5248, Avg. loss: 465774473595968592805888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1479088496.92, NNZs: 2, Bias: 12245610422.917490, T: 5376, Avg. loss: 13857243895051854020608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 682713069.92, NNZs: 2, Bias: 12250496742.161577, T: 5504, Avg. loss: 196850581912704483328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 384536529.08, NNZs: 2, Bias: 12249074951.885481, T: 5632, Avg. loss: 42766584876188393472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 259282277.74, NNZs: 2, Bias: 12245971551.090515, T: 5760, Avg. loss: 19552346136356573184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 201931886.75, NNZs: 2, Bias: 12241740497.967991, T: 5888, Avg. loss: 18243784401920477184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 172000200.98, NNZs: 2, Bias: 12237400452.084396, T: 6016, Avg. loss: 16296649739420276736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 162898197.68, NNZs: 2, Bias: 12232946791.910843, T: 6144, Avg. loss: 15375100609889957888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 141553427.22, NNZs: 2, Bias: 12228447512.070820, T: 6272, Avg. loss: 16229288936423069696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 163284106.54, NNZs: 2, Bias: 12223460245.431715, T: 6400, Avg. loss: 15692135054757752832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 155415409.84, NNZs: 2, Bias: 12218787356.941864, T: 6528, Avg. loss: 16164098558049857536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 166594747.55, NNZs: 2, Bias: 12214097203.361294, T: 6656, Avg. loss: 15475276379635222528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 146902287.44, NNZs: 2, Bias: 12209902351.820278, T: 6784, Avg. loss: 14998120783286708224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 160183879.86, NNZs: 2, Bias: 12205250043.677311, T: 6912, Avg. loss: 14628647807671085056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 154271850.54, NNZs: 2, Bias: 12200759190.221537, T: 7040, Avg. loss: 15451946289293172736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 155774956.97, NNZs: 2, Bias: 12195982834.898264, T: 7168, Avg. loss: 15828251170991994880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 169344204.58, NNZs: 2, Bias: 12191614169.772816, T: 7296, Avg. loss: 13321668471676246016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 162454201.88, NNZs: 2, Bias: 12187283517.988995, T: 7424, Avg. loss: 14478306596234346496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 156077961.82, NNZs: 2, Bias: 12182701035.602224, T: 7552, Avg. loss: 16100360067826251776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 139672282.17, NNZs: 2, Bias: 12178288474.719543, T: 7680, Avg. loss: 16074450589154775040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 166520520.07, NNZs: 2, Bias: 12173498581.752068, T: 7808, Avg. loss: 14597670547181359104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 146630689.12, NNZs: 2, Bias: 12169457292.423023, T: 7936, Avg. loss: 14755319032471318528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 150095230.66, NNZs: 2, Bias: 12168501177.920315, T: 8064, Avg. loss: 12842318406491852800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 147501924.65, NNZs: 2, Bias: 12167610956.607401, T: 8192, Avg. loss: 12986736317997504512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 148003070.12, NNZs: 2, Bias: 12166676402.371958, T: 8320, Avg. loss: 13071055276242393088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 150105949.16, NNZs: 2, Bias: 12165740995.473776, T: 8448, Avg. loss: 12738627518356682752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 146676631.93, NNZs: 2, Bias: 12164878394.904516, T: 8576, Avg. loss: 12706497005530089472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 150841796.93, NNZs: 2, Bias: 12163942740.159855, T: 8704, Avg. loss: 12363791282643163136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 149177537.82, NNZs: 2, Bias: 12163051931.955969, T: 8832, Avg. loss: 12812180687005636608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 146820239.61, NNZs: 2, Bias: 12162170253.422476, T: 8960, Avg. loss: 12757484687521542144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 146226539.96, NNZs: 2, Bias: 12161267908.103806, T: 9088, Avg. loss: 12754750607583907840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 149262467.21, NNZs: 2, Bias: 12160320512.243382, T: 9216, Avg. loss: 12780175732921292800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 148355508.22, NNZs: 2, Bias: 12159407256.770426, T: 9344, Avg. loss: 12955286708728537088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 149466058.96, NNZs: 2, Bias: 12159211467.653444, T: 9472, Avg. loss: 12467427269385512960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 150001639.24, NNZs: 2, Bias: 12159022439.640160, T: 9600, Avg. loss: 12489950988297232384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 149715736.98, NNZs: 2, Bias: 12158843084.046959, T: 9728, Avg. loss: 12517411657185271808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 149811592.30, NNZs: 2, Bias: 12158658988.681444, T: 9856, Avg. loss: 12521861354779877376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 149693469.14, NNZs: 2, Bias: 12158477608.268513, T: 9984, Avg. loss: 12514614461337499648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 78 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 675358518398.33, NNZs: 2, Bias: 9525372614.001202, T: 128, Avg. loss: 37111698830470102999457857536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1465705896778.23, NNZs: 2, Bias: 49525372614.001205, T: 256, Avg. loss: 40262215095416835234252980224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1107837193836.39, NNZs: 2, Bias: 69948576967.542343, T: 384, Avg. loss: 44081647147683559891074547712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 406552957468.10, NNZs: 2, Bias: 69948576967.542343, T: 512, Avg. loss: 42892307256229703456328253440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1493656684356.92, NNZs: 2, Bias: 49948576967.542343, T: 640, Avg. loss: 41266498668410777139098419200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2106486387866.07, NNZs: 2, Bias: 9948576967.542343, T: 768, Avg. loss: 42709542196799896262033801216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 289482915315.88, NNZs: 2, Bias: 21440699311.238796, T: 896, Avg. loss: 2230440542283985249825193984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 145667169850.73, NNZs: 2, Bias: 14084935099.916649, T: 1024, Avg. loss: 981913834906432093441490944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 31974644359.18, NNZs: 2, Bias: 16651166764.172611, T: 1152, Avg. loss: 908574393268146919304069120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 213760712401.79, NNZs: 2, Bias: 20476023977.983154, T: 1280, Avg. loss: 893433066277687119132491776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 189349516183.21, NNZs: 2, Bias: 25638794619.502995, T: 1408, Avg. loss: 1050271875476445832482390016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 194342846707.99, NNZs: 2, Bias: 40680241018.988007, T: 1536, Avg. loss: 960321240357265391981953024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 107514385541.35, NNZs: 2, Bias: 26983249128.508808, T: 1664, Avg. loss: 1022834921324132328928182272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 393836221513.48, NNZs: 2, Bias: 18064499715.201969, T: 1792, Avg. loss: 957967170200340038217105408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 13278156950.87, NNZs: 2, Bias: 30659644541.664494, T: 1920, Avg. loss: 1010025568891636227122397184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 58764042055.81, NNZs: 2, Bias: 30142663165.259754, T: 2048, Avg. loss: 33546967930178617118556160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 69339474068.74, NNZs: 2, Bias: 30821238037.749626, T: 2176, Avg. loss: 35384845730933509697044480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 76960269352.67, NNZs: 2, Bias: 28015925849.141808, T: 2304, Avg. loss: 36680348839554409151070208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 22046148208.35, NNZs: 2, Bias: 26888290218.811657, T: 2432, Avg. loss: 33711312035059744733396992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 35678942189.14, NNZs: 2, Bias: 29946551691.682526, T: 2560, Avg. loss: 32139459331541474348105728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 18589628183.24, NNZs: 2, Bias: 29966257322.914787, T: 2688, Avg. loss: 37718806618705416337489920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 30932039005.87, NNZs: 2, Bias: 28384446578.491978, T: 2816, Avg. loss: 34347272368042336088752128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 56732216708.29, NNZs: 2, Bias: 26625491946.742130, T: 2944, Avg. loss: 33571649149147117328007168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 86556233274.92, NNZs: 2, Bias: 26875219692.875134, T: 3072, Avg. loss: 35503810798243955408371712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 77330501408.85, NNZs: 2, Bias: 27689799681.477459, T: 3200, Avg. loss: 33180101139044312054497280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 992734227.58, NNZs: 2, Bias: 27489312311.874920, T: 3328, Avg. loss: 2648379480622270225842176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1147311566.68, NNZs: 2, Bias: 27707089930.919090, T: 3456, Avg. loss: 498082800025408798457856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1001730740.06, NNZs: 2, Bias: 27827080386.550240, T: 3584, Avg. loss: 552631241968167512178688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8857574066.42, NNZs: 2, Bias: 27698220456.228802, T: 3712, Avg. loss: 619856901989451314495488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3226717293.08, NNZs: 2, Bias: 27446758424.640846, T: 3840, Avg. loss: 775686110119811709140992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2262837493.87, NNZs: 2, Bias: 27374517638.661163, T: 3968, Avg. loss: 690306578541281290485760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1450143031.42, NNZs: 2, Bias: 27197236297.727467, T: 4096, Avg. loss: 682385519503471466774528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 208787026.41, NNZs: 2, Bias: 27176588363.430893, T: 4224, Avg. loss: 568761891887296282624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 185491953.49, NNZs: 2, Bias: 27165982316.041252, T: 4352, Avg. loss: 82762906667616092160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 249204412.22, NNZs: 2, Bias: 27156373081.722557, T: 4480, Avg. loss: 69083492045228703744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 291132134.81, NNZs: 2, Bias: 27147436259.752792, T: 4608, Avg. loss: 63759327093949087744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 330991253.15, NNZs: 2, Bias: 27137985341.774723, T: 4736, Avg. loss: 67935956569176489984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 308614631.61, NNZs: 2, Bias: 27129864406.209793, T: 4864, Avg. loss: 62379764991695110144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 325133663.54, NNZs: 2, Bias: 27120941056.552872, T: 4992, Avg. loss: 67045508651115839488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 327999287.38, NNZs: 2, Bias: 27112189723.663601, T: 5120, Avg. loss: 63205813729234034688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 338078641.07, NNZs: 2, Bias: 27103589402.920406, T: 5248, Avg. loss: 60695415875766984704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 326405924.54, NNZs: 2, Bias: 27094794662.338573, T: 5376, Avg. loss: 68196908151731814400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 331291257.59, NNZs: 2, Bias: 27085938307.777767, T: 5504, Avg. loss: 66491421856006946816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 356170093.20, NNZs: 2, Bias: 27076966520.482788, T: 5632, Avg. loss: 63406348516173471744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 336429996.63, NNZs: 2, Bias: 27068809057.245537, T: 5760, Avg. loss: 61390703012339802112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 329571454.79, NNZs: 2, Bias: 27060481152.459656, T: 5888, Avg. loss: 63001447330578694144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 323510328.35, NNZs: 2, Bias: 27058825598.916660, T: 6016, Avg. loss: 53949979008947929088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 333193892.24, NNZs: 2, Bias: 27056990889.173862, T: 6144, Avg. loss: 53580127708360482816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 332731073.31, NNZs: 2, Bias: 27055255191.821411, T: 6272, Avg. loss: 54343392243738869760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 328742396.84, NNZs: 2, Bias: 27053594453.179588, T: 6400, Avg. loss: 53200285634864660480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 325481783.71, NNZs: 2, Bias: 27051893235.466896, T: 6528, Avg. loss: 54359921488361070592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 329179706.84, NNZs: 2, Bias: 27050106419.701447, T: 6656, Avg. loss: 54406039318406905856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 332293668.24, NNZs: 2, Bias: 27048340259.046745, T: 6784, Avg. loss: 54121845641830490112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 330280291.71, NNZs: 2, Bias: 27046636760.908203, T: 6912, Avg. loss: 54008633517088137216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 323138095.14, NNZs: 2, Bias: 27045000650.298409, T: 7040, Avg. loss: 53747342808865071104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 325343672.71, NNZs: 2, Bias: 27044625510.338253, T: 7168, Avg. loss: 53320092965975654400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 324959904.06, NNZs: 2, Bias: 27044282573.641563, T: 7296, Avg. loss: 53134331611830460416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 326366158.81, NNZs: 2, Bias: 27043917994.051388, T: 7424, Avg. loss: 53153639435107401728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 326963117.24, NNZs: 2, Bias: 27043563147.329845, T: 7552, Avg. loss: 53146388844534022144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 326191714.75, NNZs: 2, Bias: 27043224954.119484, T: 7680, Avg. loss: 53122154474087178240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 325997343.93, NNZs: 2, Bias: 27042879573.710972, T: 7808, Avg. loss: 53158638516884938752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 325819976.05, NNZs: 2, Bias: 27042534010.428444, T: 7936, Avg. loss: 53161691043591471104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 324450813.36, NNZs: 2, Bias: 27042203230.791389, T: 8064, Avg. loss: 53070770224681279488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 327713941.41, NNZs: 2, Bias: 27041817834.515617, T: 8192, Avg. loss: 52902927268399251456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 326606343.18, NNZs: 2, Bias: 27041482826.279835, T: 8320, Avg. loss: 53282494814114619392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 326356883.80, NNZs: 2, Bias: 27041138012.978653, T: 8448, Avg. loss: 53179533768003461120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 326015185.22, NNZs: 2, Bias: 27040795029.928665, T: 8576, Avg. loss: 53055843585096269824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 326092208.15, NNZs: 2, Bias: 27040446620.244827, T: 8704, Avg. loss: 53121645360859643904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 324406231.05, NNZs: 2, Bias: 27040120572.700153, T: 8832, Avg. loss: 52926615919427502080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 69 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1520844461300.70, NNZs: 2, Bias: -26176512617.244598, T: 128, Avg. loss: 32180472222482985428413579264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1034428057897.56, NNZs: 2, Bias: -13473867438.784668, T: 256, Avg. loss: 36652449085991254293953380352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1081673198092.84, NNZs: 2, Bias: -30903738949.868267, T: 384, Avg. loss: 32710811403462624661460746240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2620886076453.29, NNZs: 2, Bias: -10903738949.868271, T: 512, Avg. loss: 34428870958268720508819210240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1943026723818.48, NNZs: 2, Bias: -34641229029.479492, T: 640, Avg. loss: 37343702939184479635570163712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1619171036371.18, NNZs: 2, Bias: -39428316851.072716, T: 768, Avg. loss: 39464005708025088985127714816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 101338476450.71, NNZs: 2, Bias: -29783786822.273926, T: 896, Avg. loss: 1385376617061428918128476160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 444356242495.53, NNZs: 2, Bias: -34348223226.349392, T: 1024, Avg. loss: 898536011629884162269249536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 47417255844.68, NNZs: 2, Bias: -43837499695.487846, T: 1152, Avg. loss: 869883719014331079507050496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 20303119605.05, NNZs: 2, Bias: -49029862456.221741, T: 1280, Avg. loss: 909028306966405131899240448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 209816836242.76, NNZs: 2, Bias: -63924967899.581497, T: 1408, Avg. loss: 951646506005706835882934272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 472684775898.88, NNZs: 2, Bias: -73936215696.729553, T: 1536, Avg. loss: 819201745908322739131777024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 188934058711.57, NNZs: 2, Bias: -64076354692.988876, T: 1664, Avg. loss: 870060009916490211255123968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 289285006800.10, NNZs: 2, Bias: -67022086384.446472, T: 1792, Avg. loss: 840607206168749798309494784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 224239678450.93, NNZs: 2, Bias: -53948408586.064697, T: 1920, Avg. loss: 941116388012193535078957056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 80662035630.14, NNZs: 2, Bias: -70766363006.989136, T: 2048, Avg. loss: 812315571199130034207981568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 372213462512.50, NNZs: 2, Bias: -81145984915.504150, T: 2176, Avg. loss: 822822622715926533042601984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 125906125936.60, NNZs: 2, Bias: -62249689957.206192, T: 2304, Avg. loss: 905668255991563969277984768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 147282290620.08, NNZs: 2, Bias: -61042361610.547722, T: 2432, Avg. loss: 850729376902954728449638400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 197748923350.77, NNZs: 2, Bias: -66517341810.272903, T: 2560, Avg. loss: 876113957364797810648547328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 220472177373.71, NNZs: 2, Bias: -75249750569.442078, T: 2688, Avg. loss: 864655183882686076603596800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 21004644248.44, NNZs: 2, Bias: -69760127697.718216, T: 2816, Avg. loss: 43441638111943547777187840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 101028167365.89, NNZs: 2, Bias: -72192917566.180206, T: 2944, Avg. loss: 29878719816875837778558976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 29866303713.91, NNZs: 2, Bias: -75933119639.278244, T: 3072, Avg. loss: 29082781926826019949379584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 20554682278.01, NNZs: 2, Bias: -75100998887.612885, T: 3200, Avg. loss: 27813626334768767829016576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 22998409764.89, NNZs: 2, Bias: -76437627158.066788, T: 3328, Avg. loss: 32808944052668414988124160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 25118682561.25, NNZs: 2, Bias: -77227103823.543335, T: 3456, Avg. loss: 32967499184720679322779648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 42162076966.97, NNZs: 2, Bias: -78075091836.692657, T: 3584, Avg. loss: 29139382543326579009781760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 21463134888.15, NNZs: 2, Bias: -79764933133.102615, T: 3712, Avg. loss: 32181948404857140471136256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 6376744744.71, NNZs: 2, Bias: -79629494435.583466, T: 3840, Avg. loss: 33084308765373376153780224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 940922313.80, NNZs: 2, Bias: -79328584573.732605, T: 3968, Avg. loss: 714233935086154271424512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1754354169.80, NNZs: 2, Bias: -79121763510.861130, T: 4096, Avg. loss: 458062714464389210046464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6809067168.57, NNZs: 2, Bias: -78876666436.742813, T: 4224, Avg. loss: 528323851115001892831232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 10559830603.11, NNZs: 2, Bias: -78652928076.534927, T: 4352, Avg. loss: 390687615683409660084224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 12483289642.84, NNZs: 2, Bias: -78742360873.437180, T: 4480, Avg. loss: 688091714839036622274560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3100530265.67, NNZs: 2, Bias: -78610551404.480545, T: 4608, Avg. loss: 578925837053886159912960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3209192726.81, NNZs: 2, Bias: -78167766795.871078, T: 4736, Avg. loss: 516340471211877170413568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6830646515.14, NNZs: 2, Bias: -78215457810.467667, T: 4864, Avg. loss: 591292589840880136880128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 5687621592.16, NNZs: 2, Bias: -78429013780.368286, T: 4992, Avg. loss: 375239458041310574804992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1167358904.64, NNZs: 2, Bias: -78354437283.168167, T: 5120, Avg. loss: 579259857148062512185344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 10506140197.77, NNZs: 2, Bias: -78368384341.482086, T: 5248, Avg. loss: 622560530088199863664640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2697388094.58, NNZs: 2, Bias: -77913431066.527222, T: 5376, Avg. loss: 466638191319713899872256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 10617977404.74, NNZs: 2, Bias: -77510418663.798904, T: 5504, Avg. loss: 502757019347795191005184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 11299992335.36, NNZs: 2, Bias: -77374120396.908264, T: 5632, Avg. loss: 552064025586148055187456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 796803588.23, NNZs: 2, Bias: -77273897862.266678, T: 5760, Avg. loss: 36538699402953573269504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 912536449.57, NNZs: 2, Bias: -77243392777.989838, T: 5888, Avg. loss: 614729085016954109952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1042493399.34, NNZs: 2, Bias: -77211745250.566559, T: 6016, Avg. loss: 637188446382001225728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1054515711.80, NNZs: 2, Bias: -77182726908.826813, T: 6144, Avg. loss: 608664840940531875840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1009647546.34, NNZs: 2, Bias: -77152243943.117401, T: 6272, Avg. loss: 650031994980015669248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1055646093.93, NNZs: 2, Bias: -77122239182.783600, T: 6400, Avg. loss: 605568997567750471680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1106818767.13, NNZs: 2, Bias: -77091423866.398438, T: 6528, Avg. loss: 631056823611198668800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 980977109.26, NNZs: 2, Bias: -77062975231.500397, T: 6656, Avg. loss: 643238362612345470976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 965066211.69, NNZs: 2, Bias: -77033580646.040695, T: 6784, Avg. loss: 621455173958355648512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1055193843.82, NNZs: 2, Bias: -77002309503.824783, T: 6912, Avg. loss: 629864512940058869760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1047121959.80, NNZs: 2, Bias: -76973604996.846085, T: 7040, Avg. loss: 601198771048475656192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1001331991.12, NNZs: 2, Bias: -76945486535.559036, T: 7168, Avg. loss: 597759561034252943360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1028794904.82, NNZs: 2, Bias: -76914408574.591476, T: 7296, Avg. loss: 637417218738742755328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 941027635.02, NNZs: 2, Bias: -76884843234.676346, T: 7424, Avg. loss: 661843529307848704000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 983797697.38, NNZs: 2, Bias: -76853377106.791183, T: 7552, Avg. loss: 660583381846809509888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 972724532.35, NNZs: 2, Bias: -76823390601.435181, T: 7680, Avg. loss: 632802825674113810432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 978359576.89, NNZs: 2, Bias: -76792878662.993256, T: 7808, Avg. loss: 623682138754003894272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1029454349.29, NNZs: 2, Bias: -76786215114.029724, T: 7936, Avg. loss: 531743782827080089600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1014719925.46, NNZs: 2, Bias: -76780400579.744781, T: 8064, Avg. loss: 534037796755324338176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1039669901.52, NNZs: 2, Bias: -76774177109.977112, T: 8192, Avg. loss: 521836258846053302272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1006033346.84, NNZs: 2, Bias: -76768608765.040970, T: 8320, Avg. loss: 535018398007297441792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1017188194.38, NNZs: 2, Bias: -76762524419.481277, T: 8448, Avg. loss: 525593272067813343232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1005806771.07, NNZs: 2, Bias: -76756691506.328949, T: 8576, Avg. loss: 530782975549595648000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1024112544.70, NNZs: 2, Bias: -76750622979.662338, T: 8704, Avg. loss: 514064295775051448320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1003673805.43, NNZs: 2, Bias: -76744958482.053909, T: 8832, Avg. loss: 526011491095257415680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1010404081.47, NNZs: 2, Bias: -76738955672.690689, T: 8960, Avg. loss: 524536126850365718528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1007176467.60, NNZs: 2, Bias: -76732973807.037064, T: 9088, Avg. loss: 535170793108164182016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1009539449.89, NNZs: 2, Bias: -76726954465.631027, T: 9216, Avg. loss: 530158987923016581120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1024698879.73, NNZs: 2, Bias: -76720733851.315063, T: 9344, Avg. loss: 534035409269253144576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1019846843.07, NNZs: 2, Bias: -76719608453.412521, T: 9472, Avg. loss: 515614327698593218560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1025013665.78, NNZs: 2, Bias: -76718354114.493851, T: 9600, Avg. loss: 513532267098758119424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1021225003.61, NNZs: 2, Bias: -76717211551.248993, T: 9728, Avg. loss: 517068807000712544256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1020662132.63, NNZs: 2, Bias: -76716029077.182846, T: 9856, Avg. loss: 515808217490339790848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1022804681.56, NNZs: 2, Bias: -76714810924.391785, T: 9984, Avg. loss: 515616529344738885632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1022731554.35, NNZs: 2, Bias: -76713620802.232407, T: 10112, Avg. loss: 516281464547222552576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1025385937.94, NNZs: 2, Bias: -76712398936.771622, T: 10240, Avg. loss: 514065446034526109696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 80 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1496446430920.96, NNZs: 2, Bias: -20833262436.364090, T: 128, Avg. loss: 32235378795422586490836746240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 611189775109.78, NNZs: 2, Bias: 3478584155.842245, T: 256, Avg. loss: 34478887041616910524090417152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1785466190207.24, NNZs: 2, Bias: 43478584155.842247, T: 384, Avg. loss: 32735410923375995037897719808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2168684336954.83, NNZs: 2, Bias: 67951124567.566925, T: 512, Avg. loss: 35163656955645603690684874752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 896436065531.93, NNZs: 2, Bias: 112203141660.849609, T: 640, Avg. loss: 34077542659869479546789036032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1803459502200.12, NNZs: 2, Bias: 132732739297.515228, T: 768, Avg. loss: 33805490089997116006159351808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 130895690523.81, NNZs: 2, Bias: 119202779953.182312, T: 896, Avg. loss: 1424577760444554114941059072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 215652479020.71, NNZs: 2, Bias: 119673268545.556290, T: 1024, Avg. loss: 750834939446176029220012032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 112101076494.13, NNZs: 2, Bias: 118737113356.307724, T: 1152, Avg. loss: 865120507974249929343238144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 98729212980.45, NNZs: 2, Bias: 117719609681.460220, T: 1280, Avg. loss: 770049259479259250530713600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 149093397403.12, NNZs: 2, Bias: 109708468480.347214, T: 1408, Avg. loss: 796078007373996182873309184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 185471374612.70, NNZs: 2, Bias: 106243610474.371429, T: 1536, Avg. loss: 748852100966270847070240768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 109270635892.12, NNZs: 2, Bias: 97302602728.206497, T: 1664, Avg. loss: 757633344313984127537774592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 453275792424.32, NNZs: 2, Bias: 98660128999.102829, T: 1792, Avg. loss: 823092455949904949893136384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 19152435073.10, NNZs: 2, Bias: 107631600059.839279, T: 1920, Avg. loss: 760289070789311540154597376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 529105865497.63, NNZs: 2, Bias: 112572863993.678635, T: 2048, Avg. loss: 767075365819801009647517696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 417927298463.30, NNZs: 2, Bias: 103965749752.450272, T: 2176, Avg. loss: 788587124344918523651293184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 35415036408.94, NNZs: 2, Bias: 102966275799.163971, T: 2304, Avg. loss: 89062046049279351086645248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 17888653423.21, NNZs: 2, Bias: 100441176467.271439, T: 2432, Avg. loss: 28512309120528503699144704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 45482850488.15, NNZs: 2, Bias: 97062187354.623306, T: 2560, Avg. loss: 31114041686908754997542912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 24144726834.72, NNZs: 2, Bias: 95126737635.814636, T: 2688, Avg. loss: 27932824615875262321524736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 101470916074.53, NNZs: 2, Bias: 91436294662.435776, T: 2816, Avg. loss: 30221416960172318500323328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 42483397571.20, NNZs: 2, Bias: 89885962859.313080, T: 2944, Avg. loss: 30546213796525359079882752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 67997518087.84, NNZs: 2, Bias: 92138872428.590271, T: 3072, Avg. loss: 26822518486595399690747904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 23741529442.62, NNZs: 2, Bias: 88925244120.117157, T: 3200, Avg. loss: 27045926263379216071393280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 64942742997.08, NNZs: 2, Bias: 87792430053.395599, T: 3328, Avg. loss: 28101382660339134776737792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 9505547815.80, NNZs: 2, Bias: 87839257369.116638, T: 3456, Avg. loss: 28207056779598599704018944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 43809443385.30, NNZs: 2, Bias: 88945908272.989807, T: 3584, Avg. loss: 28189460502403598663024640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 65627581843.34, NNZs: 2, Bias: 91834241647.731003, T: 3712, Avg. loss: 28200052136134226003099648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4050997801.22, NNZs: 2, Bias: 91230096871.409714, T: 3840, Avg. loss: 1011625990867118519746560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4696003391.58, NNZs: 2, Bias: 91306413885.177902, T: 3968, Avg. loss: 532242538198225655955456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3017502479.84, NNZs: 2, Bias: 91351037899.996094, T: 4096, Avg. loss: 577331504360674312585216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7380696380.57, NNZs: 2, Bias: 91405944874.659927, T: 4224, Avg. loss: 570841744392271901491200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3673620263.84, NNZs: 2, Bias: 91246742059.926041, T: 4352, Avg. loss: 492406710348269391708160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2787431892.34, NNZs: 2, Bias: 90834744079.112350, T: 4480, Avg. loss: 469285956402205857677312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2812577641.31, NNZs: 2, Bias: 90803375296.271149, T: 4608, Avg. loss: 417573851099051050663936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5408228573.69, NNZs: 2, Bias: 90737272687.557938, T: 4736, Avg. loss: 356775625746674245173248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2597875259.71, NNZs: 2, Bias: 90429923281.353271, T: 4864, Avg. loss: 570336662400815662628864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 12829642344.88, NNZs: 2, Bias: 90128122195.817627, T: 4992, Avg. loss: 451296177751140912332800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 6465322174.26, NNZs: 2, Bias: 89910709128.580734, T: 5120, Avg. loss: 424940860961732448747520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3639982707.63, NNZs: 2, Bias: 90021099286.393692, T: 5248, Avg. loss: 526772737606024821735424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1728505627.00, NNZs: 2, Bias: 89904966300.989731, T: 5376, Avg. loss: 463939229443949886177280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1482320823.05, NNZs: 2, Bias: 89874406506.203247, T: 5504, Avg. loss: 825930462463811649536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1260393448.24, NNZs: 2, Bias: 89843387281.272049, T: 5632, Avg. loss: 833861971575396761600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1262930334.18, NNZs: 2, Bias: 89808960813.976166, T: 5760, Avg. loss: 880897364525595099136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1202522176.05, NNZs: 2, Bias: 89776609179.014420, T: 5888, Avg. loss: 816115787201090813952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1273290592.09, NNZs: 2, Bias: 89741829260.207153, T: 6016, Avg. loss: 840361355813334548480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1224386261.43, NNZs: 2, Bias: 89708479096.559280, T: 6144, Avg. loss: 834070429741487751168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1253746841.89, NNZs: 2, Bias: 89676261688.257996, T: 6272, Avg. loss: 781671776841532702720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1292813457.81, NNZs: 2, Bias: 89642209167.303864, T: 6400, Avg. loss: 840818717510172934144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1169088274.68, NNZs: 2, Bias: 89608956993.227341, T: 6528, Avg. loss: 860206822444410863616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1228953560.30, NNZs: 2, Bias: 89575163763.234283, T: 6656, Avg. loss: 813204402066238865408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1206749852.12, NNZs: 2, Bias: 89541875049.568298, T: 6784, Avg. loss: 889138737805042253824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1367857776.54, NNZs: 2, Bias: 89508511269.265442, T: 6912, Avg. loss: 745512698189897924608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1174743807.38, NNZs: 2, Bias: 89479405204.984314, T: 7040, Avg. loss: 774483378135064510464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1139366283.76, NNZs: 2, Bias: 89446302579.803986, T: 7168, Avg. loss: 853963422542076051456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1111746340.64, NNZs: 2, Bias: 89411902345.444748, T: 7296, Avg. loss: 901475321478370426880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1185384971.65, NNZs: 2, Bias: 89377636409.577667, T: 7424, Avg. loss: 820947742047029166080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1173242078.44, NNZs: 2, Bias: 89344937699.104706, T: 7552, Avg. loss: 813126107055924576256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1187832465.09, NNZs: 2, Bias: 89338004170.942810, T: 7680, Avg. loss: 695136418473916104704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1185547813.49, NNZs: 2, Bias: 89331328983.772095, T: 7808, Avg. loss: 690623781695716982784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1197213902.61, NNZs: 2, Bias: 89324396183.832809, T: 7936, Avg. loss: 698386918632653324288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1221564632.05, NNZs: 2, Bias: 89317391497.271591, T: 8064, Avg. loss: 686284840985921585152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1214025804.13, NNZs: 2, Bias: 89310790873.725159, T: 8192, Avg. loss: 691788521148851945472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1191858809.72, NNZs: 2, Bias: 89304302138.914352, T: 8320, Avg. loss: 702527991439722020864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1189080514.10, NNZs: 2, Bias: 89297713079.361588, T: 8448, Avg. loss: 681901062938690191360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1202005208.70, NNZs: 2, Bias: 89290816425.942078, T: 8576, Avg. loss: 694721327057447026688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1170359312.48, NNZs: 2, Bias: 89284562739.585693, T: 8704, Avg. loss: 688329119047532150784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1174801846.44, NNZs: 2, Bias: 89277843341.878723, T: 8832, Avg. loss: 686223817196738183168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1190533533.48, NNZs: 2, Bias: 89270942055.241547, T: 8960, Avg. loss: 690758057421770850304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1184157523.44, NNZs: 2, Bias: 89264314809.308456, T: 9088, Avg. loss: 694383507977039511552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1169332346.47, NNZs: 2, Bias: 89263178897.224457, T: 9216, Avg. loss: 670548517676988628992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1178306466.43, NNZs: 2, Bias: 89261733735.331436, T: 9344, Avg. loss: 668445524999802322944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1167458712.21, NNZs: 2, Bias: 89260544751.938583, T: 9472, Avg. loss: 670812784111360540672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1170755602.85, NNZs: 2, Bias: 89259166097.619675, T: 9600, Avg. loss: 673174266684252225536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1170798049.74, NNZs: 2, Bias: 89257830304.681534, T: 9728, Avg. loss: 672817007167493636096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1173345689.18, NNZs: 2, Bias: 89256461542.841690, T: 9856, Avg. loss: 673068992220323119104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1172651686.53, NNZs: 2, Bias: 89255135705.598984, T: 9984, Avg. loss: 672502776381651025920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 78 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1130569383719.00, NNZs: 2, Bias: -8994660411.672634, T: 128, Avg. loss: 35377481180992501251420717056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2354494599350.57, NNZs: 2, Bias: -27701948530.753761, T: 256, Avg. loss: 34595608947703602878334631936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1651209054365.32, NNZs: 2, Bias: -7701948530.753761, T: 384, Avg. loss: 33407294760707500292624613376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1859327360758.58, NNZs: 2, Bias: -12525856094.236343, T: 512, Avg. loss: 36992425095310225512658370560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1097020441774.37, NNZs: 2, Bias: -52525856094.236343, T: 640, Avg. loss: 37162001885175112598590324736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 878094065170.67, NNZs: 2, Bias: -32525856094.236343, T: 768, Avg. loss: 31604381827733996708019830784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 686968686346.89, NNZs: 2, Bias: -12525856094.236343, T: 896, Avg. loss: 33325196461243780925600301056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 366162932133.00, NNZs: 2, Bias: 7474143905.763657, T: 1024, Avg. loss: 34881512361188947834072727552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2300477686754.81, NNZs: 2, Bias: 7474143905.763657, T: 1152, Avg. loss: 38394165708060842405117558784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 781180529829.84, NNZs: 2, Bias: -12525856094.236343, T: 1280, Avg. loss: 34397952516923644146893193216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1674249770919.26, NNZs: 2, Bias: -37389712232.345512, T: 1408, Avg. loss: 38464598329909282001142153216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 8507068976.11, NNZs: 2, Bias: -37766099634.405769, T: 1536, Avg. loss: 1273063230485829933940604928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 148647483350.13, NNZs: 2, Bias: -11627331135.204586, T: 1664, Avg. loss: 791611977914890153711632384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 50230962042.44, NNZs: 2, Bias: -20415642947.443798, T: 1792, Avg. loss: 892335738487764438357114880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 417101614482.94, NNZs: 2, Bias: -14612143646.635717, T: 1920, Avg. loss: 771001574149395029694611456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 551672917729.28, NNZs: 2, Bias: -17162677502.493547, T: 2048, Avg. loss: 794581206076920011111268352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 19494420268.46, NNZs: 2, Bias: -5995898887.091343, T: 2176, Avg. loss: 942547929234374357181005824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 58655170185.47, NNZs: 2, Bias: 7326061822.249557, T: 2304, Avg. loss: 873183664272016538112884736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 360281598132.21, NNZs: 2, Bias: 7598739713.204227, T: 2432, Avg. loss: 827773830645041033270788096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 124531007162.71, NNZs: 2, Bias: 15777465117.221394, T: 2560, Avg. loss: 846452696342932908343820288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 26335156020.86, NNZs: 2, Bias: 13947474816.052898, T: 2688, Avg. loss: 32542296078581447457243136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 68776970584.00, NNZs: 2, Bias: 11895902950.498650, T: 2816, Avg. loss: 32087115033296283086356480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 97041125597.55, NNZs: 2, Bias: 13296739187.603243, T: 2944, Avg. loss: 32224947004812196736663552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 8974110600.19, NNZs: 2, Bias: 13124034372.911205, T: 3072, Avg. loss: 31989492566036478999658496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 46091380327.38, NNZs: 2, Bias: 13321861164.347689, T: 3200, Avg. loss: 32286418044596796541370368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 38041981608.77, NNZs: 2, Bias: 11020913223.342354, T: 3328, Avg. loss: 29609069273015931421851648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 86132879324.43, NNZs: 2, Bias: 11846255698.914478, T: 3456, Avg. loss: 28915091139105096604844032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 83435951620.36, NNZs: 2, Bias: 12773500110.578499, T: 3584, Avg. loss: 30539918236382012637184000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 43462596102.62, NNZs: 2, Bias: 12137453490.579817, T: 3712, Avg. loss: 27207282867719250544427008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 30219637737.44, NNZs: 2, Bias: 11340063180.261677, T: 3840, Avg. loss: 30895144814401831657537536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 66923410736.52, NNZs: 2, Bias: 14873967876.471123, T: 3968, Avg. loss: 32294731055164874450534400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 93979661794.67, NNZs: 2, Bias: 14814073036.658770, T: 4096, Avg. loss: 29313641130901014398894080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 68370242051.95, NNZs: 2, Bias: 13827507615.526060, T: 4224, Avg. loss: 33259911750406242043953152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 16182555200.17, NNZs: 2, Bias: 10572517162.598097, T: 4352, Avg. loss: 30768134402904983498391552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4950247511.32, NNZs: 2, Bias: 10784694628.016317, T: 4480, Avg. loss: 527311583024083929923584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2126346378.10, NNZs: 2, Bias: 10901223788.848457, T: 4608, Avg. loss: 730438985065140945158144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2949828864.20, NNZs: 2, Bias: 11003426289.945602, T: 4736, Avg. loss: 590357290578367072960512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1246607491.20, NNZs: 2, Bias: 10835407553.780840, T: 4864, Avg. loss: 725864187539976011907072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1646305243.20, NNZs: 2, Bias: 10735712636.266867, T: 4992, Avg. loss: 390228094896623853764608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7867581192.26, NNZs: 2, Bias: 10850725124.604845, T: 5120, Avg. loss: 447480574621728427212800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2075630508.36, NNZs: 2, Bias: 10706128846.860405, T: 5248, Avg. loss: 563620603542625771847680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1803545281.32, NNZs: 2, Bias: 10757084185.407925, T: 5376, Avg. loss: 561468510550012993732608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 7637059365.58, NNZs: 2, Bias: 10957758085.765991, T: 5504, Avg. loss: 435677487425728181960704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5743935261.24, NNZs: 2, Bias: 10895674439.813429, T: 5632, Avg. loss: 477419479472033276887040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2665102792.05, NNZs: 2, Bias: 10926559772.984945, T: 5760, Avg. loss: 3031440795498186801152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1266469957.49, NNZs: 2, Bias: 10938285284.905684, T: 5888, Avg. loss: 630126721072692723712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 632970860.05, NNZs: 2, Bias: 10943556593.551254, T: 6016, Avg. loss: 130131531937183776768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 373450146.47, NNZs: 2, Bias: 10942761943.992582, T: 6144, Avg. loss: 31975330603781341184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 243082087.43, NNZs: 2, Bias: 10940694147.879360, T: 6272, Avg. loss: 16188011689206591488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 201868731.12, NNZs: 2, Bias: 10937566884.169125, T: 6400, Avg. loss: 10796521282086223872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 172709100.38, NNZs: 2, Bias: 10934082686.595226, T: 6528, Avg. loss: 11465082562681372672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 158781685.16, NNZs: 2, Bias: 10930339774.289425, T: 6656, Avg. loss: 11460297098165663744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 168970955.81, NNZs: 2, Bias: 10926269455.721840, T: 6784, Avg. loss: 11453461333118212096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 155011406.74, NNZs: 2, Bias: 10922308367.311291, T: 6912, Avg. loss: 12596879737662814208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 146387840.65, NNZs: 2, Bias: 10918434061.096230, T: 7040, Avg. loss: 11866303391004004352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 152749698.45, NNZs: 2, Bias: 10917570030.707336, T: 7168, Avg. loss: 9639846157972084736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 151603738.79, NNZs: 2, Bias: 10916812453.015579, T: 7296, Avg. loss: 9601999746641068032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 149981268.54, NNZs: 2, Bias: 10916055342.629644, T: 7424, Avg. loss: 9699829420944789504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 149596130.51, NNZs: 2, Bias: 10915279134.907259, T: 7552, Avg. loss: 9714563807098560512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 152387915.79, NNZs: 2, Bias: 10914474948.294765, T: 7680, Avg. loss: 9466393163508299776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 150818787.43, NNZs: 2, Bias: 10913728614.246944, T: 7808, Avg. loss: 9530248570882801664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 152972767.13, NNZs: 2, Bias: 10912918137.760174, T: 7936, Avg. loss: 9678391056074850304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 151140290.50, NNZs: 2, Bias: 10912160677.850721, T: 8064, Avg. loss: 9720975134708893696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 152010221.17, NNZs: 2, Bias: 10911371849.632494, T: 8192, Avg. loss: 9643035597667162112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 151644786.61, NNZs: 2, Bias: 10910601514.970087, T: 8320, Avg. loss: 9619393296606025728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 153112110.43, NNZs: 2, Bias: 10910426616.865866, T: 8448, Avg. loss: 9340396782969899008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 152751724.63, NNZs: 2, Bias: 10910276835.032667, T: 8576, Avg. loss: 9370653346370131968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 152708238.66, NNZs: 2, Bias: 10910122561.473333, T: 8704, Avg. loss: 9377853032141469696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 152866805.90, NNZs: 2, Bias: 10909965331.643986, T: 8832, Avg. loss: 9382987428468742144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 151990430.79, NNZs: 2, Bias: 10909823165.135674, T: 8960, Avg. loss: 9339335869297903616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 152539929.91, NNZs: 2, Bias: 10909660440.810619, T: 9088, Avg. loss: 9385291634706239488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 152371006.44, NNZs: 2, Bias: 10909507833.993471, T: 9216, Avg. loss: 9377009749946257408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 152340708.68, NNZs: 2, Bias: 10909353331.005875, T: 9344, Avg. loss: 9376327315509637120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 152275736.33, NNZs: 2, Bias: 10909199240.260695, T: 9472, Avg. loss: 9380750466564722688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 153354907.09, NNZs: 2, Bias: 10909029731.756485, T: 9600, Avg. loss: 9339481103247446016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2576314037739.68, NNZs: 2, Bias: -194234968.955956, T: 128, Avg. loss: 37144540612234651905269170176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2239742828838.25, NNZs: 2, Bias: -45035063223.026657, T: 256, Avg. loss: 37539802184981019307207032832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1773164277247.42, NNZs: 2, Bias: -85035063223.026657, T: 384, Avg. loss: 38145301747617530248234532864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 941854737281.30, NNZs: 2, Bias: -85035063223.026657, T: 512, Avg. loss: 44130256675730695069645144064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2671515765990.50, NNZs: 2, Bias: -25035063223.026657, T: 640, Avg. loss: 35732904241814265709270663168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2590188183940.93, NNZs: 2, Bias: 9444689339.969315, T: 768, Avg. loss: 38517870326547820491657183232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 337446879537.15, NNZs: 2, Bias: 17482888847.863220, T: 896, Avg. loss: 37374404783446811052511068160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2185153138018.28, NNZs: 2, Bias: 657676870.547894, T: 1024, Avg. loss: 40998600362924678617233358848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2522605838475.31, NNZs: 2, Bias: 20657676870.547894, T: 1152, Avg. loss: 33515933916542627834188791808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1077484742489.80, NNZs: 2, Bias: 657676870.547894, T: 1280, Avg. loss: 44570727331563800129301381120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 407120920168.17, NNZs: 2, Bias: 6446868627.620277, T: 1408, Avg. loss: 34670093340185103339289051136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 738264233233.30, NNZs: 2, Bias: -22480613901.334030, T: 1536, Avg. loss: 38658744823638936719277948928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2799352976094.52, NNZs: 2, Bias: -22480613901.334030, T: 1664, Avg. loss: 38169204836892119245896286208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2431515071279.54, NNZs: 2, Bias: -17267761853.341610, T: 1792, Avg. loss: 38950205383855018618990362624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 248034486468.55, NNZs: 2, Bias: -23027028087.166122, T: 1920, Avg. loss: 3188986434199324526553071616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 356074259688.39, NNZs: 2, Bias: -3089378509.720938, T: 2048, Avg. loss: 910619580756219861730852864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 201194413975.03, NNZs: 2, Bias: -12390758202.866516, T: 2176, Avg. loss: 917733817044796881028251648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 332166723902.64, NNZs: 2, Bias: -7715932249.095583, T: 2304, Avg. loss: 864423463524083050733371392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 154624444561.50, NNZs: 2, Bias: -3556491998.100863, T: 2432, Avg. loss: 876095594567774288599842816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 402207173930.78, NNZs: 2, Bias: -15556491998.100864, T: 2560, Avg. loss: 886709137645685242641514496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 530252875106.50, NNZs: 2, Bias: -15021196470.673870, T: 2688, Avg. loss: 889507128533754038364143616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 162551117658.17, NNZs: 2, Bias: -23303157516.373756, T: 2816, Avg. loss: 933284019235422326598139904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 168510114578.78, NNZs: 2, Bias: -20041120394.337494, T: 2944, Avg. loss: 865881823347057618577260544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 50214783161.23, NNZs: 2, Bias: -21233105332.001083, T: 3072, Avg. loss: 38531079506516100381671424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 23809624526.10, NNZs: 2, Bias: -18703473524.696144, T: 3200, Avg. loss: 32124061294856076835946496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 19506069834.24, NNZs: 2, Bias: -22006236166.470623, T: 3328, Avg. loss: 31791980156414655148851200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 16262417102.30, NNZs: 2, Bias: -20482081139.417431, T: 3456, Avg. loss: 36539111905069271565205504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 108100399900.41, NNZs: 2, Bias: -18564662357.613655, T: 3584, Avg. loss: 33661542425586496987725824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 93638323403.50, NNZs: 2, Bias: -22062969690.800022, T: 3712, Avg. loss: 28322340357742313242361856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 17987027469.51, NNZs: 2, Bias: -21578553751.974339, T: 3840, Avg. loss: 34548806220579221169766400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 73141452702.09, NNZs: 2, Bias: -18806772204.314098, T: 3968, Avg. loss: 35230420321415150402797568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 50216456811.55, NNZs: 2, Bias: -19526137176.232395, T: 4096, Avg. loss: 37449600652176382637375488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 12736045021.13, NNZs: 2, Bias: -17552955038.606850, T: 4224, Avg. loss: 33639696383830642124652544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 19808632929.23, NNZs: 2, Bias: -17143061239.461929, T: 4352, Avg. loss: 34286645369766564256022528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 14663392812.01, NNZs: 2, Bias: -17202074049.741673, T: 4480, Avg. loss: 695846652395377603379200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11744883704.11, NNZs: 2, Bias: -17373667794.488289, T: 4608, Avg. loss: 690001734659215542190080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2817694809.98, NNZs: 2, Bias: -17474528202.629677, T: 4736, Avg. loss: 632793237118757128634368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7009340334.80, NNZs: 2, Bias: -17480703795.665123, T: 4864, Avg. loss: 597793084500701968596992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 7560512484.27, NNZs: 2, Bias: -17134894367.405640, T: 4992, Avg. loss: 683252460607149730430976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1956096684.86, NNZs: 2, Bias: -16670748575.806541, T: 5120, Avg. loss: 629687096689869744766976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4311460502.17, NNZs: 2, Bias: -16707458412.647154, T: 5248, Avg. loss: 439420174714750684364800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6301819339.07, NNZs: 2, Bias: -16565349575.158632, T: 5376, Avg. loss: 588190851564299184242688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 10644664455.01, NNZs: 2, Bias: -16743378324.138544, T: 5504, Avg. loss: 579491779921348722163712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4212961385.05, NNZs: 2, Bias: -16850186740.455126, T: 5632, Avg. loss: 649871747394326180659200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 5601647031.87, NNZs: 2, Bias: -17023676820.409401, T: 5760, Avg. loss: 506575477635081316597760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 5355498410.96, NNZs: 2, Bias: -16988349379.778620, T: 5888, Avg. loss: 523638649368480422297600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 516288682.99, NNZs: 2, Bias: -17008243538.660126, T: 6016, Avg. loss: 4006557311669219360768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 140392172.22, NNZs: 2, Bias: -16996968103.134882, T: 6144, Avg. loss: 83462680207839428608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 110595432.63, NNZs: 2, Bias: -16988550167.164249, T: 6272, Avg. loss: 41689536880158031872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 154488016.01, NNZs: 2, Bias: -16981639593.426855, T: 6400, Avg. loss: 31920640981754818560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 194721367.95, NNZs: 2, Bias: -16974602215.157991, T: 6528, Avg. loss: 31629890196683415552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 208692589.80, NNZs: 2, Bias: -16968110932.391985, T: 6656, Avg. loss: 29867706152851034112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 198221066.70, NNZs: 2, Bias: -16961867121.496969, T: 6784, Avg. loss: 29600865111988957184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 197103939.63, NNZs: 2, Bias: -16955435598.648710, T: 6912, Avg. loss: 30163065104128491520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 226461928.64, NNZs: 2, Bias: -16948465302.325678, T: 7040, Avg. loss: 31091529456425435136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 215305976.86, NNZs: 2, Bias: -16942505289.644417, T: 7168, Avg. loss: 27950109103966498816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 228366140.39, NNZs: 2, Bias: -16936215116.058847, T: 7296, Avg. loss: 27533230036472852480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 203398116.56, NNZs: 2, Bias: -16930117356.798580, T: 7424, Avg. loss: 31205783564145197056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 198746195.21, NNZs: 2, Bias: -16923784811.005615, T: 7552, Avg. loss: 31192389570635726848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 224169899.32, NNZs: 2, Bias: -16917256229.358427, T: 7680, Avg. loss: 28624144073795657728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 216418877.71, NNZs: 2, Bias: -16911113506.309719, T: 7808, Avg. loss: 28691975723130413056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 223513564.64, NNZs: 2, Bias: -16904961921.925995, T: 7936, Avg. loss: 27989475971965911040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 220082453.10, NNZs: 2, Bias: -16903756275.203951, T: 8064, Avg. loss: 24474774578820427776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 218720228.46, NNZs: 2, Bias: -16902510427.304930, T: 8192, Avg. loss: 24720097302897188864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 216565611.44, NNZs: 2, Bias: -16901297757.948431, T: 8320, Avg. loss: 24185168327385788416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 224450144.27, NNZs: 2, Bias: -16899948007.318556, T: 8448, Avg. loss: 24390052945972850688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 222659478.67, NNZs: 2, Bias: -16898713308.340418, T: 8576, Avg. loss: 24659966838297714688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 215748338.60, NNZs: 2, Bias: -16897556034.620539, T: 8704, Avg. loss: 24437254587543461888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 211591034.75, NNZs: 2, Bias: -16896394862.046455, T: 8832, Avg. loss: 23753969035942440960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 216584460.14, NNZs: 2, Bias: -16895060816.954548, T: 8960, Avg. loss: 24933992815787958272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 219287859.89, NNZs: 2, Bias: -16893767658.889126, T: 9088, Avg. loss: 24675596531898527744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 219782365.12, NNZs: 2, Bias: -16892497579.171623, T: 9216, Avg. loss: 24796763522846539776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 214690962.01, NNZs: 2, Bias: -16891312893.017345, T: 9344, Avg. loss: 24507364158507339776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 211563584.97, NNZs: 2, Bias: -16890105563.218832, T: 9472, Avg. loss: 24425167176787181568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 215793185.68, NNZs: 2, Bias: -16889795822.733276, T: 9600, Avg. loss: 24574750493557084160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 215807503.99, NNZs: 2, Bias: -16889544952.393795, T: 9728, Avg. loss: 23991180831001772032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 215000057.53, NNZs: 2, Bias: -16889306944.530663, T: 9856, Avg. loss: 23731410165145575424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 215744167.11, NNZs: 2, Bias: -16889047452.151194, T: 9984, Avg. loss: 23909629850243633152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 215831507.03, NNZs: 2, Bias: -16888795627.925085, T: 10112, Avg. loss: 23979703805548212224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 216210765.86, NNZs: 2, Bias: -16888540387.630762, T: 10240, Avg. loss: 23963728069416136704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 216167748.30, NNZs: 2, Bias: -16888290472.359375, T: 10368, Avg. loss: 23967577579174625280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 215406718.02, NNZs: 2, Bias: -16888050332.135872, T: 10496, Avg. loss: 23893221501199855616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 82 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1498056407482.71, NNZs: 2, Bias: -8799866176.254393, T: 160, Avg. loss: 46880156715964456263883948032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 490168338430.79, NNZs: 2, Bias: -8799866176.254393, T: 320, Avg. loss: 43339828836178877820765732864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 501977091110.74, NNZs: 2, Bias: -8799866176.254393, T: 480, Avg. loss: 45160923986713970530691579904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2502290950309.34, NNZs: 2, Bias: -8799866176.254393, T: 640, Avg. loss: 44705997196136346002697224192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1379095718215.38, NNZs: 2, Bias: -8799866176.254393, T: 800, Avg. loss: 40478124420961430777154764800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 396742989856.15, NNZs: 2, Bias: -8799866176.254393, T: 960, Avg. loss: 43861259869785503781745590272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2406800781120.03, NNZs: 2, Bias: -8799866176.254393, T: 1120, Avg. loss: 43972526629081904322069921792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2201496082213.18, NNZs: 2, Bias: -8799866176.254393, T: 1280, Avg. loss: 43282379912263579380266041344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2949037978731.37, NNZs: 2, Bias: -8799866176.254393, T: 1440, Avg. loss: 44792203465607148274079236096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1458728898733.41, NNZs: 2, Bias: -8799866176.254393, T: 1600, Avg. loss: 44472754411416297297982521344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 241646891179.56, NNZs: 2, Bias: 3889021909.866741, T: 1760, Avg. loss: 1296496092159901501199745024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 147569824504.12, NNZs: 2, Bias: 16542185013.184324, T: 1920, Avg. loss: 880020073990882998976774144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 438001824462.97, NNZs: 2, Bias: 35963795179.431641, T: 2080, Avg. loss: 904025953924671697898700800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 414550843816.55, NNZs: 2, Bias: 40616478010.571136, T: 2240, Avg. loss: 906064582029237242554220544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 51513811421.07, NNZs: 2, Bias: 34576231591.799278, T: 2400, Avg. loss: 881841032403336717959954432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 32652270954.23, NNZs: 2, Bias: 32147764099.881622, T: 2560, Avg. loss: 932517188660997358073413632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 78912395205.79, NNZs: 2, Bias: 14452495503.315598, T: 2720, Avg. loss: 947089085642234931378651136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 45958372765.04, NNZs: 2, Bias: 14744446657.484585, T: 2880, Avg. loss: 32016415791612528800301056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 24880525780.58, NNZs: 2, Bias: 13514499804.644325, T: 3040, Avg. loss: 35104291158235508404912128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41562295087.56, NNZs: 2, Bias: 13988758291.256304, T: 3200, Avg. loss: 36587360474570927435153408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 78172557878.19, NNZs: 2, Bias: 15137961012.677959, T: 3360, Avg. loss: 31615867070405830263177216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 31269566695.28, NNZs: 2, Bias: 15740581180.805819, T: 3520, Avg. loss: 30233881550704745895690240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 47193229204.48, NNZs: 2, Bias: 10814390182.050257, T: 3680, Avg. loss: 35663457057364723974012928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 69581171666.60, NNZs: 2, Bias: 12436492024.441040, T: 3840, Avg. loss: 30281685840274105659555840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 57508503725.28, NNZs: 2, Bias: 11289237237.405422, T: 4000, Avg. loss: 34245658261558918345916416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 33353168146.88, NNZs: 2, Bias: 14593060363.775558, T: 4160, Avg. loss: 28427223152424722490195968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 11197386761.83, NNZs: 2, Bias: 15988104275.486097, T: 4320, Avg. loss: 28711555252071652879499264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 12143807230.91, NNZs: 2, Bias: 21699807383.568432, T: 4480, Avg. loss: 35230893637635006879760384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 93925061849.76, NNZs: 2, Bias: 17864064810.961582, T: 4640, Avg. loss: 33200082031642672061480960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 18615971487.04, NNZs: 2, Bias: 18239810182.427593, T: 4800, Avg. loss: 31179993007546466050244608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 12482390695.07, NNZs: 2, Bias: 15546393275.257650, T: 4960, Avg. loss: 30347908801196293282070528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 16293679536.40, NNZs: 2, Bias: 15537666939.520487, T: 5120, Avg. loss: 592822892709648911040512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4726876801.34, NNZs: 2, Bias: 15649586027.685928, T: 5280, Avg. loss: 516732335856279841931264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6275216726.54, NNZs: 2, Bias: 15765738878.638382, T: 5440, Avg. loss: 594645802574584012079104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1971697598.31, NNZs: 2, Bias: 15486989917.488102, T: 5600, Avg. loss: 640281841354848237256704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 14035461091.63, NNZs: 2, Bias: 15099673936.001543, T: 5760, Avg. loss: 488809979317559696031744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 118832322.54, NNZs: 2, Bias: 15307471561.210154, T: 5920, Avg. loss: 630451773108970328162304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3636057483.07, NNZs: 2, Bias: 15066053250.662615, T: 6080, Avg. loss: 600682096633458454429696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6497146042.72, NNZs: 2, Bias: 14961517090.690655, T: 6240, Avg. loss: 640035263124766474633216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1415378540.75, NNZs: 2, Bias: 14849835845.239906, T: 6400, Avg. loss: 560813024380676353294336.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3136677834.66, NNZs: 2, Bias: 14711856633.685566, T: 6560, Avg. loss: 570665039472646701449216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1142654383.20, NNZs: 2, Bias: 14726449761.004393, T: 6720, Avg. loss: 839495049965984284672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 495542212.69, NNZs: 2, Bias: 14727288971.249496, T: 6880, Avg. loss: 100459006196582809600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 273257728.70, NNZs: 2, Bias: 14722870627.943161, T: 7040, Avg. loss: 32207412690192052224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 223873337.15, NNZs: 2, Bias: 14716665391.229675, T: 7200, Avg. loss: 21500790519552831488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 204071916.50, NNZs: 2, Bias: 14710010627.158434, T: 7360, Avg. loss: 21602795934374961152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 180278463.61, NNZs: 2, Bias: 14703560157.222507, T: 7520, Avg. loss: 21473450384504135680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 168661023.21, NNZs: 2, Bias: 14696934306.998592, T: 7680, Avg. loss: 22141820788806860800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 186520279.90, NNZs: 2, Bias: 14689983472.347300, T: 7840, Avg. loss: 21260074502946332672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 187929062.57, NNZs: 2, Bias: 14683391248.336128, T: 8000, Avg. loss: 20338512716295270400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 192246141.88, NNZs: 2, Bias: 14676640025.587137, T: 8160, Avg. loss: 21139867872231317504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 182242504.99, NNZs: 2, Bias: 14670015334.523233, T: 8320, Avg. loss: 21355001762798628864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 177372037.79, NNZs: 2, Bias: 14663327775.129465, T: 8480, Avg. loss: 21777577523542237184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 194366880.20, NNZs: 2, Bias: 14656376101.923239, T: 8640, Avg. loss: 21012336373248532480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 174518126.60, NNZs: 2, Bias: 14649658430.848011, T: 8800, Avg. loss: 22759503452825849856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 178893967.98, NNZs: 2, Bias: 14648251194.385761, T: 8960, Avg. loss: 18291128468611442688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 181795713.25, NNZs: 2, Bias: 14646857917.149643, T: 9120, Avg. loss: 18265353859123881984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 182503060.29, NNZs: 2, Bias: 14645506454.207729, T: 9280, Avg. loss: 18059991263895867392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 182938928.25, NNZs: 2, Bias: 14644152285.048052, T: 9440, Avg. loss: 18132487652666028032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 185179080.33, NNZs: 2, Bias: 14642776149.350368, T: 9600, Avg. loss: 18126584589581545472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 181431323.67, NNZs: 2, Bias: 14641473907.998383, T: 9760, Avg. loss: 18100287880009777152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 180749905.47, NNZs: 2, Bias: 14640136637.973318, T: 9920, Avg. loss: 18027642778564143104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 185360602.16, NNZs: 2, Bias: 14638734727.884640, T: 10080, Avg. loss: 18002078857338245120.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 183984565.97, NNZs: 2, Bias: 14637410230.218222, T: 10240, Avg. loss: 17955401991522015232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 184423852.98, NNZs: 2, Bias: 14636062057.458372, T: 10400, Avg. loss: 17972440687492720640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 184768451.14, NNZs: 2, Bias: 14634712077.581026, T: 10560, Avg. loss: 18060626608718004224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 183790066.50, NNZs: 2, Bias: 14633378335.923922, T: 10720, Avg. loss: 18004296553338841088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 183880076.04, NNZs: 2, Bias: 14632035168.635427, T: 10880, Avg. loss: 17953085285735213056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 182247761.22, NNZs: 2, Bias: 14630709574.204144, T: 11040, Avg. loss: 18035377454516490240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 186272497.49, NNZs: 2, Bias: 14629310839.899996, T: 11200, Avg. loss: 18074792522466422784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 185917694.76, NNZs: 2, Bias: 14627970734.291931, T: 11360, Avg. loss: 18037274237606795264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 184300357.88, NNZs: 2, Bias: 14626637593.210609, T: 11520, Avg. loss: 18147046225896194048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 182907525.25, NNZs: 2, Bias: 14625304252.603889, T: 11680, Avg. loss: 18058962067401601024.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 184221593.70, NNZs: 2, Bias: 14625017906.431210, T: 11840, Avg. loss: 17666987281277108224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 184466068.91, NNZs: 2, Bias: 14624745722.344753, T: 12000, Avg. loss: 17606751292868466688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 185285662.41, NNZs: 2, Bias: 14624466791.878029, T: 12160, Avg. loss: 17567312438249377792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 185166227.12, NNZs: 2, Bias: 14624199668.401243, T: 12320, Avg. loss: 17571262043251867648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 183643798.13, NNZs: 2, Bias: 14623950997.451605, T: 12480, Avg. loss: 17513069647041675264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 183298501.38, NNZs: 2, Bias: 14623688539.869967, T: 12640, Avg. loss: 17433904569229602816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 185604197.53, NNZs: 2, Bias: 14623391124.610695, T: 12800, Avg. loss: 17552763516760320000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 184075473.29, NNZs: 2, Bias: 14623142355.893969, T: 12960, Avg. loss: 17525040367812792320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 183489446.25, NNZs: 2, Bias: 14622881538.306337, T: 13120, Avg. loss: 17527529744793954304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 183837014.03, NNZs: 2, Bias: 14622607924.379318, T: 13280, Avg. loss: 17615965868988895232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 183635694.22, NNZs: 2, Bias: 14622341647.911533, T: 13440, Avg. loss: 17578019227137370112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 84 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=SGDRegressor(learning_rate=&#x27;adaptive&#x27;, max_iter=100,\n",
       "                                    verbose=10),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=SGDRegressor(learning_rate=&#x27;adaptive&#x27;, max_iter=100,\n",
       "                                    verbose=10),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor(learning_rate=&#x27;adaptive&#x27;, max_iter=100, verbose=10)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor(learning_rate=&#x27;adaptive&#x27;, max_iter=100, verbose=10)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=SGDRegressor(learning_rate='adaptive', max_iter=100,\n",
       "                                    verbose=10),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet']})"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDRegressor(max_iter=100, verbose=10, learning_rate='adaptive')\n",
    "\n",
    "# Create parameter grid\n",
    "tuned_parameters = {'penalty':['l1','l2','elasticnet'],\n",
    "                    'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Fit the model using GridSearchCV\n",
    "estimator = GridSearchCV(clf, param_grid=tuned_parameters, cv=5)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18c2945c",
   "metadata": {},
   "source": [
    "<h1 style=\"color:orange;\">Phase Four - Part 4/ Fit - Predict - Evaluate the model  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7e8fa098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1832990964995.72, NNZs: 2, Bias: 72364387281.817902, T: 128, Avg. loss: 21441994017190494160897966080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1659475634281.16, NNZs: 2, Bias: 32364387281.817902, T: 256, Avg. loss: 23235082399700262468037115904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 250187442481.99, NNZs: 2, Bias: 152364387281.817902, T: 384, Avg. loss: 23035700605373317641737863168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2998947578412.50, NNZs: 2, Bias: 52364387281.817902, T: 512, Avg. loss: 24685951558349900667259191296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1141753033265.05, NNZs: 2, Bias: -67635612718.182098, T: 640, Avg. loss: 23709902803363779691839225856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 439148660159.42, NNZs: 2, Bias: -72288771165.928223, T: 768, Avg. loss: 24735825220653148367080128512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 169357175058.66, NNZs: 2, Bias: -92432888768.481705, T: 896, Avg. loss: 930715390718755455455199232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 24007463684.24, NNZs: 2, Bias: -91477937090.383987, T: 1024, Avg. loss: 930365282873970698693378048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 89413162169.61, NNZs: 2, Bias: -101585688363.329468, T: 1152, Avg. loss: 966382921517161732556980224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 300032950513.23, NNZs: 2, Bias: -91452003300.341064, T: 1280, Avg. loss: 879102782369595147841175552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 251472002707.17, NNZs: 2, Bias: -81908453565.684311, T: 1408, Avg. loss: 909784306519805819164295168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 143270171208.47, NNZs: 2, Bias: -79302738576.330917, T: 1536, Avg. loss: 962480035596427435433787392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 102779441887.41, NNZs: 2, Bias: -77200688980.121124, T: 1664, Avg. loss: 1008968723541785877212561408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 206822756032.10, NNZs: 2, Bias: -97512676646.544235, T: 1792, Avg. loss: 967318851352909168540385280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 459135836966.28, NNZs: 2, Bias: -113412899624.114166, T: 1920, Avg. loss: 919883797219722710103359488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 28609703310.28, NNZs: 2, Bias: -109718869982.438034, T: 2048, Avg. loss: 102973015714985610494083072.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 46817869915.83, NNZs: 2, Bias: -109595569573.127899, T: 2176, Avg. loss: 36348606648296749580419072.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 45148640679.02, NNZs: 2, Bias: -109489522899.543533, T: 2304, Avg. loss: 35993430355409270808248320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 99173271359.42, NNZs: 2, Bias: -108854541110.309967, T: 2432, Avg. loss: 32829216633862417767464960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 89395622131.84, NNZs: 2, Bias: -111055360330.927368, T: 2560, Avg. loss: 33326475152850555238350848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 100919873781.67, NNZs: 2, Bias: -109890409085.976288, T: 2688, Avg. loss: 35322135846662426396196864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 91904469753.10, NNZs: 2, Bias: -113617766627.593750, T: 2816, Avg. loss: 34851597127413590141173760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 108189680668.28, NNZs: 2, Bias: -117742966795.332077, T: 2944, Avg. loss: 32742939895962341352669184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 61967361654.51, NNZs: 2, Bias: -115143748564.593781, T: 3072, Avg. loss: 37248424331607642405339136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 84596144163.41, NNZs: 2, Bias: -117316271627.828903, T: 3200, Avg. loss: 36938675072337644311543808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 49425426816.51, NNZs: 2, Bias: -116745905181.632980, T: 3328, Avg. loss: 33727313774411329776386048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 61096446233.97, NNZs: 2, Bias: -112933616460.323486, T: 3456, Avg. loss: 32112004068292912872423424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 40339846531.59, NNZs: 2, Bias: -110190777431.254150, T: 3584, Avg. loss: 36090274795468985636749312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 5359323008.30, NNZs: 2, Bias: -110881343336.842712, T: 3712, Avg. loss: 37226264843375203930079232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 47289284027.92, NNZs: 2, Bias: -111095469614.285629, T: 3840, Avg. loss: 35670183861919795132760064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11321601612.49, NNZs: 2, Bias: -111841790149.570877, T: 3968, Avg. loss: 37182368349243542679322624.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 21052090807.13, NNZs: 2, Bias: -113632321356.013596, T: 4096, Avg. loss: 36015990362370801626251264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3661597551.75, NNZs: 2, Bias: -113432528739.164017, T: 4224, Avg. loss: 900456657330909814456320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 5240216516.71, NNZs: 2, Bias: -113703903570.565857, T: 4352, Avg. loss: 694193101440993242120192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2852024220.10, NNZs: 2, Bias: -113264984837.513931, T: 4480, Avg. loss: 753534096671915393417216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 12498240761.48, NNZs: 2, Bias: -112920143510.198273, T: 4608, Avg. loss: 543834556571524716822528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1302603318.91, NNZs: 2, Bias: -112413279362.641342, T: 4736, Avg. loss: 746946022653755647852544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1532997047.69, NNZs: 2, Bias: -112483537089.951492, T: 4864, Avg. loss: 743105614380865243054080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6695926995.37, NNZs: 2, Bias: -112259830057.706329, T: 4992, Avg. loss: 861602829686376843182080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 745290198.19, NNZs: 2, Bias: -111753263739.155502, T: 5120, Avg. loss: 744416637364911202107392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2131938878.72, NNZs: 2, Bias: -111657477499.745529, T: 5248, Avg. loss: 383643185356671985647616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 8852490415.41, NNZs: 2, Bias: -111275250732.129807, T: 5376, Avg. loss: 655362243526015127126016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 13563287858.41, NNZs: 2, Bias: -111212958121.651627, T: 5504, Avg. loss: 718006558298024261451776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 13570053897.23, NNZs: 2, Bias: -111266272351.818741, T: 5632, Avg. loss: 780922848877342915297280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3561565953.40, NNZs: 2, Bias: -111188911346.800186, T: 5760, Avg. loss: 826986805482390533701632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1875988945.62, NNZs: 2, Bias: -111150699045.618713, T: 5888, Avg. loss: 787389271101938918752256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1144318639.39, NNZs: 2, Bias: -111114389366.420715, T: 6016, Avg. loss: 1876424010865157603328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1341074058.84, NNZs: 2, Bias: -111078883223.387360, T: 6144, Avg. loss: 1087504949996326748160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1494456478.87, NNZs: 2, Bias: -111043485012.421173, T: 6272, Avg. loss: 1105980474037115944960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1561450435.02, NNZs: 2, Bias: -111011331146.479202, T: 6400, Avg. loss: 1014284654171915812864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1578740550.46, NNZs: 2, Bias: -110978614666.062637, T: 6528, Avg. loss: 1076415633666794717184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1612296355.05, NNZs: 2, Bias: -110945869674.901382, T: 6656, Avg. loss: 1069909584732306014208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1581283449.98, NNZs: 2, Bias: -110913185457.037613, T: 6784, Avg. loss: 1122906752704489193472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1603001594.06, NNZs: 2, Bias: -110880121058.652466, T: 6912, Avg. loss: 1082754206855805272064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1679566760.84, NNZs: 2, Bias: -110846188845.142395, T: 7040, Avg. loss: 1078811625202561318912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1651715277.82, NNZs: 2, Bias: -110840136253.258682, T: 7168, Avg. loss: 907047125634898460672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1695411448.62, NNZs: 2, Bias: -110833039271.787643, T: 7296, Avg. loss: 898174375379185565696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1670248439.12, NNZs: 2, Bias: -110826916546.431183, T: 7424, Avg. loss: 910007642249160949760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1648651159.23, NNZs: 2, Bias: -110820738760.107391, T: 7552, Avg. loss: 909537214224147808256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1646101727.96, NNZs: 2, Bias: -110814278600.504868, T: 7680, Avg. loss: 908822907510404939776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1650417691.72, NNZs: 2, Bias: -110807818063.534760, T: 7808, Avg. loss: 893310180825459195904.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1642165320.63, NNZs: 2, Bias: -110801491085.948013, T: 7936, Avg. loss: 902297517598600724480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1625364976.10, NNZs: 2, Bias: -110795266000.543610, T: 8064, Avg. loss: 905405033840609067008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1652156345.75, NNZs: 2, Bias: -110788421928.942001, T: 8192, Avg. loss: 900650005741793443840.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1658198847.23, NNZs: 2, Bias: -110781965684.170944, T: 8320, Avg. loss: 888536777097952231424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1638245630.34, NNZs: 2, Bias: -110775789612.472595, T: 8448, Avg. loss: 904095678987450712064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1624855968.54, NNZs: 2, Bias: -110769624809.106842, T: 8576, Avg. loss: 887467508203942182912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1654945546.06, NNZs: 2, Bias: -110762836746.742508, T: 8704, Avg. loss: 883285706193000464384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1639996464.32, NNZs: 2, Bias: -110756588916.001282, T: 8832, Avg. loss: 904789991321275990016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1636462730.72, NNZs: 2, Bias: -110750174478.619598, T: 8960, Avg. loss: 903498910947998040064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1639549432.99, NNZs: 2, Bias: -110743619038.579514, T: 9088, Avg. loss: 908874490714785447936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1632398045.71, NNZs: 2, Bias: -110737251161.716660, T: 9216, Avg. loss: 904197526579719307264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1648175219.39, NNZs: 2, Bias: -110730587255.421539, T: 9344, Avg. loss: 895658562045533356032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1640429994.97, NNZs: 2, Bias: -110729409279.287796, T: 9472, Avg. loss: 879453401031322763264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1638658648.59, NNZs: 2, Bias: -110728149365.650909, T: 9600, Avg. loss: 874561468917181579264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1630870555.61, NNZs: 2, Bias: -110726983777.174759, T: 9728, Avg. loss: 871041950545688133632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1637079238.87, NNZs: 2, Bias: -110725603748.566986, T: 9856, Avg. loss: 875800217218929524736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1639900378.36, NNZs: 2, Bias: -110724275110.432129, T: 9984, Avg. loss: 874885183356041035776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1641906662.02, NNZs: 2, Bias: -110722959593.405411, T: 10112, Avg. loss: 874167086944605306880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1630549151.89, NNZs: 2, Bias: -110721846374.603577, T: 10240, Avg. loss: 871408684012316655616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1631691345.67, NNZs: 2, Bias: -110720542647.665833, T: 10368, Avg. loss: 874896173901765410816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 81 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2213104807035.78, NNZs: 2, Bias: -109050748008.675446, T: 128, Avg. loss: 18628705734086175068671442944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2005969575108.63, NNZs: 2, Bias: -21783654162.666534, T: 256, Avg. loss: 21992059565112698938324942848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1004543464921.68, NNZs: 2, Bias: -42613904786.543518, T: 384, Avg. loss: 20439759120590589344746569728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2240059403117.38, NNZs: 2, Bias: -22613904786.543518, T: 512, Avg. loss: 20089678295353353966261895168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 221453522866.64, NNZs: 2, Bias: -42613904786.543518, T: 640, Avg. loss: 21757814261753891144199045120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 598341603655.26, NNZs: 2, Bias: -70913176163.772491, T: 768, Avg. loss: 19876995516877538003483885568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 347417483974.64, NNZs: 2, Bias: -81114760422.440735, T: 896, Avg. loss: 872522941713395568338796544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 384051136997.51, NNZs: 2, Bias: -84068323808.582092, T: 1024, Avg. loss: 812737149592066047757778944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 230067469348.93, NNZs: 2, Bias: -78167842242.949783, T: 1152, Avg. loss: 832850764536971860950122496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 399404340026.48, NNZs: 2, Bias: -80528514237.115326, T: 1280, Avg. loss: 820894579633892527813165056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 306339990396.58, NNZs: 2, Bias: -85157004917.667740, T: 1408, Avg. loss: 744508078551604785800282112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 173691328487.37, NNZs: 2, Bias: -71258933669.039948, T: 1536, Avg. loss: 879732402661611531669602304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 333170238926.87, NNZs: 2, Bias: -80010103639.007019, T: 1664, Avg. loss: 889159449071321119004295168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 183454115529.95, NNZs: 2, Bias: -94762994167.544647, T: 1792, Avg. loss: 904621513461394661407981568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 363921935644.85, NNZs: 2, Bias: -81293952523.173050, T: 1920, Avg. loss: 791008111709774814883348480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 324472645630.58, NNZs: 2, Bias: -80620341766.005310, T: 2048, Avg. loss: 856213219763916606665654272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 15286462658.39, NNZs: 2, Bias: -82812105335.036362, T: 2176, Avg. loss: 61796892066540962638200832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 50321138895.69, NNZs: 2, Bias: -81001392459.979309, T: 2304, Avg. loss: 37595882082200969287827456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 20317634043.61, NNZs: 2, Bias: -80865767706.233414, T: 2432, Avg. loss: 34087571465326839713497088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 38863910303.64, NNZs: 2, Bias: -78128695368.993027, T: 2560, Avg. loss: 30939521719970456871632896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 55978591308.67, NNZs: 2, Bias: -77684720642.470261, T: 2688, Avg. loss: 32111728611843789518012416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 83253879069.13, NNZs: 2, Bias: -78911327070.304474, T: 2816, Avg. loss: 28788721793690468672864256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 38266550117.77, NNZs: 2, Bias: -82157149106.973709, T: 2944, Avg. loss: 31323654326906852932059136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 35439411648.97, NNZs: 2, Bias: -81503429608.449417, T: 3072, Avg. loss: 32959245299914369547632640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 80223719257.13, NNZs: 2, Bias: -78818341254.173508, T: 3200, Avg. loss: 32988235865535123984220160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 5029535807.07, NNZs: 2, Bias: -77946314943.824127, T: 3328, Avg. loss: 33041002782217840510369792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 84706944377.94, NNZs: 2, Bias: -76672398935.925552, T: 3456, Avg. loss: 29926977598795134810456064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 17034296311.88, NNZs: 2, Bias: -77595655149.951797, T: 3584, Avg. loss: 1425942659368754792628224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3060777857.96, NNZs: 2, Bias: -77705282776.885239, T: 3712, Avg. loss: 663386324329703426490368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3876836068.53, NNZs: 2, Bias: -77704803196.443207, T: 3840, Avg. loss: 581762927838232265621504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6640052774.62, NNZs: 2, Bias: -77736307443.103058, T: 3968, Avg. loss: 533775295525534084104192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1975391020.46, NNZs: 2, Bias: -77710068929.473297, T: 4096, Avg. loss: 594793486707761069686784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5889636621.31, NNZs: 2, Bias: -77650544860.647797, T: 4224, Avg. loss: 634022884465375405146112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 10814704125.43, NNZs: 2, Bias: -77797245570.753525, T: 4352, Avg. loss: 459054650069647055912960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3390605822.83, NNZs: 2, Bias: -77553484844.647964, T: 4480, Avg. loss: 414670140308691328434176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 10000123716.34, NNZs: 2, Bias: -77256358533.781021, T: 4608, Avg. loss: 661034962217591627579392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 10215147003.96, NNZs: 2, Bias: -77369442279.356400, T: 4736, Avg. loss: 627453321378555821555712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3180817104.27, NNZs: 2, Bias: -77198832544.524734, T: 4864, Avg. loss: 543388279707653822742528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 8494873275.80, NNZs: 2, Bias: -76957821186.756226, T: 4992, Avg. loss: 572501784069192055521280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3274806792.71, NNZs: 2, Bias: -77169728912.925217, T: 5120, Avg. loss: 577158791888368155230208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1119996097.88, NNZs: 2, Bias: -77115095386.951843, T: 5248, Avg. loss: 2735332643880550006784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 312410823.72, NNZs: 2, Bias: -77071910536.129288, T: 5376, Avg. loss: 1120349838182790463488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 720201317.69, NNZs: 2, Bias: -77035352912.315613, T: 5504, Avg. loss: 747046349438751604736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 982786088.61, NNZs: 2, Bias: -77005474508.225403, T: 5632, Avg. loss: 599389392213172027392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1100623123.50, NNZs: 2, Bias: -76976218505.421646, T: 5760, Avg. loss: 642016022067981058048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1156413577.40, NNZs: 2, Bias: -76947958495.311188, T: 5888, Avg. loss: 628273107707046789120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1200828652.79, NNZs: 2, Bias: -76918281625.556534, T: 6016, Avg. loss: 684031990716718645248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1222475878.07, NNZs: 2, Bias: -76890940357.445190, T: 6144, Avg. loss: 615521397662458183680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1177166451.47, NNZs: 2, Bias: -76865099343.875854, T: 6272, Avg. loss: 628088504167144226816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1245951203.35, NNZs: 2, Bias: -76858148560.824402, T: 6400, Avg. loss: 566858812026164674560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1225000311.74, NNZs: 2, Bias: -76853006975.781769, T: 6528, Avg. loss: 531314547379951435776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1230208858.60, NNZs: 2, Bias: -76847591722.076782, T: 6656, Avg. loss: 515154584998467665920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1234595625.50, NNZs: 2, Bias: -76842033544.327286, T: 6784, Avg. loss: 531657215431476510720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1237490434.00, NNZs: 2, Bias: -76836588978.689255, T: 6912, Avg. loss: 521678380161552023552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1219626050.16, NNZs: 2, Bias: -76831420277.031311, T: 7040, Avg. loss: 529354856083840040960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1243306897.63, NNZs: 2, Bias: -76825725598.878052, T: 7168, Avg. loss: 513335325047307829248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1216516058.34, NNZs: 2, Bias: -76820727907.074905, T: 7296, Avg. loss: 526697885478128189440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1226742127.49, NNZs: 2, Bias: -76815171620.151764, T: 7424, Avg. loss: 521556493148972646400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1234740967.95, NNZs: 2, Bias: -76809692193.110535, T: 7552, Avg. loss: 517686972699420917760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1234929992.39, NNZs: 2, Bias: -76804287226.038452, T: 7680, Avg. loss: 523443030920011382784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1239236177.78, NNZs: 2, Bias: -76798757745.257675, T: 7808, Avg. loss: 528121289475590717440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1231253196.48, NNZs: 2, Bias: -76797803404.364578, T: 7936, Avg. loss: 510866864566119366656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1229531783.12, NNZs: 2, Bias: -76796754392.421692, T: 8064, Avg. loss: 507715806324557742080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1232197185.36, NNZs: 2, Bias: -76795632432.490372, T: 8192, Avg. loss: 508790551843942891520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1236379351.20, NNZs: 2, Bias: -76794495313.436493, T: 8320, Avg. loss: 504338909472446021632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1228983089.16, NNZs: 2, Bias: -76793535340.355713, T: 8448, Avg. loss: 508821335671637344256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1230796319.22, NNZs: 2, Bias: -76792426633.181885, T: 8576, Avg. loss: 509007144864997507072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1233705792.36, NNZs: 2, Bias: -76791301332.729355, T: 8704, Avg. loss: 508450812468869595136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1234535468.44, NNZs: 2, Bias: -76790210805.395630, T: 8832, Avg. loss: 507844351810780135424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1235988669.43, NNZs: 2, Bias: -76789113707.499878, T: 8960, Avg. loss: 506176238496050577408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 70 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1051669469890.45, NNZs: 2, Bias: -43072406346.468338, T: 128, Avg. loss: 18791193420978480204254019584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1745651813502.97, NNZs: 2, Bias: -37434683867.382423, T: 256, Avg. loss: 21289648544092706555509604352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1105557354392.89, NNZs: 2, Bias: -117434683867.382416, T: 384, Avg. loss: 19152661440944392199452229632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 923637736486.68, NNZs: 2, Bias: -79455611344.247787, T: 512, Avg. loss: 22371989279426007065432162304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 721064437657.50, NNZs: 2, Bias: 4729916864.188536, T: 640, Avg. loss: 19728340826106662811980529664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 834424265637.32, NNZs: 2, Bias: 3045289842.341843, T: 768, Avg. loss: 21326178274629321457397661696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 322623739541.03, NNZs: 2, Bias: -33323112576.724384, T: 896, Avg. loss: 847778409108903376782884864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 297453202711.59, NNZs: 2, Bias: -31469158849.869232, T: 1024, Avg. loss: 769721751191224448010158080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45813711232.39, NNZs: 2, Bias: -15340816906.137753, T: 1152, Avg. loss: 776109514181375137857667072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 123962785601.88, NNZs: 2, Bias: -12765437309.105740, T: 1280, Avg. loss: 855017569122989757706534912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 123544119553.52, NNZs: 2, Bias: 4093160753.835938, T: 1408, Avg. loss: 820197912344771042123710464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 179893001314.21, NNZs: 2, Bias: 5505857886.487312, T: 1536, Avg. loss: 811275488645585045687369728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 395270452660.34, NNZs: 2, Bias: -5790624265.159939, T: 1664, Avg. loss: 733057062805462262011133952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 266881632066.18, NNZs: 2, Bias: 2389745457.067751, T: 1792, Avg. loss: 808969737452535961838682112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 357170618553.76, NNZs: 2, Bias: 9912804459.523518, T: 1920, Avg. loss: 779285982657720821171093504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 104767304950.19, NNZs: 2, Bias: 6718338509.621365, T: 2048, Avg. loss: 926780278609211465125593088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 402438091386.55, NNZs: 2, Bias: 26485625848.822407, T: 2176, Avg. loss: 792386006770590827266703360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 260164051480.95, NNZs: 2, Bias: 1119337814.727200, T: 2304, Avg. loss: 789146591740895355023130624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 59481119596.27, NNZs: 2, Bias: 7664668638.492483, T: 2432, Avg. loss: 35020534643395126511009792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 74780023234.26, NNZs: 2, Bias: 5916839197.705338, T: 2560, Avg. loss: 29489658795534596993712128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 53359038622.63, NNZs: 2, Bias: 7240395153.722054, T: 2688, Avg. loss: 28975778777617546172432384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 75036693107.71, NNZs: 2, Bias: 8894666794.773884, T: 2816, Avg. loss: 25704486426433027542351872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 83375187487.68, NNZs: 2, Bias: 7911103587.699457, T: 2944, Avg. loss: 30225057938321175285334016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 66065647556.66, NNZs: 2, Bias: 8240553139.830918, T: 3072, Avg. loss: 28966212740250729044770816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 48340903171.67, NNZs: 2, Bias: 12449782766.603340, T: 3200, Avg. loss: 29692204658746160651960320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 15726105996.47, NNZs: 2, Bias: 13988385925.369867, T: 3328, Avg. loss: 30174084710670066000068608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 45956790046.25, NNZs: 2, Bias: 16590708204.656736, T: 3456, Avg. loss: 30041413026783344889692160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4784652732.01, NNZs: 2, Bias: 15903625232.125059, T: 3584, Avg. loss: 791835905252646128189440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 745304479.99, NNZs: 2, Bias: 15829604544.463364, T: 3712, Avg. loss: 351128952680580089118720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 6003673987.48, NNZs: 2, Bias: 16040854909.128973, T: 3840, Avg. loss: 379423407217650006228992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 8240304132.21, NNZs: 2, Bias: 16076976945.116425, T: 3968, Avg. loss: 229900874785010594349056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2158821970.78, NNZs: 2, Bias: 15997339585.461075, T: 4096, Avg. loss: 503547212100240385507328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3676647337.58, NNZs: 2, Bias: 15766893654.134621, T: 4224, Avg. loss: 338468203761333495136256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6629814457.29, NNZs: 2, Bias: 15673812818.344408, T: 4352, Avg. loss: 671321051609108817379328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2021256819.74, NNZs: 2, Bias: 15301451144.778183, T: 4480, Avg. loss: 621692660693036120932352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1997165367.36, NNZs: 2, Bias: 14787603834.350845, T: 4608, Avg. loss: 409932432789315925311488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 313127562.33, NNZs: 2, Bias: 14790737085.621845, T: 4736, Avg. loss: 1122280291176401862656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 269286262.26, NNZs: 2, Bias: 14785918334.975195, T: 4864, Avg. loss: 27587768304736542720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 264943794.63, NNZs: 2, Bias: 14781209011.720230, T: 4992, Avg. loss: 21688385675508678656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 263158977.39, NNZs: 2, Bias: 14776450707.088366, T: 5120, Avg. loss: 21524767298445082624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 250843266.47, NNZs: 2, Bias: 14771634529.484119, T: 5248, Avg. loss: 23766351710655561728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 234550174.38, NNZs: 2, Bias: 14767327235.922836, T: 5376, Avg. loss: 21397733783000969216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 241017953.90, NNZs: 2, Bias: 14762295912.679237, T: 5504, Avg. loss: 22061089306222370816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 241836004.61, NNZs: 2, Bias: 14757406841.233131, T: 5632, Avg. loss: 22658514100831584256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 234050066.05, NNZs: 2, Bias: 14752359189.426176, T: 5760, Avg. loss: 24802364433543122944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 228649454.09, NNZs: 2, Bias: 14747546598.360832, T: 5888, Avg. loss: 22385387620151193600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 243168027.91, NNZs: 2, Bias: 14742312200.825605, T: 6016, Avg. loss: 22389017893260099584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 239474723.60, NNZs: 2, Bias: 14741381705.596508, T: 6144, Avg. loss: 18457603302837129216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 241438391.83, NNZs: 2, Bias: 14740344808.306528, T: 6272, Avg. loss: 18743901934227013632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 239710316.13, NNZs: 2, Bias: 14739383647.964481, T: 6400, Avg. loss: 18465389802394746880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 239014444.00, NNZs: 2, Bias: 14738395905.273420, T: 6528, Avg. loss: 18614501863263191040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 235756979.22, NNZs: 2, Bias: 14737443238.829483, T: 6656, Avg. loss: 18777799402168520704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 237311204.06, NNZs: 2, Bias: 14736409187.467510, T: 6784, Avg. loss: 18793935996905525248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 237464091.49, NNZs: 2, Bias: 14736207913.703619, T: 6912, Avg. loss: 18000115886311112704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 237454515.63, NNZs: 2, Bias: 14736009423.084160, T: 7040, Avg. loss: 17984837265227814912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 238240616.09, NNZs: 2, Bias: 14735798409.070705, T: 7168, Avg. loss: 17950214120423168000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 237771804.14, NNZs: 2, Bias: 14735607436.415457, T: 7296, Avg. loss: 17977022875153838080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 238098103.58, NNZs: 2, Bias: 14735404312.314749, T: 7424, Avg. loss: 17907146452930654208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 238154351.68, NNZs: 2, Bias: 14735205603.096985, T: 7552, Avg. loss: 17902328581736781824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 237391942.04, NNZs: 2, Bias: 14735019297.551399, T: 7680, Avg. loss: 17983566726735101952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 237450254.51, NNZs: 2, Bias: 14734820118.980278, T: 7808, Avg. loss: 17944200609919082496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 236893501.62, NNZs: 2, Bias: 14734631628.038446, T: 7936, Avg. loss: 17876831675790895104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 238257348.17, NNZs: 2, Bias: 14734411528.488794, T: 8064, Avg. loss: 17923283099156244480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 238534186.65, NNZs: 2, Bias: 14734208723.812773, T: 8192, Avg. loss: 17952140299390806016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 238291344.76, NNZs: 2, Bias: 14734014064.681540, T: 8320, Avg. loss: 17976882845504817152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 238002726.74, NNZs: 2, Bias: 14733819963.253160, T: 8448, Avg. loss: 17994235899715379200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 237484152.89, NNZs: 2, Bias: 14733629525.456278, T: 8576, Avg. loss: 17999552666986561536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 67 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1629748818560.80, NNZs: 2, Bias: -49705693610.999176, T: 128, Avg. loss: 19182689845269481497974276096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1972266201010.24, NNZs: 2, Bias: -49705693610.999176, T: 256, Avg. loss: 20757318899747716154068566016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2025202189214.16, NNZs: 2, Bias: -149705693610.999176, T: 384, Avg. loss: 21483322622663668824063082496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 288489480723.82, NNZs: 2, Bias: -49705693610.999176, T: 512, Avg. loss: 21309163654190343309458669568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1245828515690.17, NNZs: 2, Bias: -9398085839.646122, T: 640, Avg. loss: 19517921318448360555722833920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1195886664919.43, NNZs: 2, Bias: -9663069844.192665, T: 768, Avg. loss: 22732753092691724444811395072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 377031486674.00, NNZs: 2, Bias: 8030563318.727068, T: 896, Avg. loss: 1133886892814022758052659200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 423557703250.19, NNZs: 2, Bias: 14057691988.425076, T: 1024, Avg. loss: 835122983200728114140282880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 251128372601.98, NNZs: 2, Bias: -4240566008.999783, T: 1152, Avg. loss: 845408942698671017987932160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 362124723673.49, NNZs: 2, Bias: -4078139097.806005, T: 1280, Avg. loss: 848884558448559783357186048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 273832015403.90, NNZs: 2, Bias: 8359311204.846931, T: 1408, Avg. loss: 771771550607313104418111488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 168940512998.32, NNZs: 2, Bias: 25364393357.336502, T: 1536, Avg. loss: 844545772700619449862979584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 19661011124.45, NNZs: 2, Bias: 8113412573.405325, T: 1664, Avg. loss: 785579315104100385774632960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 25916523544.11, NNZs: 2, Bias: 572686914.176407, T: 1792, Avg. loss: 805360144018722851246833664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 95298927764.64, NNZs: 2, Bias: -16388779542.046032, T: 1920, Avg. loss: 862833787527084394737041408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 234329554976.06, NNZs: 2, Bias: -20100269853.618290, T: 2048, Avg. loss: 832814022235307696732504064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 62320962176.28, NNZs: 2, Bias: -16864647414.111839, T: 2176, Avg. loss: 39406839262725888855244800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 103575722526.44, NNZs: 2, Bias: -17307913084.691128, T: 2304, Avg. loss: 31233158216454620311453696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58280026436.35, NNZs: 2, Bias: -17724926407.778618, T: 2432, Avg. loss: 33295269868840937945300992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 92937007233.43, NNZs: 2, Bias: -17425665877.830315, T: 2560, Avg. loss: 29685055545129017861472256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 34778886945.39, NNZs: 2, Bias: -20917965313.852486, T: 2688, Avg. loss: 30780419305489250618703872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 33735213300.21, NNZs: 2, Bias: -18262189702.611553, T: 2816, Avg. loss: 33200332726129510198542336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 44030982119.48, NNZs: 2, Bias: -19476522258.014042, T: 2944, Avg. loss: 28475147948581177855574016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 40387185210.37, NNZs: 2, Bias: -19866510461.872993, T: 3072, Avg. loss: 30562050259493573353275392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 13930849130.43, NNZs: 2, Bias: -18847099793.039455, T: 3200, Avg. loss: 32684793251801187378790400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 24214480973.63, NNZs: 2, Bias: -21211920889.151478, T: 3328, Avg. loss: 32927038328867569493082112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 47918829612.60, NNZs: 2, Bias: -21513173034.585262, T: 3456, Avg. loss: 30519661929404923646050304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 50809262682.59, NNZs: 2, Bias: -22155985021.661964, T: 3584, Avg. loss: 32394815109432250573258752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 804510084.31, NNZs: 2, Bias: -21395972635.783123, T: 3712, Avg. loss: 1158545595041917186342912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 272881998.94, NNZs: 2, Bias: -21175992138.353874, T: 3840, Avg. loss: 502834045572836893917184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1511893134.25, NNZs: 2, Bias: -21181124760.372246, T: 3968, Avg. loss: 446899842751272327315456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 10922746633.60, NNZs: 2, Bias: -21144361182.869705, T: 4096, Avg. loss: 559162052637509562662912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2064018735.19, NNZs: 2, Bias: -20792484293.615032, T: 4224, Avg. loss: 465706577297937287610368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4659332738.04, NNZs: 2, Bias: -20651074258.605156, T: 4352, Avg. loss: 506851438047614925275136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 747820386.28, NNZs: 2, Bias: -20584175348.471363, T: 4480, Avg. loss: 558990783980221249880064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6907224628.93, NNZs: 2, Bias: -20732104098.783401, T: 4608, Avg. loss: 540526409034276689412096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3680426410.25, NNZs: 2, Bias: -20766729803.539982, T: 4736, Avg. loss: 5455810311279125463040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2077761946.19, NNZs: 2, Bias: -20783936436.622406, T: 4864, Avg. loss: 1457941125868052807680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1276899590.68, NNZs: 2, Bias: -20792281036.853905, T: 4992, Avg. loss: 381456524102802079744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 819932554.27, NNZs: 2, Bias: -20793356748.726006, T: 5120, Avg. loss: 152647380761451200512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 614543456.88, NNZs: 2, Bias: -20790763043.993729, T: 5248, Avg. loss: 70792265371649818624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 469970305.25, NNZs: 2, Bias: -20786269831.950832, T: 5376, Avg. loss: 56843435909413732352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 413721318.26, NNZs: 2, Bias: -20780332439.922752, T: 5504, Avg. loss: 47235189449911394304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 385203910.07, NNZs: 2, Bias: -20773804908.905598, T: 5632, Avg. loss: 48211545143892992000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 364797699.27, NNZs: 2, Bias: -20767530643.314472, T: 5760, Avg. loss: 42390875370482868224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 359975948.14, NNZs: 2, Bias: -20760946064.390446, T: 5888, Avg. loss: 42661426073664561152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 362555776.43, NNZs: 2, Bias: -20754327819.962902, T: 6016, Avg. loss: 42025932741422301184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 363306719.87, NNZs: 2, Bias: -20747749804.967533, T: 6144, Avg. loss: 41202083889007648768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 377637453.18, NNZs: 2, Bias: -20741240748.979801, T: 6272, Avg. loss: 39430165389624254464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 362040710.65, NNZs: 2, Bias: -20735144530.950905, T: 6400, Avg. loss: 40740760797498941440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 372929199.34, NNZs: 2, Bias: -20728627356.001099, T: 6528, Avg. loss: 40389934586771595264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 372163024.92, NNZs: 2, Bias: -20722574810.538490, T: 6656, Avg. loss: 38488211736773853184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 357400354.53, NNZs: 2, Bias: -20716349010.894009, T: 6784, Avg. loss: 40130201500171681792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 366013988.70, NNZs: 2, Bias: -20709796857.594517, T: 6912, Avg. loss: 41062580519796260864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 379636453.96, NNZs: 2, Bias: -20703583554.169617, T: 7040, Avg. loss: 37511077570787041280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 378907474.68, NNZs: 2, Bias: -20697291237.295944, T: 7168, Avg. loss: 40218259189927378944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 370663770.64, NNZs: 2, Bias: -20690817137.595772, T: 7296, Avg. loss: 41696606441214836736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 358609439.66, NNZs: 2, Bias: -20684511999.947788, T: 7424, Avg. loss: 41472669983891283968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 357213138.64, NNZs: 2, Bias: -20677801942.840328, T: 7552, Avg. loss: 42194782447963521024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 349075092.60, NNZs: 2, Bias: -20671376027.525486, T: 7680, Avg. loss: 42024698377173876736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 349372093.54, NNZs: 2, Bias: -20670068203.719563, T: 7808, Avg. loss: 33920587172571922432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 345147483.72, NNZs: 2, Bias: -20668844834.980198, T: 7936, Avg. loss: 33771816298384429056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 348108704.38, NNZs: 2, Bias: -20667484118.479263, T: 8064, Avg. loss: 34209437354333372416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 349189497.28, NNZs: 2, Bias: -20666157713.904079, T: 8192, Avg. loss: 34093873541614657536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 346782078.29, NNZs: 2, Bias: -20664906516.127502, T: 8320, Avg. loss: 33635271642535911424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 351343159.98, NNZs: 2, Bias: -20663523947.274662, T: 8448, Avg. loss: 33999762791113527296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 347578272.43, NNZs: 2, Bias: -20662305445.722855, T: 8576, Avg. loss: 33444941365377839104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 354776786.92, NNZs: 2, Bias: -20660882948.875381, T: 8704, Avg. loss: 33908194894492340224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 350333555.31, NNZs: 2, Bias: -20659708398.027359, T: 8832, Avg. loss: 32644893267569000448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 350157040.59, NNZs: 2, Bias: -20658409068.152462, T: 8960, Avg. loss: 33970268446173192192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 352413140.99, NNZs: 2, Bias: -20657075490.764767, T: 9088, Avg. loss: 33679506171116572672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 357551064.20, NNZs: 2, Bias: -20655694036.379642, T: 9216, Avg. loss: 33654229482361450496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 355332456.29, NNZs: 2, Bias: -20654436664.957008, T: 9344, Avg. loss: 33777595742926778368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 357369016.91, NNZs: 2, Bias: -20653119918.591980, T: 9472, Avg. loss: 33314425745858162688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 357091326.33, NNZs: 2, Bias: -20652866196.474957, T: 9600, Avg. loss: 32797474410574454784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 356942317.25, NNZs: 2, Bias: -20652610170.955082, T: 9728, Avg. loss: 32802313404248113152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 357133704.84, NNZs: 2, Bias: -20652348746.343765, T: 9856, Avg. loss: 32741205853302317056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 356694574.46, NNZs: 2, Bias: -20652097919.588768, T: 9984, Avg. loss: 32780995632793497600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 358011088.71, NNZs: 2, Bias: -20651817086.465420, T: 10112, Avg. loss: 32721079364415258624.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 79 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 902857303073.41, NNZs: 2, Bias: -77754882911.198242, T: 128, Avg. loss: 19573322685592245343365365760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 371496165298.77, NNZs: 2, Bias: -26485725528.473282, T: 256, Avg. loss: 24005881801422704583332855808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2086323576909.68, NNZs: 2, Bias: -101048671762.255463, T: 384, Avg. loss: 21617179103768653894147637248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 986253296299.32, NNZs: 2, Bias: -187904415253.041016, T: 512, Avg. loss: 22580033249496338394173669376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 370853215249.85, NNZs: 2, Bias: -188256832584.742950, T: 640, Avg. loss: 22872368761294199466028433408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1808855151794.70, NNZs: 2, Bias: -268256832584.742920, T: 768, Avg. loss: 24205224380749378957678215168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 82412746520.24, NNZs: 2, Bias: -263326278200.150421, T: 896, Avg. loss: 2322250464792931806482530304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 287411251566.78, NNZs: 2, Bias: -255833594874.204620, T: 1024, Avg. loss: 996038364631974443938217984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 476800516136.65, NNZs: 2, Bias: -254930428749.440948, T: 1152, Avg. loss: 923162412440745576419557376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 65916510623.37, NNZs: 2, Bias: -263893231490.689545, T: 1280, Avg. loss: 852448709077460800268926976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 375570449790.41, NNZs: 2, Bias: -275799990547.171021, T: 1408, Avg. loss: 943312317305483287012048896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 241338852797.19, NNZs: 2, Bias: -264757786693.831421, T: 1536, Avg. loss: 934136384976365557722906624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 227041073961.42, NNZs: 2, Bias: -267911209552.895325, T: 1664, Avg. loss: 869790541406237208495521792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 150947544841.95, NNZs: 2, Bias: -252144509720.532318, T: 1792, Avg. loss: 883314829253831766415769600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 137718127222.88, NNZs: 2, Bias: -271257681750.582764, T: 1920, Avg. loss: 882664113514202577053417472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 15432298203.67, NNZs: 2, Bias: -275374886905.086853, T: 2048, Avg. loss: 35859578643034742724755456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 48361516137.60, NNZs: 2, Bias: -274856763032.312561, T: 2176, Avg. loss: 33279582474938183961280512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 12859581534.52, NNZs: 2, Bias: -276039555428.826355, T: 2304, Avg. loss: 34605281896477123795746816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 46724970000.33, NNZs: 2, Bias: -271204316849.534790, T: 2432, Avg. loss: 32744818833158676888420352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 14205939976.54, NNZs: 2, Bias: -271005943401.044281, T: 2560, Avg. loss: 32693197244622728847163392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 82550021731.79, NNZs: 2, Bias: -269213525659.126465, T: 2688, Avg. loss: 34361998609846813507715072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 85550524114.55, NNZs: 2, Bias: -267250543524.081238, T: 2816, Avg. loss: 36309336924070202132398080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 26223641978.77, NNZs: 2, Bias: -268214702838.579590, T: 2944, Avg. loss: 35748699671854632174354432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 73118227408.18, NNZs: 2, Bias: -267890196958.550385, T: 3072, Avg. loss: 31572421999537720400019456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 81020351926.28, NNZs: 2, Bias: -267178125426.948151, T: 3200, Avg. loss: 36322305757950509173440512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 53278627773.05, NNZs: 2, Bias: -263623858333.751007, T: 3328, Avg. loss: 35860179056009513439068160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 24034597474.50, NNZs: 2, Bias: -264321415304.530182, T: 3456, Avg. loss: 34986794825817199030042624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 44195690851.97, NNZs: 2, Bias: -262409222640.958038, T: 3584, Avg. loss: 37294520400095977855254528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 54563884556.90, NNZs: 2, Bias: -263225046918.416504, T: 3712, Avg. loss: 31845129257059596533497856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3938846970.91, NNZs: 2, Bias: -262754504415.328918, T: 3840, Avg. loss: 1398252051955794376130560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 13837157301.69, NNZs: 2, Bias: -262565655940.830017, T: 3968, Avg. loss: 651497770156203547033600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9601572978.50, NNZs: 2, Bias: -261662007013.094543, T: 4096, Avg. loss: 771354370998730974298112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6776084461.65, NNZs: 2, Bias: -260983506924.259918, T: 4224, Avg. loss: 796383814021817238028288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7639015853.52, NNZs: 2, Bias: -260554429942.239105, T: 4352, Avg. loss: 683493254325572657479680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2222165686.27, NNZs: 2, Bias: -260067534541.893555, T: 4480, Avg. loss: 658271518645921813364736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3320990173.60, NNZs: 2, Bias: -259879109850.109772, T: 4608, Avg. loss: 690840293845658079592448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3480260769.17, NNZs: 2, Bias: -259788318547.562927, T: 4736, Avg. loss: 7155816033359756263424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4060236405.95, NNZs: 2, Bias: -259698483489.469452, T: 4864, Avg. loss: 6344051470644815069184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4097509101.68, NNZs: 2, Bias: -259611138780.405243, T: 4992, Avg. loss: 6864177960997846253568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4230465616.80, NNZs: 2, Bias: -259521946625.626587, T: 5120, Avg. loss: 6948938944318288166912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4198856744.47, NNZs: 2, Bias: -259437280107.533966, T: 5248, Avg. loss: 6633878762877312040960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4043326641.43, NNZs: 2, Bias: -259353549438.913818, T: 5376, Avg. loss: 7092880525419528323072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4055976900.64, NNZs: 2, Bias: -259266580855.624115, T: 5504, Avg. loss: 6998642867608100012032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4108068053.90, NNZs: 2, Bias: -259248172035.144867, T: 5632, Avg. loss: 5761035812362662182912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4059611612.19, NNZs: 2, Bias: -259231766190.943024, T: 5760, Avg. loss: 5627460976423210057728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4111734793.90, NNZs: 2, Bias: -259213257479.568878, T: 5888, Avg. loss: 5794702742089216557056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4084242438.87, NNZs: 2, Bias: -259196123560.144684, T: 6016, Avg. loss: 5760573082655513378816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4069893532.20, NNZs: 2, Bias: -259178795330.724457, T: 6144, Avg. loss: 5743961271670244638720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4089577449.68, NNZs: 2, Bias: -259160872848.183685, T: 6272, Avg. loss: 5761725963212263784448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4083310229.01, NNZs: 2, Bias: -259143307225.651520, T: 6400, Avg. loss: 5782550519217202921472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4076570051.82, NNZs: 2, Bias: -259139941827.742706, T: 6528, Avg. loss: 5527593047048097628160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4081332634.30, NNZs: 2, Bias: -259136399364.059113, T: 6656, Avg. loss: 5520300735271230504960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4083085912.36, NNZs: 2, Bias: -259132888047.234711, T: 6784, Avg. loss: 5545159391040646414336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4077704996.14, NNZs: 2, Bias: -259129484633.086426, T: 6912, Avg. loss: 5553132006379129667584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4075705118.34, NNZs: 2, Bias: -259126034834.638458, T: 7040, Avg. loss: 5541579995228042952704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4080715052.90, NNZs: 2, Bias: -259122472873.327332, T: 7168, Avg. loss: 5543493965535839780864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4077636645.91, NNZs: 2, Bias: -259119034707.492859, T: 7296, Avg. loss: 5549975547140888330240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 57 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1199373552050.58, NNZs: 2, Bias: -19346633080.159668, T: 128, Avg. loss: 23507259583176161102410022912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 564803816060.50, NNZs: 2, Bias: 35635942140.597626, T: 256, Avg. loss: 23260062651825575353991036928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1352324486853.86, NNZs: 2, Bias: 32639951451.230614, T: 384, Avg. loss: 23263751286046115964322316288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 308467904958.93, NNZs: 2, Bias: 72639951451.230621, T: 512, Avg. loss: 23069816110262526625617805312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1933808731558.25, NNZs: 2, Bias: 52113866640.010635, T: 640, Avg. loss: 23602957052231960168434237440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 958590767274.52, NNZs: 2, Bias: 101289623158.125183, T: 768, Avg. loss: 22988212894643225760286900224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 978628975751.85, NNZs: 2, Bias: 92088442156.461365, T: 896, Avg. loss: 25675186710153020647430684672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1476254377510.40, NNZs: 2, Bias: -902011589.645546, T: 1024, Avg. loss: 23583036130856794776081006592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1766939382336.06, NNZs: 2, Bias: -31799674417.682167, T: 1152, Avg. loss: 25165986292926039334026477568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1661313790497.26, NNZs: 2, Bias: 31256947178.072815, T: 1280, Avg. loss: 24405156071996322407633649664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 823373857688.44, NNZs: 2, Bias: 31256947178.072815, T: 1408, Avg. loss: 25123952752694086855817166848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 398427543436.29, NNZs: 2, Bias: 31401921451.192909, T: 1536, Avg. loss: 1110152578791443226295271424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 364409700356.43, NNZs: 2, Bias: 45210086121.446846, T: 1664, Avg. loss: 998102465658905108848574464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 138300431512.44, NNZs: 2, Bias: 45210086121.446846, T: 1792, Avg. loss: 968204774036912794572423168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 113388010926.82, NNZs: 2, Bias: 55853402148.533379, T: 1920, Avg. loss: 877932997070139109658329088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 204818023258.03, NNZs: 2, Bias: 67546549621.461365, T: 2048, Avg. loss: 924172612675527716961779712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 74794351764.13, NNZs: 2, Bias: 70604277165.511719, T: 2176, Avg. loss: 940332873152056764210872320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 262223000811.77, NNZs: 2, Bias: 80225429353.349792, T: 2304, Avg. loss: 942959229223683717240717312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 401826535258.90, NNZs: 2, Bias: 90522892314.359802, T: 2432, Avg. loss: 956775673674160790373924864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 114872902361.73, NNZs: 2, Bias: 89293002407.419632, T: 2560, Avg. loss: 966220256434924330313318400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 36042626857.38, NNZs: 2, Bias: 87880866060.681839, T: 2688, Avg. loss: 36224319130153387468783616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 103714825506.89, NNZs: 2, Bias: 88880423016.888809, T: 2816, Avg. loss: 33596530388734334862360576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 43200771597.25, NNZs: 2, Bias: 90326632577.686234, T: 2944, Avg. loss: 36245280059907312877305856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 46076633369.34, NNZs: 2, Bias: 88171953109.630249, T: 3072, Avg. loss: 38301586780041872175792128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 68801935788.71, NNZs: 2, Bias: 87479434189.403870, T: 3200, Avg. loss: 32864305187001115497988096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 114843320180.26, NNZs: 2, Bias: 85096372392.461594, T: 3328, Avg. loss: 35313326277178427290157056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 31969575345.65, NNZs: 2, Bias: 85002776188.994812, T: 3456, Avg. loss: 38295834737331828575698944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 37483960427.81, NNZs: 2, Bias: 89338337096.819000, T: 3584, Avg. loss: 34213356048241844081917952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 68824188029.20, NNZs: 2, Bias: 89975302269.566177, T: 3712, Avg. loss: 34869501017925979396374528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4666822699.20, NNZs: 2, Bias: 90801765696.246490, T: 3840, Avg. loss: 34447741491982277667717120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2906103501.12, NNZs: 2, Bias: 90558904989.620514, T: 3968, Avg. loss: 626166345380219133624320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3865158579.68, NNZs: 2, Bias: 90442736114.568390, T: 4096, Avg. loss: 829022575026503159906304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6464576722.74, NNZs: 2, Bias: 90196159416.728638, T: 4224, Avg. loss: 629348100299312771104768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4048965823.51, NNZs: 2, Bias: 90184010306.853775, T: 4352, Avg. loss: 674228957440682831642624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 14108443499.57, NNZs: 2, Bias: 90136806515.525986, T: 4480, Avg. loss: 691107743013836425265152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 12225580047.39, NNZs: 2, Bias: 90048178091.926102, T: 4608, Avg. loss: 749392691881968060596224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5053793919.97, NNZs: 2, Bias: 90110687463.707840, T: 4736, Avg. loss: 30287026761970021826560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3094089114.51, NNZs: 2, Bias: 90113471566.405197, T: 4864, Avg. loss: 2679773600573847240704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2378439072.96, NNZs: 2, Bias: 90097205634.947662, T: 4992, Avg. loss: 1142417811652570120192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1845117455.37, NNZs: 2, Bias: 90076860572.914841, T: 5120, Avg. loss: 984349622958668644352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1689724534.05, NNZs: 2, Bias: 90052805758.852570, T: 5248, Avg. loss: 785847299855007088640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1481539173.73, NNZs: 2, Bias: 90029682019.856506, T: 5376, Avg. loss: 751788740510812995584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1355124267.80, NNZs: 2, Bias: 90004666323.409775, T: 5504, Avg. loss: 763528108321411039232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1336080638.48, NNZs: 2, Bias: 89978830924.519272, T: 5632, Avg. loss: 731345097584802529280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1321027606.42, NNZs: 2, Bias: 89953909353.907364, T: 5760, Avg. loss: 673463042147199352832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1403702216.32, NNZs: 2, Bias: 89927668467.563248, T: 5888, Avg. loss: 685411348771610820608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1317751901.88, NNZs: 2, Bias: 89902300900.585281, T: 6016, Avg. loss: 736233108247680647168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1387135229.73, NNZs: 2, Bias: 89874860918.456665, T: 6144, Avg. loss: 694710367596949012480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1391984864.60, NNZs: 2, Bias: 89847688613.196182, T: 6272, Avg. loss: 764427938187388387328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1422533006.72, NNZs: 2, Bias: 89821462069.403824, T: 6400, Avg. loss: 711563000604264366080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1369839165.24, NNZs: 2, Bias: 89816912201.337692, T: 6528, Avg. loss: 609980040497220288512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1373308516.94, NNZs: 2, Bias: 89811766484.018311, T: 6656, Avg. loss: 576070383885221822464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1366356504.26, NNZs: 2, Bias: 89806643999.848450, T: 6784, Avg. loss: 592401199481603489792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1368228861.51, NNZs: 2, Bias: 89801334692.809601, T: 6912, Avg. loss: 599569248304642260992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1346440993.21, NNZs: 2, Bias: 89796404505.880341, T: 7040, Avg. loss: 596718862747152678912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1350772477.94, NNZs: 2, Bias: 89791226859.452057, T: 7168, Avg. loss: 578149759350072606720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1345129173.99, NNZs: 2, Bias: 89786052927.153687, T: 7296, Avg. loss: 595601079871867846656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1343596731.42, NNZs: 2, Bias: 89785031414.998993, T: 7424, Avg. loss: 575897495523436658688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1346942103.93, NNZs: 2, Bias: 89783938740.614365, T: 7552, Avg. loss: 574702360159071567872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1348997417.94, NNZs: 2, Bias: 89782866200.607971, T: 7680, Avg. loss: 574300148711421968384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1340525789.68, NNZs: 2, Bias: 89781956753.011169, T: 7808, Avg. loss: 571611397575828307968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1344981151.78, NNZs: 2, Bias: 89780847675.086395, T: 7936, Avg. loss: 574631321584724475904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1346348195.12, NNZs: 2, Bias: 89779784658.317749, T: 8064, Avg. loss: 574742761025148616704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1341488814.66, NNZs: 2, Bias: 89778812760.285553, T: 8192, Avg. loss: 576061968131608870912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1337717170.49, NNZs: 2, Bias: 89777829031.333054, T: 8320, Avg. loss: 573501102579874201600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1342897515.73, NNZs: 2, Bias: 89776706998.009720, T: 8448, Avg. loss: 575826009039250194432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 66 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 783604585951.36, NNZs: 2, Bias: 58903002323.620712, T: 128, Avg. loss: 19636843857020951328643350528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 753530232973.45, NNZs: 2, Bias: 136058374925.477234, T: 256, Avg. loss: 21146616762754551516292448256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2617476750045.88, NNZs: 2, Bias: 238898934061.487366, T: 384, Avg. loss: 20385808446723008448623017984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2005091978044.59, NNZs: 2, Bias: 358898934061.487366, T: 512, Avg. loss: 24204968546755731249023680512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1437194036154.75, NNZs: 2, Bias: 332538953130.602234, T: 640, Avg. loss: 21505958741614826852267851776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1067801291486.41, NNZs: 2, Bias: 369880733567.681274, T: 768, Avg. loss: 21919235251030926150470729728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 291013205730.39, NNZs: 2, Bias: 398534983301.174744, T: 896, Avg. loss: 1001940283465070801116463104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 278350213928.76, NNZs: 2, Bias: 386966766667.813721, T: 1024, Avg. loss: 792375612920516772464951296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 237705891907.77, NNZs: 2, Bias: 396557171136.657410, T: 1152, Avg. loss: 861659517461515592146092032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 283058713488.16, NNZs: 2, Bias: 406434009618.002380, T: 1280, Avg. loss: 892460479110555553937489920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 444365978248.02, NNZs: 2, Bias: 417764043453.925049, T: 1408, Avg. loss: 907986253867979418548305920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 152152845075.98, NNZs: 2, Bias: 426625096102.900330, T: 1536, Avg. loss: 804954821731776024979439616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 241750084137.04, NNZs: 2, Bias: 419901480233.999573, T: 1664, Avg. loss: 872573136785750726360956928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 27784350310.06, NNZs: 2, Bias: 422329015349.684875, T: 1792, Avg. loss: 39610823936184814179188736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11174215899.66, NNZs: 2, Bias: 421004035828.003601, T: 1920, Avg. loss: 33828380515556920855101440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 30537498887.63, NNZs: 2, Bias: 417549907624.896851, T: 2048, Avg. loss: 32402978577113668076437504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 29845857042.02, NNZs: 2, Bias: 418127246198.057800, T: 2176, Avg. loss: 30968779920094647361208320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 64222280106.11, NNZs: 2, Bias: 419768532978.910461, T: 2304, Avg. loss: 29810299310977995503566848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10795855377.08, NNZs: 2, Bias: 419215981203.281860, T: 2432, Avg. loss: 32448444267061482918772736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 93308231261.76, NNZs: 2, Bias: 417223742619.939270, T: 2560, Avg. loss: 29641675554045622789079040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 76026446244.22, NNZs: 2, Bias: 416927483683.003601, T: 2688, Avg. loss: 30797114192705117304651776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 44788206176.08, NNZs: 2, Bias: 419339869316.201721, T: 2816, Avg. loss: 31475072914040630613639168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 39116429826.56, NNZs: 2, Bias: 414533781399.345947, T: 2944, Avg. loss: 32267559218822945173405696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 45291821587.44, NNZs: 2, Bias: 411311378470.082886, T: 3072, Avg. loss: 30886732741020895280103424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 81231269274.52, NNZs: 2, Bias: 412190327963.627563, T: 3200, Avg. loss: 33796680996342885754339328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 22543210407.16, NNZs: 2, Bias: 411849466761.305359, T: 3328, Avg. loss: 3201925275929889340391424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 12334271821.01, NNZs: 2, Bias: 411666344787.863892, T: 3456, Avg. loss: 763673879408608251215872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 17560759930.64, NNZs: 2, Bias: 411361987171.179016, T: 3584, Avg. loss: 738279080112861317431296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4152738827.65, NNZs: 2, Bias: 410766351619.206665, T: 3712, Avg. loss: 782686956620309241790464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3867760800.67, NNZs: 2, Bias: 409973715478.924500, T: 3840, Avg. loss: 710099722545652991787008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4101807956.23, NNZs: 2, Bias: 409450517395.657166, T: 3968, Avg. loss: 884728179126596783833088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8143576228.56, NNZs: 2, Bias: 408759985237.395020, T: 4096, Avg. loss: 925985205627700295761920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 13766993360.60, NNZs: 2, Bias: 408126935949.555969, T: 4224, Avg. loss: 750465600760345062801408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 17203236169.74, NNZs: 2, Bias: 407452511081.586060, T: 4352, Avg. loss: 937975390662578365530112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 5794649017.93, NNZs: 2, Bias: 406727628501.862488, T: 4480, Avg. loss: 879827212090859164008448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5430144653.32, NNZs: 2, Bias: 406579175249.681335, T: 4608, Avg. loss: 18715945457686637707264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6372803037.31, NNZs: 2, Bias: 406433671180.770691, T: 4736, Avg. loss: 16526426141447403077632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6633783643.14, NNZs: 2, Bias: 406286853397.167847, T: 4864, Avg. loss: 17818548680190135894016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6025453988.98, NNZs: 2, Bias: 406153035171.113647, T: 4992, Avg. loss: 18775356625596643803136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 5981599971.33, NNZs: 2, Bias: 406003708596.441223, T: 5120, Avg. loss: 18763854979831835918336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 6732927024.72, NNZs: 2, Bias: 405852472640.044067, T: 5248, Avg. loss: 17080635933503862603776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6619127850.29, NNZs: 2, Bias: 405708157086.508667, T: 5376, Avg. loss: 18389285354831771336704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 6615017492.73, NNZs: 2, Bias: 405679835287.179016, T: 5504, Avg. loss: 14522493839060022329344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 6656327826.08, NNZs: 2, Bias: 405650639510.608826, T: 5632, Avg. loss: 14573154359551037800448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6605355368.38, NNZs: 2, Bias: 405623356369.921143, T: 5760, Avg. loss: 14365721764678995017728.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 6601146294.95, NNZs: 2, Bias: 405594528789.177185, T: 5888, Avg. loss: 14769449281292205031424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 6595323562.38, NNZs: 2, Bias: 405566145600.773865, T: 6016, Avg. loss: 14544833290409712025600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 6608308847.21, NNZs: 2, Bias: 405537061166.524536, T: 6144, Avg. loss: 14762996076347735932928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 6540693539.42, NNZs: 2, Bias: 405509329917.566956, T: 6272, Avg. loss: 14731875987368643133440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 6508149300.84, NNZs: 2, Bias: 405481257006.049927, T: 6400, Avg. loss: 14597145171011531964416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 6531051937.94, NNZs: 2, Bias: 405475176107.157349, T: 6528, Avg. loss: 14218510497917247160320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 6531311583.88, NNZs: 2, Bias: 405469470425.819458, T: 6656, Avg. loss: 14193840641290247602176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 6525984978.52, NNZs: 2, Bias: 405463874320.619873, T: 6784, Avg. loss: 14145601422262859202560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 6526322513.30, NNZs: 2, Bias: 405458166470.052856, T: 6912, Avg. loss: 14196234724507796897792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 6531050835.79, NNZs: 2, Bias: 405452393554.371338, T: 7040, Avg. loss: 14181561907681479884800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 6525668499.29, NNZs: 2, Bias: 405446785728.118591, T: 7168, Avg. loss: 14175961291589242847232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 6544238800.80, NNZs: 2, Bias: 405440792586.170227, T: 7296, Avg. loss: 14171579163280626679808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 6527271799.13, NNZs: 2, Bias: 405435371130.547546, T: 7424, Avg. loss: 14178129419696376643584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 58 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 760174256464.82, NNZs: 2, Bias: 10359085347.704132, T: 128, Avg. loss: 17519812399115572498260819968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 938797702248.24, NNZs: 2, Bias: -9640914652.295868, T: 256, Avg. loss: 18491516170609083064766169088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 263021847700.74, NNZs: 2, Bias: 90359085347.704132, T: 384, Avg. loss: 20530090914342183732351336448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 888616836807.72, NNZs: 2, Bias: 58449652660.436340, T: 512, Avg. loss: 19180284536561286100826456064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1582617249506.35, NNZs: 2, Bias: 11667688203.266022, T: 640, Avg. loss: 18505494561501090809359892480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2195053297200.08, NNZs: 2, Bias: -44313268213.079697, T: 768, Avg. loss: 19826972856398872858209550336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 378786754728.11, NNZs: 2, Bias: -62009937339.138138, T: 896, Avg. loss: 2009502982747649511000113152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 107805414596.90, NNZs: 2, Bias: -52619808702.672165, T: 1024, Avg. loss: 814126796544781528867012608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 523211127427.81, NNZs: 2, Bias: -75236220081.872238, T: 1152, Avg. loss: 783951753506079995898888192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 285742374628.71, NNZs: 2, Bias: -78561520807.632202, T: 1280, Avg. loss: 833388675158198348658245632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 156429632423.06, NNZs: 2, Bias: -92927343669.727936, T: 1408, Avg. loss: 810932075376815004566159360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 133436562093.86, NNZs: 2, Bias: -105877927122.431122, T: 1536, Avg. loss: 836420014939489160031895552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 205898220223.28, NNZs: 2, Bias: -93496863110.264664, T: 1664, Avg. loss: 833384217455044914325749760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 406679160290.09, NNZs: 2, Bias: -95430072638.460724, T: 1792, Avg. loss: 830635937554117650034982912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 37213371329.81, NNZs: 2, Bias: -103515603716.729248, T: 1920, Avg. loss: 52116686517833297083498496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 57135573351.49, NNZs: 2, Bias: -105430144823.759171, T: 2048, Avg. loss: 31469488291532924937830400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 17029263801.05, NNZs: 2, Bias: -108295862937.551636, T: 2176, Avg. loss: 30731829900345612099911680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 59552382849.06, NNZs: 2, Bias: -107963487334.518692, T: 2304, Avg. loss: 27667752095813295522447360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 101372027165.15, NNZs: 2, Bias: -106438412788.200119, T: 2432, Avg. loss: 26859562995788017951571968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 74026278179.71, NNZs: 2, Bias: -106137766888.886505, T: 2560, Avg. loss: 29277126002883548644638720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 45726025599.65, NNZs: 2, Bias: -110423585742.995209, T: 2688, Avg. loss: 31479963743208104223834112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 24633780579.96, NNZs: 2, Bias: -107825457079.632401, T: 2816, Avg. loss: 29809037932101001109569536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 28161348604.94, NNZs: 2, Bias: -107435805857.862976, T: 2944, Avg. loss: 28994780884584506270416896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 38083326603.34, NNZs: 2, Bias: -110139094360.188736, T: 3072, Avg. loss: 25862856849557153820704768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 44498940644.59, NNZs: 2, Bias: -112142120762.981186, T: 3200, Avg. loss: 26903498631840793968508928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 102574666543.30, NNZs: 2, Bias: -110794149997.877548, T: 3328, Avg. loss: 28445491910085957889556480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 73357332503.08, NNZs: 2, Bias: -110059682788.957062, T: 3456, Avg. loss: 30734056804012192169984000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 41266993197.21, NNZs: 2, Bias: -109324199563.663910, T: 3584, Avg. loss: 29871605893692507388116992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 111462747686.54, NNZs: 2, Bias: -109740204582.224457, T: 3712, Avg. loss: 27327951514282819227484160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8532163580.41, NNZs: 2, Bias: -109706575036.914413, T: 3840, Avg. loss: 5177631719254630581927936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4070519351.72, NNZs: 2, Bias: -109636050180.047333, T: 3968, Avg. loss: 477151058769306806386688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1492819932.42, NNZs: 2, Bias: -109516621714.418762, T: 4096, Avg. loss: 403066736800849192812544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 12709354634.61, NNZs: 2, Bias: -109506269915.212616, T: 4224, Avg. loss: 565245945037230880849920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2983990089.66, NNZs: 2, Bias: -109723376701.721970, T: 4352, Avg. loss: 515369614636883602571264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9591702403.85, NNZs: 2, Bias: -109597808946.760498, T: 4480, Avg. loss: 518981105909583285583872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 658668492.72, NNZs: 2, Bias: -109144764747.185425, T: 4608, Avg. loss: 430242479958181690736640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8151491482.13, NNZs: 2, Bias: -108738462976.433228, T: 4736, Avg. loss: 631016712403778151645184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1734878305.53, NNZs: 2, Bias: -108751293629.393204, T: 4864, Avg. loss: 9411725939520366968832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1710955365.31, NNZs: 2, Bias: -108713507015.067627, T: 4992, Avg. loss: 1338939403490677751808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1779764813.11, NNZs: 2, Bias: -108678116526.457703, T: 5120, Avg. loss: 1158064269620420018176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1682739924.79, NNZs: 2, Bias: -108642888155.075989, T: 5248, Avg. loss: 1270255956158864162816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1851722494.52, NNZs: 2, Bias: -108605848605.673248, T: 5376, Avg. loss: 1117303137533570580480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1732393410.52, NNZs: 2, Bias: -108573833220.643143, T: 5504, Avg. loss: 1204943445351201243136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1736129076.72, NNZs: 2, Bias: -108538778393.914749, T: 5632, Avg. loss: 1186018539062694772736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1681371778.15, NNZs: 2, Bias: -108503964971.885178, T: 5760, Avg. loss: 1250763360401980653568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1712843880.72, NNZs: 2, Bias: -108467467821.165085, T: 5888, Avg. loss: 1222330400833733394432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1680506677.93, NNZs: 2, Bias: -108430454740.415283, T: 6016, Avg. loss: 1273912731893891858432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1647068552.50, NNZs: 2, Bias: -108423580565.751297, T: 6144, Avg. loss: 1012392417199142076416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1639763859.05, NNZs: 2, Bias: -108416547320.017014, T: 6272, Avg. loss: 977228911163331969024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1659967761.49, NNZs: 2, Bias: -108408927752.892517, T: 6400, Avg. loss: 999178186026522116096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1688834635.97, NNZs: 2, Bias: -108401076864.156937, T: 6528, Avg. loss: 1013350700936500740096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1683185547.82, NNZs: 2, Bias: -108393898933.445206, T: 6656, Avg. loss: 996788271205655773184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1704797608.47, NNZs: 2, Bias: -108386217075.392212, T: 6784, Avg. loss: 1004810212839881179136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1707331280.95, NNZs: 2, Bias: -108378760231.266022, T: 6912, Avg. loss: 1015629140172078448640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1706481633.55, NNZs: 2, Bias: -108377311328.008926, T: 7040, Avg. loss: 973642394324083539968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1702408814.79, NNZs: 2, Bias: -108375928017.146271, T: 7168, Avg. loss: 963945113652397342720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1707665946.97, NNZs: 2, Bias: -108374383814.279922, T: 7296, Avg. loss: 972849210495511429120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1712689499.19, NNZs: 2, Bias: -108372843621.683060, T: 7424, Avg. loss: 972352910524067872768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1704894908.13, NNZs: 2, Bias: -108371514921.700745, T: 7552, Avg. loss: 966749546344957870080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1714074714.75, NNZs: 2, Bias: -108369910575.885269, T: 7680, Avg. loss: 971265733860402135040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1706838141.28, NNZs: 2, Bias: -108368571647.429062, T: 7808, Avg. loss: 967796234797230456832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 61 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1233234169253.23, NNZs: 2, Bias: -8849503663.339546, T: 128, Avg. loss: 21430622255905192901525635072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1888842179066.63, NNZs: 2, Bias: -68849503663.339539, T: 256, Avg. loss: 20662946316553773207099801600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1614848784256.32, NNZs: 2, Bias: 11150496336.660461, T: 384, Avg. loss: 19482246257373563004037103616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2077174478560.57, NNZs: 2, Bias: 50075177702.852013, T: 512, Avg. loss: 19796290380842430173412327424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 470581564012.30, NNZs: 2, Bias: 117496273616.328033, T: 640, Avg. loss: 19681741749715955772559458304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1633407198098.88, NNZs: 2, Bias: 77496273616.328033, T: 768, Avg. loss: 20578849038220534365233872896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1019124802621.41, NNZs: 2, Bias: 92127578652.906891, T: 896, Avg. loss: 21514786655754435078396051456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 488979047806.57, NNZs: 2, Bias: 152127578652.906891, T: 1024, Avg. loss: 20935325678318162750109384704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 279323329449.42, NNZs: 2, Bias: 140617997878.279572, T: 1152, Avg. loss: 847271351831498655419858944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 531938129712.94, NNZs: 2, Bias: 155066835220.302368, T: 1280, Avg. loss: 851010736371625815651123200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 166932151588.52, NNZs: 2, Bias: 153596412608.735474, T: 1408, Avg. loss: 837367778983234062958723072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 202198540956.54, NNZs: 2, Bias: 162263045593.161926, T: 1536, Avg. loss: 882787987014809844113735680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 194109581928.94, NNZs: 2, Bias: 170622898255.220581, T: 1664, Avg. loss: 799000049182503070890721280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 135193720572.34, NNZs: 2, Bias: 166880440173.711304, T: 1792, Avg. loss: 839635253493639049828630528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 186831754086.86, NNZs: 2, Bias: 157665788160.925507, T: 1920, Avg. loss: 841677503637421621680013312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 500133455279.49, NNZs: 2, Bias: 124833436823.083176, T: 2048, Avg. loss: 770492347011972264252932096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 149888027686.59, NNZs: 2, Bias: 126660077608.645111, T: 2176, Avg. loss: 841290143043134912297172992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 334630946230.53, NNZs: 2, Bias: 129979254711.286911, T: 2304, Avg. loss: 808671453893748412383232000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 501045118996.86, NNZs: 2, Bias: 126381495418.598862, T: 2432, Avg. loss: 813299963910843051737612288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 31856278011.56, NNZs: 2, Bias: 107207090220.827423, T: 2560, Avg. loss: 851375503731395937068646400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 341102201842.73, NNZs: 2, Bias: 115848318872.837677, T: 2688, Avg. loss: 858783641279417963750883328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 22401714818.43, NNZs: 2, Bias: 113513038286.264130, T: 2816, Avg. loss: 78506738694414033393549312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 50387107891.83, NNZs: 2, Bias: 109412724924.760498, T: 2944, Avg. loss: 29140173287268406102327296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 32424488274.87, NNZs: 2, Bias: 112142096830.403030, T: 3072, Avg. loss: 29154551640482232993316864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 15597652468.95, NNZs: 2, Bias: 114670085387.012390, T: 3200, Avg. loss: 33856135325320801345863680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 35956311100.69, NNZs: 2, Bias: 113264870618.931458, T: 3328, Avg. loss: 31688175112706452038352896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 70726657198.70, NNZs: 2, Bias: 111306379348.304138, T: 3456, Avg. loss: 32002075343064344289083392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 14939287800.36, NNZs: 2, Bias: 114942360637.484909, T: 3584, Avg. loss: 30638116819105584504635392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1385726338.75, NNZs: 2, Bias: 114755378534.426514, T: 3712, Avg. loss: 747594811249657661882368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3254957529.63, NNZs: 2, Bias: 114700344705.320068, T: 3840, Avg. loss: 437755126918847909593088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 19162236214.46, NNZs: 2, Bias: 114896383043.522034, T: 3968, Avg. loss: 609518887594391886626816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 7685613376.45, NNZs: 2, Bias: 114744309808.884171, T: 4096, Avg. loss: 689490401482406616891392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5207600875.81, NNZs: 2, Bias: 114816235742.492889, T: 4224, Avg. loss: 647748040808818215485440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1153607322.19, NNZs: 2, Bias: 114666383829.892517, T: 4352, Avg. loss: 540246457437305886998528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7445865672.78, NNZs: 2, Bias: 114371499172.964020, T: 4480, Avg. loss: 684227287847494561562624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4891943912.87, NNZs: 2, Bias: 114379157876.732132, T: 4608, Avg. loss: 4817810708399455731712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3351892455.11, NNZs: 2, Bias: 114364588333.943573, T: 4736, Avg. loss: 2790816298996924940288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2644852405.76, NNZs: 2, Bias: 114338632980.043610, T: 4864, Avg. loss: 1683570837647731720192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2287515164.00, NNZs: 2, Bias: 114306413234.941269, T: 4992, Avg. loss: 1474163369135373025280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2175782085.38, NNZs: 2, Bias: 114272285881.575577, T: 5120, Avg. loss: 1300906033608612118528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2066502462.35, NNZs: 2, Bias: 114238690608.330444, T: 5248, Avg. loss: 1226251896201296740352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1937521526.00, NNZs: 2, Bias: 114205531917.166641, T: 5376, Avg. loss: 1255717058891672715264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2141171003.49, NNZs: 2, Bias: 114166101782.754822, T: 5504, Avg. loss: 1217007498967946625024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2099580920.75, NNZs: 2, Bias: 114132831866.867538, T: 5632, Avg. loss: 1238740111218874515456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2056341361.93, NNZs: 2, Bias: 114096082103.070374, T: 5760, Avg. loss: 1324553264853232648192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2080315900.80, NNZs: 2, Bias: 114063625832.403931, T: 5888, Avg. loss: 1090370154827051040768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2014408841.01, NNZs: 2, Bias: 114027565312.335907, T: 6016, Avg. loss: 1307680589846867869696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1919846896.96, NNZs: 2, Bias: 113994549843.367325, T: 6144, Avg. loss: 1211934226146044411904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1924209843.40, NNZs: 2, Bias: 113958663928.906448, T: 6272, Avg. loss: 1275000779925840199680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1966382116.69, NNZs: 2, Bias: 113924330798.360870, T: 6400, Avg. loss: 1177345689243250982912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1994496314.08, NNZs: 2, Bias: 113888246857.201920, T: 6528, Avg. loss: 1201197550871505534976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1978254748.01, NNZs: 2, Bias: 113881361509.430481, T: 6656, Avg. loss: 1032650556075865014272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1963184791.04, NNZs: 2, Bias: 113874536780.709991, T: 6784, Avg. loss: 1018556825165741293568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1995993912.09, NNZs: 2, Bias: 113866794232.413864, T: 6912, Avg. loss: 1027988455517546610688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1970592147.29, NNZs: 2, Bias: 113860172930.508881, T: 7040, Avg. loss: 1014933637845125300224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2010807544.01, NNZs: 2, Bias: 113852465375.477386, T: 7168, Avg. loss: 1002598107609331138560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1991613890.09, NNZs: 2, Bias: 113845843852.117752, T: 7296, Avg. loss: 998087830677295595520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2007091662.10, NNZs: 2, Bias: 113838432524.527084, T: 7424, Avg. loss: 1025055049107496239104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1987555305.65, NNZs: 2, Bias: 113831551987.803070, T: 7552, Avg. loss: 1040634532807379517440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2007828244.41, NNZs: 2, Bias: 113824174300.552673, T: 7680, Avg. loss: 1007451316972768591872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1997022955.30, NNZs: 2, Bias: 113817172355.761246, T: 7808, Avg. loss: 1033065978529574944768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1987375349.24, NNZs: 2, Bias: 113810193973.963623, T: 7936, Avg. loss: 1026118976358014124032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1984258482.49, NNZs: 2, Bias: 113808822601.270950, T: 8064, Avg. loss: 996710569732424597504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1981234681.28, NNZs: 2, Bias: 113807450771.305161, T: 8192, Avg. loss: 995795715106434580480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1980329822.55, NNZs: 2, Bias: 113806041617.867432, T: 8320, Avg. loss: 995986159793064640512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1979900280.14, NNZs: 2, Bias: 113804623798.419357, T: 8448, Avg. loss: 996292241162922491904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1981392820.46, NNZs: 2, Bias: 113803172668.038193, T: 8576, Avg. loss: 996049957084752773120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1982342356.19, NNZs: 2, Bias: 113801732369.383499, T: 8704, Avg. loss: 995045344477068394496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1975726215.70, NNZs: 2, Bias: 113800430176.216705, T: 8832, Avg. loss: 990849610762374217728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1979830965.97, NNZs: 2, Bias: 113798931754.175964, T: 8960, Avg. loss: 997289359405773750272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1981114710.57, NNZs: 2, Bias: 113797486519.489349, T: 9088, Avg. loss: 994421198397130539008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1978908828.49, NNZs: 2, Bias: 113796106846.385834, T: 9216, Avg. loss: 991422966273648623616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1976722068.63, NNZs: 2, Bias: 113794721476.604843, T: 9344, Avg. loss: 994896615361802928128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1976835238.03, NNZs: 2, Bias: 113793294258.718826, T: 9472, Avg. loss: 996130836624159539200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 74 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2037927119762.63, NNZs: 2, Bias: 46450447870.094879, T: 128, Avg. loss: 22362991237064569316964302848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2227729545906.87, NNZs: 2, Bias: 34973310774.038666, T: 256, Avg. loss: 23330965722877690273601683456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 472188990151.08, NNZs: 2, Bias: 71076076620.229065, T: 384, Avg. loss: 20940066702062290676448493568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1835667949711.40, NNZs: 2, Bias: 122724818758.744019, T: 512, Avg. loss: 21191616365372980116066402304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2073880532836.26, NNZs: 2, Bias: 100485321858.006287, T: 640, Avg. loss: 23710638872172421460531347456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 437771097717.18, NNZs: 2, Bias: 65837598973.861206, T: 768, Avg. loss: 25276726971659143247208382464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1359615960808.12, NNZs: 2, Bias: 85837598973.861206, T: 896, Avg. loss: 20698879781194999314136432640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2081573271054.20, NNZs: 2, Bias: 145837598973.861206, T: 1024, Avg. loss: 23366866871455574058864738304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 86328862990.93, NNZs: 2, Bias: 88167934405.412354, T: 1152, Avg. loss: 21595433416306617604496162816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 706760754625.36, NNZs: 2, Bias: 108167934405.412354, T: 1280, Avg. loss: 20371546363017581304223891456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1266099438925.13, NNZs: 2, Bias: 35527872499.476044, T: 1408, Avg. loss: 23077691633131580467401719808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 545468014040.39, NNZs: 2, Bias: 35527872499.476044, T: 1536, Avg. loss: 22052648108991625181284794368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 318853935295.40, NNZs: 2, Bias: 35527872499.476044, T: 1664, Avg. loss: 22717712840503190842373046272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1887361076373.78, NNZs: 2, Bias: 50268571094.006531, T: 1792, Avg. loss: 22505813806518330656754237440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 2452710656030.66, NNZs: 2, Bias: -9731428905.993469, T: 1920, Avg. loss: 26747705850835169240248483840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 229581129884.37, NNZs: 2, Bias: 3649992686.089872, T: 2048, Avg. loss: 2621223727984255361536229376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 173292703891.02, NNZs: 2, Bias: 5887005792.020600, T: 2176, Avg. loss: 877467734867046833802182656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 346255779671.11, NNZs: 2, Bias: 8917701220.606186, T: 2304, Avg. loss: 853256213797355789299482624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 324948029023.38, NNZs: 2, Bias: 9517744578.216812, T: 2432, Avg. loss: 890645446813711544853987328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 95463032908.55, NNZs: 2, Bias: 3577304484.291739, T: 2560, Avg. loss: 889211194129566933658370048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 204882841308.27, NNZs: 2, Bias: 2491946939.025981, T: 2688, Avg. loss: 887482990332742973400285184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4824965029.51, NNZs: 2, Bias: 3648487920.453419, T: 2816, Avg. loss: 1019478588956369533202857984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 186087514831.07, NNZs: 2, Bias: -1335613932.339667, T: 2944, Avg. loss: 914749460522051943593410560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 35309727433.55, NNZs: 2, Bias: -2781162470.152668, T: 3072, Avg. loss: 33051815992004357186912256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 55269176886.09, NNZs: 2, Bias: -5186741535.163903, T: 3200, Avg. loss: 32275142277228945746165760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 61733020113.30, NNZs: 2, Bias: -5215133064.223989, T: 3328, Avg. loss: 34637150976168488891056128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 56772248063.44, NNZs: 2, Bias: -4370125483.106955, T: 3456, Avg. loss: 35433269646723997258219520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 44176324877.60, NNZs: 2, Bias: -6588864998.142109, T: 3584, Avg. loss: 34920166641275356512780288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 56572458267.84, NNZs: 2, Bias: -6430204721.451712, T: 3712, Avg. loss: 33700247521938861195264000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 59138250239.04, NNZs: 2, Bias: -7983893139.571872, T: 3840, Avg. loss: 35653692591652423757463552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2411768757.83, NNZs: 2, Bias: -7274659521.096376, T: 3968, Avg. loss: 1862592133827879338246144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6946231765.13, NNZs: 2, Bias: -7285462428.478206, T: 4096, Avg. loss: 660828205050647346675712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2469206046.34, NNZs: 2, Bias: -7354973432.252610, T: 4224, Avg. loss: 708650424870747456405504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9541859835.40, NNZs: 2, Bias: -7455558783.787824, T: 4352, Avg. loss: 637205608172228882464768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 13492979310.70, NNZs: 2, Bias: -7148681016.152095, T: 4480, Avg. loss: 594571042471332062167040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9836591159.09, NNZs: 2, Bias: -7480402115.157770, T: 4608, Avg. loss: 848303400805247454543872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1287688003.96, NNZs: 2, Bias: -7442316405.523499, T: 4736, Avg. loss: 642600762901017458114560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1934993396.70, NNZs: 2, Bias: -6872479737.141108, T: 4864, Avg. loss: 525435287295990362537984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1582353991.57, NNZs: 2, Bias: -6780894701.979916, T: 4992, Avg. loss: 671571870052946678906880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7447060088.50, NNZs: 2, Bias: -7054946851.452813, T: 5120, Avg. loss: 431294468024403146833920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2428304232.67, NNZs: 2, Bias: -7097468905.103706, T: 5248, Avg. loss: 740616491994289226645504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6014790520.93, NNZs: 2, Bias: -7382547504.451459, T: 5376, Avg. loss: 541171187456340461092864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 10943255280.25, NNZs: 2, Bias: -7130013878.049982, T: 5504, Avg. loss: 749179806435165448699904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3432026847.14, NNZs: 2, Bias: -7258982608.276727, T: 5632, Avg. loss: 629652858996527923724288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3000690290.56, NNZs: 2, Bias: -7251502723.187229, T: 5760, Avg. loss: 587208525187532344786944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 289870336.24, NNZs: 2, Bias: -7241697378.555538, T: 5888, Avg. loss: 3246868645972685619200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 197471060.99, NNZs: 2, Bias: -7240625396.168062, T: 6016, Avg. loss: 10380842506301122560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 163054929.58, NNZs: 2, Bias: -7238822798.952000, T: 6144, Avg. loss: 6174623405994825728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 137308420.28, NNZs: 2, Bias: -7236693929.590620, T: 6272, Avg. loss: 6273925197347213312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 124646679.98, NNZs: 2, Bias: -7234414282.347398, T: 6400, Avg. loss: 5737430632759180288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 119291507.33, NNZs: 2, Bias: -7232040501.330256, T: 6528, Avg. loss: 5361453193881233408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 112614452.28, NNZs: 2, Bias: -7229623160.279379, T: 6656, Avg. loss: 5725780547148478464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 111975603.57, NNZs: 2, Bias: -7227321696.367128, T: 6784, Avg. loss: 5057122997637782528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 117430463.27, NNZs: 2, Bias: -7224838587.216629, T: 6912, Avg. loss: 5283255217157601280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 115933069.12, NNZs: 2, Bias: -7222373625.287445, T: 7040, Avg. loss: 5711595410758571008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 116691337.95, NNZs: 2, Bias: -7219796943.189974, T: 7168, Avg. loss: 6187284187521863680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 117819627.48, NNZs: 2, Bias: -7217442605.109074, T: 7296, Avg. loss: 5298778834253110272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 124507874.44, NNZs: 2, Bias: -7215112248.766041, T: 7424, Avg. loss: 4725164426183088128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 121722957.72, NNZs: 2, Bias: -7212743461.304471, T: 7552, Avg. loss: 5514375739668306944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 112120309.04, NNZs: 2, Bias: -7210421538.700730, T: 7680, Avg. loss: 5519916982387277824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 121855033.63, NNZs: 2, Bias: -7207865468.320473, T: 7808, Avg. loss: 5318803597636125696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 115131938.39, NNZs: 2, Bias: -7205425269.246182, T: 7936, Avg. loss: 5865725799332165632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 111398700.95, NNZs: 2, Bias: -7203033621.080849, T: 8064, Avg. loss: 5479014247860495360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 115231396.67, NNZs: 2, Bias: -7202456817.653529, T: 8192, Avg. loss: 4689451878915320832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 114729265.35, NNZs: 2, Bias: -7201997268.259867, T: 8320, Avg. loss: 4251655279714153472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 116422343.76, NNZs: 2, Bias: -7201499648.157891, T: 8448, Avg. loss: 4270117214882691584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 114767106.20, NNZs: 2, Bias: -7201039553.466094, T: 8576, Avg. loss: 4431953212060597760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 115353910.40, NNZs: 2, Bias: -7200538957.496021, T: 8704, Avg. loss: 4467435289546833408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 113992446.42, NNZs: 2, Bias: -7200074687.237397, T: 8832, Avg. loss: 4426019738214032384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 113661002.72, NNZs: 2, Bias: -7199594362.059950, T: 8960, Avg. loss: 4424699907867227648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 114517468.99, NNZs: 2, Bias: -7199483842.071918, T: 9088, Avg. loss: 4285266987515455488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 114452854.35, NNZs: 2, Bias: -7199388288.291446, T: 9216, Avg. loss: 4270928490670542336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 114098101.79, NNZs: 2, Bias: -7199297538.870269, T: 9344, Avg. loss: 4263558654872284160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 114159349.53, NNZs: 2, Bias: -7199199672.530979, T: 9472, Avg. loss: 4285034605256253440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 113902616.30, NNZs: 2, Bias: -7199107226.567315, T: 9600, Avg. loss: 4269213063152155136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2213097474754.67, NNZs: 2, Bias: 30022757511.741562, T: 128, Avg. loss: 24681236591199912105919643648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2504607918702.68, NNZs: 2, Bias: 46551707972.952347, T: 256, Avg. loss: 22585352871110371650910027776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1200024116101.87, NNZs: 2, Bias: 42705510938.775299, T: 384, Avg. loss: 23975033098009568187248541696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2348236021452.52, NNZs: 2, Bias: 23520415494.408264, T: 512, Avg. loss: 23020736798278509674352345088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1260410574953.13, NNZs: 2, Bias: 58692418524.252136, T: 640, Avg. loss: 26713805701504111601340383232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2591608926164.65, NNZs: 2, Bias: 95819716951.395126, T: 768, Avg. loss: 24829810061275370379066474496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2720523295585.51, NNZs: 2, Bias: 94066071510.822540, T: 896, Avg. loss: 23845958489802874973629448192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 375707444812.98, NNZs: 2, Bias: 87295060483.601730, T: 1024, Avg. loss: 4865692847094646350731542528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 203253524664.42, NNZs: 2, Bias: 81573212662.670731, T: 1152, Avg. loss: 1038772672459308142447034368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 334306505836.79, NNZs: 2, Bias: 67300904232.964325, T: 1280, Avg. loss: 995354301030583936302972928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 473391074262.44, NNZs: 2, Bias: 71670311338.312897, T: 1408, Avg. loss: 956857471278645845335998464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 403026878371.51, NNZs: 2, Bias: 85102035798.670151, T: 1536, Avg. loss: 957523965213127518602657792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 478355433603.47, NNZs: 2, Bias: 75919855699.078827, T: 1664, Avg. loss: 940329136532828663989665792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 460443336159.60, NNZs: 2, Bias: 71855527652.844666, T: 1792, Avg. loss: 916180873334821999102394368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 391041448342.83, NNZs: 2, Bias: 77888003636.950653, T: 1920, Avg. loss: 1005627609268559552574390272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 210762213329.64, NNZs: 2, Bias: 109674250417.913940, T: 2048, Avg. loss: 924194891892258309836636160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 510879215005.80, NNZs: 2, Bias: 106989795951.315872, T: 2176, Avg. loss: 878517448339406742379036672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 485664063549.67, NNZs: 2, Bias: 124063849000.432587, T: 2304, Avg. loss: 913311223087953390583414784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 419139909129.29, NNZs: 2, Bias: 130112295423.381363, T: 2432, Avg. loss: 955752910710368819226869760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 540747980267.31, NNZs: 2, Bias: 114265941392.546005, T: 2560, Avg. loss: 910303228943134660753358848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 436140852464.86, NNZs: 2, Bias: 132834279713.430664, T: 2688, Avg. loss: 920340331847830599974780928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 365508219212.73, NNZs: 2, Bias: 132490075357.974976, T: 2816, Avg. loss: 895317886861793297390632960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 94709561422.87, NNZs: 2, Bias: 135003533219.391846, T: 2944, Avg. loss: 73749590083643719095943168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 66072500253.31, NNZs: 2, Bias: 134688951680.672836, T: 3072, Avg. loss: 35646988799368567917117440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 107821364680.59, NNZs: 2, Bias: 134939434739.049469, T: 3200, Avg. loss: 35302225179929233464492032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 75618020202.52, NNZs: 2, Bias: 135115669686.278748, T: 3328, Avg. loss: 36037638454243888839262208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 84903452565.29, NNZs: 2, Bias: 131807372238.780502, T: 3456, Avg. loss: 37445483409371916989890560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 87399899459.15, NNZs: 2, Bias: 132654353036.396698, T: 3584, Avg. loss: 33496475540088273384767488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 65628143037.93, NNZs: 2, Bias: 133659552771.856400, T: 3712, Avg. loss: 35254972137591573164589056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 78993271847.61, NNZs: 2, Bias: 131910931448.552109, T: 3840, Avg. loss: 38316473781833310949867520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 93723011768.72, NNZs: 2, Bias: 132544828170.487137, T: 3968, Avg. loss: 33931974245566545087430656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 87821065263.76, NNZs: 2, Bias: 131970174109.144363, T: 4096, Avg. loss: 35399350698334783602163712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 68923638701.87, NNZs: 2, Bias: 131873629646.151199, T: 4224, Avg. loss: 36808738165739124961574912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 14893816422.52, NNZs: 2, Bias: 131892506120.785645, T: 4352, Avg. loss: 2587001331691579141783552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 16481398151.51, NNZs: 2, Bias: 131618426535.320038, T: 4480, Avg. loss: 751083242791781374361600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 16447659265.58, NNZs: 2, Bias: 131355533476.642563, T: 4608, Avg. loss: 732996358529319685849088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 17774958494.15, NNZs: 2, Bias: 131176016333.341858, T: 4736, Avg. loss: 641205239783921473814528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 20966877457.50, NNZs: 2, Bias: 130989277248.966354, T: 4864, Avg. loss: 761771346137063008239616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 5917570461.96, NNZs: 2, Bias: 131539943444.048660, T: 4992, Avg. loss: 696820883982819648339968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 16813018670.98, NNZs: 2, Bias: 131265184603.001266, T: 5120, Avg. loss: 651208783580400854237184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 18530937715.89, NNZs: 2, Bias: 131074551347.620773, T: 5248, Avg. loss: 783391183101535459475456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6221149435.36, NNZs: 2, Bias: 131045278508.205688, T: 5376, Avg. loss: 692956653914061914767360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2870982773.06, NNZs: 2, Bias: 130992197999.820511, T: 5504, Avg. loss: 9367939362479706996736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2473927345.52, NNZs: 2, Bias: 130959388208.010132, T: 5632, Avg. loss: 1762507394376264581120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2304214575.20, NNZs: 2, Bias: 130924745529.515076, T: 5760, Avg. loss: 1523876853176893440000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2168593979.97, NNZs: 2, Bias: 130887468413.643555, T: 5888, Avg. loss: 1632098648198043140096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2083572670.79, NNZs: 2, Bias: 130850540333.201889, T: 6016, Avg. loss: 1552785946181312708608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2008264635.75, NNZs: 2, Bias: 130812055397.626434, T: 6144, Avg. loss: 1602126743138901950464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1947862565.04, NNZs: 2, Bias: 130775456459.220917, T: 6272, Avg. loss: 1505496440160275398656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1913619662.71, NNZs: 2, Bias: 130738408374.269806, T: 6400, Avg. loss: 1449191545411681648640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1935838597.30, NNZs: 2, Bias: 130701014768.403610, T: 6528, Avg. loss: 1429689989813971976192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1913878775.33, NNZs: 2, Bias: 130662733316.091553, T: 6656, Avg. loss: 1570880348114673467392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1918611463.88, NNZs: 2, Bias: 130624937311.996292, T: 6784, Avg. loss: 1515513368817462411264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1974607147.48, NNZs: 2, Bias: 130586304580.882935, T: 6912, Avg. loss: 1543106414656795443200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1907469057.41, NNZs: 2, Bias: 130551501885.497787, T: 7040, Avg. loss: 1431819773074739298304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1947827662.88, NNZs: 2, Bias: 130513036841.721893, T: 7168, Avg. loss: 1457797123983402336256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1936095914.66, NNZs: 2, Bias: 130505593636.766769, T: 7296, Avg. loss: 1251997645541643649024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1953075382.80, NNZs: 2, Bias: 130497740334.814407, T: 7424, Avg. loss: 1248776550928594763776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1951207512.98, NNZs: 2, Bias: 130490155966.199661, T: 7552, Avg. loss: 1250679549372228960256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1938958051.39, NNZs: 2, Bias: 130482705907.561600, T: 7680, Avg. loss: 1256756104825610960896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1935867573.05, NNZs: 2, Bias: 130475154825.489960, T: 7808, Avg. loss: 1249206434402624602112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1922971666.43, NNZs: 2, Bias: 130467766910.402664, T: 7936, Avg. loss: 1247847656341287469056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1918901175.72, NNZs: 2, Bias: 130460217237.396393, T: 8064, Avg. loss: 1253953628385163083776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1919406165.18, NNZs: 2, Bias: 130452584021.271057, T: 8192, Avg. loss: 1255039629106854494208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1923268732.04, NNZs: 2, Bias: 130444987741.182373, T: 8320, Avg. loss: 1238351153978973093888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1910195181.75, NNZs: 2, Bias: 130437553629.621445, T: 8448, Avg. loss: 1256360698108751642624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1930935201.01, NNZs: 2, Bias: 130429578821.925827, T: 8576, Avg. loss: 1260821765158501351424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1941892414.59, NNZs: 2, Bias: 130421786027.649063, T: 8704, Avg. loss: 1255276385474467332096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1918746499.98, NNZs: 2, Bias: 130414486125.565628, T: 8832, Avg. loss: 1257315088239972581376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1933083838.78, NNZs: 2, Bias: 130406706656.719437, T: 8960, Avg. loss: 1243805914831426420736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1924189905.51, NNZs: 2, Bias: 130405323538.575684, T: 9088, Avg. loss: 1213258874641557225472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1928045065.24, NNZs: 2, Bias: 130403757424.629211, T: 9216, Avg. loss: 1208220272956041330688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1927060532.65, NNZs: 2, Bias: 130402254875.190475, T: 9344, Avg. loss: 1214858812912106471424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1937113432.63, NNZs: 2, Bias: 130400601366.493744, T: 9472, Avg. loss: 1204271746573381664768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1931807654.74, NNZs: 2, Bias: 130399165207.526764, T: 9600, Avg. loss: 1213009527950433320960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1928601867.71, NNZs: 2, Bias: 130397696376.375412, T: 9728, Avg. loss: 1214236292135356989440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1925326092.77, NNZs: 2, Bias: 130396227852.886612, T: 9856, Avg. loss: 1214760247232193101824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1929307768.64, NNZs: 2, Bias: 130394654077.070511, T: 9984, Avg. loss: 1212988222780619096064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1921260913.23, NNZs: 2, Bias: 130393266482.813065, T: 10112, Avg. loss: 1206272167429046272000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 79 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1350498453245.32, NNZs: 2, Bias: -18935833346.214233, T: 128, Avg. loss: 18512747595720061948853747712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2177169640385.79, NNZs: 2, Bias: 41064166653.785767, T: 256, Avg. loss: 20219506948890628140650463232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2506883182078.34, NNZs: 2, Bias: 21064166653.785767, T: 384, Avg. loss: 20277575302903792786294702080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 581243665346.16, NNZs: 2, Bias: 36205241619.241241, T: 512, Avg. loss: 23814213812564488685814284288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1161950082369.98, NNZs: 2, Bias: -20668180278.647934, T: 640, Avg. loss: 21422290000476072194099642368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1462815592312.90, NNZs: 2, Bias: -69435391434.706802, T: 768, Avg. loss: 20758483143826231266688106496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 176795667049.85, NNZs: 2, Bias: -66668669593.029480, T: 896, Avg. loss: 1041487226832803023613329408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 227665292877.97, NNZs: 2, Bias: -64337710481.590408, T: 1024, Avg. loss: 870752799884025050219675648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 446207846620.93, NNZs: 2, Bias: -59776593550.973969, T: 1152, Avg. loss: 839199420358793350201999360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 299569848322.85, NNZs: 2, Bias: -53065893041.880760, T: 1280, Avg. loss: 769333741811576922615840768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 287312575716.12, NNZs: 2, Bias: -63047824503.013779, T: 1408, Avg. loss: 810362706839222866380062720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 378714836976.16, NNZs: 2, Bias: -76496435208.711365, T: 1536, Avg. loss: 833660021030423385528598528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 26694634809.27, NNZs: 2, Bias: -93330732273.875656, T: 1664, Avg. loss: 860511607409836249919258624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 190864591333.67, NNZs: 2, Bias: -101107011821.222229, T: 1792, Avg. loss: 881769746553157227850498048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 50798507864.70, NNZs: 2, Bias: -93807498516.853149, T: 1920, Avg. loss: 867230896608060063034114048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 75916417082.55, NNZs: 2, Bias: -96859229053.416885, T: 2048, Avg. loss: 26616359359681182440620032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 38257542202.40, NNZs: 2, Bias: -93898003652.157990, T: 2176, Avg. loss: 33829990909340813864468480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 80561301765.43, NNZs: 2, Bias: -90784267250.858215, T: 2304, Avg. loss: 27959289683153203465551872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 31924360015.29, NNZs: 2, Bias: -89906925694.742462, T: 2432, Avg. loss: 30465783010292295454949376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 34960836961.05, NNZs: 2, Bias: -90654608600.648636, T: 2560, Avg. loss: 26688933346075920329342976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 87480090198.84, NNZs: 2, Bias: -89858890928.645157, T: 2688, Avg. loss: 31762909614869641867296768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 6997987223.09, NNZs: 2, Bias: -90193279035.945816, T: 2816, Avg. loss: 3341485174166583301373952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 11974452607.39, NNZs: 2, Bias: -90146415792.276627, T: 2944, Avg. loss: 653583540327528609611776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 7839236187.23, NNZs: 2, Bias: -89637715382.307449, T: 3072, Avg. loss: 696234477452973117014016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 13513941820.12, NNZs: 2, Bias: -89466363870.820709, T: 3200, Avg. loss: 604499324723575612506112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2195301533.63, NNZs: 2, Bias: -89465916730.531006, T: 3328, Avg. loss: 708604539153080412798976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 5878029282.12, NNZs: 2, Bias: -89039752848.821732, T: 3456, Avg. loss: 459125858757419730993152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4511644197.99, NNZs: 2, Bias: -88559163132.212448, T: 3584, Avg. loss: 600985307567145317564416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 5445569177.57, NNZs: 2, Bias: -88569588151.738647, T: 3712, Avg. loss: 553042368119557471600640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3324861526.45, NNZs: 2, Bias: -88776945224.545227, T: 3840, Avg. loss: 768816790900508020703232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6200671024.01, NNZs: 2, Bias: -88666404016.945572, T: 3968, Avg. loss: 628653077936886008250368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3412301903.32, NNZs: 2, Bias: -88560241906.103729, T: 4096, Avg. loss: 559177061247058282807296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2488025342.11, NNZs: 2, Bias: -88541017214.498764, T: 4224, Avg. loss: 1443962329200273129472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2030977193.76, NNZs: 2, Bias: -88519730925.393051, T: 4352, Avg. loss: 920482907909935988736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1692278624.32, NNZs: 2, Bias: -88494345634.225037, T: 4480, Avg. loss: 899568514967801430016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1582674626.06, NNZs: 2, Bias: -88465286529.504074, T: 4608, Avg. loss: 871617337267469418496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1535697416.02, NNZs: 2, Bias: -88435560625.460403, T: 4736, Avg. loss: 820237735778690662400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1452447849.65, NNZs: 2, Bias: -88404342515.950546, T: 4864, Avg. loss: 933338722807613227008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1522611579.96, NNZs: 2, Bias: -88373058068.390091, T: 4992, Avg. loss: 805037677822857838592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1481983986.49, NNZs: 2, Bias: -88342385267.649567, T: 5120, Avg. loss: 875929346442906173440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1445410798.94, NNZs: 2, Bias: -88313210177.418091, T: 5248, Avg. loss: 796030373050955595776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1419983011.19, NNZs: 2, Bias: -88282499238.203842, T: 5376, Avg. loss: 847140066936171790336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1487957735.64, NNZs: 2, Bias: -88251345011.974503, T: 5504, Avg. loss: 800899124759122673664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1471703125.05, NNZs: 2, Bias: -88220361616.866150, T: 5632, Avg. loss: 863381761149311647744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1439541132.38, NNZs: 2, Bias: -88190688949.704834, T: 5760, Avg. loss: 814676929741944782848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1373815825.19, NNZs: 2, Bias: -88161751905.793320, T: 5888, Avg. loss: 797387745832007761920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1427884362.52, NNZs: 2, Bias: -88154395924.708450, T: 6016, Avg. loss: 719901569567636193280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1421492922.58, NNZs: 2, Bias: -88148371627.858093, T: 6144, Avg. loss: 682095630733474398208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1403255552.27, NNZs: 2, Bias: -88142525494.095398, T: 6272, Avg. loss: 681303818724227153920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1416459366.95, NNZs: 2, Bias: -88136096588.930359, T: 6400, Avg. loss: 690813574148443734016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1411863601.97, NNZs: 2, Bias: -88129974367.220276, T: 6528, Avg. loss: 689564221994085253120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1431059591.42, NNZs: 2, Bias: -88123525939.602341, T: 6656, Avg. loss: 681111084772958404608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1428776140.71, NNZs: 2, Bias: -88117336082.102432, T: 6784, Avg. loss: 690842509810167185408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1407910687.76, NNZs: 2, Bias: -88111431247.582535, T: 6912, Avg. loss: 694001840225759657984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1409778098.80, NNZs: 2, Bias: -88105132390.534775, T: 7040, Avg. loss: 695606299975519698944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1414361062.73, NNZs: 2, Bias: -88098789692.125198, T: 7168, Avg. loss: 695890180407758159872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1408771412.41, NNZs: 2, Bias: -88092650979.184525, T: 7296, Avg. loss: 692686048038718013440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1419307497.52, NNZs: 2, Bias: -88091241985.283203, T: 7424, Avg. loss: 670187755230753456128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1416484891.01, NNZs: 2, Bias: -88090054875.629333, T: 7552, Avg. loss: 666638494641909268480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1420024641.38, NNZs: 2, Bias: -88088761116.385239, T: 7680, Avg. loss: 668832765748296286208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1415497675.86, NNZs: 2, Bias: -88087606448.898819, T: 7808, Avg. loss: 663963658653226106880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1417496809.06, NNZs: 2, Bias: -88086336819.964447, T: 7936, Avg. loss: 669210698294203252736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1415982527.36, NNZs: 2, Bias: -88085123109.568466, T: 8064, Avg. loss: 669631514787892297728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1422327712.44, NNZs: 2, Bias: -88083786983.386978, T: 8192, Avg. loss: 667117762587840610304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1423339639.18, NNZs: 2, Bias: -88082535537.091629, T: 8320, Avg. loss: 667926431531266998272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1418521006.87, NNZs: 2, Bias: -88081373297.277283, T: 8448, Avg. loss: 670786664491836375040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 66 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2317474234359.69, NNZs: 2, Bias: -71356201538.749176, T: 128, Avg. loss: 19419549328397138134065741824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2479312254419.07, NNZs: 2, Bias: -51356201538.749176, T: 256, Avg. loss: 22144671829091465837945028608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1318843657312.91, NNZs: 2, Bias: -29724504168.216965, T: 384, Avg. loss: 21311091461142355384534564864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1144539442466.79, NNZs: 2, Bias: -49724504168.216965, T: 512, Avg. loss: 19893825999462561052180348928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1185883839432.01, NNZs: 2, Bias: -129724504168.216980, T: 640, Avg. loss: 21152334349367754572055969792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1469781772966.70, NNZs: 2, Bias: -89724504168.216980, T: 768, Avg. loss: 19256428538114762057858416640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2571178803850.32, NNZs: 2, Bias: -48554990462.657379, T: 896, Avg. loss: 20663715292932631335754792960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1696287900462.19, NNZs: 2, Bias: -185340893363.496185, T: 1024, Avg. loss: 17170659094087202078780817408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 388886756873.06, NNZs: 2, Bias: -45340893363.496185, T: 1152, Avg. loss: 21647196612305124872465416192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1746265685691.07, NNZs: 2, Bias: -10975579606.510864, T: 1280, Avg. loss: 22055365721803959181147897856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 710385999107.42, NNZs: 2, Bias: 65083916965.604889, T: 1408, Avg. loss: 17856062783194101157149540352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2266928719502.66, NNZs: 2, Bias: 60277746363.783760, T: 1536, Avg. loss: 19310822665202531910843105280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2036303514682.52, NNZs: 2, Bias: 40277746363.783760, T: 1664, Avg. loss: 20911955859872075061020065792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 444644844662.08, NNZs: 2, Bias: 39196509207.072083, T: 1792, Avg. loss: 2258950220151767917557448704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 342005379191.50, NNZs: 2, Bias: 48369600171.547325, T: 1920, Avg. loss: 772625817293851048475099136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 441467119676.16, NNZs: 2, Bias: 40523899487.742004, T: 2048, Avg. loss: 795500043584561718134571008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 150088635699.90, NNZs: 2, Bias: 39490268319.198364, T: 2176, Avg. loss: 800830733426527201222721536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 230341083746.20, NNZs: 2, Bias: 25919783757.022938, T: 2304, Avg. loss: 725061390841006892020400128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 519820035225.03, NNZs: 2, Bias: 19151629456.513046, T: 2432, Avg. loss: 729677628236795583662129152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 530833555942.55, NNZs: 2, Bias: 24467345227.475670, T: 2560, Avg. loss: 778113060480975598629421056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 73500303203.38, NNZs: 2, Bias: 4845697535.424781, T: 2688, Avg. loss: 757999860158150612191543296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 419041552147.78, NNZs: 2, Bias: 7841422338.180527, T: 2816, Avg. loss: 885882530711279263998279680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 200272902325.38, NNZs: 2, Bias: 10912065062.204386, T: 2944, Avg. loss: 785319236914755357118562304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 46014869355.34, NNZs: 2, Bias: 6431617220.681699, T: 3072, Avg. loss: 31294124988539541622095872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 108816107155.78, NNZs: 2, Bias: 5712793716.467256, T: 3200, Avg. loss: 27547305540499420211052544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 40724897929.64, NNZs: 2, Bias: 3318202690.901942, T: 3328, Avg. loss: 31332531478861643092328448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 69171390166.11, NNZs: 2, Bias: 1838453888.791174, T: 3456, Avg. loss: 27244574223432546045132800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 91202914292.94, NNZs: 2, Bias: 1871534784.487641, T: 3584, Avg. loss: 31889450258185220893179904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 5533615019.10, NNZs: 2, Bias: 4258207862.735225, T: 3712, Avg. loss: 31580205427054512737091584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 99437712421.59, NNZs: 2, Bias: 1247407454.969031, T: 3840, Avg. loss: 30811578943704245622276096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 54623176085.60, NNZs: 2, Bias: 2487014819.375436, T: 3968, Avg. loss: 32419672257756333781024768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 90953390491.55, NNZs: 2, Bias: -104192240.321771, T: 4096, Avg. loss: 31192493910908503490297856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 10743197339.98, NNZs: 2, Bias: 1498615997.990685, T: 4224, Avg. loss: 1766821682505921373143040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4377224444.64, NNZs: 2, Bias: 1800800868.431433, T: 4352, Avg. loss: 536737253869028615651328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3427308018.49, NNZs: 2, Bias: 2064579762.741344, T: 4480, Avg. loss: 437100292267878576553984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 313053033.60, NNZs: 2, Bias: 1888274055.735098, T: 4608, Avg. loss: 603839944624086940909568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5991446641.00, NNZs: 2, Bias: 1783882841.900764, T: 4736, Avg. loss: 355407825758668869074944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1178182652.14, NNZs: 2, Bias: 1918609911.200572, T: 4864, Avg. loss: 410908239865188945231872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4544133323.06, NNZs: 2, Bias: 1978423158.477689, T: 4992, Avg. loss: 164169039130307667689472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 8630808658.24, NNZs: 2, Bias: 1812613323.053504, T: 5120, Avg. loss: 491771358155439687598080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1707062245.15, NNZs: 2, Bias: 1460665462.046657, T: 5248, Avg. loss: 521009533223579028553728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 18974886848.04, NNZs: 2, Bias: 1798386618.521728, T: 5376, Avg. loss: 331026282269180906438656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9821599920.14, NNZs: 2, Bias: 1642427859.461065, T: 5504, Avg. loss: 432904856190361492520960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4893658244.56, NNZs: 2, Bias: 1435345825.640428, T: 5632, Avg. loss: 580146514474033794252800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2137524691.92, NNZs: 2, Bias: 1479877276.441538, T: 5760, Avg. loss: 3206790838235655307264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1070795512.13, NNZs: 2, Bias: 1493539665.121095, T: 5888, Avg. loss: 539755797365046378496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 528091353.55, NNZs: 2, Bias: 1501170562.485613, T: 6016, Avg. loss: 134431586050830188544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 274685782.16, NNZs: 2, Bias: 1504620393.626150, T: 6144, Avg. loss: 30279261919234818048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 152487385.56, NNZs: 2, Bias: 1506201657.610105, T: 6272, Avg. loss: 7405180638094205952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 87852589.45, NNZs: 2, Bias: 1506631711.741892, T: 6400, Avg. loss: 2373916510506597888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 56382795.23, NNZs: 2, Bias: 1506552832.182050, T: 6528, Avg. loss: 818094356612669824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 39524896.21, NNZs: 2, Bias: 1506332698.937592, T: 6656, Avg. loss: 396814036465595072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 32052343.24, NNZs: 2, Bias: 1505903990.246525, T: 6784, Avg. loss: 289845469337171008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 28615796.39, NNZs: 2, Bias: 1505441204.519779, T: 6912, Avg. loss: 248900057149694400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 26873180.36, NNZs: 2, Bias: 1504967690.492788, T: 7040, Avg. loss: 231223194281104416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 25020669.46, NNZs: 2, Bias: 1504487167.399764, T: 7168, Avg. loss: 237625442622235520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 25941155.14, NNZs: 2, Bias: 1503955033.685992, T: 7296, Avg. loss: 236957913598789984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 23594824.85, NNZs: 2, Bias: 1503484738.665075, T: 7424, Avg. loss: 241161258398338368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 23984239.47, NNZs: 2, Bias: 1502971227.866750, T: 7552, Avg. loss: 246260945080978016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 23545983.31, NNZs: 2, Bias: 1502450607.875861, T: 7680, Avg. loss: 248732824575452640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 23952882.17, NNZs: 2, Bias: 1502342886.066688, T: 7808, Avg. loss: 191832393500274592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 23765518.61, NNZs: 2, Bias: 1502243908.615465, T: 7936, Avg. loss: 193340788597828160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 23657205.85, NNZs: 2, Bias: 1502143556.220503, T: 8064, Avg. loss: 193845996661219008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 23878610.15, NNZs: 2, Bias: 1502037944.782875, T: 8192, Avg. loss: 193802451750311232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 24024000.09, NNZs: 2, Bias: 1501932832.766824, T: 8320, Avg. loss: 195099318438439840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 23989985.10, NNZs: 2, Bias: 1501832602.090026, T: 8448, Avg. loss: 191402862989181216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 24225411.01, NNZs: 2, Bias: 1501726970.463226, T: 8576, Avg. loss: 193176914458814528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 23953212.03, NNZs: 2, Bias: 1501631469.206514, T: 8704, Avg. loss: 189771363770243232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 24539851.19, NNZs: 2, Bias: 1501520521.311813, T: 8832, Avg. loss: 192146304015538880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 23919811.67, NNZs: 2, Bias: 1501429478.942955, T: 8960, Avg. loss: 192129198064491328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 24168250.18, NNZs: 2, Bias: 1501325106.203881, T: 9088, Avg. loss: 189877719529548672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 24152317.24, NNZs: 2, Bias: 1501223567.377014, T: 9216, Avg. loss: 193438208490681568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 24139171.92, NNZs: 2, Bias: 1501122224.517273, T: 9344, Avg. loss: 192445448245975040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 24101017.98, NNZs: 2, Bias: 1501102593.361166, T: 9472, Avg. loss: 186727932058414400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 24119521.91, NNZs: 2, Bias: 1501082048.920896, T: 9600, Avg. loss: 186714832176219008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 24078774.80, NNZs: 2, Bias: 1501062471.749968, T: 9728, Avg. loss: 186594719990794432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 24117598.46, NNZs: 2, Bias: 1501041616.156984, T: 9856, Avg. loss: 186552444324340928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 24086848.50, NNZs: 2, Bias: 1501021890.139497, T: 9984, Avg. loss: 186485120320100768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 24137935.32, NNZs: 2, Bias: 1501000839.884621, T: 10112, Avg. loss: 186514599524751232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 24116942.44, NNZs: 2, Bias: 1500980926.307019, T: 10240, Avg. loss: 186752314936879936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 24151607.97, NNZs: 2, Bias: 1500960158.313925, T: 10368, Avg. loss: 186373572278232800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 24064308.68, NNZs: 2, Bias: 1500941441.210884, T: 10496, Avg. loss: 185585511428730208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 24100138.20, NNZs: 2, Bias: 1500920680.208940, T: 10624, Avg. loss: 186088585035141952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 24129377.93, NNZs: 2, Bias: 1500899972.945445, T: 10752, Avg. loss: 186602635883577984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 24117006.64, NNZs: 2, Bias: 1500879923.798240, T: 10880, Avg. loss: 186708378030168480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 24093575.02, NNZs: 2, Bias: 1500860073.295969, T: 11008, Avg. loss: 186514140981064576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 24179920.50, NNZs: 2, Bias: 1500838488.183427, T: 11136, Avg. loss: 186171562576561216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 87 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 959697452065.30, NNZs: 2, Bias: 73512854499.140228, T: 128, Avg. loss: 17945754424273312676277387264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1827353582170.36, NNZs: 2, Bias: 24241884108.279510, T: 256, Avg. loss: 21105865350858123014714687488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2401578101180.33, NNZs: 2, Bias: -15758115891.720490, T: 384, Avg. loss: 21232595341290098947474325504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1155580489631.02, NNZs: 2, Bias: -72018268771.472565, T: 512, Avg. loss: 21914803322836703018267705344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1263547773345.72, NNZs: 2, Bias: -100868433758.771484, T: 640, Avg. loss: 19830892303517967781495570432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 252334662478.45, NNZs: 2, Bias: -100868433758.771484, T: 768, Avg. loss: 20432646444185612234759602176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 220984198254.07, NNZs: 2, Bias: -104955684078.689911, T: 896, Avg. loss: 846412303577301606121603072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 44686792074.06, NNZs: 2, Bias: -124284868828.017639, T: 1024, Avg. loss: 825108799101328392261206016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 368053271377.07, NNZs: 2, Bias: -123785190818.233093, T: 1152, Avg. loss: 810389332875285989066539008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 286661363886.72, NNZs: 2, Bias: -110651309350.673157, T: 1280, Avg. loss: 785499060049131029112291328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 153738263139.70, NNZs: 2, Bias: -126153184872.079941, T: 1408, Avg. loss: 852921803074376327422279680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 296446298227.44, NNZs: 2, Bias: -133974958218.314957, T: 1536, Avg. loss: 810530878975941852065169408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 328838141513.83, NNZs: 2, Bias: -124612457948.996368, T: 1664, Avg. loss: 855021390688213804244795392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 412349116194.78, NNZs: 2, Bias: -133037624883.794724, T: 1792, Avg. loss: 774878472381345323246682112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 287582202057.91, NNZs: 2, Bias: -134977966210.190430, T: 1920, Avg. loss: 780415684462669623807967232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 482317031089.30, NNZs: 2, Bias: -140450841382.811401, T: 2048, Avg. loss: 772464268689437976120262656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 174807754234.07, NNZs: 2, Bias: -134774799385.363403, T: 2176, Avg. loss: 791599603063030175554863104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 359695103472.27, NNZs: 2, Bias: -130487692060.376129, T: 2304, Avg. loss: 811520071079819816814510080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 448954039189.64, NNZs: 2, Bias: -134842671705.668137, T: 2432, Avg. loss: 749478408539147276826705920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 229165604809.94, NNZs: 2, Bias: -142935726112.574799, T: 2560, Avg. loss: 784232848932399151998566400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 79875814968.95, NNZs: 2, Bias: -133000733790.254272, T: 2688, Avg. loss: 909258480497794367973490688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 266459915554.96, NNZs: 2, Bias: -122741676060.743469, T: 2816, Avg. loss: 824894042751670304750174208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 192965114153.85, NNZs: 2, Bias: -122808841809.009125, T: 2944, Avg. loss: 744836601233006945550467072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 220230057131.32, NNZs: 2, Bias: -143405337168.897644, T: 3072, Avg. loss: 796217158441398686860705792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 152344420085.38, NNZs: 2, Bias: -129198684455.097198, T: 3200, Avg. loss: 849062837677638769436524544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 146981164951.57, NNZs: 2, Bias: -137360698499.452423, T: 3328, Avg. loss: 849437386110385081764806656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 158363746958.93, NNZs: 2, Bias: -140802738344.466827, T: 3456, Avg. loss: 796401893045434701368524800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 124516634268.97, NNZs: 2, Bias: -140170521592.985077, T: 3584, Avg. loss: 798726306288961004626771968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 27703472345.59, NNZs: 2, Bias: -138632503725.713562, T: 3712, Avg. loss: 35124418153666554691059712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 94701697979.70, NNZs: 2, Bias: -136130861357.118210, T: 3840, Avg. loss: 28965758906198094264664064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 55953431050.30, NNZs: 2, Bias: -133532235588.599075, T: 3968, Avg. loss: 36873471147570902444539904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 53485931515.27, NNZs: 2, Bias: -134846830608.448120, T: 4096, Avg. loss: 28541524901674934188638208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 43642944264.13, NNZs: 2, Bias: -134049258615.003830, T: 4224, Avg. loss: 31427449925159404296994816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 82870247003.77, NNZs: 2, Bias: -136912350167.852310, T: 4352, Avg. loss: 32024768684989305227051008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 106494813803.65, NNZs: 2, Bias: -135059977081.948563, T: 4480, Avg. loss: 30994769971579261844193280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 107668983913.33, NNZs: 2, Bias: -139462538319.002411, T: 4608, Avg. loss: 32266837913093186225438720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 21608893188.45, NNZs: 2, Bias: -140629782410.714661, T: 4736, Avg. loss: 30485374446148527467790336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7748850892.56, NNZs: 2, Bias: -140881573324.021149, T: 4864, Avg. loss: 684173607780617340059648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 622787576.99, NNZs: 2, Bias: -140518100443.397156, T: 4992, Avg. loss: 671457375523042767142912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1974683257.13, NNZs: 2, Bias: -140247093528.313507, T: 5120, Avg. loss: 654729471187464556118016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2371090190.17, NNZs: 2, Bias: -140172734620.760681, T: 5248, Avg. loss: 732245806307797805039616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2291536127.43, NNZs: 2, Bias: -139855738821.018402, T: 5376, Avg. loss: 600396343170556445589504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 13953824622.86, NNZs: 2, Bias: -139465737408.773834, T: 5504, Avg. loss: 533665904920568075911168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5106193767.70, NNZs: 2, Bias: -139384390009.885437, T: 5632, Avg. loss: 494076197853784415666176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 14363066681.94, NNZs: 2, Bias: -139363970937.415283, T: 5760, Avg. loss: 509080048562931018760192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3305556879.69, NNZs: 2, Bias: -139149796000.780090, T: 5888, Avg. loss: 405702295360723363037184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2525893638.23, NNZs: 2, Bias: -138961831787.316956, T: 6016, Avg. loss: 545040451969722347421696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 11480810653.97, NNZs: 2, Bias: -139002110662.953796, T: 6144, Avg. loss: 465865076111550963515392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2070506657.38, NNZs: 2, Bias: -139215072431.824768, T: 6272, Avg. loss: 618582142336084920500224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 5647145196.95, NNZs: 2, Bias: -138711943383.895020, T: 6400, Avg. loss: 541057531315481972047872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4221119373.84, NNZs: 2, Bias: -138736311330.894196, T: 6528, Avg. loss: 570854866164640938721280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1224817798.11, NNZs: 2, Bias: -138694129082.128784, T: 6656, Avg. loss: 4322671789195517755392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1800964900.48, NNZs: 2, Bias: -138639848703.991852, T: 6784, Avg. loss: 1886498114371764617216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2115600222.11, NNZs: 2, Bias: -138589383808.598633, T: 6912, Avg. loss: 1899813399003019083776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2277424447.82, NNZs: 2, Bias: -138541157479.315125, T: 7040, Avg. loss: 1930363766092670697472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2258326401.27, NNZs: 2, Bias: -138497956194.173187, T: 7168, Avg. loss: 1789167589461194964992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2324459781.33, NNZs: 2, Bias: -138452962017.944275, T: 7296, Avg. loss: 1810512569288371994624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2454234889.73, NNZs: 2, Bias: -138407027591.235260, T: 7424, Avg. loss: 1858833429757014573056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2416143487.46, NNZs: 2, Bias: -138365574170.342010, T: 7552, Avg. loss: 1769462516199930724352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2463373568.06, NNZs: 2, Bias: -138319225144.237427, T: 7680, Avg. loss: 1934261319507725254656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2377149388.70, NNZs: 2, Bias: -138276082760.971497, T: 7808, Avg. loss: 1951405795300608573440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2447031073.85, NNZs: 2, Bias: -138229828709.961792, T: 7936, Avg. loss: 1921709379078934757376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2381612075.03, NNZs: 2, Bias: -138186393148.305695, T: 8064, Avg. loss: 1931534745604257218560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2342118301.48, NNZs: 2, Bias: -138142067396.033966, T: 8192, Avg. loss: 1888494070628030349312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2399325182.40, NNZs: 2, Bias: -138132539443.315857, T: 8320, Avg. loss: 1487251593168886169600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2374608172.97, NNZs: 2, Bias: -138124441883.282104, T: 8448, Avg. loss: 1486129944230063505408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2377866216.22, NNZs: 2, Bias: -138115736070.912292, T: 8576, Avg. loss: 1508539595882548953088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2401840311.80, NNZs: 2, Bias: -138106614763.230469, T: 8704, Avg. loss: 1515653467159656398848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2380070792.17, NNZs: 2, Bias: -138098322504.296082, T: 8832, Avg. loss: 1511468057449286074368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2400090764.55, NNZs: 2, Bias: -138089455415.401947, T: 8960, Avg. loss: 1479294724563347177472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2363358936.62, NNZs: 2, Bias: -138081622052.568726, T: 9088, Avg. loss: 1475856516176509140992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2386984937.25, NNZs: 2, Bias: -138072614596.834656, T: 9216, Avg. loss: 1498482976984176001024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2402575505.39, NNZs: 2, Bias: -138063690878.837402, T: 9344, Avg. loss: 1506594981502722768896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2421695137.07, NNZs: 2, Bias: -138054773651.169373, T: 9472, Avg. loss: 1492466734835338575872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2374325243.34, NNZs: 2, Bias: -138047161209.751038, T: 9600, Avg. loss: 1473722475459321266176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2423035399.80, NNZs: 2, Bias: -138037606873.744049, T: 9728, Avg. loss: 1514441294758260506624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2378034150.77, NNZs: 2, Bias: -138029837903.316833, T: 9856, Avg. loss: 1489142662116354818048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2406333032.79, NNZs: 2, Bias: -138020701546.872467, T: 9984, Avg. loss: 1506540014896878977024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2379338992.31, NNZs: 2, Bias: -138012540837.474060, T: 10112, Avg. loss: 1505051257655891853312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2423727900.17, NNZs: 2, Bias: -138003176969.754822, T: 10240, Avg. loss: 1493920161117604675584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 2400783380.59, NNZs: 2, Bias: -138001823911.657959, T: 10368, Avg. loss: 1488154060468835319808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 2395420250.95, NNZs: 2, Bias: -138000191942.500610, T: 10496, Avg. loss: 1462434934854367051776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 2408455263.21, NNZs: 2, Bias: -137998255517.798615, T: 10624, Avg. loss: 1448050990192797679616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 2394528295.65, NNZs: 2, Bias: -137996775857.732544, T: 10752, Avg. loss: 1460199157584751755264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 2400640764.25, NNZs: 2, Bias: -137994940437.539673, T: 10880, Avg. loss: 1465271770912908115968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 2396509616.16, NNZs: 2, Bias: -137993289377.519897, T: 11008, Avg. loss: 1460525068181511602176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 2397575458.12, NNZs: 2, Bias: -137991542465.062164, T: 11136, Avg. loss: 1464841587608963776512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 2397035143.02, NNZs: 2, Bias: -137989824904.341125, T: 11264, Avg. loss: 1463677198511357034496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 88 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1813576563411.29, NNZs: 2, Bias: 85944611171.164215, T: 128, Avg. loss: 23282766984117713887790366720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1382225210067.92, NNZs: 2, Bias: 65944611171.164215, T: 256, Avg. loss: 24337386705333354744185356288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1156220167597.94, NNZs: 2, Bias: 65944611171.164215, T: 384, Avg. loss: 22436979499485300433132453888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2522904134994.37, NNZs: 2, Bias: 65944611171.164215, T: 512, Avg. loss: 22705312547207298991813296128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 748085696625.01, NNZs: 2, Bias: 48124410423.778732, T: 640, Avg. loss: 23574023443860988035562733568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 356003301403.94, NNZs: 2, Bias: 62503927762.111603, T: 768, Avg. loss: 23421973952130330163064864768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1659596232680.04, NNZs: 2, Bias: 119424236154.277924, T: 896, Avg. loss: 20509066419831641691815673856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1273789503922.10, NNZs: 2, Bias: 172546625722.434875, T: 1024, Avg. loss: 20442550051634097217351974912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 936708780956.09, NNZs: 2, Bias: 191022899364.482513, T: 1152, Avg. loss: 21191377067147383263859834880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2028948337271.68, NNZs: 2, Bias: 285835873697.784180, T: 1280, Avg. loss: 21166642641370111952558227456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1033275085650.60, NNZs: 2, Bias: 346773928779.949585, T: 1408, Avg. loss: 21804785864948828638959108096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1464429470668.77, NNZs: 2, Bias: 325785259714.236755, T: 1536, Avg. loss: 23476934169175557011817889792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1017706527134.13, NNZs: 2, Bias: 336396459069.467834, T: 1664, Avg. loss: 23926323901952652087721459712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 254651960131.36, NNZs: 2, Bias: 301295840325.643982, T: 1792, Avg. loss: 966083452907520644328980480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 378551067823.59, NNZs: 2, Bias: 308486736171.782593, T: 1920, Avg. loss: 818390043506363678907695104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 65200135753.89, NNZs: 2, Bias: 306983859348.175171, T: 2048, Avg. loss: 1022854753113253903425601536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 180484650558.28, NNZs: 2, Bias: 311442052504.725403, T: 2176, Avg. loss: 858887630699263273702785024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 262802899330.89, NNZs: 2, Bias: 314855460997.572021, T: 2304, Avg. loss: 900110230551031831213375488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 449379110494.42, NNZs: 2, Bias: 297305186784.397217, T: 2432, Avg. loss: 908775043676232322358706176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 164785369206.25, NNZs: 2, Bias: 299045230085.772949, T: 2560, Avg. loss: 934599514610926269723836416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 103912446973.23, NNZs: 2, Bias: 302858459815.795227, T: 2688, Avg. loss: 35979486526312301155319808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 18549474296.76, NNZs: 2, Bias: 301021989835.553528, T: 2816, Avg. loss: 33468656416062494184833024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 64656245580.80, NNZs: 2, Bias: 300033628199.742920, T: 2944, Avg. loss: 31628333483444141509574656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 48435920299.72, NNZs: 2, Bias: 298877734993.882080, T: 3072, Avg. loss: 31882889651066701625688064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 65200867358.28, NNZs: 2, Bias: 296867410083.757263, T: 3200, Avg. loss: 34280101168627795139493888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 83774063867.37, NNZs: 2, Bias: 296115081233.210571, T: 3328, Avg. loss: 36512949458107197202366464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 44346391001.88, NNZs: 2, Bias: 292745959574.740295, T: 3456, Avg. loss: 34790434616463969598046208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 64762135871.82, NNZs: 2, Bias: 291636745890.304749, T: 3584, Avg. loss: 31231849728409464591089664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 13772594946.36, NNZs: 2, Bias: 292362710291.970520, T: 3712, Avg. loss: 37507618299482884395761664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 52593554619.08, NNZs: 2, Bias: 290613115173.260193, T: 3840, Avg. loss: 32764284426460032156041216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 21714915687.53, NNZs: 2, Bias: 291834670383.347290, T: 3968, Avg. loss: 33440689508167186399625216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9790469464.32, NNZs: 2, Bias: 293114908775.403442, T: 4096, Avg. loss: 35263213586957811295715328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 40530361806.72, NNZs: 2, Bias: 295545397741.961426, T: 4224, Avg. loss: 35699807634084745581690880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4524009302.88, NNZs: 2, Bias: 294254059298.405518, T: 4352, Avg. loss: 1073552639461401361907712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3869544603.14, NNZs: 2, Bias: 294053898318.616272, T: 4480, Avg. loss: 682609755099652358668288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3924026829.66, NNZs: 2, Bias: 293452532273.329956, T: 4608, Avg. loss: 900098874510276265246720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9793079411.32, NNZs: 2, Bias: 293014592860.276489, T: 4736, Avg. loss: 565171751761433726025728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 12000013591.20, NNZs: 2, Bias: 292821542828.043518, T: 4864, Avg. loss: 776862785323835762671616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 17596263500.15, NNZs: 2, Bias: 291958203993.615723, T: 4992, Avg. loss: 824487471794962686803968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 5978725638.28, NNZs: 2, Bias: 291539625078.856873, T: 5120, Avg. loss: 711810451683270199345152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 10782924172.66, NNZs: 2, Bias: 290632096724.263306, T: 5248, Avg. loss: 767234591579770235912192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 7181562548.64, NNZs: 2, Bias: 290509818903.321594, T: 5376, Avg. loss: 843810109461334453125120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 6339016459.78, NNZs: 2, Bias: 290422834100.386536, T: 5504, Avg. loss: 10255845653680110960640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5064948438.51, NNZs: 2, Bias: 290343039262.063477, T: 5632, Avg. loss: 10414051458784092487680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4768240928.76, NNZs: 2, Bias: 290249178027.836548, T: 5760, Avg. loss: 9248781001249609744384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4627282891.69, NNZs: 2, Bias: 290150873488.782288, T: 5888, Avg. loss: 9096342049111370891264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4652025828.70, NNZs: 2, Bias: 290046914465.221252, T: 6016, Avg. loss: 9598402852021461843968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4640589958.15, NNZs: 2, Bias: 289953218124.715393, T: 6144, Avg. loss: 8378172350483976421376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4407802141.21, NNZs: 2, Bias: 289859929360.632629, T: 6272, Avg. loss: 8775975381347397009408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4674955108.21, NNZs: 2, Bias: 289751753345.079346, T: 6400, Avg. loss: 9045181281258574970880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4721091013.87, NNZs: 2, Bias: 289658293474.128540, T: 6528, Avg. loss: 7948280468527860678656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4454926158.71, NNZs: 2, Bias: 289558690356.365173, T: 6656, Avg. loss: 9679264446381027229696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4541481215.54, NNZs: 2, Bias: 289460689176.762756, T: 6784, Avg. loss: 8696966875376146972672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4656610904.89, NNZs: 2, Bias: 289365659891.316040, T: 6912, Avg. loss: 8176394227472569204736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4492854366.94, NNZs: 2, Bias: 289265462585.442078, T: 7040, Avg. loss: 9546934159701910224896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4743305743.36, NNZs: 2, Bias: 289166846597.159790, T: 7168, Avg. loss: 8398323278284903677952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4714304044.63, NNZs: 2, Bias: 289147949607.513733, T: 7296, Avg. loss: 7084768250513268408320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4597480931.13, NNZs: 2, Bias: 289130368555.760132, T: 7424, Avg. loss: 7129301077830173458432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4708145244.45, NNZs: 2, Bias: 289109093368.287048, T: 7552, Avg. loss: 7100136093270084157440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4639354370.51, NNZs: 2, Bias: 289090776733.474792, T: 7680, Avg. loss: 7101664838597193236480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4594509266.39, NNZs: 2, Bias: 289071854826.949524, T: 7808, Avg. loss: 7187311217369412534272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4657120035.23, NNZs: 2, Bias: 289051420943.111633, T: 7936, Avg. loss: 7078616852985203916800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4598098137.63, NNZs: 2, Bias: 289032707145.106567, T: 8064, Avg. loss: 7190809758438170558464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4537760922.51, NNZs: 2, Bias: 289013980287.384766, T: 8192, Avg. loss: 7193519205199803056128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4577250567.48, NNZs: 2, Bias: 288993596984.656921, T: 8320, Avg. loss: 7219869925486603796480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4537157897.54, NNZs: 2, Bias: 288974894648.900757, T: 8448, Avg. loss: 7067230105989159059456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4524876655.93, NNZs: 2, Bias: 288955612385.535828, T: 8576, Avg. loss: 7111913958438473826304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4600362372.50, NNZs: 2, Bias: 288935285505.597351, T: 8704, Avg. loss: 6960981202966753050624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4590987638.14, NNZs: 2, Bias: 288915804208.402893, T: 8832, Avg. loss: 7163781028338890440704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4525761057.53, NNZs: 2, Bias: 288897082709.557861, T: 8960, Avg. loss: 7225620939345000136704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4553186806.02, NNZs: 2, Bias: 288877105592.164490, T: 9088, Avg. loss: 7128038971446533292032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 4510357289.41, NNZs: 2, Bias: 288858193785.997131, T: 9216, Avg. loss: 7161179173973374533632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 4553353181.12, NNZs: 2, Bias: 288838439394.676392, T: 9344, Avg. loss: 6953405565456754933760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 4566045875.56, NNZs: 2, Bias: 288818697243.713928, T: 9472, Avg. loss: 7140842351610609795072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 4470734703.19, NNZs: 2, Bias: 288800688778.113281, T: 9600, Avg. loss: 7127571874208561496064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 4580804222.46, NNZs: 2, Bias: 288779187684.983154, T: 9728, Avg. loss: 7207998594073727336448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 4538493871.41, NNZs: 2, Bias: 288760129216.387512, T: 9856, Avg. loss: 7207200169553802821632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 4602504121.07, NNZs: 2, Bias: 288739801261.740479, T: 9984, Avg. loss: 7030416554814777327616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 4575052565.70, NNZs: 2, Bias: 288736332839.291138, T: 10112, Avg. loss: 6929237633771784634368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 4578646606.57, NNZs: 2, Bias: 288732399964.434265, T: 10240, Avg. loss: 6873722672575478235136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 4569799780.25, NNZs: 2, Bias: 288728658916.031738, T: 10368, Avg. loss: 6885134699052028395520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 4554504153.01, NNZs: 2, Bias: 288725028094.557251, T: 10496, Avg. loss: 6870094608144634216448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 4575689622.41, NNZs: 2, Bias: 288720822496.316467, T: 10624, Avg. loss: 6862815211556423335936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 4561412658.58, NNZs: 2, Bias: 288717165596.759155, T: 10752, Avg. loss: 6888469549299577913344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 4580814689.26, NNZs: 2, Bias: 288713007555.347107, T: 10880, Avg. loss: 6827198205743232712704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 4555407019.26, NNZs: 2, Bias: 288709537980.693420, T: 11008, Avg. loss: 6869124001161739763712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 4576451729.52, NNZs: 2, Bias: 288705331424.502136, T: 11136, Avg. loss: 6868063908665208340480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 4556587954.94, NNZs: 2, Bias: 288701769407.188049, T: 11264, Avg. loss: 6876946180577900363776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 4551720768.64, NNZs: 2, Bias: 288697977350.079895, T: 11392, Avg. loss: 6860967977677364396032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 4551400872.86, NNZs: 2, Bias: 288694102501.536621, T: 11520, Avg. loss: 6881279206388770275328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 90 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 739027631585.99, NNZs: 2, Bias: -34209095296.547180, T: 128, Avg. loss: 21096251342051211822921416704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2454289157717.30, NNZs: 2, Bias: -68178130367.052032, T: 256, Avg. loss: 23634615153539471315264602112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2180992949483.91, NNZs: 2, Bias: -125257014510.853638, T: 384, Avg. loss: 26184074136013871857197383680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1548775998637.16, NNZs: 2, Bias: -125257014510.853638, T: 512, Avg. loss: 24377181957729404851230605312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2071001632045.21, NNZs: 2, Bias: -122357980608.941010, T: 640, Avg. loss: 23376823200173188514089795584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 584448356563.11, NNZs: 2, Bias: -186283570756.390198, T: 768, Avg. loss: 21832244000899816253743431680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 394442770211.65, NNZs: 2, Bias: -187957930488.303070, T: 896, Avg. loss: 926531157445278265675612160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 228611353166.08, NNZs: 2, Bias: -183505609202.491425, T: 1024, Avg. loss: 978266718306806995028541440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 272047868757.22, NNZs: 2, Bias: -175704636997.411774, T: 1152, Avg. loss: 917658612206712154180550656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 183028802707.90, NNZs: 2, Bias: -180824796291.495850, T: 1280, Avg. loss: 917858531721339130068598784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 323910415320.67, NNZs: 2, Bias: -179966286816.167938, T: 1408, Avg. loss: 936002208037858279568703488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 77592694726.77, NNZs: 2, Bias: -171968974659.606018, T: 1536, Avg. loss: 927815082917065860782751744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 234773082936.88, NNZs: 2, Bias: -180649400855.458954, T: 1664, Avg. loss: 983363529981717627996733440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 189762939094.09, NNZs: 2, Bias: -183251040074.527679, T: 1792, Avg. loss: 926923665630036363942297600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 62781752113.69, NNZs: 2, Bias: -180702915251.345520, T: 1920, Avg. loss: 35271275600142452521959424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 73084599138.19, NNZs: 2, Bias: -180013732607.847656, T: 2048, Avg. loss: 32782140385581055288016896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 7953667379.84, NNZs: 2, Bias: -180229378534.732208, T: 2176, Avg. loss: 35595161016990664218378240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 101250814622.19, NNZs: 2, Bias: -178621432735.482941, T: 2304, Avg. loss: 39218448122250153645047808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 14041734459.56, NNZs: 2, Bias: -174634181466.770660, T: 2432, Avg. loss: 36775465935444492742033408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 27495730133.79, NNZs: 2, Bias: -173118097287.220245, T: 2560, Avg. loss: 34778734748715054727692288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 98769858835.87, NNZs: 2, Bias: -173840929496.773102, T: 2688, Avg. loss: 35597420572446144128352256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 2934056389.59, NNZs: 2, Bias: -173113989305.525452, T: 2816, Avg. loss: 5366200534519861064237056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 8616886674.05, NNZs: 2, Bias: -172863139833.197418, T: 2944, Avg. loss: 708283626114342574882816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 11231115680.07, NNZs: 2, Bias: -173043717738.333862, T: 3072, Avg. loss: 782378093950369517273088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 5589228197.30, NNZs: 2, Bias: -172846799036.874786, T: 3200, Avg. loss: 870706069614382874099712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2464573023.03, NNZs: 2, Bias: -172636470608.013489, T: 3328, Avg. loss: 743039066586242135097344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 15197227070.47, NNZs: 2, Bias: -172489775996.226105, T: 3456, Avg. loss: 620300266606605964935168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1470880665.99, NNZs: 2, Bias: -172404850248.067230, T: 3584, Avg. loss: 799601618385039685320704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3437561158.12, NNZs: 2, Bias: -171974246023.614197, T: 3712, Avg. loss: 848744921912923303968768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5525161619.12, NNZs: 2, Bias: -171758089804.540131, T: 3840, Avg. loss: 719835036808441384402944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6446448195.89, NNZs: 2, Bias: -171456619616.271179, T: 3968, Avg. loss: 838843059760583413858304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9157713421.07, NNZs: 2, Bias: -171393594262.685211, T: 4096, Avg. loss: 844198082975444007649280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5805215069.82, NNZs: 2, Bias: -171388256255.285461, T: 4224, Avg. loss: 9057231390221468172288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4402150691.69, NNZs: 2, Bias: -171359021114.104248, T: 4352, Avg. loss: 4088909516729167118336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3526933349.91, NNZs: 2, Bias: -171325607082.785706, T: 4480, Avg. loss: 3074492063033928450048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3049270525.76, NNZs: 2, Bias: -171283524000.276398, T: 4608, Avg. loss: 2817451183261212475392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2889086738.73, NNZs: 2, Bias: -171234345763.104767, T: 4736, Avg. loss: 2781599068541560029184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2815590251.89, NNZs: 2, Bias: -171186540555.529755, T: 4864, Avg. loss: 2517356245675351212032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2557282725.22, NNZs: 2, Bias: -171136663259.309540, T: 4992, Avg. loss: 3013321452409308315648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2527344227.35, NNZs: 2, Bias: -171087153173.291992, T: 5120, Avg. loss: 2635483060516384931840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2567873290.06, NNZs: 2, Bias: -171036690178.442352, T: 5248, Avg. loss: 2595898520382981275648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2415051684.29, NNZs: 2, Bias: -170993971225.941986, T: 5376, Avg. loss: 2358937375818623221760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2583444715.15, NNZs: 2, Bias: -170940541463.635010, T: 5504, Avg. loss: 2724233760917032009728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2668779690.89, NNZs: 2, Bias: -170889775957.821259, T: 5632, Avg. loss: 2539929832717287424000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2491517942.28, NNZs: 2, Bias: -170841418278.315582, T: 5760, Avg. loss: 2665912862543718121472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2542634346.00, NNZs: 2, Bias: -170791607119.101318, T: 5888, Avg. loss: 2639544046725524094976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2595296004.15, NNZs: 2, Bias: -170741236681.323425, T: 6016, Avg. loss: 2655202421311353126912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2576563027.42, NNZs: 2, Bias: -170731561478.128906, T: 6144, Avg. loss: 2143680162336221167616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2587314175.87, NNZs: 2, Bias: -170721461092.442749, T: 6272, Avg. loss: 2142421498672482091008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2545890543.25, NNZs: 2, Bias: -170712113911.984467, T: 6400, Avg. loss: 2148961017823375654912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2537701202.59, NNZs: 2, Bias: -170702185951.518982, T: 6528, Avg. loss: 2165244907811244343296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2571614304.84, NNZs: 2, Bias: -170691666585.042694, T: 6656, Avg. loss: 2151470885130457317376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2526414885.36, NNZs: 2, Bias: -170682288973.131012, T: 6784, Avg. loss: 2168652350781501997056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2552149786.63, NNZs: 2, Bias: -170671989118.452332, T: 6912, Avg. loss: 2130781364984350244864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2543600740.64, NNZs: 2, Bias: -170662166666.507446, T: 7040, Avg. loss: 2139217429988600709120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2512774147.85, NNZs: 2, Bias: -170652786104.649078, T: 7168, Avg. loss: 2115765272120081514496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2530448876.94, NNZs: 2, Bias: -170642738535.462189, T: 7296, Avg. loss: 2101851535001823739904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2531120711.88, NNZs: 2, Bias: -170632852464.432159, T: 7424, Avg. loss: 2122812550595791028224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2514033055.97, NNZs: 2, Bias: -170623213601.628052, T: 7552, Avg. loss: 2124658035842356609024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2542292294.11, NNZs: 2, Bias: -170612916343.632568, T: 7680, Avg. loss: 2123114536007004585984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2551276525.05, NNZs: 2, Bias: -170602856537.745392, T: 7808, Avg. loss: 2136280210950074400768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2535283794.22, NNZs: 2, Bias: -170593139780.493317, T: 7936, Avg. loss: 2144172780254222614528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2530898189.71, NNZs: 2, Bias: -170591221745.741852, T: 8064, Avg. loss: 2077708223059750551552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2526832910.25, NNZs: 2, Bias: -170589303059.901428, T: 8192, Avg. loss: 2073289274109774528512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2531212152.23, NNZs: 2, Bias: -170587256180.976288, T: 8320, Avg. loss: 2075866893401998491648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2529827955.30, NNZs: 2, Bias: -170585297482.710785, T: 8448, Avg. loss: 2073324398814180409344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2519954558.74, NNZs: 2, Bias: -170583475331.989471, T: 8576, Avg. loss: 2062198970764489129984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2538054295.12, NNZs: 2, Bias: -170581232522.915619, T: 8704, Avg. loss: 2067458956921640845312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2530231890.96, NNZs: 2, Bias: -170579362399.647247, T: 8832, Avg. loss: 2081056283462988464128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2519169213.69, NNZs: 2, Bias: -170577560043.216614, T: 8960, Avg. loss: 2059706349745908744192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2527785413.89, NNZs: 2, Bias: -170575449920.381775, T: 9088, Avg. loss: 2076248030630062063616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2528727779.82, NNZs: 2, Bias: -170573456168.202209, T: 9216, Avg. loss: 2073658969322678648832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2528374297.26, NNZs: 2, Bias: -170571480554.801025, T: 9344, Avg. loss: 2074658158088223457280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2526016491.90, NNZs: 2, Bias: -170569532265.918732, T: 9472, Avg. loss: 2077368093215946440704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2539264209.39, NNZs: 2, Bias: -170567370384.786285, T: 9600, Avg. loss: 2057617088901245042688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2528000996.09, NNZs: 2, Bias: -170565556852.673096, T: 9728, Avg. loss: 2075310335542614556672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2527330626.93, NNZs: 2, Bias: -170563582553.435822, T: 9856, Avg. loss: 2078410253387488296960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2533310533.74, NNZs: 2, Bias: -170561515409.933258, T: 9984, Avg. loss: 2071694483206969229312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2515697280.33, NNZs: 2, Bias: -170559804665.992493, T: 10112, Avg. loss: 2065512071704724373504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2529661626.74, NNZs: 2, Bias: -170557612402.230103, T: 10240, Avg. loss: 2079060554018073083904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 80 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1688537229736.12, NNZs: 2, Bias: 13846485568.873032, T: 128, Avg. loss: 19625935618543402777808207872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 959297800714.05, NNZs: 2, Bias: 93846485568.873032, T: 256, Avg. loss: 21000609192828152762865811456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 675544630598.98, NNZs: 2, Bias: 104113170890.679123, T: 384, Avg. loss: 21263468964598535248895016960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 599715961232.61, NNZs: 2, Bias: -11705783264.173492, T: 512, Avg. loss: 21306810431536432401449222144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 377057320566.10, NNZs: 2, Bias: 15767476472.618637, T: 640, Avg. loss: 21965268279806542702614413312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 502760635235.49, NNZs: 2, Bias: 31173795620.255478, T: 768, Avg. loss: 22062495422878438836320337920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 449457159692.44, NNZs: 2, Bias: 18309647793.364723, T: 896, Avg. loss: 832253085968157101734756352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 390489468393.61, NNZs: 2, Bias: 2033568745.181414, T: 1024, Avg. loss: 850882570196208415672369152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 218322287108.57, NNZs: 2, Bias: 11036728983.869034, T: 1152, Avg. loss: 927198457383341731132473344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 424544083454.53, NNZs: 2, Bias: 13084918086.398136, T: 1280, Avg. loss: 812247342239332593991417856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 89818120904.50, NNZs: 2, Bias: 31136394213.136723, T: 1408, Avg. loss: 854194973449069286370836480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 175882788669.37, NNZs: 2, Bias: 27179594754.041706, T: 1536, Avg. loss: 841720878925321153944748032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 136462954438.25, NNZs: 2, Bias: 8739557465.114384, T: 1664, Avg. loss: 933791007279696412615376896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 177227171732.24, NNZs: 2, Bias: 11038224984.764277, T: 1792, Avg. loss: 810746888802013988691902464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 40995079932.36, NNZs: 2, Bias: 6153988672.834850, T: 1920, Avg. loss: 842256825337453825495138304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 207486692441.90, NNZs: 2, Bias: 15668931746.068825, T: 2048, Avg. loss: 859080869183554635746508800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 233188547093.19, NNZs: 2, Bias: -12796252938.698399, T: 2176, Avg. loss: 872453621830302405924749312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 472715282996.03, NNZs: 2, Bias: -20960505678.324829, T: 2304, Avg. loss: 791908902431629172795244544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 316896897715.21, NNZs: 2, Bias: -14647130640.490379, T: 2432, Avg. loss: 857357083341949015169171456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 262126691582.99, NNZs: 2, Bias: -8714991863.973223, T: 2560, Avg. loss: 926077664372053249273888768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 247084187959.12, NNZs: 2, Bias: 2806642662.290464, T: 2688, Avg. loss: 840381963433233268313423872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 62096307492.67, NNZs: 2, Bias: 10069992128.709713, T: 2816, Avg. loss: 941799371566204206247313408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 180018231097.72, NNZs: 2, Bias: 8408134316.944147, T: 2944, Avg. loss: 888459996185189077523365888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 61139442921.03, NNZs: 2, Bias: 6207917174.905001, T: 3072, Avg. loss: 40182122592930237329178624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 24585079295.91, NNZs: 2, Bias: 8079067570.566508, T: 3200, Avg. loss: 32217475682891143890075648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 36750872589.14, NNZs: 2, Bias: 6611397396.079510, T: 3328, Avg. loss: 29691312748373693884792832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 8719631930.29, NNZs: 2, Bias: 7028828911.092386, T: 3456, Avg. loss: 33589599181718594695200768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 79345106229.03, NNZs: 2, Bias: 9459047204.502653, T: 3584, Avg. loss: 28207578414665668254236672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 65209164310.75, NNZs: 2, Bias: 7934111800.096053, T: 3712, Avg. loss: 32319736843239124946124800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 82496282482.51, NNZs: 2, Bias: 5935902664.817424, T: 3840, Avg. loss: 30303843880173005610942464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 27718370966.74, NNZs: 2, Bias: 2196070567.193829, T: 3968, Avg. loss: 33139726773304363346558976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 51148138996.10, NNZs: 2, Bias: -201304713.643720, T: 4096, Avg. loss: 32225820554418619515142144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 65887622911.14, NNZs: 2, Bias: 3386772424.680282, T: 4224, Avg. loss: 31977002859443896337825792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2043989830.30, NNZs: 2, Bias: 3280296241.982241, T: 4352, Avg. loss: 1485220611445635239903232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3713874888.48, NNZs: 2, Bias: 3467162816.137902, T: 4480, Avg. loss: 470768121661275116666880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6135486246.95, NNZs: 2, Bias: 3241487864.287858, T: 4608, Avg. loss: 747824855660307572326400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2158691980.20, NNZs: 2, Bias: 3291265365.203598, T: 4736, Avg. loss: 583148394153667257696256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 16006647184.11, NNZs: 2, Bias: 2967578010.226922, T: 4864, Avg. loss: 510594607664318036049920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2340225497.40, NNZs: 2, Bias: 3089285268.290417, T: 4992, Avg. loss: 425177883855284412088320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 11572209396.91, NNZs: 2, Bias: 3396516241.611771, T: 5120, Avg. loss: 547385099559908277223424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1197208696.75, NNZs: 2, Bias: 3412288777.953580, T: 5248, Avg. loss: 588479924413075726270464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 903124189.60, NNZs: 2, Bias: 3522849295.236997, T: 5376, Avg. loss: 405153088283178768007168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 5259645174.09, NNZs: 2, Bias: 3563485028.453127, T: 5504, Avg. loss: 458436247558855707328512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 14329770826.90, NNZs: 2, Bias: 3645881723.574747, T: 5632, Avg. loss: 506849506714250054205440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3540198420.54, NNZs: 2, Bias: 3752932229.463942, T: 5760, Avg. loss: 779834903585784200167424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 5099806478.01, NNZs: 2, Bias: 3766739980.559253, T: 5888, Avg. loss: 836908412853919481331712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3768988005.53, NNZs: 2, Bias: 3850937503.313479, T: 6016, Avg. loss: 619378475878417132683264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1884547285.74, NNZs: 2, Bias: 3878839104.433060, T: 6144, Avg. loss: 1668840941726735532032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 976665246.22, NNZs: 2, Bias: 3890147624.016763, T: 6272, Avg. loss: 397276641012629569536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 529677818.08, NNZs: 2, Bias: 3895845872.762488, T: 6400, Avg. loss: 100840299600223469568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 298801953.66, NNZs: 2, Bias: 3897626508.612200, T: 6528, Avg. loss: 29227727482236555264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 183659653.71, NNZs: 2, Bias: 3898201692.207535, T: 6656, Avg. loss: 9493285522826201088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 121322025.93, NNZs: 2, Bias: 3897652048.819698, T: 6784, Avg. loss: 3885843724258823168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 92752340.75, NNZs: 2, Bias: 3896680276.039170, T: 6912, Avg. loss: 2264405595751633152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 73586333.42, NNZs: 2, Bias: 3895636137.292364, T: 7040, Avg. loss: 1854164062146017024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 70960364.59, NNZs: 2, Bias: 3894284310.465421, T: 7168, Avg. loss: 1617395905211363072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 67882831.45, NNZs: 2, Bias: 3892967049.555391, T: 7296, Avg. loss: 1632595115511140608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 62082282.43, NNZs: 2, Bias: 3891699216.233768, T: 7424, Avg. loss: 1699565169546966528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 65092093.44, NNZs: 2, Bias: 3890303051.286563, T: 7552, Avg. loss: 1606831411735567360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 69337612.88, NNZs: 2, Bias: 3888898248.098689, T: 7680, Avg. loss: 1586440758924236288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 64298324.87, NNZs: 2, Bias: 3887640080.581766, T: 7808, Avg. loss: 1606144274998448128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 64488904.99, NNZs: 2, Bias: 3886250734.946745, T: 7936, Avg. loss: 1637100497415895808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 66750539.14, NNZs: 2, Bias: 3884899752.054040, T: 8064, Avg. loss: 1530113852950400256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 66606847.69, NNZs: 2, Bias: 3883602481.542480, T: 8192, Avg. loss: 1495977592739965696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 62079978.08, NNZs: 2, Bias: 3882310952.317131, T: 8320, Avg. loss: 1605689546664575744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 62748362.15, NNZs: 2, Bias: 3880907496.366921, T: 8448, Avg. loss: 1706808956143179776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 58836227.30, NNZs: 2, Bias: 3879573937.193988, T: 8576, Avg. loss: 1748597476799259648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 62480543.25, NNZs: 2, Bias: 3878129573.148301, T: 8704, Avg. loss: 1604940790043442944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 61608515.92, NNZs: 2, Bias: 3876779488.092945, T: 8832, Avg. loss: 1623488019613756416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 62990859.07, NNZs: 2, Bias: 3876480579.388641, T: 8960, Avg. loss: 1349799041353215232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 62073821.36, NNZs: 2, Bias: 3876220705.380138, T: 9088, Avg. loss: 1343147819134688768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 62455008.11, NNZs: 2, Bias: 3875941599.209106, T: 9216, Avg. loss: 1331373130794581760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 63714622.84, NNZs: 2, Bias: 3875650199.667758, T: 9344, Avg. loss: 1322177578029904896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 62189088.22, NNZs: 2, Bias: 3875398405.795301, T: 9472, Avg. loss: 1354420426687587584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 62008891.74, NNZs: 2, Bias: 3875125803.052424, T: 9600, Avg. loss: 1346688120873340416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 62155259.63, NNZs: 2, Bias: 3874849526.049036, T: 9728, Avg. loss: 1339026207386907392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 62541766.04, NNZs: 2, Bias: 3874571584.531572, T: 9856, Avg. loss: 1323995631166872832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 61827948.09, NNZs: 2, Bias: 3874309780.644584, T: 9984, Avg. loss: 1335922413286060544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 62507126.26, NNZs: 2, Bias: 3874244321.324892, T: 10112, Avg. loss: 1296846332319248384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 62341276.78, NNZs: 2, Bias: 3874192584.805064, T: 10240, Avg. loss: 1294427383416610560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 62346626.84, NNZs: 2, Bias: 3874138132.721076, T: 10368, Avg. loss: 1293170520998459648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 62301418.54, NNZs: 2, Bias: 3874084462.452697, T: 10496, Avg. loss: 1294037018019235328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 62571981.70, NNZs: 2, Bias: 3874025892.108626, T: 10624, Avg. loss: 1289060046064276224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 62483276.37, NNZs: 2, Bias: 3873972903.416786, T: 10752, Avg. loss: 1294464527996437248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 62464834.10, NNZs: 2, Bias: 3873918862.221607, T: 10880, Avg. loss: 1292546463025383424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 62520688.68, NNZs: 2, Bias: 3873863611.347977, T: 11008, Avg. loss: 1292524713172190976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 62315405.55, NNZs: 2, Bias: 3873812726.212562, T: 11136, Avg. loss: 1289022838609991936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 62263735.76, NNZs: 2, Bias: 3873759190.891734, T: 11264, Avg. loss: 1293180241955685888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 62436485.20, NNZs: 2, Bias: 3873701963.488203, T: 11392, Avg. loss: 1294692230704240896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 62517796.34, NNZs: 2, Bias: 3873646312.517355, T: 11520, Avg. loss: 1292245829444165632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 62406344.50, NNZs: 2, Bias: 3873593669.794443, T: 11648, Avg. loss: 1294936238390517760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 62705981.98, NNZs: 2, Bias: 3873534873.763555, T: 11776, Avg. loss: 1282757673853203712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 62557776.64, NNZs: 2, Bias: 3873482719.205729, T: 11904, Avg. loss: 1297570576188001792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 62555937.04, NNZs: 2, Bias: 3873428413.663702, T: 12032, Avg. loss: 1292233796316320768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 62507632.15, NNZs: 2, Bias: 3873374798.312252, T: 12160, Avg. loss: 1293745911990113280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 62468393.03, NNZs: 2, Bias: 3873321117.993427, T: 12288, Avg. loss: 1291543801230020864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 62248761.67, NNZs: 2, Bias: 3873270394.381798, T: 12416, Avg. loss: 1290627821048585216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 97 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2249170722617.71, NNZs: 2, Bias: 43446299538.035545, T: 128, Avg. loss: 20290506500914523265424162816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 759818256977.19, NNZs: 2, Bias: 92974444961.420837, T: 256, Avg. loss: 23002023140897431996390703104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 950487586986.35, NNZs: 2, Bias: 168533828767.455322, T: 384, Avg. loss: 19244122847935836447412584448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1164981337832.86, NNZs: 2, Bias: 262083399480.023926, T: 512, Avg. loss: 19053032899451730674887688192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1639214617696.75, NNZs: 2, Bias: 191212865885.824188, T: 640, Avg. loss: 18551961375762827214057373696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 676726740217.12, NNZs: 2, Bias: 311212865885.824219, T: 768, Avg. loss: 21935586774776062787132063744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 801164152738.21, NNZs: 2, Bias: 319093294936.858826, T: 896, Avg. loss: 18477885941326794139260420096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 291498612967.06, NNZs: 2, Bias: 359093294936.858826, T: 1024, Avg. loss: 20466034642102122491609612288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 803443954905.26, NNZs: 2, Bias: 325358536443.231934, T: 1152, Avg. loss: 21767636899826967510217916416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1344964557782.85, NNZs: 2, Bias: 325358536443.231934, T: 1280, Avg. loss: 18591012635787142824007303168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2326890762358.38, NNZs: 2, Bias: 381432206317.668335, T: 1408, Avg. loss: 20225056253210124979577815040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2025476416147.47, NNZs: 2, Bias: 374862918236.444214, T: 1536, Avg. loss: 20329222711331123755000791040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 161185026277.99, NNZs: 2, Bias: 383632255121.143311, T: 1664, Avg. loss: 2304895304446564426718380032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 78393271793.59, NNZs: 2, Bias: 395067997598.396057, T: 1792, Avg. loss: 756765901750193528665800704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 129001790252.88, NNZs: 2, Bias: 389881276696.588745, T: 1920, Avg. loss: 844047920944492014966145024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 166147784183.53, NNZs: 2, Bias: 393880649817.056274, T: 2048, Avg. loss: 696220757438097010697699328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 375985242209.52, NNZs: 2, Bias: 405156991636.398865, T: 2176, Avg. loss: 757466508001787408644308992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 101292413264.66, NNZs: 2, Bias: 403350691024.679016, T: 2304, Avg. loss: 816750607679497098015801344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 273962865797.91, NNZs: 2, Bias: 404895267316.143860, T: 2432, Avg. loss: 878970742827563700744880128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 306146003006.11, NNZs: 2, Bias: 394536136651.170288, T: 2560, Avg. loss: 738364490609279795390840832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 132841074683.26, NNZs: 2, Bias: 382522863820.582947, T: 2688, Avg. loss: 775283750584396804282908672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 65267638022.13, NNZs: 2, Bias: 382400672902.510803, T: 2816, Avg. loss: 34461609560419683010609152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 80412498204.57, NNZs: 2, Bias: 385563172089.639465, T: 2944, Avg. loss: 29207100877250275806543872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 20549775229.05, NNZs: 2, Bias: 381544357658.848083, T: 3072, Avg. loss: 30338342433114172568895488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 87399952687.72, NNZs: 2, Bias: 378100057849.468628, T: 3200, Avg. loss: 31128762544367386327252992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10899753903.06, NNZs: 2, Bias: 377075575565.481445, T: 3328, Avg. loss: 28154698401679347697057792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 50417436073.28, NNZs: 2, Bias: 376436828777.956665, T: 3456, Avg. loss: 31059784350812308380844032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 34573906902.36, NNZs: 2, Bias: 375401122589.840454, T: 3584, Avg. loss: 28929973918738207880511488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 56368340315.13, NNZs: 2, Bias: 377486139665.796021, T: 3712, Avg. loss: 27714277336128598686302208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 68586586141.20, NNZs: 2, Bias: 375505161780.365479, T: 3840, Avg. loss: 29478727915906009489473536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 70038904502.08, NNZs: 2, Bias: 374962345815.057800, T: 3968, Avg. loss: 29958994166566844905816064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 51502769232.73, NNZs: 2, Bias: 377221965514.117920, T: 4096, Avg. loss: 29929853282695048610185216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 48861857728.59, NNZs: 2, Bias: 373881062658.477966, T: 4224, Avg. loss: 28846028916506354264309760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 99494541021.91, NNZs: 2, Bias: 372935195009.030151, T: 4352, Avg. loss: 28178708016939521340866560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 14303382270.23, NNZs: 2, Bias: 373518988010.753540, T: 4480, Avg. loss: 2111276024229531846967296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 20825313250.64, NNZs: 2, Bias: 372962164116.349121, T: 4608, Avg. loss: 739774514383810109374464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9705581204.18, NNZs: 2, Bias: 372502179355.238586, T: 4736, Avg. loss: 624970085213512407187456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7947312377.80, NNZs: 2, Bias: 371884523141.478210, T: 4864, Avg. loss: 684402405606007595073536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2974982985.95, NNZs: 2, Bias: 371171746439.156616, T: 4992, Avg. loss: 709232527633240308056064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 10369876871.61, NNZs: 2, Bias: 370213030023.085144, T: 5120, Avg. loss: 756817015104077018693632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9326399385.43, NNZs: 2, Bias: 369827299580.136414, T: 5248, Avg. loss: 786895034447332382867456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 18145305655.83, NNZs: 2, Bias: 369363105326.953613, T: 5376, Avg. loss: 673803533332511492931584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 7562615968.42, NNZs: 2, Bias: 369340604953.959290, T: 5504, Avg. loss: 69190923029876169506816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 6722283295.91, NNZs: 2, Bias: 369230045977.088989, T: 5632, Avg. loss: 14543716987430143787008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6427724899.00, NNZs: 2, Bias: 369111668337.958984, T: 5760, Avg. loss: 14322898214828950683648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 6020804278.19, NNZs: 2, Bias: 369001788574.307861, T: 5888, Avg. loss: 13652075410631256178688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 6374822156.96, NNZs: 2, Bias: 368870714195.597778, T: 6016, Avg. loss: 14031119228264033288192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 6353306194.19, NNZs: 2, Bias: 368748647866.895081, T: 6144, Avg. loss: 13918950194977009827840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 6566568458.86, NNZs: 2, Bias: 368621489765.394165, T: 6272, Avg. loss: 13897696387441499308032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 5919285873.16, NNZs: 2, Bias: 368514127254.788269, T: 6400, Avg. loss: 13628753626228661944320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 6294671870.26, NNZs: 2, Bias: 368390410504.903076, T: 6528, Avg. loss: 13130127230245191811072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 5664635481.83, NNZs: 2, Bias: 368275029272.366760, T: 6656, Avg. loss: 14339579852198751764480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 5783793424.14, NNZs: 2, Bias: 368145420702.668457, T: 6784, Avg. loss: 14441568908723487768576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 5894357606.08, NNZs: 2, Bias: 368019843723.987183, T: 6912, Avg. loss: 14080525112348359262208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 6049473185.36, NNZs: 2, Bias: 367883907695.744019, T: 7040, Avg. loss: 15858252723012556029952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 5966289761.16, NNZs: 2, Bias: 367763665545.717102, T: 7168, Avg. loss: 14072966039436443779072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 5982810066.58, NNZs: 2, Bias: 367738393036.154907, T: 7296, Avg. loss: 11627980256454171951104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 5968733964.09, NNZs: 2, Bias: 367714092295.984802, T: 7424, Avg. loss: 11388545836478510399488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 6014782617.70, NNZs: 2, Bias: 367688418669.169739, T: 7552, Avg. loss: 11578606895241357164544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 5913934760.35, NNZs: 2, Bias: 367665257424.375854, T: 7680, Avg. loss: 11556219136254654021632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 5962870270.04, NNZs: 2, Bias: 367639274899.690247, T: 7808, Avg. loss: 11697646279589927845888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 5946365256.96, NNZs: 2, Bias: 367614604351.449341, T: 7936, Avg. loss: 11577812254164883865600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 5855280302.38, NNZs: 2, Bias: 367591703894.543945, T: 8064, Avg. loss: 11336142242873413206016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 5959821529.69, NNZs: 2, Bias: 367564887393.834106, T: 8192, Avg. loss: 11689986634013856497664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 5898757853.32, NNZs: 2, Bias: 367540924750.707458, T: 8320, Avg. loss: 11597982806220919013376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 5881952579.56, NNZs: 2, Bias: 367515930750.774048, T: 8448, Avg. loss: 11742012084756871643136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 5871571285.21, NNZs: 2, Bias: 367491240585.475952, T: 8576, Avg. loss: 11547066418550724886528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 5914196137.21, NNZs: 2, Bias: 367465551229.033691, T: 8704, Avg. loss: 11608110307101393289216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 5924128124.14, NNZs: 2, Bias: 367460462695.609680, T: 8832, Avg. loss: 11124240223115302404096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 5876374550.96, NNZs: 2, Bias: 367456297419.862793, T: 8960, Avg. loss: 11141378554641673879552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 5889068872.79, NNZs: 2, Bias: 367451140690.176758, T: 9088, Avg. loss: 11181526958101470642176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 5903826149.79, NNZs: 2, Bias: 367445959628.748413, T: 9216, Avg. loss: 11159156413985821032448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 5876416300.45, NNZs: 2, Bias: 367441454439.137207, T: 9344, Avg. loss: 11165119353387856429056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 5879028285.76, NNZs: 2, Bias: 367436467911.296204, T: 9472, Avg. loss: 11161780536833514405888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 74 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 419059935715.38, NNZs: 2, Bias: 99799800710.320389, T: 128, Avg. loss: 20249255098727933036575326208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 566333005407.96, NNZs: 2, Bias: 103703133582.064148, T: 256, Avg. loss: 22507265260092174107378974720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 510769921368.27, NNZs: 2, Bias: 122639124340.250320, T: 384, Avg. loss: 22446760520400244689348853760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 482601915220.75, NNZs: 2, Bias: 82639124340.250320, T: 512, Avg. loss: 20778878761509848371305644032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2373117925709.24, NNZs: 2, Bias: 82639124340.250320, T: 640, Avg. loss: 18861199462008881275346092032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1693688001947.52, NNZs: 2, Bias: 91475217763.244278, T: 768, Avg. loss: 21560618474555986614926966784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1366928106042.18, NNZs: 2, Bias: 147280601951.629150, T: 896, Avg. loss: 20916246334723388978497585152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 879900298708.77, NNZs: 2, Bias: 207280601951.629150, T: 1024, Avg. loss: 22286394498700649791515262976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2561937008668.18, NNZs: 2, Bias: 232881136194.795929, T: 1152, Avg. loss: 20441933643731331920288546816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2375164049541.18, NNZs: 2, Bias: 221148680523.813171, T: 1280, Avg. loss: 21309232374808979309508689920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 195143388809.40, NNZs: 2, Bias: 167275681173.804413, T: 1408, Avg. loss: 1951559829333929566157144064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 413618000041.10, NNZs: 2, Bias: 160656656464.507965, T: 1536, Avg. loss: 842147742738149806044086272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 260886274098.33, NNZs: 2, Bias: 164294569241.000092, T: 1664, Avg. loss: 816935462617268330174611456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 249146665977.80, NNZs: 2, Bias: 159389460910.221466, T: 1792, Avg. loss: 849803899146118905930448896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 123784074490.39, NNZs: 2, Bias: 169143098135.259735, T: 1920, Avg. loss: 812236575379049036396888064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 447785043447.13, NNZs: 2, Bias: 152064825136.641846, T: 2048, Avg. loss: 783234314452461643815190528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 95293530311.82, NNZs: 2, Bias: 146436305326.579620, T: 2176, Avg. loss: 878927747413331053522190336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 198199152183.97, NNZs: 2, Bias: 123518337134.490479, T: 2304, Avg. loss: 804742078780870212097933312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 367076462697.34, NNZs: 2, Bias: 104633761744.392014, T: 2432, Avg. loss: 867131092289844625268539392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 130377105222.14, NNZs: 2, Bias: 125391791436.529755, T: 2560, Avg. loss: 759333080090663739243626496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 213762065809.61, NNZs: 2, Bias: 113052737404.077347, T: 2688, Avg. loss: 851082308347752485792776192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 77354746716.06, NNZs: 2, Bias: 106762843961.588181, T: 2816, Avg. loss: 760798305255431616319193088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 97403765912.57, NNZs: 2, Bias: 102386213077.878723, T: 2944, Avg. loss: 912511371329724705763491840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 89254792324.28, NNZs: 2, Bias: 105990209702.491943, T: 3072, Avg. loss: 807339164135821762709422080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 264548572398.55, NNZs: 2, Bias: 103165641290.176453, T: 3200, Avg. loss: 816310504139075583733661696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 65767567156.73, NNZs: 2, Bias: 108494147449.071854, T: 3328, Avg. loss: 34975596777235569952423936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 37153714189.20, NNZs: 2, Bias: 109475013489.238449, T: 3456, Avg. loss: 29983500951620824065900544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 44437564049.62, NNZs: 2, Bias: 108474032400.313049, T: 3584, Avg. loss: 31854705037443026080759808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 35766874775.84, NNZs: 2, Bias: 110345926285.584732, T: 3712, Avg. loss: 31325941881185312910082048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 53838456580.98, NNZs: 2, Bias: 111724984256.935059, T: 3840, Avg. loss: 30439924986496320182157312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 92235314258.74, NNZs: 2, Bias: 112321902506.015259, T: 3968, Avg. loss: 30895427445478133740863488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 76550525278.50, NNZs: 2, Bias: 115575067211.665451, T: 4096, Avg. loss: 31801882502343026599264256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 14121135595.09, NNZs: 2, Bias: 114589859737.318802, T: 4224, Avg. loss: 1284741804390294174564352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9012328863.85, NNZs: 2, Bias: 114281983059.955566, T: 4352, Avg. loss: 604872211823883347558400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3148801395.48, NNZs: 2, Bias: 114049806892.166077, T: 4480, Avg. loss: 585022418825226387193856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1354200915.86, NNZs: 2, Bias: 113974378635.976730, T: 4608, Avg. loss: 533816644067222056075264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8291644631.14, NNZs: 2, Bias: 114001437751.327667, T: 4736, Avg. loss: 556330039131284522926080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 11025220144.36, NNZs: 2, Bias: 113842560007.698502, T: 4864, Avg. loss: 652428215593779943440384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 12368163051.41, NNZs: 2, Bias: 113652084140.499329, T: 4992, Avg. loss: 459685706321671124680704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2390629391.92, NNZs: 2, Bias: 113231716955.413895, T: 5120, Avg. loss: 600135157584695599824896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 5765283604.33, NNZs: 2, Bias: 113157694152.152206, T: 5248, Avg. loss: 533575382220300533891072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 7978765494.30, NNZs: 2, Bias: 113061436095.783066, T: 5376, Avg. loss: 570140602347051783553024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 11600989019.54, NNZs: 2, Bias: 112547786310.557938, T: 5504, Avg. loss: 612267035813705932603392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3370365636.42, NNZs: 2, Bias: 112188278672.170273, T: 5632, Avg. loss: 586849076851610480541696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2685862598.49, NNZs: 2, Bias: 112164465140.737381, T: 5760, Avg. loss: 1544901079945440133120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2352843119.65, NNZs: 2, Bias: 112135855550.407333, T: 5888, Avg. loss: 1302888363973220237312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2158085635.26, NNZs: 2, Bias: 112105865467.870758, T: 6016, Avg. loss: 1219513563303157432320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2081773435.59, NNZs: 2, Bias: 112070488122.623047, T: 6144, Avg. loss: 1263321096155396046848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2003964548.78, NNZs: 2, Bias: 112037674094.083954, T: 6272, Avg. loss: 1195706827486314889216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1920019417.36, NNZs: 2, Bias: 112003176298.502426, T: 6400, Avg. loss: 1297234297677731594240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1930966226.58, NNZs: 2, Bias: 111968831686.317413, T: 6528, Avg. loss: 1168749371531420762112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1952713263.39, NNZs: 2, Bias: 111932656017.367874, T: 6656, Avg. loss: 1206247928576381550592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2041418631.68, NNZs: 2, Bias: 111895503708.064362, T: 6784, Avg. loss: 1206630203152920215552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1993464869.22, NNZs: 2, Bias: 111861607576.437424, T: 6912, Avg. loss: 1214102805623508828160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1957449778.92, NNZs: 2, Bias: 111827197231.049606, T: 7040, Avg. loss: 1226843027810763145216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1921542360.32, NNZs: 2, Bias: 111791144392.221466, T: 7168, Avg. loss: 1310193464175309094912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1917381204.92, NNZs: 2, Bias: 111784317021.292511, T: 7296, Avg. loss: 971891770603668111360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1926702248.65, NNZs: 2, Bias: 111777153426.386490, T: 7424, Avg. loss: 986938098961983471616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1910502752.06, NNZs: 2, Bias: 111770476659.121918, T: 7552, Avg. loss: 983789783471776202752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1928954599.24, NNZs: 2, Bias: 111763167875.059082, T: 7680, Avg. loss: 985001766876521168896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1907781174.77, NNZs: 2, Bias: 111756466324.762344, T: 7808, Avg. loss: 998725007730923667456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1907363137.52, NNZs: 2, Bias: 111749555474.261017, T: 7936, Avg. loss: 975913625469874864128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1919680392.15, NNZs: 2, Bias: 111747921305.406586, T: 8064, Avg. loss: 976291545115428388864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1932866097.20, NNZs: 2, Bias: 111746304468.498306, T: 8192, Avg. loss: 953061154458108035072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1924101489.88, NNZs: 2, Bias: 111745058823.150558, T: 8320, Avg. loss: 958995328080502849536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1928848003.68, NNZs: 2, Bias: 111743578030.482941, T: 8448, Avg. loss: 959917741273507168256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1925420261.88, NNZs: 2, Bias: 111742244499.500610, T: 8576, Avg. loss: 955763574721971093504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1929054116.28, NNZs: 2, Bias: 111740782846.266571, T: 8704, Avg. loss: 959927613118866784256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1930938180.50, NNZs: 2, Bias: 111739352742.514908, T: 8832, Avg. loss: 959019092319219089408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 69 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 529173750580.17, NNZs: 2, Bias: 38692083944.502335, T: 128, Avg. loss: 18176753485573108311468802048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1999600389223.58, NNZs: 2, Bias: -41307916055.497665, T: 256, Avg. loss: 21692021444905667556796268544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 518526451041.05, NNZs: 2, Bias: 25496690085.054413, T: 384, Avg. loss: 23001217794084908319348097024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1476591215725.91, NNZs: 2, Bias: -57987724226.796486, T: 512, Avg. loss: 21302640504084489011487309824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1237194726974.23, NNZs: 2, Bias: -76769773973.563263, T: 640, Avg. loss: 20959861219509336537256951808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 980717685854.06, NNZs: 2, Bias: 31331924537.024170, T: 768, Avg. loss: 23620078989689271391461834752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 227298231723.75, NNZs: 2, Bias: 3032679639.647139, T: 896, Avg. loss: 942337351345500556690980864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 245485119705.96, NNZs: 2, Bias: -4440710174.661366, T: 1024, Avg. loss: 1004098720010581315799744512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 198695393104.70, NNZs: 2, Bias: -11959688980.868364, T: 1152, Avg. loss: 1015603168426647059274137600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 121286732588.08, NNZs: 2, Bias: -31239549443.115200, T: 1280, Avg. loss: 911677345646631024936878080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 270739634135.20, NNZs: 2, Bias: -24931295296.801384, T: 1408, Avg. loss: 894781922696101183960907776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 228975961459.16, NNZs: 2, Bias: -27031003114.820667, T: 1536, Avg. loss: 961885072350170835081756672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 162343019502.90, NNZs: 2, Bias: -44091407517.036934, T: 1664, Avg. loss: 884787557185467414279618560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 72373542689.01, NNZs: 2, Bias: -45958108008.007935, T: 1792, Avg. loss: 854969432303318453549268992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 212341274486.24, NNZs: 2, Bias: -54401373928.920296, T: 1920, Avg. loss: 890835361471188295340785664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 250045775198.78, NNZs: 2, Bias: -41755083307.763878, T: 2048, Avg. loss: 906167226884821632476512256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 134983783877.34, NNZs: 2, Bias: -13371676309.011570, T: 2176, Avg. loss: 886455216440367536089858048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 206725661038.05, NNZs: 2, Bias: -17185613804.202747, T: 2304, Avg. loss: 940691779627199290687881216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 120934277299.92, NNZs: 2, Bias: -6802214678.785299, T: 2432, Avg. loss: 898828553798525132610732032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 5740046272.45, NNZs: 2, Bias: -2157902302.882509, T: 2560, Avg. loss: 37396637279529665086619648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 39224925697.94, NNZs: 2, Bias: -3760275169.785800, T: 2688, Avg. loss: 32707508347306207690620928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 28093569319.73, NNZs: 2, Bias: -2431099326.751581, T: 2816, Avg. loss: 36161362056836718056701952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 32664587220.65, NNZs: 2, Bias: -31855483.241646, T: 2944, Avg. loss: 31967136637816725135425536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 46961421768.55, NNZs: 2, Bias: 593209456.768436, T: 3072, Avg. loss: 31553274072050204284026880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 45355972011.11, NNZs: 2, Bias: -1045968240.555349, T: 3200, Avg. loss: 33631670529916287999541248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 95500713029.56, NNZs: 2, Bias: -3087993368.590130, T: 3328, Avg. loss: 32987500484252797857955840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 30547109407.93, NNZs: 2, Bias: -3841600315.802877, T: 3456, Avg. loss: 34500004735552066942926848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 24287186986.68, NNZs: 2, Bias: -4387175836.300872, T: 3584, Avg. loss: 30677704660048796232712192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 58752485442.77, NNZs: 2, Bias: -3476712049.321495, T: 3712, Avg. loss: 32552194662432549980078080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 62727128349.94, NNZs: 2, Bias: -3034086803.459431, T: 3840, Avg. loss: 33902611776216732000059392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 30719526897.57, NNZs: 2, Bias: -1518420123.229165, T: 3968, Avg. loss: 35358026088313017298059264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 24159914875.65, NNZs: 2, Bias: 721526704.245574, T: 4096, Avg. loss: 36287651363413482773938176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 62628944754.09, NNZs: 2, Bias: 1345030053.207167, T: 4224, Avg. loss: 35171379549037285037047808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4507722089.45, NNZs: 2, Bias: 1202532125.608772, T: 4352, Avg. loss: 1323621241488891004846080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 10999050559.74, NNZs: 2, Bias: 1322999921.588444, T: 4480, Avg. loss: 577057092982342718324736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5713608212.72, NNZs: 2, Bias: 1013580415.337280, T: 4608, Avg. loss: 528298615396506460487680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1174270154.34, NNZs: 2, Bias: 1001886577.349316, T: 4736, Avg. loss: 510114723955584087883776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8331822688.30, NNZs: 2, Bias: 1282227603.296649, T: 4864, Avg. loss: 403777742274761678913536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1577780357.14, NNZs: 2, Bias: 1618141340.413223, T: 4992, Avg. loss: 492709212211080129937408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2397903990.95, NNZs: 2, Bias: 1396429859.120557, T: 5120, Avg. loss: 669097077458032278896640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3643017148.63, NNZs: 2, Bias: 1471925416.503616, T: 5248, Avg. loss: 519276230651533510836224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6960170351.46, NNZs: 2, Bias: 1659815478.823371, T: 5376, Avg. loss: 627253002172741818777600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 652615537.81, NNZs: 2, Bias: 1643260000.580050, T: 5504, Avg. loss: 655328325731419315765248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 275367305.78, NNZs: 2, Bias: 1640236841.313428, T: 5632, Avg. loss: 64216563037586817024.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 132503991.55, NNZs: 2, Bias: 1637759984.620957, T: 5760, Avg. loss: 9947115869751199744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 54330541.19, NNZs: 2, Bias: 1636141653.285288, T: 5888, Avg. loss: 2924008279013943808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 17320271.00, NNZs: 2, Bias: 1635037488.664954, T: 6016, Avg. loss: 918004152964225024.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 10743799.80, NNZs: 2, Bias: 1634170314.801804, T: 6144, Avg. loss: 425932352137295488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 15482655.61, NNZs: 2, Bias: 1633477218.538908, T: 6272, Avg. loss: 308027238489792256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 21209443.03, NNZs: 2, Bias: 1632869266.682029, T: 6400, Avg. loss: 265402854851436896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 23327706.17, NNZs: 2, Bias: 1632282334.564683, T: 6528, Avg. loss: 279526485385888928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 25897369.85, NNZs: 2, Bias: 1631694290.009743, T: 6656, Avg. loss: 268041439368653184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 26014963.67, NNZs: 2, Bias: 1631136763.551326, T: 6784, Avg. loss: 283591626011017536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 27036858.23, NNZs: 2, Bias: 1630566766.583266, T: 6912, Avg. loss: 275844766151551680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 26184819.57, NNZs: 2, Bias: 1630053496.360785, T: 7040, Avg. loss: 270481956462001920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 25919632.66, NNZs: 2, Bias: 1629949202.109455, T: 7168, Avg. loss: 223707398526166688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 26556602.58, NNZs: 2, Bias: 1629830147.170454, T: 7296, Avg. loss: 223397458744394080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 26094759.18, NNZs: 2, Bias: 1629729786.575172, T: 7424, Avg. loss: 222187978799137664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 27043268.39, NNZs: 2, Bias: 1629609496.400519, T: 7552, Avg. loss: 214747192022138080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 26136497.69, NNZs: 2, Bias: 1629513854.715969, T: 7680, Avg. loss: 227900711097808576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 26236262.54, NNZs: 2, Bias: 1629401811.598967, T: 7808, Avg. loss: 226908878342608096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 26194144.07, NNZs: 2, Bias: 1629292506.029821, T: 7936, Avg. loss: 226309309651087040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 25880632.79, NNZs: 2, Bias: 1629187269.882807, T: 8064, Avg. loss: 227039386122843392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 25958029.49, NNZs: 2, Bias: 1629078764.393496, T: 8192, Avg. loss: 220911635187516096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 26181424.26, NNZs: 2, Bias: 1629053049.935382, T: 8320, Avg. loss: 221423922344735552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 26144899.65, NNZs: 2, Bias: 1629031774.773044, T: 8448, Avg. loss: 218803527709849568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 26193743.94, NNZs: 2, Bias: 1629009080.394116, T: 8576, Avg. loss: 219222695002290944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 26233541.32, NNZs: 2, Bias: 1628986573.309780, T: 8704, Avg. loss: 218804844753168960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 26166015.19, NNZs: 2, Bias: 1628965768.970704, T: 8832, Avg. loss: 219107342836401504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 69 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 865001794526.53, NNZs: 2, Bias: 41757088918.565063, T: 128, Avg. loss: 25210949241529935452123955200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 268308552975.49, NNZs: 2, Bias: 17498205872.949547, T: 256, Avg. loss: 24540108801611972168847982592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 631886972126.06, NNZs: 2, Bias: -13980224495.310883, T: 384, Avg. loss: 25634557520984679849798926336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 707150937132.83, NNZs: 2, Bias: 6019775504.689117, T: 512, Avg. loss: 24164199289424755013055414272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1309248703458.31, NNZs: 2, Bias: -33980224495.310883, T: 640, Avg. loss: 23960543369360956215217094656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 990596966633.67, NNZs: 2, Bias: -53980224495.310883, T: 768, Avg. loss: 24287618915825821296608935936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 832595752752.23, NNZs: 2, Bias: -35157791350.709198, T: 896, Avg. loss: 21859620293396025190402490368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 860230459651.57, NNZs: 2, Bias: 51360250623.398315, T: 1024, Avg. loss: 23536718196328536803876274176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1209783355246.93, NNZs: 2, Bias: 91360250623.398315, T: 1152, Avg. loss: 23269616858503117375061098496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2222388864303.04, NNZs: 2, Bias: 120410339658.018951, T: 1280, Avg. loss: 23658572107006544889969115136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 779996197587.75, NNZs: 2, Bias: 156401711233.248444, T: 1408, Avg. loss: 24962124071389167364576641024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 860631400463.21, NNZs: 2, Bias: 176401711233.248444, T: 1536, Avg. loss: 22900760226432527341650444288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 178124410419.37, NNZs: 2, Bias: 200824791943.030182, T: 1664, Avg. loss: 1071048336050845635322052608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 230696420828.08, NNZs: 2, Bias: 218580751238.153076, T: 1792, Avg. loss: 955650429003315103259426816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 266147875717.09, NNZs: 2, Bias: 219918984984.659088, T: 1920, Avg. loss: 941206498659992653961101312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 123106795900.18, NNZs: 2, Bias: 210412527958.435699, T: 2048, Avg. loss: 997006651507990650360430592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 186266633176.79, NNZs: 2, Bias: 218798142351.558075, T: 2176, Avg. loss: 963575085949161546262249472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 399066913381.25, NNZs: 2, Bias: 208843243448.629272, T: 2304, Avg. loss: 882121680845687927320084480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 32838644935.33, NNZs: 2, Bias: 212595259121.527954, T: 2432, Avg. loss: 883766513827214872073469952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 378475346647.50, NNZs: 2, Bias: 200651626610.330383, T: 2560, Avg. loss: 916886170776238021922521088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 276642344621.70, NNZs: 2, Bias: 201724373587.141418, T: 2688, Avg. loss: 923114671347684387093217280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 131019682372.17, NNZs: 2, Bias: 203922544221.266846, T: 2816, Avg. loss: 937088358394208303777316864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 219852274509.29, NNZs: 2, Bias: 206815810700.783813, T: 2944, Avg. loss: 922208796009486074301644800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 27481974368.82, NNZs: 2, Bias: 205984959726.705261, T: 3072, Avg. loss: 42996749166826419742834688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 58912759303.94, NNZs: 2, Bias: 208087988856.225281, T: 3200, Avg. loss: 34122319795923393200521216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 28182291047.86, NNZs: 2, Bias: 209335092688.197754, T: 3328, Avg. loss: 35552450151468037704777728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 86025955692.00, NNZs: 2, Bias: 207473144250.465118, T: 3456, Avg. loss: 34783443709083922299092992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 67872596250.61, NNZs: 2, Bias: 206715383737.838287, T: 3584, Avg. loss: 34188838588650845238198272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8717725494.06, NNZs: 2, Bias: 210107435561.935669, T: 3712, Avg. loss: 35855980419419888769040384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 102467435860.56, NNZs: 2, Bias: 208562457881.242126, T: 3840, Avg. loss: 33862783046613703745077248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 46284020119.25, NNZs: 2, Bias: 206770897930.028534, T: 3968, Avg. loss: 37289499140540976966139904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 33192160325.38, NNZs: 2, Bias: 205581397486.058868, T: 4096, Avg. loss: 37811263659945516974735360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 33328142498.96, NNZs: 2, Bias: 201061271694.325500, T: 4224, Avg. loss: 32696579372347254907076608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 16561764010.50, NNZs: 2, Bias: 201246531526.526215, T: 4352, Avg. loss: 34960168369569299697762304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 43243848341.81, NNZs: 2, Bias: 199585089693.936432, T: 4480, Avg. loss: 33572820661014577935286272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 23697415450.47, NNZs: 2, Bias: 199696695694.612915, T: 4608, Avg. loss: 34431494866264365507543040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 72422325184.82, NNZs: 2, Bias: 194963275306.652039, T: 4736, Avg. loss: 34883293805006528391938048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 89435700676.32, NNZs: 2, Bias: 196117783997.177185, T: 4864, Avg. loss: 32772811277685759995281408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 11984312781.64, NNZs: 2, Bias: 196084778186.016754, T: 4992, Avg. loss: 2126243055820081066934272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 15124756080.48, NNZs: 2, Bias: 196118408082.023529, T: 5120, Avg. loss: 894549464393032793063424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3730933508.25, NNZs: 2, Bias: 195760775149.632111, T: 5248, Avg. loss: 833908871841221477138432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2913629029.77, NNZs: 2, Bias: 195575473890.335938, T: 5376, Avg. loss: 701895410606973894262784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 11928590895.99, NNZs: 2, Bias: 195524429134.535431, T: 5504, Avg. loss: 744345418020137442738176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5006854766.97, NNZs: 2, Bias: 195394930678.410736, T: 5632, Avg. loss: 803752442089323435655168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1172803499.57, NNZs: 2, Bias: 194937237743.338470, T: 5760, Avg. loss: 678844159569205426913280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 14668979033.94, NNZs: 2, Bias: 194716933630.690521, T: 5888, Avg. loss: 635324379034829847527424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 12609704780.95, NNZs: 2, Bias: 194427015664.979370, T: 6016, Avg. loss: 731790784357700154163200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 8775184043.13, NNZs: 2, Bias: 194585836412.951996, T: 6144, Avg. loss: 836440355757622204301312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3540445087.48, NNZs: 2, Bias: 194692177564.545532, T: 6272, Avg. loss: 690443521446593295286272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 14562383963.16, NNZs: 2, Bias: 194407275330.218933, T: 6400, Avg. loss: 632883935445806970044416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 7958463246.97, NNZs: 2, Bias: 194150704394.453125, T: 6528, Avg. loss: 851663628944549060018176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 6815727916.66, NNZs: 2, Bias: 194339775879.446442, T: 6656, Avg. loss: 719791955530635259412480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9902533809.35, NNZs: 2, Bias: 193928816077.785095, T: 6784, Avg. loss: 826647838965590256517120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 5355494829.51, NNZs: 2, Bias: 193747187358.723724, T: 6912, Avg. loss: 817161449561036500762624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 7721978281.88, NNZs: 2, Bias: 193595205537.592407, T: 7040, Avg. loss: 659547528879887502802944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 5512278939.48, NNZs: 2, Bias: 193575789114.396698, T: 7168, Avg. loss: 6474789890855028129792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4045847050.99, NNZs: 2, Bias: 193540586372.310089, T: 7296, Avg. loss: 4820797303231908675584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3458382621.53, NNZs: 2, Bias: 193492454798.196228, T: 7424, Avg. loss: 3670550876479352209408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3275008446.78, NNZs: 2, Bias: 193438004417.961029, T: 7552, Avg. loss: 3418306082457450446848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3067506195.32, NNZs: 2, Bias: 193388532946.200256, T: 7680, Avg. loss: 3111149765029862047744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2953455328.72, NNZs: 2, Bias: 193334866502.882751, T: 7808, Avg. loss: 3317105483318904225792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2886479056.33, NNZs: 2, Bias: 193281088924.226410, T: 7936, Avg. loss: 3195280966043249410048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2947935438.82, NNZs: 2, Bias: 193223466475.246460, T: 8064, Avg. loss: 3408935121971141148672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2879349825.51, NNZs: 2, Bias: 193164649227.891083, T: 8192, Avg. loss: 3595841296273689280512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2765495091.21, NNZs: 2, Bias: 193109184253.010193, T: 8320, Avg. loss: 3411109280136647671808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2715218510.19, NNZs: 2, Bias: 193098538146.576813, T: 8448, Avg. loss: 2773335471283538231296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2709269606.42, NNZs: 2, Bias: 193087296618.175903, T: 8576, Avg. loss: 2756306796929892745216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2810666287.96, NNZs: 2, Bias: 193074750370.770325, T: 8704, Avg. loss: 2694152697493817131008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2754706723.54, NNZs: 2, Bias: 193064318831.042419, T: 8832, Avg. loss: 2740791991636824424448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2756741705.46, NNZs: 2, Bias: 193052949162.923065, T: 8960, Avg. loss: 2761889384513623556096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2823644053.00, NNZs: 2, Bias: 193041033937.381989, T: 9088, Avg. loss: 2653575515018671685632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2785572958.86, NNZs: 2, Bias: 193030200471.381256, T: 9216, Avg. loss: 2770052544083991199744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2805800306.44, NNZs: 2, Bias: 193018572988.182678, T: 9344, Avg. loss: 2756912973730721300480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2875120700.57, NNZs: 2, Bias: 193006687187.579285, T: 9472, Avg. loss: 2635964204233965699072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2790418961.07, NNZs: 2, Bias: 192996799824.837494, T: 9600, Avg. loss: 2705925471041571258368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2834605581.39, NNZs: 2, Bias: 192984866418.184265, T: 9728, Avg. loss: 2739931541874615517184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2795805863.42, NNZs: 2, Bias: 192974079313.878357, T: 9856, Avg. loss: 2766106851523378544640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2801706515.25, NNZs: 2, Bias: 192962727718.782257, T: 9984, Avg. loss: 2742928447130356940800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2855039922.78, NNZs: 2, Bias: 192950790089.000793, T: 10112, Avg. loss: 2704809478527449563136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2848764297.36, NNZs: 2, Bias: 192948635634.072601, T: 10240, Avg. loss: 2663166976960920289280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 2844696911.37, NNZs: 2, Bias: 192946448982.647766, T: 10368, Avg. loss: 2662323484257782071296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 2831345171.93, NNZs: 2, Bias: 192944409052.853302, T: 10496, Avg. loss: 2650352549680112467968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 2856237865.92, NNZs: 2, Bias: 192941830721.032074, T: 10624, Avg. loss: 2617934964081431150592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 2834478594.98, NNZs: 2, Bias: 192939919292.281158, T: 10752, Avg. loss: 2645578123519798018048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 2842390270.71, NNZs: 2, Bias: 192937556426.396637, T: 10880, Avg. loss: 2661247508060543909888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 2852317009.65, NNZs: 2, Bias: 192935176539.400299, T: 11008, Avg. loss: 2645293757665769947136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 2844436581.78, NNZs: 2, Bias: 192933051565.950623, T: 11136, Avg. loss: 2655904168579155099648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 2835841846.49, NNZs: 2, Bias: 192930939998.082092, T: 11264, Avg. loss: 2651956413813165129728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 88 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2257418265370.02, NNZs: 2, Bias: -26281950504.886642, T: 128, Avg. loss: 19886370389918648658508644352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1278780995958.24, NNZs: 2, Bias: 25022204284.438599, T: 256, Avg. loss: 22273085202381157690320617472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 981434622912.00, NNZs: 2, Bias: -27657337364.632050, T: 384, Avg. loss: 21871356229337832248508940288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1191088893547.88, NNZs: 2, Bias: 34115599484.229385, T: 512, Avg. loss: 20454359625351334352740417536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 868706512370.98, NNZs: 2, Bias: 52053181370.281342, T: 640, Avg. loss: 19361291477996113244152922112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1733931315770.46, NNZs: 2, Bias: 66527628584.265549, T: 768, Avg. loss: 20364791117676493077122908160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 939451276994.36, NNZs: 2, Bias: 65402555158.075867, T: 896, Avg. loss: 23166215173532796786202116096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1626201379159.30, NNZs: 2, Bias: 82422376259.573837, T: 1024, Avg. loss: 21626948681039394713840386048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 546055436877.69, NNZs: 2, Bias: 82422376259.573853, T: 1152, Avg. loss: 20091011823370403159096688640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 565231031716.48, NNZs: 2, Bias: 122422376259.573853, T: 1280, Avg. loss: 22549080369291280833486782464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 90254687275.01, NNZs: 2, Bias: 133647407632.713333, T: 1408, Avg. loss: 890869026563791709309763584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 402899074618.92, NNZs: 2, Bias: 139189925131.583679, T: 1536, Avg. loss: 886235831189854618648576000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 166869074439.36, NNZs: 2, Bias: 136271119059.094360, T: 1664, Avg. loss: 800420888311850063441690624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 275787924643.56, NNZs: 2, Bias: 125181403266.143539, T: 1792, Avg. loss: 714505483433726499203579904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 70571747296.34, NNZs: 2, Bias: 123978820508.640106, T: 1920, Avg. loss: 838813708476704416080068608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 187621727065.82, NNZs: 2, Bias: 133665065193.646973, T: 2048, Avg. loss: 806302408415189848628920320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 418813014024.47, NNZs: 2, Bias: 123425416056.230423, T: 2176, Avg. loss: 852851542167909464608342016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 141891140265.06, NNZs: 2, Bias: 131680948184.123016, T: 2304, Avg. loss: 935199031846361065511190528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 342360724920.70, NNZs: 2, Bias: 134188990176.103790, T: 2432, Avg. loss: 807201254809499551418810368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 87834795268.98, NNZs: 2, Bias: 134778224370.283630, T: 2560, Avg. loss: 62954414404879929894240256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 101805662256.59, NNZs: 2, Bias: 133696365308.745132, T: 2688, Avg. loss: 28000336801248838051430400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 69603606406.57, NNZs: 2, Bias: 131660706740.292267, T: 2816, Avg. loss: 32935444328982251871141888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 18772218431.08, NNZs: 2, Bias: 131085247059.310623, T: 2944, Avg. loss: 35177760034725416707031040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 19252776974.88, NNZs: 2, Bias: 127330842445.583694, T: 3072, Avg. loss: 31471840625251669512290304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 82213016728.83, NNZs: 2, Bias: 129053020967.220520, T: 3200, Avg. loss: 30166155448511621089984512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 6913306703.56, NNZs: 2, Bias: 124917117558.476959, T: 3328, Avg. loss: 33398109432640945715675136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1447353020.65, NNZs: 2, Bias: 124648734525.173813, T: 3456, Avg. loss: 521933068267146834870272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2634422429.66, NNZs: 2, Bias: 124433650782.555099, T: 3584, Avg. loss: 658489633180472980799488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 12178436002.38, NNZs: 2, Bias: 123798514730.885544, T: 3712, Avg. loss: 655624611806198968090624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3303273888.61, NNZs: 2, Bias: 123613203712.383575, T: 3840, Avg. loss: 762958395770839544889344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5247878676.95, NNZs: 2, Bias: 123452701214.004333, T: 3968, Avg. loss: 602586425859033310167040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4167419703.58, NNZs: 2, Bias: 123364794986.437302, T: 4096, Avg. loss: 594171332884913645944832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 967371463.45, NNZs: 2, Bias: 123268598801.882401, T: 4224, Avg. loss: 5759185148533922594816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1425464929.56, NNZs: 2, Bias: 123214154779.417969, T: 4352, Avg. loss: 1733832806564639801344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1682009577.57, NNZs: 2, Bias: 123167606081.743500, T: 4480, Avg. loss: 1564496533407226658816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1973604527.04, NNZs: 2, Bias: 123121428657.492920, T: 4608, Avg. loss: 1517974340803380641792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1981761759.72, NNZs: 2, Bias: 123075614855.963593, T: 4736, Avg. loss: 1697850528508735651840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1917021367.61, NNZs: 2, Bias: 123032917723.797516, T: 4864, Avg. loss: 1618170282639930163200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1988681703.16, NNZs: 2, Bias: 122989131845.651581, T: 4992, Avg. loss: 1553055830617295945728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1986425438.17, NNZs: 2, Bias: 122946731235.040421, T: 5120, Avg. loss: 1577647275579700936704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1939860533.72, NNZs: 2, Bias: 122901423118.688721, T: 5248, Avg. loss: 1665897914157658800128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1983987684.86, NNZs: 2, Bias: 122892070130.357391, T: 5376, Avg. loss: 1335380818238147657728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1972152476.97, NNZs: 2, Bias: 122883587450.525970, T: 5504, Avg. loss: 1345819266272309280768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1975605297.98, NNZs: 2, Bias: 122874830923.937851, T: 5632, Avg. loss: 1346662384154401046528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1960265434.88, NNZs: 2, Bias: 122866334645.660782, T: 5760, Avg. loss: 1354159527553141833728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1940293607.78, NNZs: 2, Bias: 122858143342.895508, T: 5888, Avg. loss: 1315175720480630374400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1947472142.79, NNZs: 2, Bias: 122849322438.327682, T: 6016, Avg. loss: 1347729108284832219136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1961959271.23, NNZs: 2, Bias: 122840502463.707489, T: 6144, Avg. loss: 1327346688320837255168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1985427466.57, NNZs: 2, Bias: 122831599603.790619, T: 6272, Avg. loss: 1317390913283663331328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1989341345.77, NNZs: 2, Bias: 122822917426.540833, T: 6400, Avg. loss: 1333431631828060209152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1987130367.14, NNZs: 2, Bias: 122814242210.412125, T: 6528, Avg. loss: 1346937693426033360896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1977731752.94, NNZs: 2, Bias: 122812662796.450806, T: 6656, Avg. loss: 1305737003705688391680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1978591676.16, NNZs: 2, Bias: 122810924327.275177, T: 6784, Avg. loss: 1300323839364070899712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1981494165.59, NNZs: 2, Bias: 122809157415.644028, T: 6912, Avg. loss: 1296690114914587508736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1974207171.10, NNZs: 2, Bias: 122807551040.316940, T: 7040, Avg. loss: 1300099965439244500992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1977536950.07, NNZs: 2, Bias: 122805770784.967804, T: 7168, Avg. loss: 1301802907193498664960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1980078333.59, NNZs: 2, Bias: 122804007082.814148, T: 7296, Avg. loss: 1298758119030653452288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1971993823.75, NNZs: 2, Bias: 122802416404.109009, T: 7424, Avg. loss: 1297783904524305432576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1975373779.48, NNZs: 2, Bias: 122800638359.103348, T: 7552, Avg. loss: 1299465861927418724352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 59 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2250637770724.79, NNZs: 2, Bias: 95440299439.768524, T: 128, Avg. loss: 18122500965564367001268256768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 999670460487.57, NNZs: 2, Bias: 67657161922.522156, T: 256, Avg. loss: 21477674237562132972831768576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 843362631086.48, NNZs: 2, Bias: 18275660771.793365, T: 384, Avg. loss: 20549087620771809108665827328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1728863914493.58, NNZs: 2, Bias: -81724339228.206635, T: 512, Avg. loss: 19454409645836946369153073152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1681647087116.54, NNZs: 2, Bias: -161724339228.206635, T: 640, Avg. loss: 19820723266855659548419555328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2511230483336.35, NNZs: 2, Bias: -161724339228.206635, T: 768, Avg. loss: 18956065756556652546107637760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 256667570966.30, NNZs: 2, Bias: -110589676988.464661, T: 896, Avg. loss: 2624397995485576976178085888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 149777007302.34, NNZs: 2, Bias: -117532339473.548370, T: 1024, Avg. loss: 816358321012340044884606976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 318396127710.15, NNZs: 2, Bias: -106034936396.508408, T: 1152, Avg. loss: 815042443403496592108421120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 228976297236.31, NNZs: 2, Bias: -118342181587.925690, T: 1280, Avg. loss: 818980120566553073873321984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 175568602464.80, NNZs: 2, Bias: -107524952012.209961, T: 1408, Avg. loss: 802938643642236761108643840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 236453046882.10, NNZs: 2, Bias: -104078520294.138962, T: 1536, Avg. loss: 815710335080812579750150144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 533547022949.17, NNZs: 2, Bias: -97625290372.313080, T: 1664, Avg. loss: 709156253369851664123559936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 198352794410.09, NNZs: 2, Bias: -96224326273.204391, T: 1792, Avg. loss: 906238603319386979260432384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 320558866036.32, NNZs: 2, Bias: -86551495029.894409, T: 1920, Avg. loss: 793053455608076396021153792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 254340697228.75, NNZs: 2, Bias: -112729240636.492752, T: 2048, Avg. loss: 752586981221949577610919936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 307599757452.70, NNZs: 2, Bias: -118803669692.176224, T: 2176, Avg. loss: 827975425571718408808955904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 134810589392.30, NNZs: 2, Bias: -117790199030.403809, T: 2304, Avg. loss: 850200513172717226726260736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 57139341954.23, NNZs: 2, Bias: -118703830396.250397, T: 2432, Avg. loss: 30403523171069022846320640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 7650202051.08, NNZs: 2, Bias: -120059108236.270264, T: 2560, Avg. loss: 27600039236894353233281024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 16773290404.61, NNZs: 2, Bias: -121062096165.256332, T: 2688, Avg. loss: 31145263423142481994186752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 68396329454.65, NNZs: 2, Bias: -119060320488.252975, T: 2816, Avg. loss: 25641463917168280568070144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 27032450109.57, NNZs: 2, Bias: -119619995646.898529, T: 2944, Avg. loss: 28242030254373489652793344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 60257656858.52, NNZs: 2, Bias: -119385405943.361237, T: 3072, Avg. loss: 30254234092753393207476224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 25962758891.45, NNZs: 2, Bias: -116410886320.177750, T: 3200, Avg. loss: 31180750239980574256136192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 79040778529.96, NNZs: 2, Bias: -117895422077.015869, T: 3328, Avg. loss: 29370904048071717387501568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 14858198657.82, NNZs: 2, Bias: -116600256418.257034, T: 3456, Avg. loss: 29406892924092404952203264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1008287291.00, NNZs: 2, Bias: -116527864933.943344, T: 3584, Avg. loss: 405415790251889517395968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2335551354.12, NNZs: 2, Bias: -116090476066.726654, T: 3712, Avg. loss: 535083703230837532131328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 7219457791.74, NNZs: 2, Bias: -116443636246.786774, T: 3840, Avg. loss: 422060009977917644734464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 18296944613.29, NNZs: 2, Bias: -116251888150.010773, T: 3968, Avg. loss: 509711352753033599516672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8063390863.68, NNZs: 2, Bias: -116044182662.950287, T: 4096, Avg. loss: 596740404165518865465344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4922045706.08, NNZs: 2, Bias: -115865610059.770218, T: 4224, Avg. loss: 627195213783441558470656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3280239818.88, NNZs: 2, Bias: -115852272911.047882, T: 4352, Avg. loss: 2717624294886854885376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2668308213.35, NNZs: 2, Bias: -115825871231.049530, T: 4480, Avg. loss: 1646257176820245331968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2226778475.09, NNZs: 2, Bias: -115792960517.618073, T: 4608, Avg. loss: 1591232784666293960704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2037925543.20, NNZs: 2, Bias: -115755243797.965424, T: 4736, Avg. loss: 1531569940641316339712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2092544050.47, NNZs: 2, Bias: -115719419881.348984, T: 4864, Avg. loss: 1207440280183710154752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1942727968.63, NNZs: 2, Bias: -115684176121.510559, T: 4992, Avg. loss: 1353750184271508406272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1970545600.57, NNZs: 2, Bias: -115643888930.759796, T: 5120, Avg. loss: 1409504120937290137600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1922112860.26, NNZs: 2, Bias: -115605685040.035461, T: 5248, Avg. loss: 1428279120050245074944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1861844309.92, NNZs: 2, Bias: -115567668911.990051, T: 5376, Avg. loss: 1364881016303627796480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1778652372.68, NNZs: 2, Bias: -115529930069.376083, T: 5504, Avg. loss: 1446115674630843793408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1830816754.02, NNZs: 2, Bias: -115521137825.476212, T: 5632, Avg. loss: 1163574759814406078464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1826267949.50, NNZs: 2, Bias: -115513391798.245300, T: 5760, Avg. loss: 1140444262160247947264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1819146344.78, NNZs: 2, Bias: -115505659708.091095, T: 5888, Avg. loss: 1146253576023185555456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1817500056.96, NNZs: 2, Bias: -115497855444.260025, T: 6016, Avg. loss: 1144362615843499933696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1835347947.20, NNZs: 2, Bias: -115489783684.054779, T: 6144, Avg. loss: 1136136317979530625024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1853478912.36, NNZs: 2, Bias: -115481680894.736420, T: 6272, Avg. loss: 1137069819561286828032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1827252500.78, NNZs: 2, Bias: -115474440160.666519, T: 6400, Avg. loss: 1119557222757964447744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1814690355.67, NNZs: 2, Bias: -115466763171.930725, T: 6528, Avg. loss: 1149376148382733434880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1830561014.92, NNZs: 2, Bias: -115458740139.177399, T: 6656, Avg. loss: 1132714454507954241536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1841237757.16, NNZs: 2, Bias: -115450847812.265823, T: 6784, Avg. loss: 1123614423486253236224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1849205611.98, NNZs: 2, Bias: -115442962534.421295, T: 6912, Avg. loss: 1131750809743245967360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1835232143.15, NNZs: 2, Bias: -115435270920.722488, T: 7040, Avg. loss: 1155525413040299573248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1835803885.56, NNZs: 2, Bias: -115433707187.204163, T: 7168, Avg. loss: 1102427578912029016064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1830066564.40, NNZs: 2, Bias: -115432243898.743805, T: 7296, Avg. loss: 1102542911778545205248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1829866048.85, NNZs: 2, Bias: -115430691116.884094, T: 7424, Avg. loss: 1103396121502051336192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1832219005.92, NNZs: 2, Bias: -115429094982.650375, T: 7552, Avg. loss: 1105291917621642133504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1833505788.62, NNZs: 2, Bias: -115427520706.854858, T: 7680, Avg. loss: 1101743285425287331840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1841360615.71, NNZs: 2, Bias: -115425843248.013199, T: 7808, Avg. loss: 1100441825524745895936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1840186599.73, NNZs: 2, Bias: -115424305334.101562, T: 7936, Avg. loss: 1103913813936803414016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1839499513.04, NNZs: 2, Bias: -115422760390.502060, T: 8064, Avg. loss: 1103353980672692715520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1839797047.63, NNZs: 2, Bias: -115421199385.283890, T: 8192, Avg. loss: 1103499674032058269696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1833882981.75, NNZs: 2, Bias: -115419739648.599167, T: 8320, Avg. loss: 1102079416933440946176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1843645315.05, NNZs: 2, Bias: -115418032444.058884, T: 8448, Avg. loss: 1099749721781332869120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1833823718.50, NNZs: 2, Bias: -115416642092.697723, T: 8576, Avg. loss: 1097287216180367327232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1836480487.61, NNZs: 2, Bias: -115415042324.450058, T: 8704, Avg. loss: 1104255240704668729344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1847900095.38, NNZs: 2, Bias: -115413316013.363403, T: 8832, Avg. loss: 1094231451776223412224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1844203737.60, NNZs: 2, Bias: -115411815104.381256, T: 8960, Avg. loss: 1106357360151600168960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1850483733.86, NNZs: 2, Bias: -115410170161.955322, T: 9088, Avg. loss: 1094763412760526716928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1842872381.31, NNZs: 2, Bias: -115408732666.886841, T: 9216, Avg. loss: 1105964423640737906688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1836689343.69, NNZs: 2, Bias: -115407282370.120834, T: 9344, Avg. loss: 1098344625972831715328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1844373431.35, NNZs: 2, Bias: -115405604968.467300, T: 9472, Avg. loss: 1101894769563908964352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 74 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1335900471366.71, NNZs: 2, Bias: 71878226650.120483, T: 128, Avg. loss: 18358903794877218135407067136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 383801510937.04, NNZs: 2, Bias: 4457313619.671883, T: 256, Avg. loss: 22937932731142111484060893184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1373984210266.58, NNZs: 2, Bias: -29855659459.550568, T: 384, Avg. loss: 20763053180434393637561827328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2250083810105.74, NNZs: 2, Bias: -57933901401.414108, T: 512, Avg. loss: 20000270365605138658733588480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1830663408627.34, NNZs: 2, Bias: -2857887498.783157, T: 640, Avg. loss: 22713244938192984164060364800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1594012652921.24, NNZs: 2, Bias: 5940242283.160080, T: 768, Avg. loss: 20847481773580106485723037696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 120479913700.42, NNZs: 2, Bias: -18844969994.641502, T: 896, Avg. loss: 1717220208933992469513633792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 505762937949.74, NNZs: 2, Bias: -30005135363.939976, T: 1024, Avg. loss: 823730921141721677393035264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 313411966367.97, NNZs: 2, Bias: -26791629839.748802, T: 1152, Avg. loss: 876542576028851284371046400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 157972350783.95, NNZs: 2, Bias: -53066006626.266808, T: 1280, Avg. loss: 906833748290181724601581568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 158373801714.75, NNZs: 2, Bias: -66041749606.098480, T: 1408, Avg. loss: 809490669355896064012451840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 305731286726.97, NNZs: 2, Bias: -55173191802.520004, T: 1536, Avg. loss: 847021620453494342488686592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 44513430818.40, NNZs: 2, Bias: -38672029442.073540, T: 1664, Avg. loss: 843478300622170890889592832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 238942535783.03, NNZs: 2, Bias: -40741333288.349251, T: 1792, Avg. loss: 738990895294657351131332608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 284235784841.72, NNZs: 2, Bias: -18301871688.494480, T: 1920, Avg. loss: 847143511464872854077571072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 170228970234.33, NNZs: 2, Bias: -11755741484.180580, T: 2048, Avg. loss: 846473236035959249891753984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 544928890289.17, NNZs: 2, Bias: -19540437370.331200, T: 2176, Avg. loss: 834358123213515205554208768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 416007616519.78, NNZs: 2, Bias: -35848477556.844109, T: 2304, Avg. loss: 834911099589448443612889088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 32130719511.88, NNZs: 2, Bias: -36475142851.817001, T: 2432, Avg. loss: 779175420468174410211131392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 65429978990.39, NNZs: 2, Bias: -37215049431.520142, T: 2560, Avg. loss: 28420524850510686270259200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 31375702997.23, NNZs: 2, Bias: -39600023266.799721, T: 2688, Avg. loss: 32197947455243092920107008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 29311144416.52, NNZs: 2, Bias: -38824603407.750130, T: 2816, Avg. loss: 32257046211860726441574400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 94828590227.91, NNZs: 2, Bias: -36566923499.374527, T: 2944, Avg. loss: 30034618971746420159152128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 21762468931.59, NNZs: 2, Bias: -37608846809.832443, T: 3072, Avg. loss: 27126359053317465056477184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 6663834574.66, NNZs: 2, Bias: -38553499934.061508, T: 3200, Avg. loss: 30463968425638433986183168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 45038269733.18, NNZs: 2, Bias: -38030923658.184753, T: 3328, Avg. loss: 28469667531309884567977984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 42173234525.09, NNZs: 2, Bias: -38506770365.499725, T: 3456, Avg. loss: 30614601683524688621338624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 40592855351.11, NNZs: 2, Bias: -37317821758.746376, T: 3584, Avg. loss: 27994392558136636364292096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 59791357431.10, NNZs: 2, Bias: -37021468085.983940, T: 3712, Avg. loss: 32083804443229603995058176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5417749194.93, NNZs: 2, Bias: -37350381663.221153, T: 3840, Avg. loss: 1384029722002442508304384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 3849829642.05, NNZs: 2, Bias: -37273193206.540916, T: 3968, Avg. loss: 598270575178085063196672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5399838504.70, NNZs: 2, Bias: -37186216949.908134, T: 4096, Avg. loss: 517336736736258677538816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 11704372634.76, NNZs: 2, Bias: -37082649421.724625, T: 4224, Avg. loss: 474358263094921897443328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4205828477.60, NNZs: 2, Bias: -36978555894.487030, T: 4352, Avg. loss: 566255364287733740601344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3155364476.87, NNZs: 2, Bias: -37050467809.488457, T: 4480, Avg. loss: 550520076780585311272960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5663491005.99, NNZs: 2, Bias: -36875770853.203506, T: 4608, Avg. loss: 531568047861807800385536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5336137445.41, NNZs: 2, Bias: -36986055915.823318, T: 4736, Avg. loss: 459824018508797584605184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 10881506729.46, NNZs: 2, Bias: -36973470180.388969, T: 4864, Avg. loss: 728340133451565027557376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9027744408.70, NNZs: 2, Bias: -37069726573.165176, T: 4992, Avg. loss: 575476868290137785630720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 10845323353.55, NNZs: 2, Bias: -36435843299.356979, T: 5120, Avg. loss: 580808551797448098447360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1456377499.02, NNZs: 2, Bias: -36625536762.277275, T: 5248, Avg. loss: 487222373719809066008576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 5339864858.82, NNZs: 2, Bias: -36480452332.256645, T: 5376, Avg. loss: 448199945833585850712064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1272307060.19, NNZs: 2, Bias: -36578190348.962715, T: 5504, Avg. loss: 410650177021854112284672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 6843958279.57, NNZs: 2, Bias: -36948146676.708984, T: 5632, Avg. loss: 554205301471270542508032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 10427245253.66, NNZs: 2, Bias: -36844432515.192139, T: 5760, Avg. loss: 531345603313551886254080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 5317284784.34, NNZs: 2, Bias: -36871066615.258270, T: 5888, Avg. loss: 522452435810083779117056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 10799442036.39, NNZs: 2, Bias: -36305176054.758804, T: 6016, Avg. loss: 667441359357428377845760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 6514323043.69, NNZs: 2, Bias: -36241055358.362167, T: 6144, Avg. loss: 483995850178097183719424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2040440582.01, NNZs: 2, Bias: -36288773728.840195, T: 6272, Avg. loss: 5293681576946043977728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1414119672.72, NNZs: 2, Bias: -36286858119.432785, T: 6400, Avg. loss: 420841046655085903872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1051981103.60, NNZs: 2, Bias: -36282429723.642059, T: 6528, Avg. loss: 201173653563664859136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 863455642.92, NNZs: 2, Bias: -36274570568.909004, T: 6656, Avg. loss: 155247599398942703616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 764093120.98, NNZs: 2, Bias: -36264955092.237106, T: 6784, Avg. loss: 137895604240147857408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 674710957.20, NNZs: 2, Bias: -36254701501.723335, T: 6912, Avg. loss: 142005737273290244096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 665617079.84, NNZs: 2, Bias: -36244046028.607567, T: 7040, Avg. loss: 120677650331552333824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 672447667.61, NNZs: 2, Bias: -36231680959.760826, T: 7168, Avg. loss: 134118919686455738368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 659208680.38, NNZs: 2, Bias: -36221142473.119522, T: 7296, Avg. loss: 117843608142228930560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 657007229.77, NNZs: 2, Bias: -36210771578.420158, T: 7424, Avg. loss: 113044127600916758528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 622610780.33, NNZs: 2, Bias: -36199323218.378372, T: 7552, Avg. loss: 137464179308638797824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 623479152.88, NNZs: 2, Bias: -36187883264.183792, T: 7680, Avg. loss: 129468007900891316224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 640092662.08, NNZs: 2, Bias: -36176528926.716843, T: 7808, Avg. loss: 124464332357970952192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 658081275.27, NNZs: 2, Bias: -36165130924.788803, T: 7936, Avg. loss: 123124059690414456832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 672851777.98, NNZs: 2, Bias: -36153819183.091240, T: 8064, Avg. loss: 122239927048394129408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 645939177.43, NNZs: 2, Bias: -36152011110.916016, T: 8192, Avg. loss: 105376345689266208768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 644358910.21, NNZs: 2, Bias: -36149805351.196442, T: 8320, Avg. loss: 101732386763983224832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 656668853.66, NNZs: 2, Bias: -36147322621.387794, T: 8448, Avg. loss: 103003706968696881152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 649591511.32, NNZs: 2, Bias: -36145193828.433617, T: 8576, Avg. loss: 103562802704681238528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 651935967.71, NNZs: 2, Bias: -36142890464.174255, T: 8704, Avg. loss: 102941694693943525376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 639997785.37, NNZs: 2, Bias: -36140862591.310196, T: 8832, Avg. loss: 102291852454134448128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 638705379.54, NNZs: 2, Bias: -36138610334.186432, T: 8960, Avg. loss: 103780409169785634816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 640535595.15, NNZs: 2, Bias: -36138122788.734604, T: 9088, Avg. loss: 101000031051364728832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 639846860.03, NNZs: 2, Bias: -36137683401.933990, T: 9216, Avg. loss: 100244299117297319936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 640308550.99, NNZs: 2, Bias: -36137222575.122040, T: 9344, Avg. loss: 100464577614309834752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 639386824.19, NNZs: 2, Bias: -36136789013.551872, T: 9472, Avg. loss: 99857271294765924352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 638776878.91, NNZs: 2, Bias: -36136347671.733841, T: 9600, Avg. loss: 100359428536269225984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 639095811.03, NNZs: 2, Bias: -36135889285.349342, T: 9728, Avg. loss: 100486026533553618944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 640683013.89, NNZs: 2, Bias: -36135409157.743080, T: 9856, Avg. loss: 100298717738779344896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 640141367.11, NNZs: 2, Bias: -36134966007.281044, T: 9984, Avg. loss: 100494932403097485312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 638992423.65, NNZs: 2, Bias: -36134534184.496765, T: 10112, Avg. loss: 100365401065454059520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 79 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1127399875567.02, NNZs: 2, Bias: -6701807064.541988, T: 128, Avg. loss: 23697899658461803588559568896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1670431471248.28, NNZs: 2, Bias: -39901265153.101395, T: 256, Avg. loss: 23128826514154154348802736128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 881086853425.02, NNZs: 2, Bias: -159901265153.101379, T: 384, Avg. loss: 22327002883122157963649744896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 945842210430.68, NNZs: 2, Bias: -102933948376.809570, T: 512, Avg. loss: 24072880266041953634679259136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1035809189481.45, NNZs: 2, Bias: -164018599585.040283, T: 640, Avg. loss: 21153002368572761099183587328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1507583063618.71, NNZs: 2, Bias: -137554424462.840942, T: 768, Avg. loss: 22388554742503272521444360192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 517838910731.92, NNZs: 2, Bias: -107838454123.511902, T: 896, Avg. loss: 21489876579730589944599543808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 644916717351.79, NNZs: 2, Bias: -56738402682.641502, T: 1024, Avg. loss: 21711586062352292960182206464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1771400579783.01, NNZs: 2, Bias: -80724477967.062668, T: 1152, Avg. loss: 19328746328646640635119403008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2357587709917.17, NNZs: 2, Bias: -99232377504.728836, T: 1280, Avg. loss: 23181560783205962924808994816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 768974115595.28, NNZs: 2, Bias: -159232377504.728821, T: 1408, Avg. loss: 22023247377436929356436865024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2421202009488.10, NNZs: 2, Bias: -139232377504.728821, T: 1536, Avg. loss: 20857194116660303338653351936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1102164972273.41, NNZs: 2, Bias: -158166451833.918457, T: 1664, Avg. loss: 22942083125589548779171741696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 735003881879.26, NNZs: 2, Bias: -177880044900.588379, T: 1792, Avg. loss: 22461942811497623142898073600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 511048108458.81, NNZs: 2, Bias: -179076425438.788788, T: 1920, Avg. loss: 867708268662646833693065216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 113373368009.82, NNZs: 2, Bias: -192648590631.403290, T: 2048, Avg. loss: 948087678407799224043307008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 207565624293.66, NNZs: 2, Bias: -217469903290.095215, T: 2176, Avg. loss: 874172835991680923761377280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 82211034039.87, NNZs: 2, Bias: -216718924506.241058, T: 2304, Avg. loss: 882755022652011406090567680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 522911748480.16, NNZs: 2, Bias: -248665215560.669586, T: 2432, Avg. loss: 934968831733583611481292800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 519644531350.26, NNZs: 2, Bias: -250710815360.232330, T: 2560, Avg. loss: 888702395474429568375324672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 118011600636.93, NNZs: 2, Bias: -251755098904.954285, T: 2688, Avg. loss: 72448606834417874860244992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 30510020065.66, NNZs: 2, Bias: -252836482992.668549, T: 2816, Avg. loss: 32724143923960593778737152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 70269624579.29, NNZs: 2, Bias: -251585526960.421356, T: 2944, Avg. loss: 34745320446940719968419840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 21160685947.67, NNZs: 2, Bias: -249327281719.710205, T: 3072, Avg. loss: 32784168867848308387741696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 28742809895.20, NNZs: 2, Bias: -249653907868.987610, T: 3200, Avg. loss: 32898145547254266610057216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 32038217923.31, NNZs: 2, Bias: -246265539620.061920, T: 3328, Avg. loss: 33484285746711091222675456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 13995762813.91, NNZs: 2, Bias: -243958305371.879242, T: 3456, Avg. loss: 32990400169177865835773952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 11805476899.03, NNZs: 2, Bias: -243830954517.599731, T: 3584, Avg. loss: 804863556601001489203200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8587979236.22, NNZs: 2, Bias: -243376747480.765106, T: 3712, Avg. loss: 816622125464149198635008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2181131879.73, NNZs: 2, Bias: -242990835908.248688, T: 3840, Avg. loss: 745382824921341926309888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2878677037.11, NNZs: 2, Bias: -242474682909.601562, T: 3968, Avg. loss: 766727472349533872062464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2294657503.72, NNZs: 2, Bias: -241904139441.225189, T: 4096, Avg. loss: 734983721234409738731520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3546512472.97, NNZs: 2, Bias: -241370181777.223999, T: 4224, Avg. loss: 741821500868642429992960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7394794154.93, NNZs: 2, Bias: -241200138718.364441, T: 4352, Avg. loss: 827606005207957795504128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 12472862194.97, NNZs: 2, Bias: -240911355971.243103, T: 4480, Avg. loss: 644723664596374248226816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2995606598.06, NNZs: 2, Bias: -240381491926.064117, T: 4608, Avg. loss: 810217443462731899338752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3469429116.25, NNZs: 2, Bias: -239999673175.167542, T: 4736, Avg. loss: 719717557960310893051904.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 10834947146.55, NNZs: 2, Bias: -239767399265.766266, T: 4864, Avg. loss: 724059925094642124587008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 7613997307.36, NNZs: 2, Bias: -239693656305.092438, T: 4992, Avg. loss: 737471234530028206161920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 10151526609.08, NNZs: 2, Bias: -239592347783.521790, T: 5120, Avg. loss: 713822068706342747504640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1359700237.13, NNZs: 2, Bias: -239501234016.504791, T: 5248, Avg. loss: 26299417708463283765248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1684060532.23, NNZs: 2, Bias: -239402812305.659790, T: 5376, Avg. loss: 6807710534818357837824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2845802718.74, NNZs: 2, Bias: -239305435841.215607, T: 5504, Avg. loss: 6011750035032188649472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3238678455.12, NNZs: 2, Bias: -239215438113.036133, T: 5632, Avg. loss: 6139423859068388769792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3300423698.89, NNZs: 2, Bias: -239134763850.311798, T: 5760, Avg. loss: 5838820789431685873664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3566799482.66, NNZs: 2, Bias: -239048892784.653137, T: 5888, Avg. loss: 6044908727168265093120.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3683833001.01, NNZs: 2, Bias: -238970334375.978516, T: 6016, Avg. loss: 5573119174305320534016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3855140220.44, NNZs: 2, Bias: -238884647554.552429, T: 6144, Avg. loss: 6221681824102794395648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3816454369.57, NNZs: 2, Bias: -238811069728.129578, T: 6272, Avg. loss: 5447874850770548424704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3593459863.23, NNZs: 2, Bias: -238733127903.053070, T: 6400, Avg. loss: 6117500688638400266240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3492588693.88, NNZs: 2, Bias: -238653933567.716248, T: 6528, Avg. loss: 5794866153277286776832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3526251350.85, NNZs: 2, Bias: -238571803027.020874, T: 6656, Avg. loss: 6117876163366851969024.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3595701886.74, NNZs: 2, Bias: -238492342175.332642, T: 6784, Avg. loss: 5753537636085975220224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3919889442.39, NNZs: 2, Bias: -238407353209.663086, T: 6912, Avg. loss: 5884696639232700055552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3797733662.30, NNZs: 2, Bias: -238392968256.901672, T: 7040, Avg. loss: 4946092333289727590400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3770380848.51, NNZs: 2, Bias: -238377380351.025330, T: 7168, Avg. loss: 4833580716828338946048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3785231102.78, NNZs: 2, Bias: -238360968575.356079, T: 7296, Avg. loss: 4876229961868676956160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3758812209.53, NNZs: 2, Bias: -238345113022.900665, T: 7424, Avg. loss: 4906068954089358622720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3752714842.64, NNZs: 2, Bias: -238329264510.006805, T: 7552, Avg. loss: 4798792321246160748544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3758171863.07, NNZs: 2, Bias: -238313116643.846161, T: 7680, Avg. loss: 4839820393243852406784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3742461444.22, NNZs: 2, Bias: -238297131707.983673, T: 7808, Avg. loss: 4890561313013078425600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3680820633.47, NNZs: 2, Bias: -238282266815.136139, T: 7936, Avg. loss: 4772491290198742663168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3768257550.15, NNZs: 2, Bias: -238264689464.676239, T: 8064, Avg. loss: 4868873608639469846528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3793710707.63, NNZs: 2, Bias: -238248289367.461700, T: 8192, Avg. loss: 4807067836206622441472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3736582673.91, NNZs: 2, Bias: -238233196266.744568, T: 8320, Avg. loss: 4814999783959246667776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3718378403.97, NNZs: 2, Bias: -238217304921.154541, T: 8448, Avg. loss: 4872497154656232800256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3678783133.49, NNZs: 2, Bias: -238201907094.540192, T: 8576, Avg. loss: 4821778802509825966080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3717258498.99, NNZs: 2, Bias: -238198071606.428070, T: 8704, Avg. loss: 4735019923968959184896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3718032633.73, NNZs: 2, Bias: -238194859391.758453, T: 8832, Avg. loss: 4682440783714512273408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3707989225.53, NNZs: 2, Bias: -238191820439.450562, T: 8960, Avg. loss: 4676595400837394071552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 3706678248.45, NNZs: 2, Bias: -238188638524.086945, T: 9088, Avg. loss: 4685853374146606006272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 3719783399.80, NNZs: 2, Bias: -238185227452.389893, T: 9216, Avg. loss: 4690553538661802573824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 3736885222.39, NNZs: 2, Bias: -238181789270.008545, T: 9344, Avg. loss: 4636578055839541100544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 3737044971.59, NNZs: 2, Bias: -238178585696.607544, T: 9472, Avg. loss: 4683372344299193630720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 3728422819.41, NNZs: 2, Bias: -238175520886.937012, T: 9600, Avg. loss: 4682914895273311862784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 3721476900.51, NNZs: 2, Bias: -238172426556.777588, T: 9728, Avg. loss: 4686735573948311273472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 3710712100.58, NNZs: 2, Bias: -238169401061.501495, T: 9856, Avg. loss: 4673028819185632804864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 3729346218.78, NNZs: 2, Bias: -238165911087.123383, T: 9984, Avg. loss: 4678574440207687352320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 78 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2201451875587.22, NNZs: 2, Bias: 84040723253.010529, T: 128, Avg. loss: 21259560591695459799070146560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 550899796125.87, NNZs: 2, Bias: 138029350252.574036, T: 256, Avg. loss: 24580571241603240944316973056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 890655212811.13, NNZs: 2, Bias: 202663789990.440826, T: 384, Avg. loss: 25300696777734586297015599104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1676037081535.75, NNZs: 2, Bias: 182663789990.440826, T: 512, Avg. loss: 22711735840712723445154054144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1068188253722.85, NNZs: 2, Bias: 222663789990.440826, T: 640, Avg. loss: 22545808992276804461811204096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 184212975700.75, NNZs: 2, Bias: 127576909041.178589, T: 768, Avg. loss: 23183795767206346361627738112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 289962097939.28, NNZs: 2, Bias: 115656340064.096512, T: 896, Avg. loss: 937270002444650497815085056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 222616902627.43, NNZs: 2, Bias: 101583394382.633820, T: 1024, Avg. loss: 890808311470759026989465600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 146113162423.93, NNZs: 2, Bias: 86477372626.958328, T: 1152, Avg. loss: 916776715343432373497757696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 380380211687.19, NNZs: 2, Bias: 82729612318.160385, T: 1280, Avg. loss: 927195465780310733697843200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 78680461075.43, NNZs: 2, Bias: 86157894210.774704, T: 1408, Avg. loss: 899137035380497885494771712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 317092025375.07, NNZs: 2, Bias: 89915860546.893341, T: 1536, Avg. loss: 919733846537128822309912576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 255916693039.91, NNZs: 2, Bias: 83368840207.843185, T: 1664, Avg. loss: 911406640769879341084442624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 73453155256.17, NNZs: 2, Bias: 82838533532.625000, T: 1792, Avg. loss: 47432039098890785591918592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 83522574253.31, NNZs: 2, Bias: 86660698526.000778, T: 1920, Avg. loss: 35228005730733651608469504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 23382692401.51, NNZs: 2, Bias: 88557365735.530365, T: 2048, Avg. loss: 34808160794808266788962304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 77579848434.77, NNZs: 2, Bias: 89488526461.670242, T: 2176, Avg. loss: 32543335755090278758744064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 26760902245.11, NNZs: 2, Bias: 89301717730.842331, T: 2304, Avg. loss: 35990929400358785028980736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 78368965725.34, NNZs: 2, Bias: 90978011426.008621, T: 2432, Avg. loss: 34369115811869183380029440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 26210544316.47, NNZs: 2, Bias: 91068849045.067169, T: 2560, Avg. loss: 34351737069117510577553408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 28158729796.51, NNZs: 2, Bias: 88918014551.539093, T: 2688, Avg. loss: 33948696643283072168493056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 58783019147.69, NNZs: 2, Bias: 90550118614.135101, T: 2816, Avg. loss: 33267193950419860485832704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1997506400.79, NNZs: 2, Bias: 90589920663.387360, T: 2944, Avg. loss: 1725014815462557113909248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 17165099595.01, NNZs: 2, Bias: 90575369155.764206, T: 3072, Avg. loss: 648387897120906203365376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 5078056963.11, NNZs: 2, Bias: 90510622080.335754, T: 3200, Avg. loss: 618756207876313752535040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 9768905315.91, NNZs: 2, Bias: 90354067680.163559, T: 3328, Avg. loss: 784897878910606212333568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 12054247350.80, NNZs: 2, Bias: 90223408584.955765, T: 3456, Avg. loss: 812981123343395233726464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 14074750107.09, NNZs: 2, Bias: 89948544389.213150, T: 3584, Avg. loss: 595807230287523491086336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 15001917776.27, NNZs: 2, Bias: 89882052434.158218, T: 3712, Avg. loss: 643768723912521427189760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2981712462.48, NNZs: 2, Bias: 90008199205.663864, T: 3840, Avg. loss: 787325452810456330665984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4681304185.07, NNZs: 2, Bias: 89937431245.062347, T: 3968, Avg. loss: 838304672836967934722048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 7313796069.22, NNZs: 2, Bias: 90115051266.321518, T: 4096, Avg. loss: 814993070205092306616320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 12710670282.28, NNZs: 2, Bias: 89938397933.480331, T: 4224, Avg. loss: 647626594927547621834752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2994513404.67, NNZs: 2, Bias: 89976748885.174026, T: 4352, Avg. loss: 50900715571884429672448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2103068157.04, NNZs: 2, Bias: 89965106578.172684, T: 4480, Avg. loss: 1124430549098271342592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1685900665.99, NNZs: 2, Bias: 89946673103.619736, T: 4608, Avg. loss: 787753044960388448256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1518393082.96, NNZs: 2, Bias: 89921982543.391403, T: 4736, Avg. loss: 809516280624896933888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1401610962.42, NNZs: 2, Bias: 89898309768.582794, T: 4864, Avg. loss: 689738472437324709888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1416479650.92, NNZs: 2, Bias: 89872453047.410034, T: 4992, Avg. loss: 714955048829649289216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1346115180.27, NNZs: 2, Bias: 89846297159.646698, T: 5120, Avg. loss: 765005965490133532672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1317600570.57, NNZs: 2, Bias: 89819802619.526505, T: 5248, Avg. loss: 752190545572059152384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1280850648.23, NNZs: 2, Bias: 89793921910.649597, T: 5376, Avg. loss: 717484489739007295488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1315960206.05, NNZs: 2, Bias: 89767513025.421814, T: 5504, Avg. loss: 704894823500909510656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1338030471.08, NNZs: 2, Bias: 89761930180.066589, T: 5632, Avg. loss: 594320583088847585280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1333633908.24, NNZs: 2, Bias: 89756796373.334747, T: 5760, Avg. loss: 589277131747410771968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1314853717.80, NNZs: 2, Bias: 89751806256.003265, T: 5888, Avg. loss: 597451688271821275136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1325711318.85, NNZs: 2, Bias: 89746445052.844269, T: 6016, Avg. loss: 586755413632533004288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1317253987.98, NNZs: 2, Bias: 89741348969.201111, T: 6144, Avg. loss: 589992744775244775424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1315644421.77, NNZs: 2, Bias: 89736132954.584991, T: 6272, Avg. loss: 591992672703799361536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1339893275.40, NNZs: 2, Bias: 89730593399.363068, T: 6400, Avg. loss: 584488685857072742400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1331859050.15, NNZs: 2, Bias: 89725419193.508316, T: 6528, Avg. loss: 599379545279405359104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1344993259.73, NNZs: 2, Bias: 89720050095.456772, T: 6656, Avg. loss: 584738380322074460160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1319854415.82, NNZs: 2, Bias: 89715131283.211700, T: 6784, Avg. loss: 598689860050343821312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1321477347.55, NNZs: 2, Bias: 89709882376.795654, T: 6912, Avg. loss: 590093782570595385344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1324520396.22, NNZs: 2, Bias: 89704543930.190063, T: 7040, Avg. loss: 598934006710350905344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1324186923.41, NNZs: 2, Bias: 89703505732.782852, T: 7168, Avg. loss: 574588088828121448448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1327157947.58, NNZs: 2, Bias: 89702420162.867737, T: 7296, Avg. loss: 573706814519560765440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1325747499.21, NNZs: 2, Bias: 89701398058.952576, T: 7424, Avg. loss: 574606253803678990336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1318893300.16, NNZs: 2, Bias: 89700460233.003128, T: 7552, Avg. loss: 572387519884889686016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1323961117.67, NNZs: 2, Bias: 89699346201.931946, T: 7680, Avg. loss: 572299031762830884864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1325857696.79, NNZs: 2, Bias: 89698275808.484451, T: 7808, Avg. loss: 574141628304217473024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1330446518.89, NNZs: 2, Bias: 89697170411.801559, T: 7936, Avg. loss: 571356564726857269248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1330596490.12, NNZs: 2, Bias: 89696129431.376633, T: 8064, Avg. loss: 572122715645126311936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1327472472.23, NNZs: 2, Bias: 89695130169.671051, T: 8192, Avg. loss: 575945245630905057280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1325122025.55, NNZs: 2, Bias: 89694120289.856491, T: 8320, Avg. loss: 575467505406697209856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1327616555.16, NNZs: 2, Bias: 89693041482.706985, T: 8448, Avg. loss: 573798351336312012800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1327696736.02, NNZs: 2, Bias: 89691997326.177414, T: 8576, Avg. loss: 574442544972615909376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 67 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 658405683282.52, NNZs: 2, Bias: 22551327834.097214, T: 128, Avg. loss: 22474219235420127343711092736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 226002840598.50, NNZs: 2, Bias: 42551327834.097214, T: 256, Avg. loss: 22985930570731148423840399360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 200916668388.23, NNZs: 2, Bias: 70287840431.823700, T: 384, Avg. loss: 22338895455146139327408373760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1362592125931.07, NNZs: 2, Bias: 132304947075.086060, T: 512, Avg. loss: 22163894712996613615398158336.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1146944048605.09, NNZs: 2, Bias: 189127648036.833008, T: 640, Avg. loss: 21085740481819312726543958016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 306410057939.36, NNZs: 2, Bias: 259163838953.849487, T: 768, Avg. loss: 22668570575425307166340284416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 747873022109.90, NNZs: 2, Bias: 219163838953.849487, T: 896, Avg. loss: 21182375781372751079337361408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 428800448540.79, NNZs: 2, Bias: 225283513645.426117, T: 1024, Avg. loss: 22412765568561513369706692608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2014108345674.92, NNZs: 2, Bias: 325283513645.426147, T: 1152, Avg. loss: 19105639308302993482963746816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 313562124044.91, NNZs: 2, Bias: 365283513645.426147, T: 1280, Avg. loss: 21964833539899716156683976704.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 617270848488.77, NNZs: 2, Bias: 405283513645.426147, T: 1408, Avg. loss: 19034800774660976258043609088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1266491807802.85, NNZs: 2, Bias: 368091427492.770081, T: 1536, Avg. loss: 21916280783566566059967250432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1186823111368.10, NNZs: 2, Bias: 341343495565.310913, T: 1664, Avg. loss: 21183836151153961315281666048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 577226824295.93, NNZs: 2, Bias: 364342245369.142761, T: 1792, Avg. loss: 19286450586138605476955291648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 185231515848.21, NNZs: 2, Bias: 347621577159.239014, T: 1920, Avg. loss: 20242776983700321807022161920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2653157046689.27, NNZs: 2, Bias: 372937361589.941650, T: 2048, Avg. loss: 22083550092613929962861232128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 85387013819.53, NNZs: 2, Bias: 417715529457.669250, T: 2176, Avg. loss: 2625240942114860265149300736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 318246853051.14, NNZs: 2, Bias: 419283980280.167664, T: 2304, Avg. loss: 859687248432084680074854400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 380264539697.69, NNZs: 2, Bias: 424342703863.149719, T: 2432, Avg. loss: 851739165391167433234972672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 209631951700.38, NNZs: 2, Bias: 415296694982.840759, T: 2560, Avg. loss: 873729334829079779119988736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 155760339983.39, NNZs: 2, Bias: 428642058802.021729, T: 2688, Avg. loss: 821354252128636349469163520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100939557488.59, NNZs: 2, Bias: 419768590673.202332, T: 2816, Avg. loss: 828275801294456216296095744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 328357077785.73, NNZs: 2, Bias: 418557523885.073669, T: 2944, Avg. loss: 955185437778433057298055168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 392218527972.05, NNZs: 2, Bias: 422370418985.682434, T: 3072, Avg. loss: 870888707750783559208534016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 242025762240.77, NNZs: 2, Bias: 423034896177.651917, T: 3200, Avg. loss: 775956905997616824981651456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 80040379930.57, NNZs: 2, Bias: 422540876977.449707, T: 3328, Avg. loss: 846940668628444973621051392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 165218867081.99, NNZs: 2, Bias: 420013384501.140930, T: 3456, Avg. loss: 814850764442695152630235136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 161441001957.08, NNZs: 2, Bias: 428611846961.073975, T: 3584, Avg. loss: 865309687486060414111842304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 232988618859.14, NNZs: 2, Bias: 437675013087.835938, T: 3712, Avg. loss: 882510864355169764395450368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 87379351219.75, NNZs: 2, Bias: 457288011488.704529, T: 3840, Avg. loss: 819047471334101353068756992.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 50908983491.39, NNZs: 2, Bias: 453654102062.123291, T: 3968, Avg. loss: 31671299342969916771794944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 45859829712.52, NNZs: 2, Bias: 454280851004.290466, T: 4096, Avg. loss: 29718553338481368008491008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 19791331469.36, NNZs: 2, Bias: 454392693295.164246, T: 4224, Avg. loss: 31777101628585694153670656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 68230979532.14, NNZs: 2, Bias: 452752875400.617981, T: 4352, Avg. loss: 29386436493500873401434112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 40120277041.79, NNZs: 2, Bias: 450784417753.179626, T: 4480, Avg. loss: 32769630944477388119998464.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 27004357571.12, NNZs: 2, Bias: 455170549003.467651, T: 4608, Avg. loss: 32748491320115420259680256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 79796350925.37, NNZs: 2, Bias: 454072307949.743652, T: 4736, Avg. loss: 31286181584920014403665920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 55081743699.54, NNZs: 2, Bias: 456640665279.947327, T: 4864, Avg. loss: 32093087071750336857243648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 63447678574.81, NNZs: 2, Bias: 451626617984.216980, T: 4992, Avg. loss: 31883443885391118291959808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7665145671.93, NNZs: 2, Bias: 450913405588.196411, T: 5120, Avg. loss: 1930684151556263452344320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 15769641901.33, NNZs: 2, Bias: 450300246176.659180, T: 5248, Avg. loss: 722186548398748810084352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 10817095771.70, NNZs: 2, Bias: 449759308271.621094, T: 5376, Avg. loss: 826180780053401620709376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 6608964537.45, NNZs: 2, Bias: 449193478893.622742, T: 5504, Avg. loss: 683209307832748397821952.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5561906720.47, NNZs: 2, Bias: 448366853748.751099, T: 5632, Avg. loss: 787254471528395661377536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 15353576615.45, NNZs: 2, Bias: 447887460376.209717, T: 5760, Avg. loss: 731334543917747934330880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 22390885182.92, NNZs: 2, Bias: 447278010667.571960, T: 5888, Avg. loss: 767094619768188252979200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 24514750602.73, NNZs: 2, Bias: 446495911357.413513, T: 6016, Avg. loss: 787622723465083898298368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9300265954.77, NNZs: 2, Bias: 446221904503.098389, T: 6144, Avg. loss: 869463558678392975917056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 7985230331.90, NNZs: 2, Bias: 446076364937.326233, T: 6272, Avg. loss: 23063765583620231659520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 7806890869.13, NNZs: 2, Bias: 445934892031.295532, T: 6400, Avg. loss: 18666937863591109328896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 7540907799.70, NNZs: 2, Bias: 445783340859.757141, T: 6528, Avg. loss: 21107040129534604083200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 7225669945.48, NNZs: 2, Bias: 445620996723.975769, T: 6656, Avg. loss: 23418613976144170450944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 6964301296.58, NNZs: 2, Bias: 445468437148.150024, T: 6784, Avg. loss: 21533093926969643368448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 6707246515.69, NNZs: 2, Bias: 445310055224.505615, T: 6912, Avg. loss: 22702194319797516238848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 7071590906.76, NNZs: 2, Bias: 445150519787.738953, T: 7040, Avg. loss: 20464255600399162015744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 7060036993.58, NNZs: 2, Bias: 445119529613.521729, T: 7168, Avg. loss: 17482232700013406846976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 7102924467.20, NNZs: 2, Bias: 445087736049.578796, T: 7296, Avg. loss: 17439865296796189196288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 7120771893.15, NNZs: 2, Bias: 445055849610.406067, T: 7424, Avg. loss: 17723244296281964675072.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 7004746861.46, NNZs: 2, Bias: 445026439605.666443, T: 7552, Avg. loss: 17563506262945814282240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 7084086729.66, NNZs: 2, Bias: 444993890164.156128, T: 7680, Avg. loss: 17531775518066396364800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 7008949401.68, NNZs: 2, Bias: 444963825647.368469, T: 7808, Avg. loss: 17536151631525180342272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 7131809502.18, NNZs: 2, Bias: 444930361132.833496, T: 7936, Avg. loss: 17640547752002671607808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 7103895287.87, NNZs: 2, Bias: 444924519815.346619, T: 8064, Avg. loss: 17183127563866426310656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 7098324875.74, NNZs: 2, Bias: 444918349974.386169, T: 8192, Avg. loss: 17098026456729908150272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 7091266751.57, NNZs: 2, Bias: 444912210686.871216, T: 8320, Avg. loss: 17078237765779511574528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 7091279791.44, NNZs: 2, Bias: 444905956207.728638, T: 8448, Avg. loss: 17084221102346570039296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 7081422724.29, NNZs: 2, Bias: 444899868426.542908, T: 8576, Avg. loss: 17060059646075141619712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 7123407867.08, NNZs: 2, Bias: 444892984414.980225, T: 8704, Avg. loss: 16965584331595763941376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 7109267188.47, NNZs: 2, Bias: 444886956020.103516, T: 8832, Avg. loss: 17087436095096090525696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 7095770790.75, NNZs: 2, Bias: 444880915802.672852, T: 8960, Avg. loss: 17090007224689704828928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 7078370186.99, NNZs: 2, Bias: 444874954509.910278, T: 9088, Avg. loss: 17041963063171761569792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 7097613797.38, NNZs: 2, Bias: 444868387551.995300, T: 9216, Avg. loss: 17094936491442810388480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 7103319730.33, NNZs: 2, Bias: 444862041378.924622, T: 9344, Avg. loss: 17083707570773498527744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 73 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1012326717658.79, NNZs: 2, Bias: -96971760582.813309, T: 128, Avg. loss: 20134695857734354199086366720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1846836926543.05, NNZs: 2, Bias: -105410662993.771042, T: 256, Avg. loss: 20125980783784732723228180480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1077831853789.50, NNZs: 2, Bias: -45410662993.771042, T: 384, Avg. loss: 19506228959237813989384650752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1427604142345.17, NNZs: 2, Bias: -52979241524.006226, T: 512, Avg. loss: 20431152587070262911078236160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1033858678617.35, NNZs: 2, Bias: -52979241524.006226, T: 640, Avg. loss: 17765578571326788477158162432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2185011888495.49, NNZs: 2, Bias: 18113725275.948975, T: 768, Avg. loss: 20485207137576416669885005824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1566976846286.78, NNZs: 2, Bias: 75350209657.419250, T: 896, Avg. loss: 19733729068453175697642356736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1810681208467.67, NNZs: 2, Bias: 5688170894.677002, T: 1024, Avg. loss: 19612174870699650437554896896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 551242295361.44, NNZs: 2, Bias: -59152662663.577347, T: 1152, Avg. loss: 20117292000059445033283092480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1414524494372.74, NNZs: 2, Bias: -47521006274.275650, T: 1280, Avg. loss: 19584609388127153448231632896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 343786211780.96, NNZs: 2, Bias: -23917011643.363152, T: 1408, Avg. loss: 1099709313613834752853278720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 168549150290.39, NNZs: 2, Bias: -29784464413.908581, T: 1536, Avg. loss: 752505651910008222739595264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 217093138011.39, NNZs: 2, Bias: -24308577339.961132, T: 1664, Avg. loss: 798676129001669320276705280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 646366189447.97, NNZs: 2, Bias: -17619381982.448982, T: 1792, Avg. loss: 795456487715176191677693952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 444447296455.35, NNZs: 2, Bias: -25349838418.798779, T: 1920, Avg. loss: 785831963597128929374109696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 418547557153.40, NNZs: 2, Bias: -28965079763.090561, T: 2048, Avg. loss: 760511505641770701234896896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 200724300043.47, NNZs: 2, Bias: -35777941083.685822, T: 2176, Avg. loss: 806453875583259612620521472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11134418573.42, NNZs: 2, Bias: -30790730569.898026, T: 2304, Avg. loss: 29793806883060897399439360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 89587226073.12, NNZs: 2, Bias: -30273151763.624996, T: 2432, Avg. loss: 25878166903839343903768576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 51906927831.66, NNZs: 2, Bias: -28693707844.047115, T: 2560, Avg. loss: 30783809835870236746711040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11097464933.78, NNZs: 2, Bias: -31170538806.345993, T: 2688, Avg. loss: 31648278320140858775568384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 68718988997.43, NNZs: 2, Bias: -34059934033.315742, T: 2816, Avg. loss: 34076133693006397390716928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 39218170214.98, NNZs: 2, Bias: -35343727249.852463, T: 2944, Avg. loss: 29713450211843491479158784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 31610326529.65, NNZs: 2, Bias: -32596754742.834095, T: 3072, Avg. loss: 30102908760703127120773120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4487901201.79, NNZs: 2, Bias: -32533305693.376022, T: 3200, Avg. loss: 601963427282906041548800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10188480012.42, NNZs: 2, Bias: -32291440470.223381, T: 3328, Avg. loss: 570328989790165278916608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1215295884.42, NNZs: 2, Bias: -32226220282.098209, T: 3456, Avg. loss: 351146340035058944966656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4887227445.09, NNZs: 2, Bias: -32305444270.872997, T: 3584, Avg. loss: 564858584624274998296576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1895846998.47, NNZs: 2, Bias: -32244676991.132584, T: 3712, Avg. loss: 208254378397253431721984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 12384436603.67, NNZs: 2, Bias: -31985962052.948738, T: 3840, Avg. loss: 527074794975285571747840.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6267846491.29, NNZs: 2, Bias: -32114254003.262489, T: 3968, Avg. loss: 523318600625179594850304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5803857185.97, NNZs: 2, Bias: -32183835558.685345, T: 4096, Avg. loss: 381308416499296273170432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4262381058.21, NNZs: 2, Bias: -32237125167.113121, T: 4224, Avg. loss: 458593677290764624723968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 5199096321.27, NNZs: 2, Bias: -32195242444.614300, T: 4352, Avg. loss: 289306832234106700431360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1936179545.80, NNZs: 2, Bias: -32128759764.198299, T: 4480, Avg. loss: 4319676494303587205120.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 706401322.22, NNZs: 2, Bias: -32100440660.983444, T: 4608, Avg. loss: 758681285570506915840.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 182851538.87, NNZs: 2, Bias: -32078783892.337238, T: 4736, Avg. loss: 272209225813169963008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 255350201.81, NNZs: 2, Bias: -32064045469.504791, T: 4864, Avg. loss: 129300620417302986752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 366407739.00, NNZs: 2, Bias: -32050818502.692654, T: 4992, Avg. loss: 117183411590251331584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 443586094.75, NNZs: 2, Bias: -32038544630.448708, T: 5120, Avg. loss: 112313628606827347968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 450692635.94, NNZs: 2, Bias: -32027997202.842827, T: 5248, Avg. loss: 107537846459735408640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 446237183.99, NNZs: 2, Bias: -32016160174.729622, T: 5376, Avg. loss: 118875162028776210432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 478643726.07, NNZs: 2, Bias: -32004746134.175030, T: 5504, Avg. loss: 106103007518146904064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 506374884.49, NNZs: 2, Bias: -31994411945.064404, T: 5632, Avg. loss: 96620953751362568192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 516994922.24, NNZs: 2, Bias: -31983285711.454769, T: 5760, Avg. loss: 105563963543637393408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 537176999.18, NNZs: 2, Bias: -31972109424.876740, T: 5888, Avg. loss: 105381107839236390912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 478501015.03, NNZs: 2, Bias: -31962231422.532806, T: 6016, Avg. loss: 110088207380314505216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 464811305.58, NNZs: 2, Bias: -31950662106.424175, T: 6144, Avg. loss: 121761912688607657984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 503584141.47, NNZs: 2, Bias: -31939389969.843525, T: 6272, Avg. loss: 103077941239564845056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 501305907.50, NNZs: 2, Bias: -31937277882.701504, T: 6400, Avg. loss: 86793716197370183680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 501995763.76, NNZs: 2, Bias: -31935136554.376968, T: 6528, Avg. loss: 86092768637727490048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 519741145.16, NNZs: 2, Bias: -31932751027.515167, T: 6656, Avg. loss: 84588162251421564928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 508426508.36, NNZs: 2, Bias: -31930810426.284679, T: 6784, Avg. loss: 85772901778097111040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 508096028.09, NNZs: 2, Bias: -31928635495.826786, T: 6912, Avg. loss: 88074472738756280320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 508151271.80, NNZs: 2, Bias: -31926445306.902748, T: 7040, Avg. loss: 88320448449125974016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 512661919.93, NNZs: 2, Bias: -31924192053.169487, T: 7168, Avg. loss: 87974837885084598272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 513919983.01, NNZs: 2, Bias: -31922004894.528877, T: 7296, Avg. loss: 87391929856327385088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 511781440.49, NNZs: 2, Bias: -31921609492.346619, T: 7424, Avg. loss: 84308801681053499392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 511919687.09, NNZs: 2, Bias: -31921178467.697266, T: 7552, Avg. loss: 84104467792484057088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 512428220.06, NNZs: 2, Bias: -31920739897.053848, T: 7680, Avg. loss: 84397010914949922816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 512877688.75, NNZs: 2, Bias: -31920302051.490158, T: 7808, Avg. loss: 84442188766994235392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 513337176.40, NNZs: 2, Bias: -31919865684.378685, T: 7936, Avg. loss: 84119978823030161408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 512659742.11, NNZs: 2, Bias: -31919446382.086071, T: 8064, Avg. loss: 84377516834071642112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 511466750.65, NNZs: 2, Bias: -31919036975.804642, T: 8192, Avg. loss: 84060996237480656896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 512045399.72, NNZs: 2, Bias: -31918596894.302639, T: 8320, Avg. loss: 84470306871640915968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 512071271.90, NNZs: 2, Bias: -31918166682.097385, T: 8448, Avg. loss: 84282020291304538112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 512723329.46, NNZs: 2, Bias: -31917725511.672272, T: 8576, Avg. loss: 84445790589373923328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 513520141.90, NNZs: 2, Bias: -31917282823.119419, T: 8704, Avg. loss: 84277653778808324096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 513565988.32, NNZs: 2, Bias: -31916852812.516605, T: 8832, Avg. loss: 84163936474898317312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 69 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 872769017472.50, NNZs: 2, Bias: -17232488332.251091, T: 128, Avg. loss: 17850941406896123645742022656.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1135591420289.08, NNZs: 2, Bias: 22767511667.748909, T: 256, Avg. loss: 20551017918206340306231623680.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1167752390535.53, NNZs: 2, Bias: 2767511667.748901, T: 384, Avg. loss: 21924684589796390878769577984.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 273933188678.20, NNZs: 2, Bias: 42767511667.748901, T: 512, Avg. loss: 20639692200741645746182291456.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 849813688730.42, NNZs: 2, Bias: 22767511667.748901, T: 640, Avg. loss: 19492544511032521033464676352.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 798447478793.05, NNZs: 2, Bias: 115452613691.727448, T: 768, Avg. loss: 20335652618631562378535239680.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 216101692414.12, NNZs: 2, Bias: 119273910672.048584, T: 896, Avg. loss: 870904891250272129968504832.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 201094948795.71, NNZs: 2, Bias: 123756271562.114410, T: 1024, Avg. loss: 832395641133389796243144704.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 22064535941.89, NNZs: 2, Bias: 127742215036.567230, T: 1152, Avg. loss: 864871142763233148953165824.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 217664182928.01, NNZs: 2, Bias: 123398695112.978287, T: 1280, Avg. loss: 837698037718595137588690944.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 348255750610.34, NNZs: 2, Bias: 115775478245.955490, T: 1408, Avg. loss: 846233828652640196037181440.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 101673085724.42, NNZs: 2, Bias: 90831403174.759628, T: 1536, Avg. loss: 856580421467343358609326080.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 74170890806.59, NNZs: 2, Bias: 74993897443.592529, T: 1664, Avg. loss: 886862331361313847773233152.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 59904439858.95, NNZs: 2, Bias: 76191813953.223328, T: 1792, Avg. loss: 31089944785352997287755776.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 9008220140.52, NNZs: 2, Bias: 75405607142.932312, T: 1920, Avg. loss: 33709218022323750233440256.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 18930974013.57, NNZs: 2, Bias: 74700590244.454926, T: 2048, Avg. loss: 32037845709393551410855936.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 55257080614.38, NNZs: 2, Bias: 74029943955.267395, T: 2176, Avg. loss: 27177333746612858293059584.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 13116507653.03, NNZs: 2, Bias: 74065944168.162689, T: 2304, Avg. loss: 31585922815849533043376128.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40755747945.90, NNZs: 2, Bias: 71964767115.612534, T: 2432, Avg. loss: 30915576973485878991126528.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 41216393009.80, NNZs: 2, Bias: 73641989638.328613, T: 2560, Avg. loss: 30705500388370816188809216.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 93645473329.58, NNZs: 2, Bias: 74670944469.185776, T: 2688, Avg. loss: 30562394704742843131363328.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 76693399307.38, NNZs: 2, Bias: 75816102396.486145, T: 2816, Avg. loss: 31085158219353421321863168.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 3773343369.32, NNZs: 2, Bias: 75583656075.856369, T: 2944, Avg. loss: 2423391251573971565412352.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 8915511057.42, NNZs: 2, Bias: 75433170008.820160, T: 3072, Avg. loss: 460182065836830840848384.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1354089599.84, NNZs: 2, Bias: 75149529475.622879, T: 3200, Avg. loss: 481068477139709060972544.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10245440484.61, NNZs: 2, Bias: 74982689239.548050, T: 3328, Avg. loss: 517797166941702312689664.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 559641023.92, NNZs: 2, Bias: 75297010203.789917, T: 3456, Avg. loss: 399152445286254272053248.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 8448830397.61, NNZs: 2, Bias: 75058372382.598892, T: 3584, Avg. loss: 512852058614961037901824.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 16982115548.50, NNZs: 2, Bias: 74562682008.306778, T: 3712, Avg. loss: 417253985549614948810752.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5997545300.70, NNZs: 2, Bias: 74598323465.820801, T: 3840, Avg. loss: 551863478998053576245248.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4938277620.20, NNZs: 2, Bias: 74809803201.689651, T: 3968, Avg. loss: 698598376729512821915648.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9178278597.32, NNZs: 2, Bias: 74749290019.602264, T: 4096, Avg. loss: 557700018724405801648128.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5377045886.52, NNZs: 2, Bias: 74790097635.289032, T: 4224, Avg. loss: 8088495563209583886336.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3436500301.57, NNZs: 2, Bias: 74799508024.999054, T: 4352, Avg. loss: 2530201317191360970752.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2383752947.02, NNZs: 2, Bias: 74795281497.231735, T: 4480, Avg. loss: 1138606040531987333120.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1832495777.86, NNZs: 2, Bias: 74780078471.211761, T: 4608, Avg. loss: 767717252089722568704.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1572434008.87, NNZs: 2, Bias: 74761137375.643509, T: 4736, Avg. loss: 578039672646157729792.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1416616852.73, NNZs: 2, Bias: 74741439750.747864, T: 4864, Avg. loss: 539472578245405245440.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1347701642.30, NNZs: 2, Bias: 74719096076.768341, T: 4992, Avg. loss: 569884702772343603200.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1272521711.73, NNZs: 2, Bias: 74696576364.520264, T: 5120, Avg. loss: 556153217041331126272.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1310578410.17, NNZs: 2, Bias: 74672548474.006668, T: 5248, Avg. loss: 541887382801789943808.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1292373166.00, NNZs: 2, Bias: 74647753867.445511, T: 5376, Avg. loss: 570258046954907238400.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1325809805.19, NNZs: 2, Bias: 74624194661.142044, T: 5504, Avg. loss: 506060841053575315456.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1368667993.62, NNZs: 2, Bias: 74601342946.304657, T: 5632, Avg. loss: 496298111627377573888.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1351588796.58, NNZs: 2, Bias: 74578326836.196991, T: 5760, Avg. loss: 539780173263438938112.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1319756550.05, NNZs: 2, Bias: 74554998884.639664, T: 5888, Avg. loss: 561963464059762638848.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1370208822.19, NNZs: 2, Bias: 74531147355.100891, T: 6016, Avg. loss: 512554008275945193472.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1242314928.26, NNZs: 2, Bias: 74509617558.592728, T: 6144, Avg. loss: 561801191839052988416.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1318201363.78, NNZs: 2, Bias: 74485870484.255844, T: 6272, Avg. loss: 513365773354643423232.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1280450033.72, NNZs: 2, Bias: 74481770272.555359, T: 6400, Avg. loss: 448773258767967125504.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1295958221.25, NNZs: 2, Bias: 74476819453.311722, T: 6528, Avg. loss: 439791103929678561280.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1299169432.73, NNZs: 2, Bias: 74472158700.412567, T: 6656, Avg. loss: 432387794161820303360.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1297825377.26, NNZs: 2, Bias: 74467564845.518173, T: 6784, Avg. loss: 434192409521080107008.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1282176945.61, NNZs: 2, Bias: 74463159535.470993, T: 6912, Avg. loss: 440253905425438408704.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1294628039.73, NNZs: 2, Bias: 74458246482.557755, T: 7040, Avg. loss: 441483697659141226496.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1284270773.43, NNZs: 2, Bias: 74453751042.127975, T: 7168, Avg. loss: 439576184200402763776.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1277037096.43, NNZs: 2, Bias: 74449154895.261902, T: 7296, Avg. loss: 443818304336405004288.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1282084165.97, NNZs: 2, Bias: 74448130523.163696, T: 7424, Avg. loss: 428608517767775059968.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1285034290.71, NNZs: 2, Bias: 74447147508.730026, T: 7552, Avg. loss: 426109629605818531840.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1284582649.20, NNZs: 2, Bias: 74446223590.873306, T: 7680, Avg. loss: 426012031168656310272.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1286182317.15, NNZs: 2, Bias: 74445264286.151154, T: 7808, Avg. loss: 425929654877254057984.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1280601676.17, NNZs: 2, Bias: 74444433833.940735, T: 7936, Avg. loss: 423814540122883162112.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1287420683.98, NNZs: 2, Bias: 74443386551.202850, T: 8064, Avg. loss: 424862951227294941184.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1288938295.71, NNZs: 2, Bias: 74442429903.487167, T: 8192, Avg. loss: 425327888281708920832.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1285931187.99, NNZs: 2, Bias: 74441550879.927078, T: 8320, Avg. loss: 425718927223639638016.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1289043147.43, NNZs: 2, Bias: 74440568479.097778, T: 8448, Avg. loss: 424405753851764408320.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1284810959.81, NNZs: 2, Bias: 74439709616.640213, T: 8576, Avg. loss: 426205191375280930816.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 67 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2521420012124.94, NNZs: 2, Bias: 18629120864.324867, T: 128, Avg. loss: 21576242008405831584514572288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1704919723527.37, NNZs: 2, Bias: 98629120864.324860, T: 256, Avg. loss: 24121309646218104396570427392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 576911647536.45, NNZs: 2, Bias: 39300715319.652405, T: 384, Avg. loss: 23438528211425543742910627840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1651643741381.96, NNZs: 2, Bias: 99215108183.906723, T: 512, Avg. loss: 23859377384765422047514853376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 933901423060.41, NNZs: 2, Bias: 119215108183.906738, T: 640, Avg. loss: 21306077626773945286632931328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1528788410445.39, NNZs: 2, Bias: 155013045091.517883, T: 768, Avg. loss: 24704164643996972064329170944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1945400465145.93, NNZs: 2, Bias: 164512669956.741974, T: 896, Avg. loss: 20886631778647009954761801728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2192876579121.27, NNZs: 2, Bias: 133167728616.975220, T: 1024, Avg. loss: 20816870568443763712073924608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2044769715167.99, NNZs: 2, Bias: 115880835020.481689, T: 1152, Avg. loss: 22206556909088767849894248448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 131832869017.05, NNZs: 2, Bias: 183506399209.529846, T: 1280, Avg. loss: 24325874491546018027329814528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1199473325767.50, NNZs: 2, Bias: 203506399209.529846, T: 1408, Avg. loss: 21869416537498461369750519808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 968968497428.30, NNZs: 2, Bias: 143506399209.529846, T: 1536, Avg. loss: 23342429317623084467947044864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 968092526232.07, NNZs: 2, Bias: -37005970363.308868, T: 1664, Avg. loss: 23115101573888876644776542208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 239292324352.68, NNZs: 2, Bias: -36797958671.412125, T: 1792, Avg. loss: 1038354361847130176700284928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 73945169400.30, NNZs: 2, Bias: -20975601812.135647, T: 1920, Avg. loss: 980690416454582987690868736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 194214831081.32, NNZs: 2, Bias: -26549856010.964226, T: 2048, Avg. loss: 920068223141716154457784320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 440353967262.96, NNZs: 2, Bias: -19613450209.026257, T: 2176, Avg. loss: 869707587539315220113522688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 113963770396.53, NNZs: 2, Bias: -29021328739.794708, T: 2304, Avg. loss: 1024971209072035247029223424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 57465579332.78, NNZs: 2, Bias: -48423697167.788315, T: 2432, Avg. loss: 919488371531992959031443456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 117048374065.04, NNZs: 2, Bias: -36099343923.692184, T: 2560, Avg. loss: 817432422503170827226185728.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 417791289879.99, NNZs: 2, Bias: -44766725875.309593, T: 2688, Avg. loss: 924647823992294993821696000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 271669805779.69, NNZs: 2, Bias: -42184744835.848885, T: 2816, Avg. loss: 929796556899810882632024064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 214769192081.00, NNZs: 2, Bias: -57724711770.265945, T: 2944, Avg. loss: 920797051168254231272488960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 354499726319.28, NNZs: 2, Bias: -56921832198.772041, T: 3072, Avg. loss: 956829169090934281703784448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 359523562254.69, NNZs: 2, Bias: -68018538141.863907, T: 3200, Avg. loss: 838442826727066179295248384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 63014813702.62, NNZs: 2, Bias: -64140373330.057106, T: 3328, Avg. loss: 92697162720613697790672896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 50566651007.06, NNZs: 2, Bias: -65249136706.903870, T: 3456, Avg. loss: 32159702047714512201580544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 87996595498.46, NNZs: 2, Bias: -66383421310.613647, T: 3584, Avg. loss: 35883860895075955241910272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 11184084403.77, NNZs: 2, Bias: -65084851104.303543, T: 3712, Avg. loss: 36963326381928737341964288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 70249613968.25, NNZs: 2, Bias: -63441885558.108688, T: 3840, Avg. loss: 32341383704412449004322816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 40010821779.64, NNZs: 2, Bias: -63159145685.759193, T: 3968, Avg. loss: 35170407762841055795347456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 58867520405.90, NNZs: 2, Bias: -61107795094.541733, T: 4096, Avg. loss: 38512342761239343097970688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5410663297.56, NNZs: 2, Bias: -61684516964.421379, T: 4224, Avg. loss: 1178421759867682241380352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2445591853.20, NNZs: 2, Bias: -61796298522.552925, T: 4352, Avg. loss: 515511440406892423151616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 13485180337.68, NNZs: 2, Bias: -61770643538.692001, T: 4480, Avg. loss: 486268934255126482255872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4163988917.85, NNZs: 2, Bias: -61466313189.690811, T: 4608, Avg. loss: 626178956390399842713600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 14534310159.11, NNZs: 2, Bias: -61443233173.236053, T: 4736, Avg. loss: 764252196380117827584000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8637659012.41, NNZs: 2, Bias: -61258769050.969421, T: 4864, Avg. loss: 820936347208251703558144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4935906458.00, NNZs: 2, Bias: -60966459121.514305, T: 4992, Avg. loss: 720327040376189310992384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 5274039247.00, NNZs: 2, Bias: -60942020599.929672, T: 5120, Avg. loss: 633372646598755420733440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3107966200.93, NNZs: 2, Bias: -60952677839.588936, T: 5248, Avg. loss: 2860863850565057642496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2090410575.32, NNZs: 2, Bias: -60948251226.809288, T: 5376, Avg. loss: 950716557225740599296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1521441104.97, NNZs: 2, Bias: -60938431283.736107, T: 5504, Avg. loss: 541971716572218916864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1229887756.46, NNZs: 2, Bias: -60922496466.417664, T: 5632, Avg. loss: 449625586483408404480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1089937387.97, NNZs: 2, Bias: -60904714265.449028, T: 5760, Avg. loss: 400002166981309235200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1036351039.23, NNZs: 2, Bias: -60885174838.244270, T: 5888, Avg. loss: 391754575023525855232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 998677494.12, NNZs: 2, Bias: -60865007786.587883, T: 6016, Avg. loss: 404617134631512178688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 985857527.80, NNZs: 2, Bias: -60844307473.631386, T: 6144, Avg. loss: 400648249833336209408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 954703236.61, NNZs: 2, Bias: -60824492779.976646, T: 6272, Avg. loss: 373492086389677555712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 984607117.18, NNZs: 2, Bias: -60803747861.600952, T: 6400, Avg. loss: 380950428403597508608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 942383435.79, NNZs: 2, Bias: -60783804056.107956, T: 6528, Avg. loss: 397552642407602061312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 956341211.52, NNZs: 2, Bias: -60762013593.762131, T: 6656, Avg. loss: 402681187142164086784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 947563423.91, NNZs: 2, Bias: -60740969013.070763, T: 6784, Avg. loss: 428519442888665399296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 934110505.19, NNZs: 2, Bias: -60720557308.297554, T: 6912, Avg. loss: 389732666020576428032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 932076243.07, NNZs: 2, Bias: -60716502012.326080, T: 7040, Avg. loss: 313392440330332209152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 934164468.20, NNZs: 2, Bias: -60712378056.731705, T: 7168, Avg. loss: 313371405166182793216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 924973534.69, NNZs: 2, Bias: -60708468106.622856, T: 7296, Avg. loss: 310490088940010078208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 934064108.07, NNZs: 2, Bias: -60704251456.100990, T: 7424, Avg. loss: 312149481532114534400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 935443217.31, NNZs: 2, Bias: -60700105900.565956, T: 7552, Avg. loss: 316110509502921179136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 931991803.53, NNZs: 2, Bias: -60696158946.311691, T: 7680, Avg. loss: 306509969862564970496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 943269996.16, NNZs: 2, Bias: -60691939657.439056, T: 7808, Avg. loss: 309435966446535114752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 953851465.08, NNZs: 2, Bias: -60687726546.362190, T: 7936, Avg. loss: 309670498882140307456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 955123449.25, NNZs: 2, Bias: -60683594952.135941, T: 8064, Avg. loss: 314998126317019791360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 955860423.32, NNZs: 2, Bias: -60679504482.284904, T: 8192, Avg. loss: 312065850721751007232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 947692643.90, NNZs: 2, Bias: -60675486927.699821, T: 8320, Avg. loss: 318367772117691924480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 946157907.05, NNZs: 2, Bias: -60674697839.567505, T: 8448, Avg. loss: 303010846673039327232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 949691974.63, NNZs: 2, Bias: -60673828091.765793, T: 8576, Avg. loss: 303506678688561954816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 944844675.12, NNZs: 2, Bias: -60673095848.260719, T: 8704, Avg. loss: 301251880017874059264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 945486346.12, NNZs: 2, Bias: -60672270745.266724, T: 8832, Avg. loss: 303830946857784115200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 949106145.77, NNZs: 2, Bias: -60671398452.350800, T: 8960, Avg. loss: 303953486081455620096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 947315485.22, NNZs: 2, Bias: -60670610494.137985, T: 9088, Avg. loss: 304139990088850210816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 951120624.14, NNZs: 2, Bias: -60669737325.656021, T: 9216, Avg. loss: 303150383917665484800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 949259403.94, NNZs: 2, Bias: -60668950474.888397, T: 9344, Avg. loss: 304190511106422210560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 73 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1459210416765.04, NNZs: 2, Bias: 68698901444.766006, T: 128, Avg. loss: 23593128949710364957913120768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1196580937822.02, NNZs: 2, Bias: 38824310717.757103, T: 256, Avg. loss: 24195356311931451132327493632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1720323796897.12, NNZs: 2, Bias: 58824310717.757111, T: 384, Avg. loss: 24504120029873851550511661056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 684853557318.05, NNZs: 2, Bias: 138824310717.757111, T: 512, Avg. loss: 26595431602543650130465128448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 579375453895.43, NNZs: 2, Bias: 88923502389.504150, T: 640, Avg. loss: 22959376757663358149759860736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1633149039159.54, NNZs: 2, Bias: 29316837795.638687, T: 768, Avg. loss: 23663727523144314375762870272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 626925838235.31, NNZs: 2, Bias: 85398363111.179169, T: 896, Avg. loss: 23383584512052147983831007232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1265153227049.57, NNZs: 2, Bias: 63834677921.216736, T: 1024, Avg. loss: 24516021103566195497528983552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 278760619846.72, NNZs: 2, Bias: 103834677921.216736, T: 1152, Avg. loss: 22740619284522341826505474048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 664518209823.19, NNZs: 2, Bias: 43834677921.216736, T: 1280, Avg. loss: 23473849754087144123438989312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 216284698691.36, NNZs: 2, Bias: -121798378513.580276, T: 1408, Avg. loss: 24956353094430264281370984448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1418476400393.03, NNZs: 2, Bias: -97592892847.601730, T: 1536, Avg. loss: 22940461221154494369478213632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 589103558282.43, NNZs: 2, Bias: -137592892847.601746, T: 1664, Avg. loss: 24397240390595850183966195712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 889922460143.43, NNZs: 2, Bias: -117592892847.601746, T: 1792, Avg. loss: 24545222044070003631877783552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 325950727861.12, NNZs: 2, Bias: -137277828257.491119, T: 1920, Avg. loss: 1027711692379945611716198400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 341723175417.89, NNZs: 2, Bias: -147667043696.203949, T: 2048, Avg. loss: 948178345230579229500899328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 376289327561.21, NNZs: 2, Bias: -150886596806.506683, T: 2176, Avg. loss: 885531683323219198603165696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 273631465689.20, NNZs: 2, Bias: -129224014140.590210, T: 2304, Avg. loss: 970612509731938980427988992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 93111288982.15, NNZs: 2, Bias: -119380046157.302414, T: 2432, Avg. loss: 961846513990848742500073472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 478579202140.85, NNZs: 2, Bias: -114204296550.990738, T: 2560, Avg. loss: 901803033570229504081657856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 202829975069.97, NNZs: 2, Bias: -101427356515.302109, T: 2688, Avg. loss: 1025970093325972130773336064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 223001666235.66, NNZs: 2, Bias: -104732406366.814896, T: 2816, Avg. loss: 975050513906513320530149376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 53371472077.55, NNZs: 2, Bias: -100095889197.429581, T: 2944, Avg. loss: 38169479762620538878427136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 81529019342.43, NNZs: 2, Bias: -102049186675.817520, T: 3072, Avg. loss: 35696804989659631564357632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 96570646958.43, NNZs: 2, Bias: -104969645570.883347, T: 3200, Avg. loss: 40607464164828598079848448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 21476234839.33, NNZs: 2, Bias: -102615826863.035904, T: 3328, Avg. loss: 37305388390030592052297728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 101517353364.50, NNZs: 2, Bias: -104076876431.700027, T: 3456, Avg. loss: 35740592623364558437744640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 44044723576.60, NNZs: 2, Bias: -101590384103.134995, T: 3584, Avg. loss: 38479480319559219200131072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 26040248876.88, NNZs: 2, Bias: -103331745251.494308, T: 3712, Avg. loss: 38102638106155185772429312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 16159905600.44, NNZs: 2, Bias: -102614379091.534195, T: 3840, Avg. loss: 929409755316063039389696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4677263215.06, NNZs: 2, Bias: -101942634146.241928, T: 3968, Avg. loss: 841972522442942794694656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 10593506266.39, NNZs: 2, Bias: -101641495480.024475, T: 4096, Avg. loss: 864131051644255970787328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7511143545.51, NNZs: 2, Bias: -101522967178.340286, T: 4224, Avg. loss: 736573247247435979292672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4547601484.85, NNZs: 2, Bias: -101420338238.761276, T: 4352, Avg. loss: 729431379671952450912256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2873894032.51, NNZs: 2, Bias: -101625058208.335281, T: 4480, Avg. loss: 758570787757316405985280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 594293516.80, NNZs: 2, Bias: -101508185132.691711, T: 4608, Avg. loss: 704834785130003417792512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9077674674.96, NNZs: 2, Bias: -101265308974.146194, T: 4736, Avg. loss: 771198493506950869811200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9068071931.40, NNZs: 2, Bias: -101031279250.413742, T: 4864, Avg. loss: 761610918807110426820608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4896651629.14, NNZs: 2, Bias: -101270374676.199890, T: 4992, Avg. loss: 812498600633587715801088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1843260575.86, NNZs: 2, Bias: -101190361837.796768, T: 5120, Avg. loss: 774651269141020828237824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 7143669487.37, NNZs: 2, Bias: -101316851124.615646, T: 5248, Avg. loss: 528351902240845466697728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2181189360.35, NNZs: 2, Bias: -101236313256.992142, T: 5376, Avg. loss: 732561112501288945319936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2285044387.80, NNZs: 2, Bias: -100993766719.709717, T: 5504, Avg. loss: 618357923036153216237568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1083984087.48, NNZs: 2, Bias: -100909913340.702972, T: 5632, Avg. loss: 733277165727406612283392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6202059919.12, NNZs: 2, Bias: -100851951284.430405, T: 5760, Avg. loss: 782368892791475228639232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4545825708.33, NNZs: 2, Bias: -100668315324.901123, T: 5888, Avg. loss: 685949991482517090205696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1585273488.21, NNZs: 2, Bias: -100608346656.104889, T: 6016, Avg. loss: 4624601200386039611392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 632527617.47, NNZs: 2, Bias: -100559139996.984283, T: 6144, Avg. loss: 1742206082097051598848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 756522445.32, NNZs: 2, Bias: -100520420328.114838, T: 6272, Avg. loss: 1084042146581788229632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1110164970.98, NNZs: 2, Bias: -100484034133.303543, T: 6400, Avg. loss: 980741701468691496960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1266183566.02, NNZs: 2, Bias: -100452286037.671555, T: 6528, Avg. loss: 909806162447220080640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1314635169.43, NNZs: 2, Bias: -100420794965.538651, T: 6656, Avg. loss: 976322356795393441792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1360696849.52, NNZs: 2, Bias: -100391514800.250549, T: 6784, Avg. loss: 855950335135893684224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1353450545.30, NNZs: 2, Bias: -100362870815.567062, T: 6912, Avg. loss: 873702577908508393472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1527325317.80, NNZs: 2, Bias: -100330525582.099030, T: 7040, Avg. loss: 894293692547727753216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1450198932.64, NNZs: 2, Bias: -100301775141.406845, T: 7168, Avg. loss: 915150422563876634624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1483805898.78, NNZs: 2, Bias: -100272286047.407745, T: 7296, Avg. loss: 889548191850757619712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1440706330.79, NNZs: 2, Bias: -100243666407.393539, T: 7424, Avg. loss: 871259764212792950784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1438686146.73, NNZs: 2, Bias: -100237796144.414566, T: 7552, Avg. loss: 744887889558952869888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1431697893.29, NNZs: 2, Bias: -100232001778.960510, T: 7680, Avg. loss: 745644418436567400448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1431822941.94, NNZs: 2, Bias: -100226109142.107544, T: 7808, Avg. loss: 744052220552455651328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1460833570.86, NNZs: 2, Bias: -100219910205.382080, T: 7936, Avg. loss: 729029616726470426624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1456241809.48, NNZs: 2, Bias: -100214169725.513931, T: 8064, Avg. loss: 733105835035718975488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1459080663.47, NNZs: 2, Bias: -100208276129.283203, T: 8192, Avg. loss: 739797708545473511424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1484548747.76, NNZs: 2, Bias: -100202109710.099045, T: 8320, Avg. loss: 730094824948530675712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1457891334.25, NNZs: 2, Bias: -100196671494.244171, T: 8448, Avg. loss: 737400844720919281664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1450120839.26, NNZs: 2, Bias: -100190957272.754929, T: 8576, Avg. loss: 736123120555845484544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1472027546.33, NNZs: 2, Bias: -100189456380.441055, T: 8704, Avg. loss: 726298775373825966080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1470682915.15, NNZs: 2, Bias: -100188313893.960220, T: 8832, Avg. loss: 715067156536090034176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1473953640.72, NNZs: 2, Bias: -100187105006.142654, T: 8960, Avg. loss: 713970805076707377152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1473729909.05, NNZs: 2, Bias: -100185942621.318527, T: 9088, Avg. loss: 717143745583851372544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1472105742.46, NNZs: 2, Bias: -100184800997.290833, T: 9216, Avg. loss: 717061477381837946880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1470828442.78, NNZs: 2, Bias: -100183654227.705643, T: 9344, Avg. loss: 717072107628143443968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1469838930.39, NNZs: 2, Bias: -100182504616.689117, T: 9472, Avg. loss: 716191846221645611008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1474077644.61, NNZs: 2, Bias: -100181279513.484299, T: 9600, Avg. loss: 715134722112524255232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 271923817204.38, NNZs: 2, Bias: 14441096341.658707, T: 128, Avg. loss: 21385801829663763896297586688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1492646483999.05, NNZs: 2, Bias: 147033388629.360626, T: 256, Avg. loss: 22945499631103824762196983808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2207460832301.85, NNZs: 2, Bias: 144270636013.098877, T: 384, Avg. loss: 21308367146576874149978832896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2490830154635.42, NNZs: 2, Bias: 127523982284.063812, T: 512, Avg. loss: 20308174504153227018343809024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1885842603350.89, NNZs: 2, Bias: 167523982284.063812, T: 640, Avg. loss: 21286336122452541622016016384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2419596741960.71, NNZs: 2, Bias: 38674286149.491089, T: 768, Avg. loss: 21837690897568046473323479040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 640541535618.75, NNZs: 2, Bias: 48484447867.728271, T: 896, Avg. loss: 21216531542184059036569174016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2175465981783.97, NNZs: 2, Bias: 63949428831.102783, T: 1024, Avg. loss: 20428971826322487615971917824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 915257591818.16, NNZs: 2, Bias: 62448983648.793228, T: 1152, Avg. loss: 21070929607913240065071906816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 234911247793.22, NNZs: 2, Bias: 69298988471.689194, T: 1280, Avg. loss: 1022661769072456740842242048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 359705861940.71, NNZs: 2, Bias: 79900811718.076431, T: 1408, Avg. loss: 861758111661627148110659584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 92196746270.47, NNZs: 2, Bias: 86667537711.756729, T: 1536, Avg. loss: 861770583898785058561982464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 214181452273.54, NNZs: 2, Bias: 92929592929.371704, T: 1664, Avg. loss: 875316872561678341294260224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 228291270518.45, NNZs: 2, Bias: 94053908333.116104, T: 1792, Avg. loss: 853205365278765082585595904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 137827013739.54, NNZs: 2, Bias: 74881829310.529251, T: 1920, Avg. loss: 815108405038437872969973760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 204790979466.12, NNZs: 2, Bias: 73623472184.131500, T: 2048, Avg. loss: 847727696627643353596428288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 301686037071.66, NNZs: 2, Bias: 89750659919.350357, T: 2176, Avg. loss: 907517495811762955048976384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 200426675767.09, NNZs: 2, Bias: 89595837579.669189, T: 2304, Avg. loss: 823791402975286947261448192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 297704373943.48, NNZs: 2, Bias: 94387599757.268890, T: 2432, Avg. loss: 914697111359863380326219776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 521365147994.10, NNZs: 2, Bias: 105863673482.381805, T: 2560, Avg. loss: 793730938209348285747953664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 414860535575.90, NNZs: 2, Bias: 115103302948.200485, T: 2688, Avg. loss: 871660006452456771544940544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 234697775002.03, NNZs: 2, Bias: 113355089627.870239, T: 2816, Avg. loss: 909707191941143863920427008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 73390479799.08, NNZs: 2, Bias: 105606795056.971298, T: 2944, Avg. loss: 858036315232140646414286848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 204739554039.10, NNZs: 2, Bias: 118340240306.148804, T: 3072, Avg. loss: 883232518808435883969085440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 337766613251.57, NNZs: 2, Bias: 113546842556.688644, T: 3200, Avg. loss: 765208410990777928958083072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 232032513341.21, NNZs: 2, Bias: 107674007835.875107, T: 3328, Avg. loss: 897502768542178693338890240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 331580665263.46, NNZs: 2, Bias: 102982183131.772247, T: 3456, Avg. loss: 862029010839059507198296064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 408924838443.42, NNZs: 2, Bias: 103716993772.505127, T: 3584, Avg. loss: 877259491198207918172274688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 39562746236.17, NNZs: 2, Bias: 76175935414.413620, T: 3712, Avg. loss: 833332839021170824983871488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 267216599182.80, NNZs: 2, Bias: 80106228611.109985, T: 3840, Avg. loss: 810549823566488985105596416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 12982614273.44, NNZs: 2, Bias: 76231047255.719070, T: 3968, Avg. loss: 35257530479183513784418304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 61021094246.07, NNZs: 2, Bias: 72815477294.396393, T: 4096, Avg. loss: 28867769791101947346944000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 26142643305.69, NNZs: 2, Bias: 71702365632.860840, T: 4224, Avg. loss: 32389105512596018548441088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 39063297167.69, NNZs: 2, Bias: 71398863228.271011, T: 4352, Avg. loss: 30132448123949450790961152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 39886450779.09, NNZs: 2, Bias: 69422144132.613403, T: 4480, Avg. loss: 31528316195185470451220480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 22589312037.66, NNZs: 2, Bias: 68927752977.357224, T: 4608, Avg. loss: 32508750954668862367334400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 48039735177.99, NNZs: 2, Bias: 67919708739.671951, T: 4736, Avg. loss: 33534440057221248683343872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 16166600718.40, NNZs: 2, Bias: 68731779876.337326, T: 4864, Avg. loss: 909235412116916821557248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 11989708404.20, NNZs: 2, Bias: 68763605874.304733, T: 4992, Avg. loss: 776830736263326224875520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1959023925.48, NNZs: 2, Bias: 68781830921.324509, T: 5120, Avg. loss: 720984678320514751528960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 6848527354.75, NNZs: 2, Bias: 68964844932.217621, T: 5248, Avg. loss: 475792957924095863816192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3881554395.40, NNZs: 2, Bias: 68527872638.049828, T: 5376, Avg. loss: 517020604592886860742656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 7129289951.73, NNZs: 2, Bias: 68442228571.117882, T: 5504, Avg. loss: 457884089721224565882880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 6110710855.85, NNZs: 2, Bias: 68660835209.807419, T: 5632, Avg. loss: 660962300251817910468608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1374003726.85, NNZs: 2, Bias: 68884930384.359863, T: 5760, Avg. loss: 917576425702767217082368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1953650566.66, NNZs: 2, Bias: 68581669329.723625, T: 5888, Avg. loss: 661378460162372958945280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 8548320581.62, NNZs: 2, Bias: 68569532514.039856, T: 6016, Avg. loss: 541816812878538437820416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 10255303998.20, NNZs: 2, Bias: 68012060772.947784, T: 6144, Avg. loss: 622719118640327579140096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2737905951.90, NNZs: 2, Bias: 68062126310.528755, T: 6272, Avg. loss: 22525982146304692715520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2054282975.56, NNZs: 2, Bias: 68050478846.939438, T: 6400, Avg. loss: 779059158879185666048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1493305185.07, NNZs: 2, Bias: 68034804025.032288, T: 6528, Avg. loss: 722297365183175065600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1253698795.49, NNZs: 2, Bias: 68015476104.276863, T: 6656, Avg. loss: 520225583265033158656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1217677111.79, NNZs: 2, Bias: 67990481161.921852, T: 6784, Avg. loss: 533583547261719347200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1164394800.17, NNZs: 2, Bias: 67967853992.763420, T: 6912, Avg. loss: 503234286182548701184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1103900407.45, NNZs: 2, Bias: 67944250464.486092, T: 7040, Avg. loss: 511202741022665736192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1096934347.08, NNZs: 2, Bias: 67920729021.398155, T: 7168, Avg. loss: 493672877162841767936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1041323638.14, NNZs: 2, Bias: 67897022102.870819, T: 7296, Avg. loss: 507171185268808417280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1003873218.72, NNZs: 2, Bias: 67872971689.185974, T: 7424, Avg. loss: 545022316844525355008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1152322105.68, NNZs: 2, Bias: 67847743147.355492, T: 7552, Avg. loss: 451727884071979843584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1070336520.18, NNZs: 2, Bias: 67825558422.115227, T: 7680, Avg. loss: 482043487378012635136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1030038165.59, NNZs: 2, Bias: 67802815144.737984, T: 7808, Avg. loss: 487309857758098030592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1045646156.81, NNZs: 2, Bias: 67778937634.011818, T: 7936, Avg. loss: 483005312800153796608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1041197341.38, NNZs: 2, Bias: 67753808414.656815, T: 8064, Avg. loss: 551789941057214545920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1080623978.21, NNZs: 2, Bias: 67728780147.182579, T: 8192, Avg. loss: 514865087182823686144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1076412058.55, NNZs: 2, Bias: 67724080886.587120, T: 8320, Avg. loss: 406175656665616875520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1067858522.62, NNZs: 2, Bias: 67719456715.130585, T: 8448, Avg. loss: 406346219467584176128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1083924116.79, NNZs: 2, Bias: 67714411491.297035, T: 8576, Avg. loss: 407933726796619710464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1078736028.10, NNZs: 2, Bias: 67709740802.156082, T: 8704, Avg. loss: 405912893954865299456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1080260443.03, NNZs: 2, Bias: 67704944176.259392, T: 8832, Avg. loss: 406892478447715287040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1083513405.09, NNZs: 2, Bias: 67700130324.907417, T: 8960, Avg. loss: 405942980361917169664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1080577821.10, NNZs: 2, Bias: 67695442426.688095, T: 9088, Avg. loss: 403563248913201561600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1097858558.94, NNZs: 2, Bias: 67690456760.695389, T: 9216, Avg. loss: 400916416770636775424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1082120235.76, NNZs: 2, Bias: 67685899655.398041, T: 9344, Avg. loss: 410579607436239831040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1078195388.85, NNZs: 2, Bias: 67681361514.211304, T: 9472, Avg. loss: 391011266039174135808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1078569255.63, NNZs: 2, Bias: 67676557314.220154, T: 9600, Avg. loss: 409429163378761728000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1077266951.17, NNZs: 2, Bias: 67671835610.889923, T: 9728, Avg. loss: 403729392725472772096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1076191451.20, NNZs: 2, Bias: 67667207555.184303, T: 9856, Avg. loss: 395034998044033089536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1084381072.45, NNZs: 2, Bias: 67662274260.191925, T: 9984, Avg. loss: 409160704144056188928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1089811115.75, NNZs: 2, Bias: 67657401392.050514, T: 10112, Avg. loss: 408084405086586863616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1084903509.25, NNZs: 2, Bias: 67656525737.920639, T: 10240, Avg. loss: 396617228305124294656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1085882538.38, NNZs: 2, Bias: 67655560405.447296, T: 10368, Avg. loss: 394444953511031734272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1079538831.09, NNZs: 2, Bias: 67654717397.117157, T: 10496, Avg. loss: 392440955177325035520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 1081027467.66, NNZs: 2, Bias: 67653743013.289177, T: 10624, Avg. loss: 394828875981816659968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 1083091142.25, NNZs: 2, Bias: 67652757986.433098, T: 10752, Avg. loss: 395375646887908802560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 84 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1340200685127.05, NNZs: 2, Bias: -2616944888.899117, T: 128, Avg. loss: 20295550817707085979992457216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 940825664377.67, NNZs: 2, Bias: -48680116295.814445, T: 256, Avg. loss: 20398840901134151684053794816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2345852679646.49, NNZs: 2, Bias: -28680116295.814453, T: 384, Avg. loss: 18557897967667898072166301696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 208833880016.70, NNZs: 2, Bias: -189935687054.118469, T: 512, Avg. loss: 21395764731221277634967109632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1539363795332.64, NNZs: 2, Bias: -172291920425.692261, T: 640, Avg. loss: 21389124486960169435608907776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 264716614328.61, NNZs: 2, Bias: -192291920425.692261, T: 768, Avg. loss: 20344416714560242212346527744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 800480040362.70, NNZs: 2, Bias: -272291920425.692261, T: 896, Avg. loss: 21517677387059674065320017920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 660428580262.62, NNZs: 2, Bias: -207700180934.647217, T: 1024, Avg. loss: 20194170834396132584850456576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 314676815285.06, NNZs: 2, Bias: -228635281731.764313, T: 1152, Avg. loss: 794045959451565244180070400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 200620927577.39, NNZs: 2, Bias: -246428883047.148224, T: 1280, Avg. loss: 784664244998582292738736128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 54969673843.29, NNZs: 2, Bias: -231862828111.266357, T: 1408, Avg. loss: 800613194485982859326652416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 480049537184.72, NNZs: 2, Bias: -246635131260.781952, T: 1536, Avg. loss: 780310447702736005968691200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 368525141296.42, NNZs: 2, Bias: -243282485380.261017, T: 1664, Avg. loss: 813750865910258450323996672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 389177631828.34, NNZs: 2, Bias: -251825041212.934387, T: 1792, Avg. loss: 877790303450171187413385216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 99316991807.73, NNZs: 2, Bias: -241926267013.795166, T: 1920, Avg. loss: 701486327546002694004015104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 274151344375.71, NNZs: 2, Bias: -233633054312.653015, T: 2048, Avg. loss: 675552631773232062739251200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 209123792169.49, NNZs: 2, Bias: -237736469544.916809, T: 2176, Avg. loss: 763803445522979466747314176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 303960275380.27, NNZs: 2, Bias: -241626915982.039062, T: 2304, Avg. loss: 806820975064909598005657600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 173442878347.44, NNZs: 2, Bias: -238615273329.265717, T: 2432, Avg. loss: 764141461782542300294938624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 166984910519.48, NNZs: 2, Bias: -261090683847.656403, T: 2560, Avg. loss: 844511036158689310408704000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 140516848530.15, NNZs: 2, Bias: -241999315772.997070, T: 2688, Avg. loss: 783593785276634186024747008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 47276578637.98, NNZs: 2, Bias: -238667505499.258057, T: 2816, Avg. loss: 30292216855210370252406784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 29020870737.15, NNZs: 2, Bias: -236715704003.778992, T: 2944, Avg. loss: 26513123836745666487386112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 25002774046.21, NNZs: 2, Bias: -234744646742.832458, T: 3072, Avg. loss: 28498025130509294188363776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 81099954512.71, NNZs: 2, Bias: -233495112028.448120, T: 3200, Avg. loss: 29127957168750220971868160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 40157315785.53, NNZs: 2, Bias: -232065845814.685577, T: 3328, Avg. loss: 28971074731343894095593472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 23822904265.50, NNZs: 2, Bias: -231276758421.031769, T: 3456, Avg. loss: 28742890041420098448654336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 82152039783.92, NNZs: 2, Bias: -231982054968.387238, T: 3584, Avg. loss: 28020476253605216347226112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 10943471672.54, NNZs: 2, Bias: -231594546535.347504, T: 3712, Avg. loss: 3129477015947182583316480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 12320881562.97, NNZs: 2, Bias: -231129935774.121552, T: 3840, Avg. loss: 677797602869220678303744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6449377562.89, NNZs: 2, Bias: -230856980335.129486, T: 3968, Avg. loss: 575254057701063773913088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8221201858.77, NNZs: 2, Bias: -230519273972.467896, T: 4096, Avg. loss: 615081854833789262364672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6274064386.42, NNZs: 2, Bias: -230454056139.084808, T: 4224, Avg. loss: 441278856658512372563968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9595449689.36, NNZs: 2, Bias: -229642856650.101685, T: 4352, Avg. loss: 639812865693450164502528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3188536834.53, NNZs: 2, Bias: -229150583204.655548, T: 4480, Avg. loss: 609409177831475895074816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 14364095960.25, NNZs: 2, Bias: -229070776028.576782, T: 4608, Avg. loss: 542301815715279906275328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8396489418.34, NNZs: 2, Bias: -228753122362.718628, T: 4736, Avg. loss: 588003216667981010436096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4406914160.81, NNZs: 2, Bias: -228494080783.411438, T: 4864, Avg. loss: 422209356605824859897856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 16218714229.77, NNZs: 2, Bias: -227941112597.534760, T: 4992, Avg. loss: 538119827330851783311360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 15937355291.62, NNZs: 2, Bias: -227963279505.134827, T: 5120, Avg. loss: 647243535497340618014720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 6233648764.65, NNZs: 2, Bias: -227614750068.458466, T: 5248, Avg. loss: 592248356951438756151296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 5111062427.06, NNZs: 2, Bias: -227256303262.549377, T: 5376, Avg. loss: 562026141049103274999808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9224067829.87, NNZs: 2, Bias: -226902779349.106842, T: 5504, Avg. loss: 634396419582798476607488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5564940748.85, NNZs: 2, Bias: -226884972085.751770, T: 5632, Avg. loss: 11211142278015396872192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4536156143.49, NNZs: 2, Bias: -226817256791.186005, T: 5760, Avg. loss: 6998484722939266596864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4218013086.14, NNZs: 2, Bias: -226745527149.129608, T: 5888, Avg. loss: 5676836061455482617856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4032238809.44, NNZs: 2, Bias: -226669672205.892273, T: 6016, Avg. loss: 5813569416368731717632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3651320236.42, NNZs: 2, Bias: -226596293504.244110, T: 6144, Avg. loss: 5811525728138229186560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3874930012.57, NNZs: 2, Bias: -226519815679.638245, T: 6272, Avg. loss: 5193546750810281476096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3401351197.01, NNZs: 2, Bias: -226449716155.014404, T: 6400, Avg. loss: 5581078690336394444800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3489025787.10, NNZs: 2, Bias: -226368271721.101227, T: 6528, Avg. loss: 5638237710122235199488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3555047765.99, NNZs: 2, Bias: -226290575793.683197, T: 6656, Avg. loss: 5355079969076624228352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3658427715.70, NNZs: 2, Bias: -226210319921.104095, T: 6784, Avg. loss: 5537620909595936423936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3603310452.26, NNZs: 2, Bias: -226128033014.538849, T: 6912, Avg. loss: 5860465456807814365184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3600043449.91, NNZs: 2, Bias: -226112726762.574280, T: 7040, Avg. loss: 4382439426534515671040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3628822914.23, NNZs: 2, Bias: -226097172051.292816, T: 7168, Avg. loss: 4314337497494970171392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3629019178.34, NNZs: 2, Bias: -226082386399.399628, T: 7296, Avg. loss: 4227652567536781230080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3639346212.52, NNZs: 2, Bias: -226066898071.189423, T: 7424, Avg. loss: 4376948401012613316608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3666567814.71, NNZs: 2, Bias: -226051107723.467834, T: 7552, Avg. loss: 4392835094500301340672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3650717551.51, NNZs: 2, Bias: -226036195211.125305, T: 7680, Avg. loss: 4333103910719383404544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3649073982.14, NNZs: 2, Bias: -226020887378.182678, T: 7808, Avg. loss: 4379782445981496246272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3663160373.56, NNZs: 2, Bias: -226005386618.794556, T: 7936, Avg. loss: 4360874581170104303616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3639819830.11, NNZs: 2, Bias: -226002699914.605377, T: 8064, Avg. loss: 4256570236465178476544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3647186616.31, NNZs: 2, Bias: -225999545198.099121, T: 8192, Avg. loss: 4214742545259825201152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3640695865.87, NNZs: 2, Bias: -225996598539.296631, T: 8320, Avg. loss: 4237255019459340926976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3649056500.74, NNZs: 2, Bias: -225993425284.208466, T: 8448, Avg. loss: 4217588950087047315456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3641276448.23, NNZs: 2, Bias: -225990503596.982330, T: 8576, Avg. loss: 4232252780477294313472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3641767565.58, NNZs: 2, Bias: -225987454338.066467, T: 8704, Avg. loss: 4222003255325836181504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3639681980.32, NNZs: 2, Bias: -225984438558.965179, T: 8832, Avg. loss: 4233963405918382063616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 69 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 519552808572.84, NNZs: 2, Bias: -40314953768.419739, T: 128, Avg. loss: 18016663703853018787707092992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 506621697135.46, NNZs: 2, Bias: 19685046231.580261, T: 256, Avg. loss: 22120282685080621357065043968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 718395137916.29, NNZs: 2, Bias: 8351540878.844315, T: 384, Avg. loss: 21005182549502987445035073536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1070080288478.65, NNZs: 2, Bias: -91648459121.155685, T: 512, Avg. loss: 21626386756264990038695084032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 329614085079.87, NNZs: 2, Bias: -89999855049.348755, T: 640, Avg. loss: 20131899045519139033294307328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 359438189445.81, NNZs: 2, Bias: -129999855049.348755, T: 768, Avg. loss: 20386349657548061604013146112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 507444308885.94, NNZs: 2, Bias: -129315585766.182541, T: 896, Avg. loss: 838908182237276775437565952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 297452461394.94, NNZs: 2, Bias: -120054497674.338440, T: 1024, Avg. loss: 890951249105227877474893824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 137781898994.54, NNZs: 2, Bias: -113270942332.028854, T: 1152, Avg. loss: 816458705298345808155901952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 167752954483.81, NNZs: 2, Bias: -111949607565.330688, T: 1280, Avg. loss: 862345618186116398122532864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 178750460726.06, NNZs: 2, Bias: -115785412907.305939, T: 1408, Avg. loss: 820390204614583009807433728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 85049410334.87, NNZs: 2, Bias: -119249919235.496201, T: 1536, Avg. loss: 864311727243326659747643392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 345731228033.90, NNZs: 2, Bias: -110473346914.844376, T: 1664, Avg. loss: 789163805452495028253360128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 240785968101.03, NNZs: 2, Bias: -111432252214.836624, T: 1792, Avg. loss: 765993855432682690326822912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 73241165094.98, NNZs: 2, Bias: -94987640318.756958, T: 1920, Avg. loss: 897819028506002060071665664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 186887896736.58, NNZs: 2, Bias: -104394167340.463242, T: 2048, Avg. loss: 902837179367069671170768896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 248025189799.02, NNZs: 2, Bias: -97639342806.926376, T: 2176, Avg. loss: 840589681844421211644231680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 486473935509.56, NNZs: 2, Bias: -89083302690.635971, T: 2304, Avg. loss: 834404547105036859030372352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 359150626568.20, NNZs: 2, Bias: -87328310725.512878, T: 2432, Avg. loss: 792414864271163494399737856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 17212537843.75, NNZs: 2, Bias: -84151853435.765930, T: 2560, Avg. loss: 68383038696597371266007040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 53633179933.36, NNZs: 2, Bias: -84083656236.450729, T: 2688, Avg. loss: 29795472523402615170531328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 57645821348.39, NNZs: 2, Bias: -83556999140.038467, T: 2816, Avg. loss: 32356039080051231632130048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 20519754078.90, NNZs: 2, Bias: -81680065287.688080, T: 2944, Avg. loss: 28426841822078146675998720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 50909212561.48, NNZs: 2, Bias: -80938848428.337280, T: 3072, Avg. loss: 33028551230037841126883328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 20442393842.40, NNZs: 2, Bias: -79948796368.666870, T: 3200, Avg. loss: 30980643343228585396666368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 78512450630.60, NNZs: 2, Bias: -81594627517.624329, T: 3328, Avg. loss: 25744146833431917565575168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 37811512081.27, NNZs: 2, Bias: -80131482261.107758, T: 3456, Avg. loss: 31410637349404696754782208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 18485970677.47, NNZs: 2, Bias: -79367278956.668274, T: 3584, Avg. loss: 30780699779711978279272448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 27715990470.80, NNZs: 2, Bias: -78491855643.069351, T: 3712, Avg. loss: 33087698517536030895112192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 31638584016.04, NNZs: 2, Bias: -78336460636.961288, T: 3840, Avg. loss: 31288201690563424555106304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 36396338168.63, NNZs: 2, Bias: -77231965949.542847, T: 3968, Avg. loss: 29139425431100990030872576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8259542351.97, NNZs: 2, Bias: -77193320477.072464, T: 4096, Avg. loss: 925234536547581199122432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9136937911.27, NNZs: 2, Bias: -76849221395.784302, T: 4224, Avg. loss: 650892053040444771139584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1214976237.50, NNZs: 2, Bias: -76551038806.501099, T: 4352, Avg. loss: 265817440832166842859520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2544903637.56, NNZs: 2, Bias: -76011454743.229370, T: 4480, Avg. loss: 531338079691437437353984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 13206213165.29, NNZs: 2, Bias: -76035647163.642944, T: 4608, Avg. loss: 557904953650971781627904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4165892348.57, NNZs: 2, Bias: -75920555764.749603, T: 4736, Avg. loss: 484426029533278081384448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4775250538.61, NNZs: 2, Bias: -76054138976.209686, T: 4864, Avg. loss: 407646573222796948668416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1040328502.81, NNZs: 2, Bias: -76018919195.146271, T: 4992, Avg. loss: 575208045282474202234880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 905299806.87, NNZs: 2, Bias: -75981379405.498795, T: 5120, Avg. loss: 930924790452382072832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1069894170.01, NNZs: 2, Bias: -75955350443.480362, T: 5248, Avg. loss: 527777298633465266176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1192669493.40, NNZs: 2, Bias: -75929432039.172806, T: 5376, Avg. loss: 564995861486615658496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1293986203.03, NNZs: 2, Bias: -75903409810.227783, T: 5504, Avg. loss: 552292391593845653504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1290369118.17, NNZs: 2, Bias: -75880426829.991348, T: 5632, Avg. loss: 523788441248481607680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1361066341.28, NNZs: 2, Bias: -75856329842.332321, T: 5760, Avg. loss: 524968747015289307136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1377926323.29, NNZs: 2, Bias: -75832256543.424759, T: 5888, Avg. loss: 555894565609647046656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1319113644.13, NNZs: 2, Bias: -75809394896.031113, T: 6016, Avg. loss: 569954028515238215680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1332279450.40, NNZs: 2, Bias: -75784535094.200882, T: 6144, Avg. loss: 585834548037318082560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1330140760.91, NNZs: 2, Bias: -75761032013.155823, T: 6272, Avg. loss: 538438962395998126080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1324432839.23, NNZs: 2, Bias: -75756404509.499710, T: 6400, Avg. loss: 452297946022144704512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1334721123.93, NNZs: 2, Bias: -75751422744.827362, T: 6528, Avg. loss: 458872261236886536192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1336700417.53, NNZs: 2, Bias: -75746637074.895157, T: 6656, Avg. loss: 454696357563946827776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1318715284.97, NNZs: 2, Bias: -75742177833.885010, T: 6784, Avg. loss: 456828037289141075968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1336295150.60, NNZs: 2, Bias: -75737122673.906631, T: 6912, Avg. loss: 452722668136522317824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1334833172.48, NNZs: 2, Bias: -75732443422.214737, T: 7040, Avg. loss: 449291047780995432448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1323864937.02, NNZs: 2, Bias: -75727928866.278381, T: 7168, Avg. loss: 450019910663384203264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1328232120.99, NNZs: 2, Bias: -75723145314.641907, T: 7296, Avg. loss: 449378924215760650240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1324665873.52, NNZs: 2, Bias: -75718460439.064880, T: 7424, Avg. loss: 454479130559464996864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1322239010.79, NNZs: 2, Bias: -75713771281.036041, T: 7552, Avg. loss: 452748760316390473728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1328065354.38, NNZs: 2, Bias: -75708913319.131668, T: 7680, Avg. loss: 454533505885405511680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1327990225.50, NNZs: 2, Bias: -75707968289.474167, T: 7808, Avg. loss: 439996913423158738944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1328145256.32, NNZs: 2, Bias: -75707018524.728027, T: 7936, Avg. loss: 440368750061208403968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1320082603.38, NNZs: 2, Bias: -75706227129.811371, T: 8064, Avg. loss: 433708121690224525312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1324333024.09, NNZs: 2, Bias: -75705202422.420364, T: 8192, Avg. loss: 441831829189642354688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1323374394.73, NNZs: 2, Bias: -75704273475.171860, T: 8320, Avg. loss: 439818301248472612864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1326115701.13, NNZs: 2, Bias: -75703278764.984848, T: 8448, Avg. loss: 440112236157836328960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1328369750.24, NNZs: 2, Bias: -75702295947.360092, T: 8576, Avg. loss: 438492611907816521728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1320069645.69, NNZs: 2, Bias: -75701498207.069778, T: 8704, Avg. loss: 438659138366705106944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 68 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 527318812241.05, NNZs: 2, Bias: -27313957552.248428, T: 128, Avg. loss: 22223843090579141395457507328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 316516715736.71, NNZs: 2, Bias: 52686042447.751572, T: 256, Avg. loss: 21365335929582460038417481728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1565863379796.02, NNZs: 2, Bias: 32686042447.751572, T: 384, Avg. loss: 22499252454676206459614658560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1150035224401.47, NNZs: 2, Bias: 89497052464.384323, T: 512, Avg. loss: 22083121363908696282255851520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 63895418105.71, NNZs: 2, Bias: 9497052464.384323, T: 640, Avg. loss: 21116737530739721450945511424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 799184249187.99, NNZs: 2, Bias: -50502947535.615677, T: 768, Avg. loss: 22045634085252033692460646400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1947126893522.74, NNZs: 2, Bias: -155016579697.468811, T: 896, Avg. loss: 23634283355777800195708813312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1439134535372.59, NNZs: 2, Bias: -155996709730.284668, T: 1024, Avg. loss: 24877334177924260308398899200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 288532607109.33, NNZs: 2, Bias: -175996709730.284668, T: 1152, Avg. loss: 22066511108722893429812494336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 890702230654.88, NNZs: 2, Bias: -163903920956.411072, T: 1280, Avg. loss: 23059155419773890066441568256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 178404960522.25, NNZs: 2, Bias: -153669951511.210815, T: 1408, Avg. loss: 957415212569872077567295488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 239399969849.54, NNZs: 2, Bias: -154186009004.911896, T: 1536, Avg. loss: 1052094402505429938014781440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 504257158577.23, NNZs: 2, Bias: -135412934581.284027, T: 1664, Avg. loss: 802954005969565621514403840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 336967404525.05, NNZs: 2, Bias: -162591777105.451782, T: 1792, Avg. loss: 909461978782097275011203072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 276010914224.27, NNZs: 2, Bias: -167558371501.652191, T: 1920, Avg. loss: 890780654584003566705311744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 371141826193.25, NNZs: 2, Bias: -175023071482.328094, T: 2048, Avg. loss: 967391582871285858626961408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 344738939940.12, NNZs: 2, Bias: -158752871214.271729, T: 2176, Avg. loss: 843695393108207214796996608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 335846349942.20, NNZs: 2, Bias: -170620181787.942200, T: 2304, Avg. loss: 939330024928484079217672192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 8124649605.28, NNZs: 2, Bias: -168293808547.255676, T: 2432, Avg. loss: 76779483912603734665854976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40303814337.25, NNZs: 2, Bias: -168498838160.864594, T: 2560, Avg. loss: 33981072137770512326590464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 71263384083.90, NNZs: 2, Bias: -172211426810.023682, T: 2688, Avg. loss: 32487441539902939907227648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 52872022958.23, NNZs: 2, Bias: -171440741279.404968, T: 2816, Avg. loss: 34074187722691241798795264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 13008485449.14, NNZs: 2, Bias: -169095206653.886780, T: 2944, Avg. loss: 37680152514310479563194368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 23363458428.13, NNZs: 2, Bias: -165319335862.501740, T: 3072, Avg. loss: 34456989500571503648833536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1434487942.70, NNZs: 2, Bias: -164808087947.135254, T: 3200, Avg. loss: 32925517343353998267121664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 45798070608.88, NNZs: 2, Bias: -163512786151.323181, T: 3328, Avg. loss: 33853462681604336415408128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 9482989925.23, NNZs: 2, Bias: -163275252185.506653, T: 3456, Avg. loss: 908816974304595029262336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4132129899.51, NNZs: 2, Bias: -162670680485.673981, T: 3584, Avg. loss: 706184990790539116806144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4026339838.21, NNZs: 2, Bias: -162308427519.608337, T: 3712, Avg. loss: 610300560126451006832640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 652722912.45, NNZs: 2, Bias: -162290332909.063080, T: 3840, Avg. loss: 533014979304068489412608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6694307448.54, NNZs: 2, Bias: -161843228930.351532, T: 3968, Avg. loss: 600957906114028322684928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8240863421.36, NNZs: 2, Bias: -161932051972.717834, T: 4096, Avg. loss: 806931090116926421073920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4804589211.13, NNZs: 2, Bias: -161482316919.612671, T: 4224, Avg. loss: 674196158520233612541952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 17960759703.51, NNZs: 2, Bias: -161681635612.866669, T: 4352, Avg. loss: 844818515118269703127040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7632214260.72, NNZs: 2, Bias: -161225168540.392090, T: 4480, Avg. loss: 733590245959300900978688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 600639401.40, NNZs: 2, Bias: -161160436471.184875, T: 4608, Avg. loss: 15216119091644829007872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1287356446.62, NNZs: 2, Bias: -161088494610.699188, T: 4736, Avg. loss: 3217681248417132576768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1805573014.53, NNZs: 2, Bias: -161022873290.513763, T: 4864, Avg. loss: 2880937333612382519296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2382933735.08, NNZs: 2, Bias: -160960406739.940430, T: 4992, Avg. loss: 2725181792547489972224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2679871608.36, NNZs: 2, Bias: -160904349964.174042, T: 5120, Avg. loss: 2487761690475509055488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2575642781.15, NNZs: 2, Bias: -160854767053.141632, T: 5248, Avg. loss: 2500570071096974376960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2574934035.64, NNZs: 2, Bias: -160800019032.709778, T: 5376, Avg. loss: 2769153904117701672960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2649405381.07, NNZs: 2, Bias: -160747887593.901428, T: 5504, Avg. loss: 2488210761198902181888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2644699775.98, NNZs: 2, Bias: -160689982766.922272, T: 5632, Avg. loss: 3011073368705653014528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2707819944.32, NNZs: 2, Bias: -160637369733.171478, T: 5760, Avg. loss: 2621511726405719687168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2587875399.08, NNZs: 2, Bias: -160627895114.118927, T: 5888, Avg. loss: 2338403606818252652544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2565531670.92, NNZs: 2, Bias: -160617492168.200348, T: 6016, Avg. loss: 2187766799437222641664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2560549301.72, NNZs: 2, Bias: -160606969873.650330, T: 6144, Avg. loss: 2148741820589132480512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2554140769.44, NNZs: 2, Bias: -160596202665.757416, T: 6272, Avg. loss: 2211961965296319987712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2555257230.23, NNZs: 2, Bias: -160585317620.345551, T: 6400, Avg. loss: 2201853793625619824640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2546951333.17, NNZs: 2, Bias: -160574528679.951904, T: 6528, Avg. loss: 2217772330254640611328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2519596347.56, NNZs: 2, Bias: -160564083134.461121, T: 6656, Avg. loss: 2209434803600305946624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2535268874.04, NNZs: 2, Bias: -160552894652.156769, T: 6784, Avg. loss: 2220997101654026747904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2527097693.53, NNZs: 2, Bias: -160550867330.085968, T: 6912, Avg. loss: 2127200724342014738432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2531785979.01, NNZs: 2, Bias: -160548632296.539062, T: 7040, Avg. loss: 2131180949190698336256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2531578506.57, NNZs: 2, Bias: -160546480273.376282, T: 7168, Avg. loss: 2125587000740948213760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2536160792.36, NNZs: 2, Bias: -160544248910.399445, T: 7296, Avg. loss: 2129046463095398203392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2539822265.52, NNZs: 2, Bias: -160542036264.843048, T: 7424, Avg. loss: 2124895503002720272384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2523660181.70, NNZs: 2, Bias: -160540138532.888123, T: 7552, Avg. loss: 2124079864655728082944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2518887734.06, NNZs: 2, Bias: -160538076088.253021, T: 7680, Avg. loss: 2108028038346389061632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2524752316.82, NNZs: 2, Bias: -160535820895.839325, T: 7808, Avg. loss: 2132883622004443840512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2524717892.81, NNZs: 2, Bias: -160533663154.332336, T: 7936, Avg. loss: 2128355204446847500288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2533907647.94, NNZs: 2, Bias: -160531362758.551880, T: 8064, Avg. loss: 2125073117970066833408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2525214211.63, NNZs: 2, Bias: -160529347741.946167, T: 8192, Avg. loss: 2122766766217870966784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2522697912.93, NNZs: 2, Bias: -160527233031.746277, T: 8320, Avg. loss: 2124411319920393191424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 65 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2493517770283.09, NNZs: 2, Bias: 108593831054.981400, T: 128, Avg. loss: 23703949543560892113068490752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1650628267398.99, NNZs: 2, Bias: 28593831054.981400, T: 256, Avg. loss: 24176883154786921957990334464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 963046624863.19, NNZs: 2, Bias: 28593831054.981400, T: 384, Avg. loss: 25076735297877474025601499136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 986744512560.92, NNZs: 2, Bias: -51406168945.018600, T: 512, Avg. loss: 26611050286344188159384879104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 721105372130.42, NNZs: 2, Bias: -31750588329.727585, T: 640, Avg. loss: 26640907187429771018711859200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 887463068594.21, NNZs: 2, Bias: -11750588329.727585, T: 768, Avg. loss: 22257434127690246607796699136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2083913631088.92, NNZs: 2, Bias: -51750588329.727585, T: 896, Avg. loss: 22460886423731036817218076672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 963013800429.93, NNZs: 2, Bias: 17363022365.172356, T: 1024, Avg. loss: 23271697016984427962455556096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1303068764032.61, NNZs: 2, Bias: -22636977634.827644, T: 1152, Avg. loss: 25905877359559542789279580160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2479454774622.70, NNZs: 2, Bias: -28445896038.704689, T: 1280, Avg. loss: 23170976277203539347822870528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1897423067473.97, NNZs: 2, Bias: -88445896038.704681, T: 1408, Avg. loss: 22925137846827579922416926720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 605724734975.29, NNZs: 2, Bias: -105008173856.518723, T: 1536, Avg. loss: 1134070348232893941917155328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 171985630632.46, NNZs: 2, Bias: -124274595357.294388, T: 1664, Avg. loss: 1000390430623482117716180992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 235091263599.92, NNZs: 2, Bias: -107146333933.469849, T: 1792, Avg. loss: 997802269192691343987572736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 169243864168.39, NNZs: 2, Bias: -105141201143.156433, T: 1920, Avg. loss: 964540977271303026581176320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 272717345084.90, NNZs: 2, Bias: -95478407359.517029, T: 2048, Avg. loss: 1013045679359758180850597888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 348358330686.88, NNZs: 2, Bias: -72833297075.975418, T: 2176, Avg. loss: 880959038487211326486609920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 332363048893.63, NNZs: 2, Bias: -71823299048.102692, T: 2304, Avg. loss: 923989150716237728672907264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 142583837188.15, NNZs: 2, Bias: -63277679015.688019, T: 2432, Avg. loss: 964613663390832648607760384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 64826261566.08, NNZs: 2, Bias: -80995341083.460068, T: 2560, Avg. loss: 885042985304419640471977984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 253966610108.89, NNZs: 2, Bias: -78195601719.560577, T: 2688, Avg. loss: 989015095028012489023422464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 49174479821.63, NNZs: 2, Bias: -86072373330.789230, T: 2816, Avg. loss: 967956450724024615469842432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 69088304242.60, NNZs: 2, Bias: -84194281121.258057, T: 2944, Avg. loss: 33610824425318151553548288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 49111807586.05, NNZs: 2, Bias: -83386686258.557571, T: 3072, Avg. loss: 35137287152503234244902912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 25488340471.31, NNZs: 2, Bias: -80959318506.213745, T: 3200, Avg. loss: 35241438947261952085196800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 55681153560.41, NNZs: 2, Bias: -82488479179.999771, T: 3328, Avg. loss: 36896747679041496643796992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 20754001510.27, NNZs: 2, Bias: -83010306260.444077, T: 3456, Avg. loss: 36416832196444543795593216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 6306501456.15, NNZs: 2, Bias: -84656489278.883545, T: 3584, Avg. loss: 36506274336893292634963968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 6045869934.60, NNZs: 2, Bias: -84568119064.207748, T: 3712, Avg. loss: 776926732626549958246400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2634553430.63, NNZs: 2, Bias: -84273042779.302826, T: 3840, Avg. loss: 775380541234107421556736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5748803132.09, NNZs: 2, Bias: -84301318358.569824, T: 3968, Avg. loss: 686706640048301558202368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3587691831.44, NNZs: 2, Bias: -84288089535.417191, T: 4096, Avg. loss: 745997355632680503345152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5604012787.80, NNZs: 2, Bias: -84575245695.464996, T: 4224, Avg. loss: 566999635495937636302848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4121921963.16, NNZs: 2, Bias: -84439019358.856491, T: 4352, Avg. loss: 761489879360062858723328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 12688637858.44, NNZs: 2, Bias: -84260842840.107605, T: 4480, Avg. loss: 601311372666771114819584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 10459503111.44, NNZs: 2, Bias: -84223777495.893112, T: 4608, Avg. loss: 805925219275626720002048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1509847297.84, NNZs: 2, Bias: -83924111060.749847, T: 4736, Avg. loss: 863918080439322876575744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3800375879.43, NNZs: 2, Bias: -83623117610.586716, T: 4864, Avg. loss: 775887806968774923386880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1168459685.82, NNZs: 2, Bias: -83614658558.071106, T: 4992, Avg. loss: 2325726275059428098048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1216731072.80, NNZs: 2, Bias: -83589735912.800095, T: 5120, Avg. loss: 614241832428947243008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1208630977.61, NNZs: 2, Bias: -83564243744.304977, T: 5248, Avg. loss: 663054117209006014464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1215875361.34, NNZs: 2, Bias: -83540633783.762970, T: 5376, Avg. loss: 594381077543281098752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1210385008.46, NNZs: 2, Bias: -83516379834.072693, T: 5504, Avg. loss: 621698870256396271616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1257758340.11, NNZs: 2, Bias: -83491670779.737274, T: 5632, Avg. loss: 624068441450671374336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1252566253.52, NNZs: 2, Bias: -83469092635.591705, T: 5760, Avg. loss: 574137388629666627584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1181547537.08, NNZs: 2, Bias: -83445573849.468781, T: 5888, Avg. loss: 653959713824449626112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1191691074.87, NNZs: 2, Bias: -83421863749.230560, T: 6016, Avg. loss: 609531995210788241408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1231845658.46, NNZs: 2, Bias: -83396375446.431183, T: 6144, Avg. loss: 630013809359203336192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1195741527.97, NNZs: 2, Bias: -83372475716.579620, T: 6272, Avg. loss: 613059375920465969152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1216105437.38, NNZs: 2, Bias: -83347346000.040436, T: 6400, Avg. loss: 631320205887716196352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1229594930.16, NNZs: 2, Bias: -83342443506.662308, T: 6528, Avg. loss: 494372891636609646592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1226506632.72, NNZs: 2, Bias: -83337820983.330124, T: 6656, Avg. loss: 488894132761048907776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1242228865.01, NNZs: 2, Bias: -83332860191.318115, T: 6784, Avg. loss: 494657193102037876736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1215710598.93, NNZs: 2, Bias: -83328364000.482422, T: 6912, Avg. loss: 514388726522190233600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1215891510.36, NNZs: 2, Bias: -83323480569.252960, T: 7040, Avg. loss: 512238774278881542144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1240736756.66, NNZs: 2, Bias: -83318316413.638260, T: 7168, Avg. loss: 502559746865002577920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1214875060.85, NNZs: 2, Bias: -83313834499.542480, T: 7296, Avg. loss: 511783787237507268608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1222320384.41, NNZs: 2, Bias: -83312752386.251068, T: 7424, Avg. loss: 497667219379469221888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1225392897.83, NNZs: 2, Bias: -83311741417.304688, T: 7552, Avg. loss: 494008652366651654144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1221865436.92, NNZs: 2, Bias: -83310825966.234894, T: 7680, Avg. loss: 494863588841323495424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1225493028.47, NNZs: 2, Bias: -83309807130.145264, T: 7808, Avg. loss: 493803411219858456576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1223721701.72, NNZs: 2, Bias: -83308865407.866714, T: 7936, Avg. loss: 495158179796120371200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 62 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 870879948691.64, NNZs: 2, Bias: -68963923928.432419, T: 128, Avg. loss: 21479771931472482246150062080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1089639011024.32, NNZs: 2, Bias: -40120583564.594986, T: 256, Avg. loss: 20816296321017119114231021568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1227668294792.58, NNZs: 2, Bias: 1846804281.159121, T: 384, Avg. loss: 20910705636238125964652969984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1843028709201.84, NNZs: 2, Bias: -78153195718.840881, T: 512, Avg. loss: 21180132031295762184152285184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1703057270988.92, NNZs: 2, Bias: -78153195718.840881, T: 640, Avg. loss: 21303525765340677195234803712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1583143144905.26, NNZs: 2, Bias: 17373834568.133987, T: 768, Avg. loss: 19394924997284604077483753472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 204681153920.16, NNZs: 2, Bias: 43673244305.121368, T: 896, Avg. loss: 23229592916982243835187822592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1333793412227.22, NNZs: 2, Bias: -45543508392.477669, T: 1024, Avg. loss: 22103753562246024243548520448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1781375892177.61, NNZs: 2, Bias: -46074033557.532196, T: 1152, Avg. loss: 20605188787189382138919124992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 233168340786.74, NNZs: 2, Bias: -165303607165.138611, T: 1280, Avg. loss: 21847899786012498511800565760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 514995441733.69, NNZs: 2, Bias: -125303607165.138611, T: 1408, Avg. loss: 20340596889522541910929965056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 99743551654.12, NNZs: 2, Bias: -139062802551.166626, T: 1536, Avg. loss: 915100701826769578971103232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 348771963588.02, NNZs: 2, Bias: -141967467565.598846, T: 1664, Avg. loss: 881032004609128954266124288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109419395123.22, NNZs: 2, Bias: -139981015598.505127, T: 1792, Avg. loss: 917959613597590623438766080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 354351457945.31, NNZs: 2, Bias: -134456409838.747742, T: 1920, Avg. loss: 823298648752162137272483840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61684014235.80, NNZs: 2, Bias: -121914008443.049637, T: 2048, Avg. loss: 768072421801042754427420672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 78468091121.60, NNZs: 2, Bias: -118172742422.099075, T: 2176, Avg. loss: 807080415185898655207915520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 222969529651.29, NNZs: 2, Bias: -111449979883.786926, T: 2304, Avg. loss: 923217609832062028276039680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 195265863739.74, NNZs: 2, Bias: -132765734250.676300, T: 2432, Avg. loss: 905254387043074368344162304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 309387834728.78, NNZs: 2, Bias: -125806622217.084015, T: 2560, Avg. loss: 834803620128876604514369536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 387490086714.57, NNZs: 2, Bias: -125095644236.875427, T: 2688, Avg. loss: 809715703948406229070512128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 23042313679.25, NNZs: 2, Bias: -118451517095.057236, T: 2816, Avg. loss: 60419678119717607313506304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 96355253974.32, NNZs: 2, Bias: -117495455919.077652, T: 2944, Avg. loss: 29640446294652613147230208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 46139578854.71, NNZs: 2, Bias: -114172943836.400452, T: 3072, Avg. loss: 29684140569460485583273984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 17759578297.59, NNZs: 2, Bias: -115411632709.495697, T: 3200, Avg. loss: 32867480305101342909661184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 28193644904.12, NNZs: 2, Bias: -115628091357.954819, T: 3328, Avg. loss: 33434693292642762250780672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 19700678765.47, NNZs: 2, Bias: -115079256876.659363, T: 3456, Avg. loss: 30283215774140609746436096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 88485508404.37, NNZs: 2, Bias: -119299333653.136047, T: 3584, Avg. loss: 28810314393643470798454784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 45707517100.89, NNZs: 2, Bias: -120231619126.563354, T: 3712, Avg. loss: 32068814141895289090342912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 88370791774.43, NNZs: 2, Bias: -118713797010.208939, T: 3840, Avg. loss: 32138448575819513396723712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 37930995745.72, NNZs: 2, Bias: -117759467755.454788, T: 3968, Avg. loss: 29887787861516532607614976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 50217724402.09, NNZs: 2, Bias: -117830379365.530594, T: 4096, Avg. loss: 28863452230096848555081728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 60640153031.41, NNZs: 2, Bias: -117595017849.153900, T: 4224, Avg. loss: 32323973999482242190016512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 17791825268.89, NNZs: 2, Bias: -118093875651.987244, T: 4352, Avg. loss: 1190594685938967479582720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7171922429.60, NNZs: 2, Bias: -118072629585.297638, T: 4480, Avg. loss: 584740890669647004696576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4943412880.52, NNZs: 2, Bias: -117807236054.839096, T: 4608, Avg. loss: 851831238731018264379392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8503416069.92, NNZs: 2, Bias: -117384775922.743393, T: 4736, Avg. loss: 581897642203025917345792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4334950165.91, NNZs: 2, Bias: -117020208756.958496, T: 4864, Avg. loss: 583916939078120819916800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6240865748.75, NNZs: 2, Bias: -117093686860.768845, T: 4992, Avg. loss: 639350819577026253422592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3701087301.21, NNZs: 2, Bias: -116774704800.630905, T: 5120, Avg. loss: 707528956786241286701056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1254580361.59, NNZs: 2, Bias: -116759888379.642944, T: 5248, Avg. loss: 642326532362035357810688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 11696298089.45, NNZs: 2, Bias: -116697752615.713318, T: 5376, Avg. loss: 641406125508841080619008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1763286659.60, NNZs: 2, Bias: -116603240802.553864, T: 5504, Avg. loss: 50847833482195432898560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1758473269.33, NNZs: 2, Bias: -116561543476.661545, T: 5632, Avg. loss: 1463257489727653150720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1768206318.50, NNZs: 2, Bias: -116519822143.624130, T: 5760, Avg. loss: 1464471327856167223296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1791700920.75, NNZs: 2, Bias: -116478004340.579117, T: 5888, Avg. loss: 1483991854268536586240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1798625996.58, NNZs: 2, Bias: -116439340515.194290, T: 6016, Avg. loss: 1314032987973481922560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1872346473.92, NNZs: 2, Bias: -116397837256.208496, T: 6144, Avg. loss: 1461037662120903180288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1833098348.50, NNZs: 2, Bias: -116355912360.438263, T: 6272, Avg. loss: 1531879099977403990016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1887247655.77, NNZs: 2, Bias: -116311813714.294159, T: 6400, Avg. loss: 1542079871612078784512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1854780692.16, NNZs: 2, Bias: -116270973558.478760, T: 6528, Avg. loss: 1529215946329493078016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1962087162.71, NNZs: 2, Bias: -116227458721.959274, T: 6656, Avg. loss: 1475618903775356125184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1952413535.05, NNZs: 2, Bias: -116219430581.022949, T: 6784, Avg. loss: 1200529197270443491328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1914721834.17, NNZs: 2, Bias: -116211852527.942764, T: 6912, Avg. loss: 1203363875585533411328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1911764885.72, NNZs: 2, Bias: -116203717434.783569, T: 7040, Avg. loss: 1200401508595587612672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1929731314.91, NNZs: 2, Bias: -116195307409.905685, T: 7168, Avg. loss: 1186810169944113414144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1899140160.02, NNZs: 2, Bias: -116187543779.863556, T: 7296, Avg. loss: 1213382943247888547840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1907305596.17, NNZs: 2, Bias: -116179168802.434280, T: 7424, Avg. loss: 1206359059966285053952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1865799520.69, NNZs: 2, Bias: -116171817583.344833, T: 7552, Avg. loss: 1177748703283886030848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1874049155.03, NNZs: 2, Bias: -116163551152.089584, T: 7680, Avg. loss: 1191697971032742690816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1912735805.15, NNZs: 2, Bias: -116155096296.681244, T: 7808, Avg. loss: 1142186701739612438528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1876387106.72, NNZs: 2, Bias: -116147476504.350662, T: 7936, Avg. loss: 1202491119776566083584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1860922413.80, NNZs: 2, Bias: -116139522139.897659, T: 8064, Avg. loss: 1203507970786039693312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1880239575.26, NNZs: 2, Bias: -116131001588.155869, T: 8192, Avg. loss: 1200661688437413249024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1867860839.83, NNZs: 2, Bias: -116123053069.982971, T: 8320, Avg. loss: 1193552985140753334272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1905577288.00, NNZs: 2, Bias: -116114247847.559891, T: 8448, Avg. loss: 1196372043242488201216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1880797377.15, NNZs: 2, Bias: -116112984711.906281, T: 8576, Avg. loss: 1189836863756887392256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1880146853.35, NNZs: 2, Bias: -116111371794.079422, T: 8704, Avg. loss: 1157377718152906276864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1880315561.29, NNZs: 2, Bias: -116109736749.671356, T: 8832, Avg. loss: 1163675025837440761856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1879147283.44, NNZs: 2, Bias: -116108125313.024780, T: 8960, Avg. loss: 1162275537176971313152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1866266275.83, NNZs: 2, Bias: -116106713440.495453, T: 9088, Avg. loss: 1155115368636468166656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 71 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1797549604257.77, NNZs: 2, Bias: 48594268046.704956, T: 128, Avg. loss: 18322011048164611885388267520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 478761043154.75, NNZs: 2, Bias: 68594268046.704956, T: 256, Avg. loss: 20342397195322384600514166784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1390708646393.09, NNZs: 2, Bias: 102018834291.854630, T: 384, Avg. loss: 21027900329492714714862452736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 773047652207.64, NNZs: 2, Bias: 37457760099.308289, T: 512, Avg. loss: 17992168411117848803963568128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 974388085796.54, NNZs: 2, Bias: 8329057234.513367, T: 640, Avg. loss: 21331900928076056381865590784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 420318408677.17, NNZs: 2, Bias: -11530525250.977600, T: 768, Avg. loss: 20874463915586456383658131456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2090570731809.23, NNZs: 2, Bias: -18981736671.148964, T: 896, Avg. loss: 18358431690283200168689926144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 964154360673.06, NNZs: 2, Bias: -73508471723.733673, T: 1024, Avg. loss: 20955627976034450138132905984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 773259433620.67, NNZs: 2, Bias: -13508471723.733673, T: 1152, Avg. loss: 19551834418028961199265153024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 169413927524.04, NNZs: 2, Bias: -8123388290.028141, T: 1280, Avg. loss: 944380101614962105355599872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 119320850891.93, NNZs: 2, Bias: -10890571857.208723, T: 1408, Avg. loss: 756776503959904402234408960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 186998246047.67, NNZs: 2, Bias: -3159830033.832588, T: 1536, Avg. loss: 872460172355414466928574464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 263090635847.13, NNZs: 2, Bias: -4552799395.348242, T: 1664, Avg. loss: 793724121079063151906914304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 156911648479.44, NNZs: 2, Bias: 12407526463.257576, T: 1792, Avg. loss: 888952620244928087430529024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 85423616227.54, NNZs: 2, Bias: 2617199879.999088, T: 1920, Avg. loss: 831000356542925431195566080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 342250097109.58, NNZs: 2, Bias: 9677189317.588579, T: 2048, Avg. loss: 798905194876174012434612224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 61801067395.35, NNZs: 2, Bias: 5001822556.270226, T: 2176, Avg. loss: 42236910954179114251059200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 49538662885.62, NNZs: 2, Bias: 4810707257.594459, T: 2304, Avg. loss: 31214078607576275963871232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 38395669583.30, NNZs: 2, Bias: 6448710042.312576, T: 2432, Avg. loss: 27354090249701218062434304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 47362316081.92, NNZs: 2, Bias: 9552191301.333588, T: 2560, Avg. loss: 31118332570260107171987456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 47542440061.46, NNZs: 2, Bias: 9015119210.145184, T: 2688, Avg. loss: 31415116069861949886693376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 115968420788.39, NNZs: 2, Bias: 11530558128.741354, T: 2816, Avg. loss: 28234865101011322784448512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 6766353844.30, NNZs: 2, Bias: 12699385369.530701, T: 2944, Avg. loss: 34091838099051349840756736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 64956654577.46, NNZs: 2, Bias: 11064019952.209599, T: 3072, Avg. loss: 27696461792788871890599936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2033852864.83, NNZs: 2, Bias: 10337350967.391851, T: 3200, Avg. loss: 1385572108462522229587968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 345626506.50, NNZs: 2, Bias: 10524662746.171097, T: 3328, Avg. loss: 413072966466966338404352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 19366390157.96, NNZs: 2, Bias: 10712536446.894016, T: 3456, Avg. loss: 289290170809383974338560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1509183264.88, NNZs: 2, Bias: 10779499776.594715, T: 3584, Avg. loss: 661312394127452240084992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 478292553.18, NNZs: 2, Bias: 10790786659.837542, T: 3712, Avg. loss: 402408807421988583768064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1638583381.06, NNZs: 2, Bias: 10742141086.238752, T: 3840, Avg. loss: 328191278174350168031232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1659470172.06, NNZs: 2, Bias: 10618847929.781576, T: 3968, Avg. loss: 369483583775380003094528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1302163203.63, NNZs: 2, Bias: 10529543352.010241, T: 4096, Avg. loss: 315913242940449021231104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 714158465.22, NNZs: 2, Bias: 10535111324.774792, T: 4224, Avg. loss: 170276911113403531264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 434035077.72, NNZs: 2, Bias: 10536155210.807734, T: 4352, Avg. loss: 50323936615307591680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 312456477.07, NNZs: 2, Bias: 10534596088.651863, T: 4480, Avg. loss: 20305852887826604032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 236674652.32, NNZs: 2, Bias: 10532029112.177063, T: 4608, Avg. loss: 16104878116837705728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 202083370.13, NNZs: 2, Bias: 10529261006.158880, T: 4736, Avg. loss: 11766273498085752832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 189783915.13, NNZs: 2, Bias: 10526096885.019377, T: 4864, Avg. loss: 11777685952679753728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 172712569.10, NNZs: 2, Bias: 10522855040.065548, T: 4992, Avg. loss: 11892264760050845696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 158858101.07, NNZs: 2, Bias: 10519535702.673613, T: 5120, Avg. loss: 12017287243315372032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 164078602.02, NNZs: 2, Bias: 10515962199.353317, T: 5248, Avg. loss: 11329699739692183552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 158621143.45, NNZs: 2, Bias: 10512359129.385538, T: 5376, Avg. loss: 11825345234403442688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 168017581.03, NNZs: 2, Bias: 10508801840.265934, T: 5504, Avg. loss: 10643981199855454208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 164091241.33, NNZs: 2, Bias: 10505213797.877026, T: 5632, Avg. loss: 12284727735583143936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 178482022.21, NNZs: 2, Bias: 10501699260.096369, T: 5760, Avg. loss: 10520097504744282112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 177969657.05, NNZs: 2, Bias: 10498469600.123100, T: 5888, Avg. loss: 10624512598734266368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 183073931.93, NNZs: 2, Bias: 10494718219.263500, T: 6016, Avg. loss: 11922651121908367360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 184109369.79, NNZs: 2, Bias: 10491199134.904839, T: 6144, Avg. loss: 11509678200232857600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 187515842.28, NNZs: 2, Bias: 10487488094.426210, T: 6272, Avg. loss: 11927582161866201088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 167118941.75, NNZs: 2, Bias: 10484328908.904484, T: 6400, Avg. loss: 11555573052890873856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 169440264.18, NNZs: 2, Bias: 10483581911.081812, T: 6528, Avg. loss: 9398115041164302336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 168141437.30, NNZs: 2, Bias: 10482887679.093727, T: 6656, Avg. loss: 9471943088133894144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 168207936.54, NNZs: 2, Bias: 10482172913.086056, T: 6784, Avg. loss: 9455790862473752576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 167323145.14, NNZs: 2, Bias: 10481492452.532700, T: 6912, Avg. loss: 9225809592362516480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 166451846.78, NNZs: 2, Bias: 10480793713.159479, T: 7040, Avg. loss: 9451542816587976704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 168972229.02, NNZs: 2, Bias: 10480046546.765478, T: 7168, Avg. loss: 9367514910016407552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 169874270.70, NNZs: 2, Bias: 10479322886.824610, T: 7296, Avg. loss: 9384276507795091456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 168103522.85, NNZs: 2, Bias: 10478637721.743189, T: 7424, Avg. loss: 9470300449474437120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 168456647.16, NNZs: 2, Bias: 10477925939.135958, T: 7552, Avg. loss: 9339151061839499264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 168546837.24, NNZs: 2, Bias: 10477783092.223867, T: 7680, Avg. loss: 9101063857580122112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 168689807.20, NNZs: 2, Bias: 10477639612.030247, T: 7808, Avg. loss: 9087266230696258560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 169348846.14, NNZs: 2, Bias: 10477487872.032021, T: 7936, Avg. loss: 9079844394115168256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 168598309.65, NNZs: 2, Bias: 10477359098.259077, T: 8064, Avg. loss: 9072094383494029312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 168686453.53, NNZs: 2, Bias: 10477216637.887218, T: 8192, Avg. loss: 9078663620121100288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 168603815.90, NNZs: 2, Bias: 10477076863.126829, T: 8320, Avg. loss: 9083035937443667968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 168654484.28, NNZs: 2, Bias: 10476934758.321526, T: 8448, Avg. loss: 9094456280840857600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 169004702.12, NNZs: 2, Bias: 10476787802.714010, T: 8576, Avg. loss: 9093604977411565568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 169045350.91, NNZs: 2, Bias: 10476645881.601616, T: 8704, Avg. loss: 9092478745109098496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 68 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 575571454975.90, NNZs: 2, Bias: -82886200924.480469, T: 128, Avg. loss: 18040445252601954895505915904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 882091331702.11, NNZs: 2, Bias: -121782430599.779602, T: 256, Avg. loss: 21516046207247098978022457344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1086633530229.30, NNZs: 2, Bias: -61782430599.779602, T: 384, Avg. loss: 21168785229402052485225381888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 217921866579.30, NNZs: 2, Bias: -1223468106.730042, T: 512, Avg. loss: 20801454437846841809455546368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2416489691215.20, NNZs: 2, Bias: -41223468106.730042, T: 640, Avg. loss: 19952158359196568201692446720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1515127268796.08, NNZs: 2, Bias: -101223468106.730042, T: 768, Avg. loss: 21778458787803679820051644416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 206911717537.78, NNZs: 2, Bias: -97181516530.521652, T: 896, Avg. loss: 1373191308946399415312056320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 55595062899.08, NNZs: 2, Bias: -101090777936.254700, T: 1024, Avg. loss: 796951933836125061796331520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 518113209233.45, NNZs: 2, Bias: -99699864447.693359, T: 1152, Avg. loss: 834189947506049607855505408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 79880953115.18, NNZs: 2, Bias: -103360126468.880707, T: 1280, Avg. loss: 872735733082137998804385792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 149003982685.85, NNZs: 2, Bias: -113064822638.454666, T: 1408, Avg. loss: 845531135442562335918522368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 82632740435.44, NNZs: 2, Bias: -122489215547.224091, T: 1536, Avg. loss: 829744776285080667167916032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 220886064536.81, NNZs: 2, Bias: -130650470518.494965, T: 1664, Avg. loss: 836799216913903719140032512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 5185886131.13, NNZs: 2, Bias: -125324798300.877441, T: 1792, Avg. loss: 41122184549736412696543232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 108127789363.32, NNZs: 2, Bias: -123912747691.443207, T: 1920, Avg. loss: 28408450504700697883181056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 19684885804.72, NNZs: 2, Bias: -125469970965.242676, T: 2048, Avg. loss: 32836824636148501555707904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 47980993729.87, NNZs: 2, Bias: -122447451481.543991, T: 2176, Avg. loss: 31735221189539762158960640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 88166402210.63, NNZs: 2, Bias: -119071891484.243393, T: 2304, Avg. loss: 28280490770832608980893696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 63892764687.92, NNZs: 2, Bias: -120244413895.510910, T: 2432, Avg. loss: 30816585452183159182458880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 25633587172.67, NNZs: 2, Bias: -119609789034.376648, T: 2560, Avg. loss: 34073521653875748823367680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 24778483825.18, NNZs: 2, Bias: -119429883939.060226, T: 2688, Avg. loss: 32030728373876614362038272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 89439046077.31, NNZs: 2, Bias: -118172462967.771225, T: 2816, Avg. loss: 29178799521026028284674048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 18195282253.79, NNZs: 2, Bias: -116925967135.935867, T: 2944, Avg. loss: 28921995475774207053266944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2775755554.96, NNZs: 2, Bias: -116384679247.837952, T: 3072, Avg. loss: 667893534702915408625664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 13506732746.94, NNZs: 2, Bias: -116476419440.042648, T: 3200, Avg. loss: 593716258036791421960192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1126133345.31, NNZs: 2, Bias: -116391990409.246094, T: 3328, Avg. loss: 759169725978267862695936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 9336025084.78, NNZs: 2, Bias: -116174902945.563492, T: 3456, Avg. loss: 663659805949528635342848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 11990520144.31, NNZs: 2, Bias: -116026740225.182343, T: 3584, Avg. loss: 499566919560078003535872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 6691274048.81, NNZs: 2, Bias: -116164149845.924683, T: 3712, Avg. loss: 549862136528542076239872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 11385804567.11, NNZs: 2, Bias: -116160063588.689835, T: 3840, Avg. loss: 499358429353659546468352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 12116323263.30, NNZs: 2, Bias: -115991524936.782883, T: 3968, Avg. loss: 412746132107000901795840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 7805199020.76, NNZs: 2, Bias: -115877895797.731384, T: 4096, Avg. loss: 463811803514958596014080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3363181826.25, NNZs: 2, Bias: -115760710654.747467, T: 4224, Avg. loss: 478420159757995858722816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 16998661794.52, NNZs: 2, Bias: -115507301583.628174, T: 4352, Avg. loss: 528870248277250605580288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6136321588.67, NNZs: 2, Bias: -115151191470.449493, T: 4480, Avg. loss: 747796381319719592919040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 13065832884.01, NNZs: 2, Bias: -114905279032.342102, T: 4608, Avg. loss: 602025333570678491709440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2006513908.95, NNZs: 2, Bias: -114926309274.053421, T: 4736, Avg. loss: 45827705598722831286272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1902107252.45, NNZs: 2, Bias: -114890854049.257858, T: 4864, Avg. loss: 1327376261048750047232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1996738499.66, NNZs: 2, Bias: -114854733251.837952, T: 4992, Avg. loss: 1190951781496992563200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1991255573.35, NNZs: 2, Bias: -114818812165.118683, T: 5120, Avg. loss: 1251929547234461614080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1936986938.31, NNZs: 2, Bias: -114783443577.455185, T: 5248, Avg. loss: 1322167194178451406848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1984420795.67, NNZs: 2, Bias: -114748725427.850174, T: 5376, Avg. loss: 1189944615232199983104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2036069071.81, NNZs: 2, Bias: -114711020398.945450, T: 5504, Avg. loss: 1297747855818020618240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1999165061.38, NNZs: 2, Bias: -114674712109.663086, T: 5632, Avg. loss: 1284284398363790278656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1892528796.76, NNZs: 2, Bias: -114641188208.573853, T: 5760, Avg. loss: 1213533754534637862912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1969811261.73, NNZs: 2, Bias: -114603884081.594498, T: 5888, Avg. loss: 1275509161834152198144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1914303388.57, NNZs: 2, Bias: -114568274110.430054, T: 6016, Avg. loss: 1293537015564832604160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1921048094.15, NNZs: 2, Bias: -114560924061.965271, T: 6144, Avg. loss: 1045092182037545484288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1920910707.05, NNZs: 2, Bias: -114553723138.303543, T: 6272, Avg. loss: 1040870702362699497472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1912746588.03, NNZs: 2, Bias: -114546672934.439316, T: 6400, Avg. loss: 1037202403302339903488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1972280130.37, NNZs: 2, Bias: -114538810107.598846, T: 6528, Avg. loss: 985136723405851721728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1948392443.74, NNZs: 2, Bias: -114531950755.222763, T: 6656, Avg. loss: 1050330800189533323264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1933078861.11, NNZs: 2, Bias: -114525092919.133896, T: 6784, Avg. loss: 1026806746381009944576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1954954483.18, NNZs: 2, Bias: -114517530839.112274, T: 6912, Avg. loss: 1036859679953477304320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1962589138.34, NNZs: 2, Bias: -114510187578.399475, T: 7040, Avg. loss: 1039976723686288523264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1957770469.32, NNZs: 2, Bias: -114502963510.897751, T: 7168, Avg. loss: 1056599331425365262336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1960361573.67, NNZs: 2, Bias: -114501489592.602783, T: 7296, Avg. loss: 1005017823397759811584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1954233887.15, NNZs: 2, Bias: -114500161407.126801, T: 7424, Avg. loss: 1007861586145884110848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1958333954.53, NNZs: 2, Bias: -114498657226.568665, T: 7552, Avg. loss: 1008255131320317902848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1959705486.77, NNZs: 2, Bias: -114497203753.097290, T: 7680, Avg. loss: 1005481433567761006592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1962689146.77, NNZs: 2, Bias: -114495722123.977722, T: 7808, Avg. loss: 1005776407107061284864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 61 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1252236258500.70, NNZs: 2, Bias: 35122060442.444931, T: 128, Avg. loss: 20965970537051203046666665984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 812854227251.71, NNZs: 2, Bias: 15122060442.444931, T: 256, Avg. loss: 22382194732951265061178966016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1074345756143.22, NNZs: 2, Bias: 7744866734.539665, T: 384, Avg. loss: 23152048241145207231776555008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2040926604408.17, NNZs: 2, Bias: -32255133265.460335, T: 512, Avg. loss: 23009009544231245385570451456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1233363300576.73, NNZs: 2, Bias: -6812113924.690338, T: 640, Avg. loss: 22300991691184137848401952768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1506742491778.56, NNZs: 2, Bias: 91812381324.102600, T: 768, Avg. loss: 23408871062598692961494499328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 380146494251.51, NNZs: 2, Bias: 131629112091.134659, T: 896, Avg. loss: 1004379908073997571817734144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 328865135597.06, NNZs: 2, Bias: 144269243611.848999, T: 1024, Avg. loss: 856270454031627460561338368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 226112278737.13, NNZs: 2, Bias: 144121101951.256134, T: 1152, Avg. loss: 905441334481001225541124096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 150105507394.22, NNZs: 2, Bias: 153257489425.168274, T: 1280, Avg. loss: 923222519104028837112971264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 326128642339.28, NNZs: 2, Bias: 147025072042.494446, T: 1408, Avg. loss: 832825081945870762055303168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 253699503614.31, NNZs: 2, Bias: 138545470055.327026, T: 1536, Avg. loss: 918886608844132608731250688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 522274839812.84, NNZs: 2, Bias: 149157253074.977417, T: 1664, Avg. loss: 911197576365063987225690112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 58062093626.45, NNZs: 2, Bias: 161944256687.973999, T: 1792, Avg. loss: 948849237706687865191137280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 215648961522.53, NNZs: 2, Bias: 168534721749.533997, T: 1920, Avg. loss: 858477771141306698017275904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 405293606304.97, NNZs: 2, Bias: 150689040238.828522, T: 2048, Avg. loss: 881604050184335224568020992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 41394651456.87, NNZs: 2, Bias: 153374299097.800446, T: 2176, Avg. loss: 80875012311859834153598976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40894759773.65, NNZs: 2, Bias: 151809205042.944641, T: 2304, Avg. loss: 32995169399058790682198016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 53932941695.70, NNZs: 2, Bias: 150371412241.706970, T: 2432, Avg. loss: 34074347727866764925599744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28942094598.19, NNZs: 2, Bias: 149856168814.577179, T: 2560, Avg. loss: 31896290938671840031145984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 31494674012.79, NNZs: 2, Bias: 147898932044.278168, T: 2688, Avg. loss: 33691955941078379754684416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 20495200388.50, NNZs: 2, Bias: 146626296227.143890, T: 2816, Avg. loss: 33708250806356371889455104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 68845273711.39, NNZs: 2, Bias: 146316238941.668396, T: 2944, Avg. loss: 30893073333012590632108032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 30686213437.49, NNZs: 2, Bias: 146613873316.236267, T: 3072, Avg. loss: 32993277002361386813095936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 47977033689.93, NNZs: 2, Bias: 145329899119.566101, T: 3200, Avg. loss: 35901402754298699006869504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 78146466669.67, NNZs: 2, Bias: 148365375672.628387, T: 3328, Avg. loss: 31695310061965208641863680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 85062408335.82, NNZs: 2, Bias: 149405230323.665192, T: 3456, Avg. loss: 30992655965949681909891072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 68854234459.26, NNZs: 2, Bias: 148273586397.192413, T: 3584, Avg. loss: 30954598494624619360681984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4812026821.11, NNZs: 2, Bias: 148493123266.283295, T: 3712, Avg. loss: 1879383670006314298245120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2474809343.18, NNZs: 2, Bias: 148414191511.731232, T: 3840, Avg. loss: 730696445457333735129088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5297361209.17, NNZs: 2, Bias: 148499187377.941742, T: 3968, Avg. loss: 763704135313830734462976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3889483696.57, NNZs: 2, Bias: 148707579061.180023, T: 4096, Avg. loss: 670763241564760203853824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7003984541.81, NNZs: 2, Bias: 148282488093.387329, T: 4224, Avg. loss: 658226386877971966197760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7318982274.57, NNZs: 2, Bias: 147583711925.413147, T: 4352, Avg. loss: 696888132931660074188800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1265054334.06, NNZs: 2, Bias: 147360073892.494995, T: 4480, Avg. loss: 649721669559115369676800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3540684897.30, NNZs: 2, Bias: 147131779383.407715, T: 4608, Avg. loss: 645467980279575721541632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1638943596.51, NNZs: 2, Bias: 147047662432.049744, T: 4736, Avg. loss: 570856615311378292408320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2415044465.85, NNZs: 2, Bias: 146701345777.383728, T: 4864, Avg. loss: 893438496479617759576064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 5868016775.15, NNZs: 2, Bias: 146250639738.328857, T: 4992, Avg. loss: 437424003813795520577536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2703389689.47, NNZs: 2, Bias: 146173721698.957642, T: 5120, Avg. loss: 652397863713248060112896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 11546244926.82, NNZs: 2, Bias: 145795305953.324860, T: 5248, Avg. loss: 700502269018754911305728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3494281633.86, NNZs: 2, Bias: 145719512645.817444, T: 5376, Avg. loss: 791196093836728666685440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 7252400488.59, NNZs: 2, Bias: 145541858314.572571, T: 5504, Avg. loss: 737483954730030891794432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3102770034.80, NNZs: 2, Bias: 145171403806.846832, T: 5632, Avg. loss: 663750999806963521421312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 907751147.68, NNZs: 2, Bias: 145080429883.168640, T: 5760, Avg. loss: 5319467160782684291072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1597417925.07, NNZs: 2, Bias: 145019639260.091797, T: 5888, Avg. loss: 2334887989687954702336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1964714784.55, NNZs: 2, Bias: 144964769983.936920, T: 6016, Avg. loss: 2263332880530180669440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2049281161.06, NNZs: 2, Bias: 144913018345.354218, T: 6144, Avg. loss: 2231380690035206258688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2061570469.97, NNZs: 2, Bias: 144862537949.554657, T: 6272, Avg. loss: 2227783273045890170880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2236973407.02, NNZs: 2, Bias: 144809586420.616150, T: 6400, Avg. loss: 2335145275120397582336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2211516202.98, NNZs: 2, Bias: 144762517678.206024, T: 6528, Avg. loss: 2252486442442600218624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2232482432.19, NNZs: 2, Bias: 144713885214.173737, T: 6656, Avg. loss: 2219363166663484899328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2195128607.50, NNZs: 2, Bias: 144668448381.100922, T: 6784, Avg. loss: 2112838819630829010944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2170583722.79, NNZs: 2, Bias: 144618928652.621552, T: 6912, Avg. loss: 2303228758641419223040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2326304721.66, NNZs: 2, Bias: 144567003104.882721, T: 7040, Avg. loss: 2244430248255452348416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2316039415.16, NNZs: 2, Bias: 144518246042.813660, T: 7168, Avg. loss: 2204799225356716081152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2299165840.59, NNZs: 2, Bias: 144467673516.638824, T: 7296, Avg. loss: 2324975096219869642752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2245599603.24, NNZs: 2, Bias: 144419656139.277863, T: 7424, Avg. loss: 2253217256795699150848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2242674133.66, NNZs: 2, Bias: 144409845207.521393, T: 7552, Avg. loss: 1801528000536697896960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2224811056.39, NNZs: 2, Bias: 144400364170.685913, T: 7680, Avg. loss: 1782282770057189654528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2220772474.19, NNZs: 2, Bias: 144390785993.263306, T: 7808, Avg. loss: 1759063662292130070528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2237719726.23, NNZs: 2, Bias: 144380737993.892181, T: 7936, Avg. loss: 1786323716639857573888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2248717404.66, NNZs: 2, Bias: 144370819689.195953, T: 8064, Avg. loss: 1776217219323958657024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2224813293.76, NNZs: 2, Bias: 144361529268.646149, T: 8192, Avg. loss: 1759308438644343701504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2242782814.26, NNZs: 2, Bias: 144351646613.573303, T: 8320, Avg. loss: 1747502401280451280896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2234417770.69, NNZs: 2, Bias: 144342007298.539001, T: 8448, Avg. loss: 1784601989287273299968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2271470195.47, NNZs: 2, Bias: 144331609436.035126, T: 8576, Avg. loss: 1789484952920332697600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2261906142.45, NNZs: 2, Bias: 144322116763.603821, T: 8704, Avg. loss: 1758037321016897961984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2260724006.60, NNZs: 2, Bias: 144312408293.875092, T: 8832, Avg. loss: 1774770178993433870336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2223997047.95, NNZs: 2, Bias: 144303383610.284149, T: 8960, Avg. loss: 1752530488957261053952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2247928513.33, NNZs: 2, Bias: 144301048045.291809, T: 9088, Avg. loss: 1740247589937354113024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2251457777.48, NNZs: 2, Bias: 144299051316.407837, T: 9216, Avg. loss: 1720912889840908107776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2258180237.64, NNZs: 2, Bias: 144297009989.359406, T: 9344, Avg. loss: 1715807780742079447040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2252785857.98, NNZs: 2, Bias: 144295151891.190094, T: 9472, Avg. loss: 1721976822360089559040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2256130945.94, NNZs: 2, Bias: 144293162219.993530, T: 9600, Avg. loss: 1717085251861291728896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2254340697.60, NNZs: 2, Bias: 144291247159.425232, T: 9728, Avg. loss: 1722344557675547983872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2252055477.31, NNZs: 2, Bias: 144289343304.873474, T: 9856, Avg. loss: 1719119017408072253440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2256544092.94, NNZs: 2, Bias: 144287332674.824585, T: 9984, Avg. loss: 1719714525205700018176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 78 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1381704210182.95, NNZs: 2, Bias: 30514275570.088760, T: 128, Avg. loss: 23015444884087377152197001216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 826164803871.46, NNZs: 2, Bias: 85015992736.811218, T: 256, Avg. loss: 23333022806528105100987072512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1206011347399.72, NNZs: 2, Bias: 107649114053.732849, T: 384, Avg. loss: 24624827521334543162965753856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2298051736445.62, NNZs: 2, Bias: -12350885946.267151, T: 512, Avg. loss: 23375502517182575678377164800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 617307046449.51, NNZs: 2, Bias: -39410986588.510010, T: 640, Avg. loss: 28158447102965048609207222272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1800915513395.66, NNZs: 2, Bias: -57400261612.642838, T: 768, Avg. loss: 24550132520055293132150931456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 399100879511.75, NNZs: 2, Bias: -64549498349.686920, T: 896, Avg. loss: 2154049192859626185970155520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 384940161142.31, NNZs: 2, Bias: -60512567168.907471, T: 1024, Avg. loss: 940296693493007232574423040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 247814539718.53, NNZs: 2, Bias: -61681181112.331581, T: 1152, Avg. loss: 990444712979477753157910528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 70389131009.59, NNZs: 2, Bias: -61670319105.362160, T: 1280, Avg. loss: 1016776345239609704026472448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 340980300962.77, NNZs: 2, Bias: -53153249030.397301, T: 1408, Avg. loss: 915457688627494572773081088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 368422515026.97, NNZs: 2, Bias: -47776053294.007072, T: 1536, Avg. loss: 955617240016419513534775296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 357339415957.14, NNZs: 2, Bias: -38757000162.400009, T: 1664, Avg. loss: 894696522332232965395841024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 326240913009.33, NNZs: 2, Bias: -25627159432.424423, T: 1792, Avg. loss: 930151510537999832684953600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 144802972938.64, NNZs: 2, Bias: -12386153020.158306, T: 1920, Avg. loss: 983412264101076540042772480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 40423777625.13, NNZs: 2, Bias: -16841865751.618374, T: 2048, Avg. loss: 1017048279898552608657244160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 131905923341.42, NNZs: 2, Bias: -26723148863.713692, T: 2176, Avg. loss: 1022318054269045167009824768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 257518846260.04, NNZs: 2, Bias: -40484152248.109619, T: 2304, Avg. loss: 913521745318367717564088320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 30434733166.98, NNZs: 2, Bias: -37885719362.994904, T: 2432, Avg. loss: 43831007762162058797252608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 19864000180.94, NNZs: 2, Bias: -36266398362.439583, T: 2560, Avg. loss: 34518161063173698468446208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 41125777294.50, NNZs: 2, Bias: -34686021535.274963, T: 2688, Avg. loss: 37436579012178581552889856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 48391938740.83, NNZs: 2, Bias: -34478555599.871490, T: 2816, Avg. loss: 36607135350902239241699328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 70420102411.10, NNZs: 2, Bias: -33439050933.223499, T: 2944, Avg. loss: 34833514905092361642049536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 80391101786.18, NNZs: 2, Bias: -31660156080.940342, T: 3072, Avg. loss: 37465039624965668472881152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 63045467918.07, NNZs: 2, Bias: -33068107931.865253, T: 3200, Avg. loss: 38382740372856715410931712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 5851581619.50, NNZs: 2, Bias: -32927440728.373596, T: 3328, Avg. loss: 1763682612117371208335360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 3005678635.08, NNZs: 2, Bias: -32757312828.554615, T: 3456, Avg. loss: 698339548665110404792320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4459057185.14, NNZs: 2, Bias: -32716790018.053703, T: 3584, Avg. loss: 662571772764529069391872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9211111237.88, NNZs: 2, Bias: -32537367843.262642, T: 3712, Avg. loss: 561631274044368613277696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 14382180476.15, NNZs: 2, Bias: -32539795109.775314, T: 3840, Avg. loss: 662234848700189514924032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4544926378.20, NNZs: 2, Bias: -32805985872.204918, T: 3968, Avg. loss: 714306848819934736154624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 10117636144.91, NNZs: 2, Bias: -32946481657.429562, T: 4096, Avg. loss: 668093757316857725976576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 18502604194.54, NNZs: 2, Bias: -32641788324.239170, T: 4224, Avg. loss: 692121938729491905904640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6174004446.23, NNZs: 2, Bias: -32330268424.082363, T: 4352, Avg. loss: 501245906029849681592320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 16468702535.66, NNZs: 2, Bias: -32127184483.520901, T: 4480, Avg. loss: 700070421064404153925632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5769314692.93, NNZs: 2, Bias: -32050125886.438938, T: 4608, Avg. loss: 594232076688111863595008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5328754566.88, NNZs: 2, Bias: -31966085855.562454, T: 4736, Avg. loss: 589151019069518125203456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3923391741.15, NNZs: 2, Bias: -31926760350.900578, T: 4864, Avg. loss: 682284110540364759171072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2406992314.74, NNZs: 2, Bias: -32027811998.082050, T: 4992, Avg. loss: 454065903403005500194816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 10121175754.09, NNZs: 2, Bias: -31925912268.536976, T: 5120, Avg. loss: 549568907408576442531840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2894614400.28, NNZs: 2, Bias: -31978510850.493351, T: 5248, Avg. loss: 684043387724621089341440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 503180116.20, NNZs: 2, Bias: -32084817325.535091, T: 5376, Avg. loss: 645831522838357827649536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2053178746.94, NNZs: 2, Bias: -32492095129.037296, T: 5504, Avg. loss: 708945194918194196774912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1366150937.66, NNZs: 2, Bias: -32491490566.035351, T: 5632, Avg. loss: 864756421309108632682496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 804524161.01, NNZs: 2, Bias: -32488201580.249920, T: 5760, Avg. loss: 294896779139615948800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 637626604.88, NNZs: 2, Bias: -32481389237.163052, T: 5888, Avg. loss: 112082636257954955264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 575794898.49, NNZs: 2, Bias: -32472748769.581394, T: 6016, Avg. loss: 106474439932972875776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 529086108.61, NNZs: 2, Bias: -32463350950.111088, T: 6144, Avg. loss: 103381038917277286400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 505397919.82, NNZs: 2, Bias: -32454006720.760426, T: 6272, Avg. loss: 97521668102106480640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 528926850.00, NNZs: 2, Bias: -32444101701.753948, T: 6400, Avg. loss: 94548878692607377408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 467467015.17, NNZs: 2, Bias: -32435322648.195488, T: 6528, Avg. loss: 96457593696773144576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 454662532.63, NNZs: 2, Bias: -32425787731.854877, T: 6656, Avg. loss: 98243420827002585088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 495316177.09, NNZs: 2, Bias: -32416026860.464928, T: 6784, Avg. loss: 91899472484286857216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 485270842.83, NNZs: 2, Bias: -32406600021.158825, T: 6912, Avg. loss: 93778328717392232448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 510341130.73, NNZs: 2, Bias: -32397019086.997791, T: 7040, Avg. loss: 93271325502067851264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 501883241.40, NNZs: 2, Bias: -32387309490.439789, T: 7168, Avg. loss: 96423906287579381760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 471718889.96, NNZs: 2, Bias: -32378400415.690140, T: 7296, Avg. loss: 91759574451931938816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 484648700.13, NNZs: 2, Bias: -32369634648.569435, T: 7424, Avg. loss: 82842284501775564800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 501853079.41, NNZs: 2, Bias: -32359570191.200401, T: 7552, Avg. loss: 94060520403908788224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 496509856.86, NNZs: 2, Bias: -32350492065.486694, T: 7680, Avg. loss: 91074335051206426624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 508387436.79, NNZs: 2, Bias: -32340879012.692699, T: 7808, Avg. loss: 94853273401588875264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 478085065.86, NNZs: 2, Bias: -32331905487.286797, T: 7936, Avg. loss: 91978863177994665984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 516077641.13, NNZs: 2, Bias: -32321805613.414726, T: 8064, Avg. loss: 95133116725552365568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 504743191.20, NNZs: 2, Bias: -32320085241.174377, T: 8192, Avg. loss: 77579654141005299712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 495701046.12, NNZs: 2, Bias: -32318311561.534660, T: 8320, Avg. loss: 78220222962511724544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 489548621.26, NNZs: 2, Bias: -32316544315.938652, T: 8448, Avg. loss: 75854074634042015744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 495254768.89, NNZs: 2, Bias: -32314573598.536274, T: 8576, Avg. loss: 76707451606335733760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 485833951.99, NNZs: 2, Bias: -32312841467.345280, T: 8704, Avg. loss: 76318270456593940480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 483238790.00, NNZs: 2, Bias: -32310991486.027611, T: 8832, Avg. loss: 77107945758902009856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 478040365.95, NNZs: 2, Bias: -32309203313.105335, T: 8960, Avg. loss: 76146508315595915264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 488044615.64, NNZs: 2, Bias: -32307161423.110558, T: 9088, Avg. loss: 76971478811250032640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 482428106.89, NNZs: 2, Bias: -32306868530.527267, T: 9216, Avg. loss: 74890500206531461120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 481667385.11, NNZs: 2, Bias: -32306504767.501144, T: 9344, Avg. loss: 74426237358942535680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 483773724.08, NNZs: 2, Bias: -32306097693.021591, T: 9472, Avg. loss: 74492079070674567168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 482225136.14, NNZs: 2, Bias: -32305745545.917767, T: 9600, Avg. loss: 74471507169703428096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 482477815.30, NNZs: 2, Bias: -32305366071.187038, T: 9728, Avg. loss: 74530684844717522944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 484394473.98, NNZs: 2, Bias: -32304964138.653870, T: 9856, Avg. loss: 74020181571518939136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 481277301.37, NNZs: 2, Bias: -32304636073.434086, T: 9984, Avg. loss: 74348587925729935360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 481596816.23, NNZs: 2, Bias: -32304255755.916344, T: 10112, Avg. loss: 74496224195084664832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 481483159.72, NNZs: 2, Bias: -32303882663.415554, T: 10240, Avg. loss: 74344432670590615552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 480941387.87, NNZs: 2, Bias: -32303515237.723446, T: 10368, Avg. loss: 74492265275039416320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 481218398.67, NNZs: 2, Bias: -32303137394.543972, T: 10496, Avg. loss: 74109629511067860992.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 82 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 304920141687.64, NNZs: 2, Bias: 54619631017.997437, T: 128, Avg. loss: 19176689779802342091330158592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2129183780047.40, NNZs: 2, Bias: 64502959441.292938, T: 256, Avg. loss: 21013090380868461023354421248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1785784702946.13, NNZs: 2, Bias: 124502959441.292938, T: 384, Avg. loss: 20490776572196156391395688448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 644521421460.84, NNZs: 2, Bias: 44502959441.292938, T: 512, Avg. loss: 22981301020313260183991091200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 112315150912.44, NNZs: 2, Bias: 58155668264.109070, T: 640, Avg. loss: 20927734712507408974016937984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1957935602813.45, NNZs: 2, Bias: 28358043176.913277, T: 768, Avg. loss: 22531223972027197943214768128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 306471628299.08, NNZs: 2, Bias: 48308169000.888008, T: 896, Avg. loss: 2373971213688886696374960128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 274061104866.59, NNZs: 2, Bias: 50788207709.342995, T: 1024, Avg. loss: 827206329898195436588498944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 26287216675.83, NNZs: 2, Bias: 79036952016.365387, T: 1152, Avg. loss: 863703119395061868364038144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 189327446917.65, NNZs: 2, Bias: 86824464668.298721, T: 1280, Avg. loss: 837517968415500243195396096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 107885657454.00, NNZs: 2, Bias: 99260827445.269333, T: 1408, Avg. loss: 960271197905378203058307072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 170059853053.95, NNZs: 2, Bias: 97029225960.196991, T: 1536, Avg. loss: 828237126933128235899158528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 167276035224.95, NNZs: 2, Bias: 90136443115.693481, T: 1664, Avg. loss: 837106112959611869318873088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 34393738245.63, NNZs: 2, Bias: 91169913790.647156, T: 1792, Avg. loss: 37005349525214508978536448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 53988959380.62, NNZs: 2, Bias: 88595064293.034271, T: 1920, Avg. loss: 31476570047617885175545856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 32234524697.20, NNZs: 2, Bias: 84387148815.234650, T: 2048, Avg. loss: 34642775664264390371180544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 59804715294.64, NNZs: 2, Bias: 83786339224.269135, T: 2176, Avg. loss: 30931115807331979001593856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 75411040008.50, NNZs: 2, Bias: 86349707537.465683, T: 2304, Avg. loss: 31023731604823125142798336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 15475516957.07, NNZs: 2, Bias: 82493883019.541519, T: 2432, Avg. loss: 31987538424258786765045760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 35424184830.48, NNZs: 2, Bias: 81931414596.741058, T: 2560, Avg. loss: 28816951306963481360596992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 74983302484.33, NNZs: 2, Bias: 79812322459.312943, T: 2688, Avg. loss: 32376969226176788709769216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 33440202324.32, NNZs: 2, Bias: 79382585699.112061, T: 2816, Avg. loss: 31894086939014523139391488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 56390721955.60, NNZs: 2, Bias: 77300628136.006821, T: 2944, Avg. loss: 32883355129679853970784256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 41097061207.79, NNZs: 2, Bias: 82358496889.091614, T: 3072, Avg. loss: 29071834668543892023934976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 7337632723.49, NNZs: 2, Bias: 82775862143.793915, T: 3200, Avg. loss: 30479311591277501391831040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2412231884.12, NNZs: 2, Bias: 82645496439.115906, T: 3328, Avg. loss: 645662464501473444102144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 609124688.04, NNZs: 2, Bias: 82318046846.785126, T: 3456, Avg. loss: 707122969332201277095936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 6932717479.63, NNZs: 2, Bias: 82498840931.611435, T: 3584, Avg. loss: 589528700288246745137152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4203088001.61, NNZs: 2, Bias: 82533496838.069580, T: 3712, Avg. loss: 523625817008968336146432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 6330686676.69, NNZs: 2, Bias: 82199553797.256393, T: 3840, Avg. loss: 519912707808783901917184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4249048322.34, NNZs: 2, Bias: 82352765953.428452, T: 3968, Avg. loss: 719248845240604345499648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1237117466.60, NNZs: 2, Bias: 82560907466.628723, T: 4096, Avg. loss: 756878137856707602153472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9675822506.24, NNZs: 2, Bias: 82401364532.279785, T: 4224, Avg. loss: 502179949894847703285760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9501209517.44, NNZs: 2, Bias: 82546901458.100586, T: 4352, Avg. loss: 815615566863496875343872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2455481935.20, NNZs: 2, Bias: 82392712510.923111, T: 4480, Avg. loss: 489003703258543158198272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9335645275.77, NNZs: 2, Bias: 82235701952.468643, T: 4608, Avg. loss: 523482789331454052532224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 14262443690.97, NNZs: 2, Bias: 81958618368.066086, T: 4736, Avg. loss: 550938183986009700564992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8277477845.06, NNZs: 2, Bias: 81912207832.629852, T: 4864, Avg. loss: 537202963421043407978496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 276744739.14, NNZs: 2, Bias: 81919838960.933990, T: 4992, Avg. loss: 702010185356013327089664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 8632284929.32, NNZs: 2, Bias: 81884296572.520538, T: 5120, Avg. loss: 514341011208825907183616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1825656264.12, NNZs: 2, Bias: 81823893016.054932, T: 5248, Avg. loss: 19069586762301083484160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1595163725.12, NNZs: 2, Bias: 81800566747.540619, T: 5376, Avg. loss: 711656717912182489088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1460610183.89, NNZs: 2, Bias: 81774581409.378296, T: 5504, Avg. loss: 763286326351813148672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1336832658.90, NNZs: 2, Bias: 81747800570.591675, T: 5632, Avg. loss: 720837499404941000704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1309947670.78, NNZs: 2, Bias: 81718923078.487213, T: 5760, Avg. loss: 744421977955152822272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1257085360.11, NNZs: 2, Bias: 81689255808.978027, T: 5888, Avg. loss: 769922010577146085376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1215911089.82, NNZs: 2, Bias: 81661017298.916473, T: 6016, Avg. loss: 738165272017602871296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1277776756.83, NNZs: 2, Bias: 81653828686.288071, T: 6144, Avg. loss: 642220634096486449152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1287418120.39, NNZs: 2, Bias: 81647854473.153595, T: 6272, Avg. loss: 598602983420051718144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1295197093.76, NNZs: 2, Bias: 81641931311.336838, T: 6400, Avg. loss: 596113494111390007296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1288560294.75, NNZs: 2, Bias: 81636232282.618195, T: 6528, Avg. loss: 597657073139545014272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1296553737.71, NNZs: 2, Bias: 81630392309.714676, T: 6656, Avg. loss: 586942167811804037120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1295732214.46, NNZs: 2, Bias: 81624600296.342819, T: 6784, Avg. loss: 596856966965076819968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1274322206.46, NNZs: 2, Bias: 81619332101.669571, T: 6912, Avg. loss: 575964862207644794880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1302954904.63, NNZs: 2, Bias: 81613083051.153763, T: 7040, Avg. loss: 594565472519546601472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1307894797.76, NNZs: 2, Bias: 81607210225.023254, T: 7168, Avg. loss: 595072466888170274816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1296113024.17, NNZs: 2, Bias: 81601714128.329941, T: 7296, Avg. loss: 584520137008121315328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1317013306.18, NNZs: 2, Bias: 81595781806.078629, T: 7424, Avg. loss: 573512704709781487616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1298447842.52, NNZs: 2, Bias: 81590318700.924454, T: 7552, Avg. loss: 593248880994461810688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1321891964.49, NNZs: 2, Bias: 81584188728.648895, T: 7680, Avg. loss: 589948976604041379840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1301115705.62, NNZs: 2, Bias: 81578782744.154602, T: 7808, Avg. loss: 589938249260296699904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1326394530.16, NNZs: 2, Bias: 81572637042.451126, T: 7936, Avg. loss: 588340810315172020224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1315147915.75, NNZs: 2, Bias: 81567174296.198410, T: 8064, Avg. loss: 580413187993686835200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1315027885.44, NNZs: 2, Bias: 81566030723.209442, T: 8192, Avg. loss: 573695721151264980992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1313839346.50, NNZs: 2, Bias: 81564907212.688812, T: 8320, Avg. loss: 572316214819450126336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1318307646.17, NNZs: 2, Bias: 81563687842.929977, T: 8448, Avg. loss: 574395392844728238080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1317436904.51, NNZs: 2, Bias: 81562558065.272095, T: 8576, Avg. loss: 572815772139809538048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1323733927.51, NNZs: 2, Bias: 81561317206.256256, T: 8704, Avg. loss: 570153612740645093376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1322068833.29, NNZs: 2, Bias: 81560199683.490067, T: 8832, Avg. loss: 573182326453549268992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1318812998.55, NNZs: 2, Bias: 81559104586.234711, T: 8960, Avg. loss: 574866445809056153600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1319266222.42, NNZs: 2, Bias: 81557951536.069611, T: 9088, Avg. loss: 573709524465820368896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1315978077.49, NNZs: 2, Bias: 81556859981.442108, T: 9216, Avg. loss: 573239990566268698624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1319489726.39, NNZs: 2, Bias: 81555657664.524933, T: 9344, Avg. loss: 573552949643512512512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 73 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 500177030793.18, NNZs: 2, Bias: 4428710613.057816, T: 128, Avg. loss: 19224074528552332872908800000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 766449153959.71, NNZs: 2, Bias: 34214358717.229691, T: 256, Avg. loss: 20892713033300318403841490944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2278977397237.56, NNZs: 2, Bias: 135009520841.498138, T: 384, Avg. loss: 18681866286680271719441104896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 415611765155.58, NNZs: 2, Bias: 87284297763.227188, T: 512, Avg. loss: 20755250501048402263026958336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 90123686904.66, NNZs: 2, Bias: 108434778559.914551, T: 640, Avg. loss: 20279756673358301852399042560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1330644999083.69, NNZs: 2, Bias: 134357132691.371582, T: 768, Avg. loss: 19848151696047855350509993984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1233772425500.05, NNZs: 2, Bias: 174357132691.371582, T: 896, Avg. loss: 20060143790703317585936515072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 928090411291.93, NNZs: 2, Bias: 154357132691.371582, T: 1024, Avg. loss: 18430661996669907919899197440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 773103627906.91, NNZs: 2, Bias: 178150882959.826782, T: 1152, Avg. loss: 20909364530733873640608104448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 980667224120.69, NNZs: 2, Bias: 118494259978.383911, T: 1280, Avg. loss: 21620047152422117356391628800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 180838429786.67, NNZs: 2, Bias: 144322899466.589905, T: 1408, Avg. loss: 20885726201772626324832124928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 319431286347.95, NNZs: 2, Bias: 144322899466.589905, T: 1536, Avg. loss: 20421913666903040323032711168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 2803079118433.76, NNZs: 2, Bias: 133026235857.811218, T: 1664, Avg. loss: 19666936467068314949227905024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 255047579373.92, NNZs: 2, Bias: 172354117672.694519, T: 1792, Avg. loss: 3543214747114766058387406848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 440427894298.26, NNZs: 2, Bias: 159188633868.245239, T: 1920, Avg. loss: 821063042382604892641427456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 252921399022.69, NNZs: 2, Bias: 152177007462.860168, T: 2048, Avg. loss: 724227272997484638486134784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 68443673864.34, NNZs: 2, Bias: 147728855055.723114, T: 2176, Avg. loss: 773628985966771246836219904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 338537868615.25, NNZs: 2, Bias: 141404968580.247986, T: 2304, Avg. loss: 805770726602667201382055936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 32456828251.72, NNZs: 2, Bias: 164456503887.561462, T: 2432, Avg. loss: 844148909473830563706044416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 204877760772.69, NNZs: 2, Bias: 140127055320.327820, T: 2560, Avg. loss: 800275681872376793940361216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 352034955136.13, NNZs: 2, Bias: 138602007547.580475, T: 2688, Avg. loss: 770647486862099426268151808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 31728574380.79, NNZs: 2, Bias: 136231340896.369904, T: 2816, Avg. loss: 78392304376577017090408448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 23307945103.53, NNZs: 2, Bias: 134668914973.790222, T: 2944, Avg. loss: 28328175901854104897454080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 39654813790.98, NNZs: 2, Bias: 133924800680.571747, T: 3072, Avg. loss: 30347614306781731024273408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 41738691776.41, NNZs: 2, Bias: 134253743818.924332, T: 3200, Avg. loss: 32759863181243314346131456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 76264710519.66, NNZs: 2, Bias: 133943930619.529816, T: 3328, Avg. loss: 30114136958324984921456640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 97786962370.75, NNZs: 2, Bias: 133011179234.082382, T: 3456, Avg. loss: 28220400719405091597058048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 73052057620.32, NNZs: 2, Bias: 129492506400.681091, T: 3584, Avg. loss: 31296301519324906642210816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 35488282560.29, NNZs: 2, Bias: 128025139000.457169, T: 3712, Avg. loss: 31100453394296385979809792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 26925885297.56, NNZs: 2, Bias: 126906444575.319901, T: 3840, Avg. loss: 27198530263471480039800832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 28046908467.55, NNZs: 2, Bias: 127452527218.125977, T: 3968, Avg. loss: 25707917221290423986683904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 65737520524.20, NNZs: 2, Bias: 127683209088.663406, T: 4096, Avg. loss: 30088239593166677561311232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 27018990216.60, NNZs: 2, Bias: 125188380932.641388, T: 4224, Avg. loss: 29503414284242523225325568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 82026218039.40, NNZs: 2, Bias: 126645385030.961288, T: 4352, Avg. loss: 28269939282662807799070720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 20383709013.11, NNZs: 2, Bias: 128361646343.106277, T: 4480, Avg. loss: 32717504608825473211826176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 103690062300.59, NNZs: 2, Bias: 127859198354.251221, T: 4608, Avg. loss: 27242194603740119911366656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2212671582.84, NNZs: 2, Bias: 127130109639.065033, T: 4736, Avg. loss: 4814089366115650411429888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1303519404.32, NNZs: 2, Bias: 126822233504.586090, T: 4864, Avg. loss: 359615278728748053037056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6081832600.13, NNZs: 2, Bias: 126194625125.579300, T: 4992, Avg. loss: 516042342516273019092992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9474253234.53, NNZs: 2, Bias: 126342148303.704208, T: 5120, Avg. loss: 530099593076463324102656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 13687003607.09, NNZs: 2, Bias: 126027779131.254593, T: 5248, Avg. loss: 540024689445573377392640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 7824581287.26, NNZs: 2, Bias: 126223784278.197906, T: 5376, Avg. loss: 493539775080646959955968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1409895152.38, NNZs: 2, Bias: 126036999088.303146, T: 5504, Avg. loss: 641665865743346832506880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1656193547.44, NNZs: 2, Bias: 125988036942.501877, T: 5632, Avg. loss: 1761071673043863732224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1856616081.85, NNZs: 2, Bias: 125942909334.421326, T: 5760, Avg. loss: 1662728824519654637568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1802046856.85, NNZs: 2, Bias: 125900929781.619598, T: 5888, Avg. loss: 1740598476846158839808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1998931080.22, NNZs: 2, Bias: 125853139161.101028, T: 6016, Avg. loss: 1755617212500399095808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1934764561.56, NNZs: 2, Bias: 125813027841.152878, T: 6144, Avg. loss: 1596907517395096305664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2081610717.46, NNZs: 2, Bias: 125765590262.823547, T: 6272, Avg. loss: 1781251482660502765568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2019322001.71, NNZs: 2, Bias: 125722859190.277039, T: 6400, Avg. loss: 1699779116278813032448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2095816286.49, NNZs: 2, Bias: 125676984398.058243, T: 6528, Avg. loss: 1774187420959148605440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1961392732.52, NNZs: 2, Bias: 125633519263.845612, T: 6656, Avg. loss: 1917157808011650531328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1862105410.81, NNZs: 2, Bias: 125590749179.066086, T: 6784, Avg. loss: 1776385293092377329664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1967227076.35, NNZs: 2, Bias: 125580330928.792404, T: 6912, Avg. loss: 1394187832995141910528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1965603394.83, NNZs: 2, Bias: 125571903699.999954, T: 7040, Avg. loss: 1339576790035880738816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1969296209.17, NNZs: 2, Bias: 125563466745.748703, T: 7168, Avg. loss: 1328145800643475144704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1957813003.15, NNZs: 2, Bias: 125555281569.818054, T: 7296, Avg. loss: 1327843727362556952576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1969700529.04, NNZs: 2, Bias: 125546837842.834351, T: 7424, Avg. loss: 1308256366962091229184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2006313599.75, NNZs: 2, Bias: 125537787150.507462, T: 7552, Avg. loss: 1344011840807315963904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2010126953.44, NNZs: 2, Bias: 125529209005.198181, T: 7680, Avg. loss: 1351727612657919852544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1999498801.45, NNZs: 2, Bias: 125520924000.550201, T: 7808, Avg. loss: 1342843198419758481408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2005892378.68, NNZs: 2, Bias: 125512290191.751068, T: 7936, Avg. loss: 1353898095139222192128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2038710547.89, NNZs: 2, Bias: 125503260822.111603, T: 8064, Avg. loss: 1345854947248721100800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2009376484.73, NNZs: 2, Bias: 125501999513.436722, T: 8192, Avg. loss: 1339146599059340132352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2006524887.67, NNZs: 2, Bias: 125500353796.797241, T: 8320, Avg. loss: 1304267951219839598592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1997712053.03, NNZs: 2, Bias: 125498809287.342957, T: 8448, Avg. loss: 1299676355485622337536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2001767464.55, NNZs: 2, Bias: 125497050496.807068, T: 8576, Avg. loss: 1306038275230176116736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2000420810.45, NNZs: 2, Bias: 125495386079.877274, T: 8704, Avg. loss: 1299879748236328828928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2006742842.59, NNZs: 2, Bias: 125493595878.108170, T: 8832, Avg. loss: 1302035273734832783360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2008532326.72, NNZs: 2, Bias: 125491874517.102676, T: 8960, Avg. loss: 1304937341130181443584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2008965959.11, NNZs: 2, Bias: 125490176478.299088, T: 9088, Avg. loss: 1303674489010653495296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 71 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2024462514528.87, NNZs: 2, Bias: -54094530261.237823, T: 128, Avg. loss: 20269030749671613291137335296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1582908783133.54, NNZs: 2, Bias: -41067074567.409409, T: 256, Avg. loss: 21177338286740123881490612224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 984097017825.72, NNZs: 2, Bias: -61067074567.409409, T: 384, Avg. loss: 20736198116838838985709060096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1614646021150.19, NNZs: 2, Bias: -15586854210.128769, T: 512, Avg. loss: 20515830626574356681643261952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 541366006201.95, NNZs: 2, Bias: -115586854210.128784, T: 640, Avg. loss: 21215630897015304099626745856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1227687195293.76, NNZs: 2, Bias: -137371636033.924118, T: 768, Avg. loss: 20441907500966592718670135296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 188363124355.84, NNZs: 2, Bias: -139421800392.417084, T: 896, Avg. loss: 1105807829635468269503643648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 175934815078.93, NNZs: 2, Bias: -157741464944.606750, T: 1024, Avg. loss: 855046044611220491764498432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 226277980034.45, NNZs: 2, Bias: -164910085275.045715, T: 1152, Avg. loss: 879430996369336542850711552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 132400161565.59, NNZs: 2, Bias: -155933436591.137146, T: 1280, Avg. loss: 809434944927293203999096832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 151821206886.97, NNZs: 2, Bias: -170946877287.982452, T: 1408, Avg. loss: 888260107891371656267956224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 440059714627.83, NNZs: 2, Bias: -166949752380.763367, T: 1536, Avg. loss: 863335415524826189777600512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 209254709619.25, NNZs: 2, Bias: -182068264185.671234, T: 1664, Avg. loss: 717146426611105842113544192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 410697721473.02, NNZs: 2, Bias: -190853236557.746124, T: 1792, Avg. loss: 849116641567552157127802880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 388907158473.00, NNZs: 2, Bias: -188329551510.743469, T: 1920, Avg. loss: 915381182102134271695126528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 279952332286.39, NNZs: 2, Bias: -198705571442.777710, T: 2048, Avg. loss: 800219028891131209628778496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 245740246478.15, NNZs: 2, Bias: -184412710099.420227, T: 2176, Avg. loss: 828353558501178962511659008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 218958829892.98, NNZs: 2, Bias: -168058924144.478851, T: 2304, Avg. loss: 777554950751932772429856768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 27387000174.72, NNZs: 2, Bias: -164275715054.319214, T: 2432, Avg. loss: 37343276866745484240224256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 46453291446.01, NNZs: 2, Bias: -162677604607.601379, T: 2560, Avg. loss: 29151947251592304663724032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 42808936058.44, NNZs: 2, Bias: -163540302801.860077, T: 2688, Avg. loss: 29633434895370833648156672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 12103083757.21, NNZs: 2, Bias: -165675040953.183655, T: 2816, Avg. loss: 31931035957277064119189504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 7374996290.25, NNZs: 2, Bias: -166954053479.461182, T: 2944, Avg. loss: 31417193375056647619084288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 91806683528.08, NNZs: 2, Bias: -168359007542.329193, T: 3072, Avg. loss: 30269724144442236095954944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 64805596741.94, NNZs: 2, Bias: -170704819161.996918, T: 3200, Avg. loss: 32689002111579927733075968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 7063512867.32, NNZs: 2, Bias: -169919115952.802521, T: 3328, Avg. loss: 1657588766529300541210624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 7683334231.35, NNZs: 2, Bias: -170038853257.316559, T: 3456, Avg. loss: 522423804819826848825344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2861950310.02, NNZs: 2, Bias: -169749528344.171234, T: 3584, Avg. loss: 644418238451282341789696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4990353247.73, NNZs: 2, Bias: -169786634689.217072, T: 3712, Avg. loss: 669226155941725894344704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 14172597687.27, NNZs: 2, Bias: -169382565431.706573, T: 3840, Avg. loss: 552146670774942030626816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4178709465.42, NNZs: 2, Bias: -169145128104.709778, T: 3968, Avg. loss: 647280572993518155333632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4053976602.88, NNZs: 2, Bias: -168929319552.078369, T: 4096, Avg. loss: 678317018673595818180608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3334281918.87, NNZs: 2, Bias: -168889047719.650787, T: 4224, Avg. loss: 3067698490841449365504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3116556743.93, NNZs: 2, Bias: -168841727785.706665, T: 4352, Avg. loss: 2707731536770347565056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2978363134.65, NNZs: 2, Bias: -168792556001.055756, T: 4480, Avg. loss: 2870948371838895390720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2774542009.18, NNZs: 2, Bias: -168742373054.186127, T: 4608, Avg. loss: 2823478377057272463360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2806324816.88, NNZs: 2, Bias: -168688244400.413849, T: 4736, Avg. loss: 2732801357226400284672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2739066593.76, NNZs: 2, Bias: -168634963171.347504, T: 4864, Avg. loss: 2941690373743213281280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2922347770.24, NNZs: 2, Bias: -168580374397.905426, T: 4992, Avg. loss: 2693028057823009832960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2871823485.35, NNZs: 2, Bias: -168526013232.824371, T: 5120, Avg. loss: 2941896318909791862784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2943713440.19, NNZs: 2, Bias: -168471729706.109467, T: 5248, Avg. loss: 2670870139385536315392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2859346778.46, NNZs: 2, Bias: -168419710233.114960, T: 5376, Avg. loss: 2835546371552531972096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2899950192.25, NNZs: 2, Bias: -168369805883.911072, T: 5504, Avg. loss: 2468041471370578624512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2872867521.54, NNZs: 2, Bias: -168317557021.498779, T: 5632, Avg. loss: 2704524928196515201024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2772164683.33, NNZs: 2, Bias: -168264547057.410126, T: 5760, Avg. loss: 2880048662651470348288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2928599398.77, NNZs: 2, Bias: -168211834098.748016, T: 5888, Avg. loss: 2561837855400658993152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3034798951.05, NNZs: 2, Bias: -168158452399.346985, T: 6016, Avg. loss: 2536411893756493037568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2960024299.09, NNZs: 2, Bias: -168105497142.923950, T: 6144, Avg. loss: 2737354081022236426240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2991969583.35, NNZs: 2, Bias: -168094605892.213989, T: 6272, Avg. loss: 2186099916843667423232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2957251934.26, NNZs: 2, Bias: -168084751546.583435, T: 6400, Avg. loss: 2219348989997419331584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2942326294.02, NNZs: 2, Bias: -168074379928.474945, T: 6528, Avg. loss: 2256309610016025870336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2942112532.52, NNZs: 2, Bias: -168063886981.594360, T: 6656, Avg. loss: 2226182536265315123200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2951387740.66, NNZs: 2, Bias: -168053308206.128632, T: 6784, Avg. loss: 2215372713438133878784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2919829258.74, NNZs: 2, Bias: -168043273557.109314, T: 6912, Avg. loss: 2249664453403142258688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2933607770.29, NNZs: 2, Bias: -168040916641.097321, T: 7040, Avg. loss: 2184178678146696478720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2938677262.04, NNZs: 2, Bias: -168038723483.706512, T: 7168, Avg. loss: 2171644870864949477376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2938776756.41, NNZs: 2, Bias: -168036617844.601746, T: 7296, Avg. loss: 2171388204557492289536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2938589889.56, NNZs: 2, Bias: -168034516776.138550, T: 7424, Avg. loss: 2171626105732797562880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2933050085.75, NNZs: 2, Bias: -168032509653.211731, T: 7552, Avg. loss: 2171565027770317144064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2929447213.22, NNZs: 2, Bias: -168030474254.422760, T: 7680, Avg. loss: 2165670856919336615936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2946142392.23, NNZs: 2, Bias: -168028093702.504669, T: 7808, Avg. loss: 2154235367362578612224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2941510020.86, NNZs: 2, Bias: -168026067451.494629, T: 7936, Avg. loss: 2175154763709226156032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2933125278.57, NNZs: 2, Bias: -168024110352.074005, T: 8064, Avg. loss: 2171434814573275774976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2940249060.42, NNZs: 2, Bias: -168021895989.176086, T: 8192, Avg. loss: 2156262801758424399872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2938994252.16, NNZs: 2, Bias: -168019814088.310089, T: 8320, Avg. loss: 2171085077918733828096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2930598657.95, NNZs: 2, Bias: -168017858644.771362, T: 8448, Avg. loss: 2169818933243069595648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 66 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 828234558125.92, NNZs: 2, Bias: -16493764111.717850, T: 128, Avg. loss: 23210915562722325232888053760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2314408164036.27, NNZs: 2, Bias: -36041191933.903625, T: 256, Avg. loss: 23423542466437972787801882624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1277437390185.70, NNZs: 2, Bias: -36041191933.903625, T: 384, Avg. loss: 22667994231769092144903487488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2516861126591.19, NNZs: 2, Bias: -88483138526.538757, T: 512, Avg. loss: 22062880086819290848363020288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 628226101720.22, NNZs: 2, Bias: -107315719976.089844, T: 640, Avg. loss: 23903832097219589163586682880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 971354411862.96, NNZs: 2, Bias: -102872535960.036285, T: 768, Avg. loss: 24349601676940344572617162752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1528397270434.34, NNZs: 2, Bias: -102872535960.036285, T: 896, Avg. loss: 21329879453072492238079000576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 286835274317.44, NNZs: 2, Bias: -42872535960.036285, T: 1024, Avg. loss: 24504271804102419254297493504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1503772976057.91, NNZs: 2, Bias: -88929432967.419540, T: 1152, Avg. loss: 23215134465256684354017427456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1632404094943.55, NNZs: 2, Bias: -128360687046.557693, T: 1280, Avg. loss: 24320834083298823494048940032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2231312888447.30, NNZs: 2, Bias: -159782967721.388123, T: 1408, Avg. loss: 25468821394742341393354588160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 305002778700.41, NNZs: 2, Bias: -73262463029.516846, T: 1536, Avg. loss: 24346623692055088785524785152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 54802308250.76, NNZs: 2, Bias: -68719168543.933990, T: 1664, Avg. loss: 911062680541509474609790976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 394302809521.12, NNZs: 2, Bias: -73435517342.970520, T: 1792, Avg. loss: 899536479475694442752507904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 255413874899.51, NNZs: 2, Bias: -85030201470.597351, T: 1920, Avg. loss: 918237898425506191248457728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 108210625424.37, NNZs: 2, Bias: -81099925485.496902, T: 2048, Avg. loss: 881935589975964663135862784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 415178582865.78, NNZs: 2, Bias: -70424643575.962006, T: 2176, Avg. loss: 919277614134834853262131200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 323348412697.65, NNZs: 2, Bias: -66698505475.489868, T: 2304, Avg. loss: 847922140206279947618091008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 304844194715.24, NNZs: 2, Bias: -65200696571.706802, T: 2432, Avg. loss: 780880357773141820695379968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 320296923851.83, NNZs: 2, Bias: -81059855563.954803, T: 2560, Avg. loss: 865294359805053504317292544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 106170716225.63, NNZs: 2, Bias: -68072566835.726334, T: 2688, Avg. loss: 858016141459009551370027008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 221553220392.64, NNZs: 2, Bias: -68548285499.284698, T: 2816, Avg. loss: 881004817937643622925074432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 151184721662.53, NNZs: 2, Bias: -59859260922.908997, T: 2944, Avg. loss: 882904929854273112825135104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 191401490784.91, NNZs: 2, Bias: -44174146396.167114, T: 3072, Avg. loss: 921473348119193141678964736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 71233286541.48, NNZs: 2, Bias: -37055949191.902145, T: 3200, Avg. loss: 34012512148200734486167552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 56512514611.43, NNZs: 2, Bias: -31494493968.944424, T: 3328, Avg. loss: 32471964925470494638997504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 101414712483.80, NNZs: 2, Bias: -32323205890.422913, T: 3456, Avg. loss: 31725445788139555735470080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 46391033635.53, NNZs: 2, Bias: -31278626847.411716, T: 3584, Avg. loss: 33966562821288498407931904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 12853372562.08, NNZs: 2, Bias: -33378848818.694839, T: 3712, Avg. loss: 34248730713994592874659840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 53387971313.25, NNZs: 2, Bias: -33036511975.843258, T: 3840, Avg. loss: 35910666020612841477767168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 14820829274.51, NNZs: 2, Bias: -33128591787.252361, T: 3968, Avg. loss: 33247036584329247960596480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 97074081642.82, NNZs: 2, Bias: -32993425113.079296, T: 4096, Avg. loss: 36736566391988257172750336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 13611022308.57, NNZs: 2, Bias: -34029512640.702477, T: 4224, Avg. loss: 2346073450127967901450240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6025719896.78, NNZs: 2, Bias: -33879138491.961018, T: 4352, Avg. loss: 718592609011072153681920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 19148741848.90, NNZs: 2, Bias: -34113433805.759113, T: 4480, Avg. loss: 472352259671574553034752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3688820894.18, NNZs: 2, Bias: -34059096775.052303, T: 4608, Avg. loss: 844875605027108165779456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3208603077.50, NNZs: 2, Bias: -34030350972.534599, T: 4736, Avg. loss: 841113605600951423467520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4876508479.16, NNZs: 2, Bias: -33412211861.275932, T: 4864, Avg. loss: 516876478634098312609792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 5368478955.96, NNZs: 2, Bias: -33587474289.179291, T: 4992, Avg. loss: 525922497553284571594752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 6686693936.03, NNZs: 2, Bias: -33313441593.251007, T: 5120, Avg. loss: 731088594077004035260416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1258223879.47, NNZs: 2, Bias: -33243664739.595905, T: 5248, Avg. loss: 8169195380283803697152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 396437729.31, NNZs: 2, Bias: -33220387772.946663, T: 5376, Avg. loss: 429347732022300704768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 108817289.53, NNZs: 2, Bias: -33203423502.022308, T: 5504, Avg. loss: 184186116947608961024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 282474781.93, NNZs: 2, Bias: -33189313608.058960, T: 5632, Avg. loss: 127119723709923082240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 430049752.27, NNZs: 2, Bias: -33175327515.964920, T: 5760, Avg. loss: 123263987234031501312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 470043918.42, NNZs: 2, Bias: -33163876432.937134, T: 5888, Avg. loss: 109328485597902389248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 505927669.95, NNZs: 2, Bias: -33151275399.052662, T: 6016, Avg. loss: 124198672403685834752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 519366496.07, NNZs: 2, Bias: -33139817410.744202, T: 6144, Avg. loss: 115550465322676862976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 497038701.09, NNZs: 2, Bias: -33129081948.490017, T: 6272, Avg. loss: 113047488207977562112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 510525325.48, NNZs: 2, Bias: -33117424565.344559, T: 6400, Avg. loss: 118387314842081427456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 524623177.82, NNZs: 2, Bias: -33105901267.800003, T: 6528, Avg. loss: 114758895577395838976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 529375264.49, NNZs: 2, Bias: -33103643024.020344, T: 6656, Avg. loss: 91201934093952172032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 522872800.47, NNZs: 2, Bias: -33101514543.995796, T: 6784, Avg. loss: 93358743970752184320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 521812460.98, NNZs: 2, Bias: -33099296584.321564, T: 6912, Avg. loss: 93437063021714374656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 521865045.90, NNZs: 2, Bias: -33097093348.221737, T: 7040, Avg. loss: 92111184428072796160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 537575796.44, NNZs: 2, Bias: -33094706083.378181, T: 7168, Avg. loss: 88998077680206004224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 518446567.33, NNZs: 2, Bias: -33092814910.277630, T: 7296, Avg. loss: 92239130275214049280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 530613141.57, NNZs: 2, Bias: -33090382472.372925, T: 7424, Avg. loss: 93559116727188111360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 516642572.88, NNZs: 2, Bias: -33088381849.417233, T: 7552, Avg. loss: 93135604559025897472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 519556018.12, NNZs: 2, Bias: -33086097284.526768, T: 7680, Avg. loss: 93565188566514237440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 523538165.42, NNZs: 2, Bias: -33083806700.356014, T: 7808, Avg. loss: 92931140728923865088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 525048523.35, NNZs: 2, Bias: -33083337274.018494, T: 7936, Avg. loss: 90524393870128709632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 525006040.33, NNZs: 2, Bias: -33082893274.252743, T: 8064, Avg. loss: 90367944322121826304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 524987970.54, NNZs: 2, Bias: -33082449240.202984, T: 8192, Avg. loss: 90305940121487507456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 523389655.76, NNZs: 2, Bias: -33082030342.827236, T: 8320, Avg. loss: 90300247791008186368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 525231874.06, NNZs: 2, Bias: -33081556643.095852, T: 8448, Avg. loss: 90307955870174838784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 66 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1499765587004.52, NNZs: 2, Bias: 16108711305.846138, T: 128, Avg. loss: 22313905963338682478761082880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1530850317050.65, NNZs: 2, Bias: 554816799.215218, T: 256, Avg. loss: 23980898952412027334168674304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 985195513691.74, NNZs: 2, Bias: -89867330771.872101, T: 384, Avg. loss: 23826885855343004467737919488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 605679616579.10, NNZs: 2, Bias: 18421219619.183136, T: 512, Avg. loss: 24838306508661925142394306560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2523008118975.52, NNZs: 2, Bias: -15654213337.271034, T: 640, Avg. loss: 22390646865040438287090581504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1121214339303.67, NNZs: 2, Bias: -55654213337.271027, T: 768, Avg. loss: 24071479194364245121964179456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 469272905679.40, NNZs: 2, Bias: -84882792290.504379, T: 896, Avg. loss: 982685311863355923473891328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 266133200347.49, NNZs: 2, Bias: -59518412123.406723, T: 1024, Avg. loss: 938547221058808813474283520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 162312943319.68, NNZs: 2, Bias: -42619044346.820305, T: 1152, Avg. loss: 881983450824113251743170560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 280128422613.44, NNZs: 2, Bias: -33104878580.580795, T: 1280, Avg. loss: 963785013612944318516953088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 190353701640.84, NNZs: 2, Bias: -35420082738.154243, T: 1408, Avg. loss: 961083657571279436255330304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 280480732114.84, NNZs: 2, Bias: -27090532748.446571, T: 1536, Avg. loss: 978123575232309730117419008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 304556042799.18, NNZs: 2, Bias: -39728036400.046692, T: 1664, Avg. loss: 933902530305008740086054912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 315822045387.43, NNZs: 2, Bias: -61712312217.459320, T: 1792, Avg. loss: 874731404537067937070055424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 136911289360.98, NNZs: 2, Bias: -52620660345.321259, T: 1920, Avg. loss: 880046965712974202923909120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 451463235096.92, NNZs: 2, Bias: -66896601518.858276, T: 2048, Avg. loss: 909287159163771233790590976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 33611496479.69, NNZs: 2, Bias: -61786408738.988007, T: 2176, Avg. loss: 928264847459141916578283520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 416887932610.44, NNZs: 2, Bias: -35958501974.989563, T: 2304, Avg. loss: 949187405808380571287552000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 142527051233.54, NNZs: 2, Bias: -22416279043.773132, T: 2432, Avg. loss: 951556670540063822057570304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 21054336130.01, NNZs: 2, Bias: -23433072209.242050, T: 2560, Avg. loss: 35950298767653514944446464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 81394401912.33, NNZs: 2, Bias: -24860535521.722401, T: 2688, Avg. loss: 34552184604082521367379968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 70792821229.14, NNZs: 2, Bias: -25071492264.976025, T: 2816, Avg. loss: 36565168398477862333579264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 66500347169.25, NNZs: 2, Bias: -26129473296.147758, T: 2944, Avg. loss: 32450482062392428886753280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 56550750810.12, NNZs: 2, Bias: -26559597095.998955, T: 3072, Avg. loss: 34388731277177712562667520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 97249047133.56, NNZs: 2, Bias: -28873652254.173634, T: 3200, Avg. loss: 32105434691024120621039616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 39408134070.13, NNZs: 2, Bias: -31257843059.403419, T: 3328, Avg. loss: 34403898930997043946061824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 13184131959.53, NNZs: 2, Bias: -33277948413.356632, T: 3456, Avg. loss: 37732017502829555461652480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 98119453934.94, NNZs: 2, Bias: -36106711650.603767, T: 3584, Avg. loss: 33698893554908521971056640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 86798053472.24, NNZs: 2, Bias: -35223961955.127869, T: 3712, Avg. loss: 33685823553933560426528768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 89888592933.90, NNZs: 2, Bias: -34463163418.744141, T: 3840, Avg. loss: 36447959233489104875290624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4828677891.84, NNZs: 2, Bias: -34550333972.308846, T: 3968, Avg. loss: 3955736916173268784775168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11774794167.96, NNZs: 2, Bias: -34637426936.409943, T: 4096, Avg. loss: 709690252393338472759296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6144419182.93, NNZs: 2, Bias: -34585274458.938698, T: 4224, Avg. loss: 742179136902902249947136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6760030116.74, NNZs: 2, Bias: -34654959712.984970, T: 4352, Avg. loss: 586152852072829655449600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9284113007.73, NNZs: 2, Bias: -34824120283.957581, T: 4480, Avg. loss: 558114395484307800981504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11897954218.31, NNZs: 2, Bias: -34801082958.513023, T: 4608, Avg. loss: 664127309419519835897856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9888176746.25, NNZs: 2, Bias: -34437162904.561836, T: 4736, Avg. loss: 690075919175474477006848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3911485855.17, NNZs: 2, Bias: -34460394774.948532, T: 4864, Avg. loss: 689639237956705391214592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3872213872.54, NNZs: 2, Bias: -34897103271.509689, T: 4992, Avg. loss: 717577966963527803469824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1918841016.15, NNZs: 2, Bias: -35251827005.710678, T: 5120, Avg. loss: 620463743122881204191232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 310793814.79, NNZs: 2, Bias: -35223798089.018250, T: 5248, Avg. loss: 964868453504044761088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 178475570.60, NNZs: 2, Bias: -35210024988.108650, T: 5376, Avg. loss: 148840162483726548992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 359563504.64, NNZs: 2, Bias: -35197424613.389626, T: 5504, Avg. loss: 112415774047832752128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 472117947.05, NNZs: 2, Bias: -35185456340.046715, T: 5632, Avg. loss: 108112889496614322176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 491831192.69, NNZs: 2, Bias: -35174846920.795235, T: 5760, Avg. loss: 109798608124097839104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 500686986.14, NNZs: 2, Bias: -35165157152.419579, T: 5888, Avg. loss: 100772078679111942144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 509456447.61, NNZs: 2, Bias: -35154712132.540161, T: 6016, Avg. loss: 108447539011803987968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 543248348.94, NNZs: 2, Bias: -35144029715.308609, T: 6144, Avg. loss: 106568018778544291840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 531506893.34, NNZs: 2, Bias: -35133781165.856728, T: 6272, Avg. loss: 113375010073474990080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 501086734.96, NNZs: 2, Bias: -35123581765.878006, T: 6400, Avg. loss: 119485101410631892992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 514269051.03, NNZs: 2, Bias: -35112575387.745934, T: 6528, Avg. loss: 114929135494372261888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 512742062.83, NNZs: 2, Bias: -35110539971.351761, T: 6656, Avg. loss: 91157255118538375168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 511216706.80, NNZs: 2, Bias: -35108505727.178535, T: 6784, Avg. loss: 91059584103525875712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 507947718.32, NNZs: 2, Bias: -35106504360.359558, T: 6912, Avg. loss: 90735480352003719168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 509255190.88, NNZs: 2, Bias: -35104478416.375420, T: 7040, Avg. loss: 88664355614891278336.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 522859168.38, NNZs: 2, Bias: -35102264168.792854, T: 7168, Avg. loss: 88896272860213575680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 516497166.68, NNZs: 2, Bias: -35100304750.565063, T: 7296, Avg. loss: 90905785686281748480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 512529356.59, NNZs: 2, Bias: -35098327489.082825, T: 7424, Avg. loss: 90179984286457724928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 522639271.11, NNZs: 2, Bias: -35096145068.686287, T: 7552, Avg. loss: 89660250160820813824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 515929997.87, NNZs: 2, Bias: -35094195734.007683, T: 7680, Avg. loss: 90546158593979318272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 517633671.87, NNZs: 2, Bias: -35093761377.909286, T: 7808, Avg. loss: 88181522712346116096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 519711543.65, NNZs: 2, Bias: -35093322633.131630, T: 7936, Avg. loss: 87909014832897228800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 518456609.31, NNZs: 2, Bias: -35092934161.321793, T: 8064, Avg. loss: 87726022826021519360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 519141935.85, NNZs: 2, Bias: -35092516751.550819, T: 8192, Avg. loss: 87760304666964705280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 518989279.70, NNZs: 2, Bias: -35092110728.872498, T: 8320, Avg. loss: 87985054223590981632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 517297635.65, NNZs: 2, Bias: -35091729099.296211, T: 8448, Avg. loss: 87623797562646118400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 519564615.27, NNZs: 2, Bias: -35091287978.805710, T: 8576, Avg. loss: 87818405402344554496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 521544516.07, NNZs: 2, Bias: -35090852810.823608, T: 8704, Avg. loss: 87412294947912679424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 520755673.11, NNZs: 2, Bias: -35090456068.374496, T: 8832, Avg. loss: 88028254362881835008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 519368671.27, NNZs: 2, Bias: -35090067879.098640, T: 8960, Avg. loss: 88090661917571891200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 518908933.53, NNZs: 2, Bias: -35089667058.614464, T: 9088, Avg. loss: 87828889042755633152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 518181526.08, NNZs: 2, Bias: -35089270553.403038, T: 9216, Avg. loss: 87761023851725848576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 519194294.57, NNZs: 2, Bias: -35088847388.406494, T: 9344, Avg. loss: 87941995086094909440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 73 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1315447697015.64, NNZs: 2, Bias: 25953837301.441925, T: 128, Avg. loss: 19747515467893431592627994624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1066850795206.74, NNZs: 2, Bias: 5953837301.441925, T: 256, Avg. loss: 23595896024264750129576148992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2707381496322.84, NNZs: 2, Bias: -118419858.414482, T: 384, Avg. loss: 22996028655340236108076154880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1471649562127.29, NNZs: 2, Bias: -48366374649.494247, T: 512, Avg. loss: 21855806509658476818632540160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1238937811132.39, NNZs: 2, Bias: -112866417966.659637, T: 640, Avg. loss: 22522087391387933637236228096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 402104135901.91, NNZs: 2, Bias: -112866417966.659637, T: 768, Avg. loss: 20676725250774569588245921792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 505606937522.70, NNZs: 2, Bias: -120394300194.361023, T: 896, Avg. loss: 818525457321277659191181312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 308146072971.89, NNZs: 2, Bias: -131109615705.572845, T: 1024, Avg. loss: 827813645130194890434543616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 287964927492.05, NNZs: 2, Bias: -112308108030.405289, T: 1152, Avg. loss: 821053037283231980763217920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 116878887524.01, NNZs: 2, Bias: -110153337967.489883, T: 1280, Avg. loss: 827299276751997291506696192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 96206230547.64, NNZs: 2, Bias: -121722108750.229187, T: 1408, Avg. loss: 838798319323823463462862848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 287216086302.23, NNZs: 2, Bias: -128502405300.352966, T: 1536, Avg. loss: 821237023743531507752370176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 59987242674.01, NNZs: 2, Bias: -133427130825.081894, T: 1664, Avg. loss: 38974325656839465696493568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 27967841021.89, NNZs: 2, Bias: -134341880358.369858, T: 1792, Avg. loss: 32509002168946914842640384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 51610365338.15, NNZs: 2, Bias: -133680789022.294067, T: 1920, Avg. loss: 30654804483803776498532352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 49828082193.31, NNZs: 2, Bias: -133381158525.748383, T: 2048, Avg. loss: 31875563981858387978616832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 60249188227.64, NNZs: 2, Bias: -131631625440.351425, T: 2176, Avg. loss: 29498103496639624077377536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 17604799068.01, NNZs: 2, Bias: -130800697052.288666, T: 2304, Avg. loss: 28627635677298522442432512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 35714124693.63, NNZs: 2, Bias: -128541779122.028900, T: 2432, Avg. loss: 35514127599069361183129600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 24359612044.81, NNZs: 2, Bias: -131329889710.569351, T: 2560, Avg. loss: 33887616771388526368391168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 22154580031.00, NNZs: 2, Bias: -130939294554.245087, T: 2688, Avg. loss: 33026765943594902190292992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 52143038344.13, NNZs: 2, Bias: -131033620773.360489, T: 2816, Avg. loss: 33981832054389761252524032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 86196336129.22, NNZs: 2, Bias: -130677317341.502335, T: 2944, Avg. loss: 32458475453363897210241024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 13758704989.02, NNZs: 2, Bias: -130350512873.611526, T: 3072, Avg. loss: 2809248617824737522876416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 3403220182.76, NNZs: 2, Bias: -130441520616.567673, T: 3200, Avg. loss: 754609434599168193593344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4939132031.21, NNZs: 2, Bias: -130225844943.582367, T: 3328, Avg. loss: 604197421923187451494400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4703219220.91, NNZs: 2, Bias: -130227887582.457565, T: 3456, Avg. loss: 517609831625493898592256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4043028931.94, NNZs: 2, Bias: -129968200240.349564, T: 3584, Avg. loss: 754954696402594772811776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2290887710.24, NNZs: 2, Bias: -129640940413.201538, T: 3712, Avg. loss: 491005519887149247234048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5464698722.82, NNZs: 2, Bias: -129484450591.659653, T: 3840, Avg. loss: 502837516134138878361600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 15727591498.45, NNZs: 2, Bias: -129101407020.554581, T: 3968, Avg. loss: 521643686823323022393344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8918595345.09, NNZs: 2, Bias: -129054520645.164948, T: 4096, Avg. loss: 671084481290166595485696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2429136680.30, NNZs: 2, Bias: -129117243958.482529, T: 4224, Avg. loss: 654579230233465861439488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8918585336.03, NNZs: 2, Bias: -128882627509.387650, T: 4352, Avg. loss: 605046726848851447119872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4048211917.39, NNZs: 2, Bias: -128844455552.282028, T: 4480, Avg. loss: 17487550846930096488448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3148774488.50, NNZs: 2, Bias: -128814029744.974777, T: 4608, Avg. loss: 2212697045295683862528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2627995210.24, NNZs: 2, Bias: -128777854991.190170, T: 4736, Avg. loss: 2096345490847765889024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2302058008.76, NNZs: 2, Bias: -128737072453.535126, T: 4864, Avg. loss: 1902804182978039382016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1981341389.79, NNZs: 2, Bias: -128695652516.640640, T: 4992, Avg. loss: 1949289509891412066304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2066503477.62, NNZs: 2, Bias: -128651858265.796967, T: 5120, Avg. loss: 1684988197862544244736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1924648472.88, NNZs: 2, Bias: -128606904249.730255, T: 5248, Avg. loss: 1883980450540739100672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2069067625.59, NNZs: 2, Bias: -128562111746.979691, T: 5376, Avg. loss: 1642250100261814272000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1922606972.90, NNZs: 2, Bias: -128518540661.964355, T: 5504, Avg. loss: 1809593793789210656768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1905613316.27, NNZs: 2, Bias: -128473700229.283417, T: 5632, Avg. loss: 1776126151706921402368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2102890216.38, NNZs: 2, Bias: -128424612571.346222, T: 5760, Avg. loss: 1746184405313260355584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2145211769.22, NNZs: 2, Bias: -128379088044.306976, T: 5888, Avg. loss: 1744893879572284309504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1932991215.73, NNZs: 2, Bias: -128335432652.659882, T: 6016, Avg. loss: 1923898927361425932288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1982938971.62, NNZs: 2, Bias: -128325495377.914734, T: 6144, Avg. loss: 1480677456998402097152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1990955127.93, NNZs: 2, Bias: -128316492472.471008, T: 6272, Avg. loss: 1434595987321299927040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2014768939.16, NNZs: 2, Bias: -128307094003.009201, T: 6400, Avg. loss: 1456135103343947415552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1999328779.82, NNZs: 2, Bias: -128298428022.014313, T: 6528, Avg. loss: 1439754511351123017728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2032439429.53, NNZs: 2, Bias: -128288723391.075027, T: 6656, Avg. loss: 1481588811855302230016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2052057089.96, NNZs: 2, Bias: -128279524228.333099, T: 6784, Avg. loss: 1431325005688593448960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2042727936.76, NNZs: 2, Bias: -128270521485.460785, T: 6912, Avg. loss: 1480013919387247181824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2022130283.92, NNZs: 2, Bias: -128261790925.610626, T: 7040, Avg. loss: 1464967927678324441088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2042870203.96, NNZs: 2, Bias: -128252442246.380371, T: 7168, Avg. loss: 1457296951467222499328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2046782364.76, NNZs: 2, Bias: -128243388087.481400, T: 7296, Avg. loss: 1452195334100723957760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2046598395.81, NNZs: 2, Bias: -128234423620.568481, T: 7424, Avg. loss: 1448267111966127161344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2059457236.36, NNZs: 2, Bias: -128232417876.769974, T: 7552, Avg. loss: 1416401649551335227392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2059823681.57, NNZs: 2, Bias: -128230611171.313461, T: 7680, Avg. loss: 1417790456675967959040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2049031547.41, NNZs: 2, Bias: -128228996582.756531, T: 7808, Avg. loss: 1407759610504821080064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2062525239.14, NNZs: 2, Bias: -128226983015.329056, T: 7936, Avg. loss: 1414213638307585196032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2056424927.66, NNZs: 2, Bias: -128225280151.601730, T: 8064, Avg. loss: 1418118254605121093632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2058166644.27, NNZs: 2, Bias: -128223449722.243927, T: 8192, Avg. loss: 1418870388218554482688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2058240498.05, NNZs: 2, Bias: -128221646394.581177, T: 8320, Avg. loss: 1418730226430516133888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2061799318.41, NNZs: 2, Bias: -128219789565.090805, T: 8448, Avg. loss: 1416633594372680318976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 66 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 308819653790.06, NNZs: 2, Bias: 84893527567.975845, T: 128, Avg. loss: 19697356005628669771638636544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1333958906481.03, NNZs: 2, Bias: 104893527567.975845, T: 256, Avg. loss: 19760834569957747292154888192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2966102848502.51, NNZs: 2, Bias: 104893527567.975845, T: 384, Avg. loss: 19414621797138955056485236736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1208048577739.98, NNZs: 2, Bias: 164893527567.975830, T: 512, Avg. loss: 20172622592276379151357706240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1878151950071.04, NNZs: 2, Bias: 94589708796.843323, T: 640, Avg. loss: 20254882085995165880680448000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1568414429844.09, NNZs: 2, Bias: 111347016088.596619, T: 768, Avg. loss: 22108544655204729485044744192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1599067797739.24, NNZs: 2, Bias: 117699813844.990265, T: 896, Avg. loss: 20733710321014628776971075584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 669739480673.85, NNZs: 2, Bias: 110269966289.766449, T: 1024, Avg. loss: 18625493719251943128452562944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1862615303234.04, NNZs: 2, Bias: 110269966289.766449, T: 1152, Avg. loss: 18595911732702962402436579328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1527798463234.73, NNZs: 2, Bias: 56567079488.647903, T: 1280, Avg. loss: 19069813488184537166653685760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1377168522203.23, NNZs: 2, Bias: 62666549620.898499, T: 1408, Avg. loss: 21034582045394291488427343872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 795795696171.47, NNZs: 2, Bias: 114223198049.675217, T: 1536, Avg. loss: 20513143537508834932129005568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 359846323867.32, NNZs: 2, Bias: 121938467525.041504, T: 1664, Avg. loss: 18910448159828610838316449792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 3062421289863.19, NNZs: 2, Bias: 161704823367.776062, T: 1792, Avg. loss: 18104081079229177952473186304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1268387439955.04, NNZs: 2, Bias: 261704823367.776062, T: 1920, Avg. loss: 21911964697678333957623513088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1013817805898.80, NNZs: 2, Bias: 201704823367.776062, T: 2048, Avg. loss: 20473765459549966679645618176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 397105031446.81, NNZs: 2, Bias: 201704823367.776062, T: 2176, Avg. loss: 19830784071986683307532222464.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1745648940685.71, NNZs: 2, Bias: 221704823367.776062, T: 2304, Avg. loss: 19737766878045514447229812736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 467203236114.62, NNZs: 2, Bias: 201704823367.776062, T: 2432, Avg. loss: 21919231982557121734424657920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 142898860701.33, NNZs: 2, Bias: 224113023578.275024, T: 2560, Avg. loss: 862472597284832971369480192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 145696133784.56, NNZs: 2, Bias: 227991810212.990509, T: 2688, Avg. loss: 764667717022469467792211968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 550890404290.41, NNZs: 2, Bias: 245703720575.390594, T: 2816, Avg. loss: 740131159065159140930224128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 420922911605.03, NNZs: 2, Bias: 253054034142.919159, T: 2944, Avg. loss: 782896380019376721494016000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 97755444480.89, NNZs: 2, Bias: 256213652343.774963, T: 3072, Avg. loss: 769601406888322915777904640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 431258776614.88, NNZs: 2, Bias: 260330636617.607697, T: 3200, Avg. loss: 736907715755097173188935680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 33496346156.71, NNZs: 2, Bias: 248442559330.667206, T: 3328, Avg. loss: 896887263418682642635161600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 440139924188.82, NNZs: 2, Bias: 250759628034.494232, T: 3456, Avg. loss: 751923308099913814036709376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 398854859059.31, NNZs: 2, Bias: 235203903008.359924, T: 3584, Avg. loss: 793126672478443333555847168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 284069561203.68, NNZs: 2, Bias: 227895900645.879730, T: 3712, Avg. loss: 758392459196260125176233984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 259307204012.00, NNZs: 2, Bias: 228904970947.456116, T: 3840, Avg. loss: 798258988954544179655999488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 29315303688.25, NNZs: 2, Bias: 234137553117.924072, T: 3968, Avg. loss: 32617769490691189507096576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 47270436254.90, NNZs: 2, Bias: 234551611649.633728, T: 4096, Avg. loss: 31883735755029025684193280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 86795248613.44, NNZs: 2, Bias: 233596151426.624817, T: 4224, Avg. loss: 28567698917895284556038144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 37261875754.92, NNZs: 2, Bias: 233733324474.135620, T: 4352, Avg. loss: 31490418752765599569412096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 43706956578.44, NNZs: 2, Bias: 231601337380.845459, T: 4480, Avg. loss: 28962712784772830521720832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 92524542346.97, NNZs: 2, Bias: 231023730726.642120, T: 4608, Avg. loss: 28999522265617456280109056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 42175613009.34, NNZs: 2, Bias: 229015795810.233856, T: 4736, Avg. loss: 29583811199486402437840896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 76243411589.78, NNZs: 2, Bias: 232302262428.904266, T: 4864, Avg. loss: 26274883509510832172040192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 27906669374.93, NNZs: 2, Bias: 231878865404.847137, T: 4992, Avg. loss: 27228560728099136422805504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 56341484988.54, NNZs: 2, Bias: 233483239228.009674, T: 5120, Avg. loss: 31318517150640239449997312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 20949001888.55, NNZs: 2, Bias: 235509093656.736420, T: 5248, Avg. loss: 31448259023959301363335168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 56807336269.94, NNZs: 2, Bias: 235839892132.483398, T: 5376, Avg. loss: 29735476655805202211799040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 75701407590.78, NNZs: 2, Bias: 232282468712.781403, T: 5504, Avg. loss: 27032352739769075609108480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 12606916348.30, NNZs: 2, Bias: 233592151645.595154, T: 5632, Avg. loss: 1317532331046495074648064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 8181045657.85, NNZs: 2, Bias: 233096377661.697723, T: 5760, Avg. loss: 504303619100086993158144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4845221418.34, NNZs: 2, Bias: 232652635977.322174, T: 5888, Avg. loss: 510127608994652001140736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 20659075874.39, NNZs: 2, Bias: 232262917758.517731, T: 6016, Avg. loss: 514577581919348014972928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3910921520.83, NNZs: 2, Bias: 231626837534.918091, T: 6144, Avg. loss: 505697354817538713714688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 5586160701.44, NNZs: 2, Bias: 231575962318.279175, T: 6272, Avg. loss: 522414097260180844576768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4760413365.41, NNZs: 2, Bias: 231414751349.726044, T: 6400, Avg. loss: 491173657642007938465792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 5098740934.94, NNZs: 2, Bias: 231155662061.452240, T: 6528, Avg. loss: 708119946160836869881856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 7096022924.41, NNZs: 2, Bias: 230709454422.541809, T: 6656, Avg. loss: 567364726256421333630976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 8164014359.59, NNZs: 2, Bias: 230814779595.046051, T: 6784, Avg. loss: 717108634185849276203008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2351462175.52, NNZs: 2, Bias: 230437217432.431274, T: 6912, Avg. loss: 551842890492284531376128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 17097618218.33, NNZs: 2, Bias: 230225006871.660797, T: 7040, Avg. loss: 585089871080475057979392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 7954811044.65, NNZs: 2, Bias: 230103617777.368530, T: 7168, Avg. loss: 56142262849002113335296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 5901670463.58, NNZs: 2, Bias: 230059922573.707581, T: 7296, Avg. loss: 8118582355078771900416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4570204041.92, NNZs: 2, Bias: 230008645961.363373, T: 7424, Avg. loss: 6411454740027383218176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4362919544.17, NNZs: 2, Bias: 229929043390.431122, T: 7552, Avg. loss: 6167534942737607426048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3916067120.43, NNZs: 2, Bias: 229855135673.747375, T: 7680, Avg. loss: 5928287869554332270592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4017124271.76, NNZs: 2, Bias: 229778784616.275940, T: 7808, Avg. loss: 5303773629861437898752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3712442495.54, NNZs: 2, Bias: 229705995570.165009, T: 7936, Avg. loss: 5739388721554842976256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3822166465.83, NNZs: 2, Bias: 229627187277.627228, T: 8064, Avg. loss: 5373447587833269190656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3863589288.87, NNZs: 2, Bias: 229549608685.166870, T: 8192, Avg. loss: 5418818468303878488064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3712057086.46, NNZs: 2, Bias: 229474955269.726166, T: 8320, Avg. loss: 5580843017242349142016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3660764077.90, NNZs: 2, Bias: 229401692793.643097, T: 8448, Avg. loss: 5594989238524545335296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3695367521.67, NNZs: 2, Bias: 229385810205.900421, T: 8576, Avg. loss: 4445347950363234795520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3697178980.51, NNZs: 2, Bias: 229370225141.852325, T: 8704, Avg. loss: 4512915526322350456832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3651509513.27, NNZs: 2, Bias: 229355369649.924988, T: 8832, Avg. loss: 4530683148108614336512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3624576150.77, NNZs: 2, Bias: 229340502496.126373, T: 8960, Avg. loss: 4450578292367616376832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 3643289568.28, NNZs: 2, Bias: 229324591751.290314, T: 9088, Avg. loss: 4523282323879048511488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 3684063636.73, NNZs: 2, Bias: 229308853741.503021, T: 9216, Avg. loss: 4365593742535013433344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 3685201720.31, NNZs: 2, Bias: 229293577860.526367, T: 9344, Avg. loss: 4425454709490167316480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 3657218964.63, NNZs: 2, Bias: 229278381463.328125, T: 9472, Avg. loss: 4535900265925369659392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 3644311714.74, NNZs: 2, Bias: 229263198309.415222, T: 9600, Avg. loss: 4465888964152795332608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 3643638932.63, NNZs: 2, Bias: 229247885253.063385, T: 9728, Avg. loss: 4450577475494761463808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 3676234132.00, NNZs: 2, Bias: 229232093499.770966, T: 9856, Avg. loss: 4421649667570463670272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 3672320819.40, NNZs: 2, Bias: 229229070388.153870, T: 9984, Avg. loss: 4346198247298108489728.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 3673532601.61, NNZs: 2, Bias: 229225972811.816132, T: 10112, Avg. loss: 4334404834548204437504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 3670620358.01, NNZs: 2, Bias: 229222933857.889130, T: 10240, Avg. loss: 4345169792656395993088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 3671569299.54, NNZs: 2, Bias: 229219829338.288086, T: 10368, Avg. loss: 4350806282309186617344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 3674558524.80, NNZs: 2, Bias: 229216692062.877045, T: 10496, Avg. loss: 4350306709980876111872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 3689370167.64, NNZs: 2, Bias: 229213376876.354706, T: 10624, Avg. loss: 4331522939687174930432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 3674508321.50, NNZs: 2, Bias: 229210524084.893524, T: 10752, Avg. loss: 4355032302651454259200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 3671553104.03, NNZs: 2, Bias: 229207482216.363129, T: 10880, Avg. loss: 4350634431268657823744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 3664582213.24, NNZs: 2, Bias: 229204526789.548828, T: 11008, Avg. loss: 4320347094282612506624.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 3696607820.61, NNZs: 2, Bias: 229200956346.061066, T: 11136, Avg. loss: 4300701279899113488384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 3682784725.95, NNZs: 2, Bias: 229198080311.653015, T: 11264, Avg. loss: 4364478532206269562880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 3694743940.79, NNZs: 2, Bias: 229194811427.809967, T: 11392, Avg. loss: 4330723136821962211328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 3684257830.75, NNZs: 2, Bias: 229191887782.806824, T: 11520, Avg. loss: 4355213956011476385792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 3664294967.88, NNZs: 2, Bias: 229189135435.793274, T: 11648, Avg. loss: 4327525058655597625344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 3687596850.42, NNZs: 2, Bias: 229185677261.726349, T: 11776, Avg. loss: 4341113456415484674048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 92 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1708385008913.99, NNZs: 2, Bias: -86312787899.222153, T: 128, Avg. loss: 17257412180424115315885998080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1098088350522.63, NNZs: 2, Bias: -99643617879.186722, T: 256, Avg. loss: 23395878650071269343796133888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 877320717681.87, NNZs: 2, Bias: -19643617879.186707, T: 384, Avg. loss: 21296198942722449657145851904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1664067726673.09, NNZs: 2, Bias: -48087051539.056198, T: 512, Avg. loss: 21972862466455155445543731200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1743825070392.61, NNZs: 2, Bias: -88087051539.056198, T: 640, Avg. loss: 19413977300446027265247019008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 781374245895.83, NNZs: 2, Bias: -88087051539.056198, T: 768, Avg. loss: 22718607018677215040936869888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 457028834357.60, NNZs: 2, Bias: -88847005392.464828, T: 896, Avg. loss: 866402788577577506193801216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 289294362367.94, NNZs: 2, Bias: -88052595154.620163, T: 1024, Avg. loss: 878921921262983728074850304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 40821907844.33, NNZs: 2, Bias: -87320567077.412231, T: 1152, Avg. loss: 894750053684356944517660672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 313910680203.40, NNZs: 2, Bias: -63785100353.291794, T: 1280, Avg. loss: 819111063746930564954849280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 357997432927.17, NNZs: 2, Bias: -79624891202.006805, T: 1408, Avg. loss: 684685966459595274122690560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 446279602453.09, NNZs: 2, Bias: -89021107846.997269, T: 1536, Avg. loss: 814952273869149925892161536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 348952969939.80, NNZs: 2, Bias: -85261601343.749756, T: 1664, Avg. loss: 919978605650171960062115840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 188186815101.80, NNZs: 2, Bias: -83703893048.307556, T: 1792, Avg. loss: 833195113335310096776822784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 244630527651.42, NNZs: 2, Bias: -87594168946.185440, T: 1920, Avg. loss: 791301932010701337810436096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 287205902452.74, NNZs: 2, Bias: -90112787359.014923, T: 2048, Avg. loss: 821845696563725915448672256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 34888729568.39, NNZs: 2, Bias: -83525223771.488571, T: 2176, Avg. loss: 36251720898957899234017280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 73880804013.17, NNZs: 2, Bias: -83736840253.279373, T: 2304, Avg. loss: 29887493464472770190508032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 25772366736.80, NNZs: 2, Bias: -83974059454.208145, T: 2432, Avg. loss: 31957278000019187737559040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 31264238767.65, NNZs: 2, Bias: -85144388551.704971, T: 2560, Avg. loss: 30941592230006698778034176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 122696671596.37, NNZs: 2, Bias: -83084318786.557312, T: 2688, Avg. loss: 31209066543257651188334592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 78605911551.12, NNZs: 2, Bias: -85473632814.404968, T: 2816, Avg. loss: 31766571096293437396221952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 13876768358.24, NNZs: 2, Bias: -87844605852.028778, T: 2944, Avg. loss: 32015770295137458165121024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 391134842.89, NNZs: 2, Bias: -88040688615.677368, T: 3072, Avg. loss: 470088983531603430998016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 11744119054.72, NNZs: 2, Bias: -87794299334.781219, T: 3200, Avg. loss: 480701215767926470082560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 566127427.82, NNZs: 2, Bias: -87813598085.481155, T: 3328, Avg. loss: 351426961809950721966080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1732946623.88, NNZs: 2, Bias: -87538816905.366669, T: 3456, Avg. loss: 527885595051793254973440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3666501734.57, NNZs: 2, Bias: -87477363149.317245, T: 3584, Avg. loss: 593457694092550299713536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 7303658822.11, NNZs: 2, Bias: -87403679208.951996, T: 3712, Avg. loss: 564459898340268899827712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2499175050.48, NNZs: 2, Bias: -87376674898.015091, T: 3840, Avg. loss: 636139845702867170099200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 3770847600.09, NNZs: 2, Bias: -87375164630.336182, T: 3968, Avg. loss: 443023709089709005209600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2524815236.78, NNZs: 2, Bias: -87370575333.325592, T: 4096, Avg. loss: 1466605710784922648576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2119592674.89, NNZs: 2, Bias: -87350925927.835144, T: 4224, Avg. loss: 841723472138423631872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1900701243.63, NNZs: 2, Bias: -87329505055.827942, T: 4352, Avg. loss: 693476338240983400448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1750525648.03, NNZs: 2, Bias: -87304127345.140686, T: 4480, Avg. loss: 770673866452324450304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1589674368.79, NNZs: 2, Bias: -87279625261.820312, T: 4608, Avg. loss: 802062157976490737664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1628326975.60, NNZs: 2, Bias: -87251361293.340759, T: 4736, Avg. loss: 757962129771509317632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1516603533.18, NNZs: 2, Bias: -87225545751.634247, T: 4864, Avg. loss: 734593406097095131136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1494824382.02, NNZs: 2, Bias: -87196902824.141495, T: 4992, Avg. loss: 769194822406939607040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1526273061.66, NNZs: 2, Bias: -87190810742.429626, T: 5120, Avg. loss: 610697430444383797248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1512986728.07, NNZs: 2, Bias: -87185556447.913910, T: 5248, Avg. loss: 604313617092028530688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1514204438.24, NNZs: 2, Bias: -87180203291.977127, T: 5376, Avg. loss: 585797300761320423424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1517967034.73, NNZs: 2, Bias: -87174617080.449753, T: 5504, Avg. loss: 606688047619607494656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1524212041.49, NNZs: 2, Bias: -87169008947.318359, T: 5632, Avg. loss: 605187821795376365568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1527142438.73, NNZs: 2, Bias: -87163513413.408844, T: 5760, Avg. loss: 598202772299956617216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1513625277.48, NNZs: 2, Bias: -87158340737.128082, T: 5888, Avg. loss: 594477404362274635776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1522407823.73, NNZs: 2, Bias: -87152735097.208038, T: 6016, Avg. loss: 598633302511378366464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1516306743.06, NNZs: 2, Bias: -87151750883.410599, T: 6144, Avg. loss: 583950116019064537088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1524378653.79, NNZs: 2, Bias: -87150528951.538635, T: 6272, Avg. loss: 578400826891017781248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1520037219.67, NNZs: 2, Bias: -87149510442.550400, T: 6400, Avg. loss: 585923318566669189120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1516556528.31, NNZs: 2, Bias: -87148481004.248871, T: 6528, Avg. loss: 583591841737858023424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1519435860.63, NNZs: 2, Bias: -87147342386.413315, T: 6656, Avg. loss: 582453510272597491712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1526875007.11, NNZs: 2, Bias: -87146140307.519913, T: 6784, Avg. loss: 573542039512506564608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1513887545.80, NNZs: 2, Bias: -87145293129.691910, T: 6912, Avg. loss: 575097979364375461888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1519087217.89, NNZs: 2, Bias: -87144112771.630539, T: 7040, Avg. loss: 583021407736275271680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1520406721.33, NNZs: 2, Bias: -87142999709.363968, T: 7168, Avg. loss: 583319838963767771136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1522377632.43, NNZs: 2, Bias: -87141877896.953400, T: 7296, Avg. loss: 581894370483647479808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1516816299.60, NNZs: 2, Bias: -87140884036.827316, T: 7424, Avg. loss: 583986520365779582976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 58 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 694023258711.65, NNZs: 2, Bias: -411257474.753473, T: 128, Avg. loss: 24747972357011893502087266304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 719221280874.72, NNZs: 2, Bias: 39588742525.246529, T: 256, Avg. loss: 23089767473159374364626386944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1242557456627.37, NNZs: 2, Bias: 19588742525.246529, T: 384, Avg. loss: 22665397441656454789807996928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 809332199970.42, NNZs: 2, Bias: 20268073043.017365, T: 512, Avg. loss: 23974441002640666908988276736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 185684461192.63, NNZs: 2, Bias: 80268073043.017365, T: 640, Avg. loss: 21045770587918947780560683008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 879479935455.89, NNZs: 2, Bias: 132607430302.435791, T: 768, Avg. loss: 23144941195843124967090683904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1067247710926.24, NNZs: 2, Bias: 52607430302.435791, T: 896, Avg. loss: 22927922389819229247146819584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2250501381534.59, NNZs: 2, Bias: -87392569697.564209, T: 1024, Avg. loss: 23346606018476025127322517504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1733094414455.07, NNZs: 2, Bias: -101465910279.399094, T: 1152, Avg. loss: 21322738220749067915144200192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 474151227754.74, NNZs: 2, Bias: -87690831070.320175, T: 1280, Avg. loss: 22479891478792830361719013376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 89835779175.04, NNZs: 2, Bias: -68092691331.336609, T: 1408, Avg. loss: 954149863804136256383746048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 121084660841.39, NNZs: 2, Bias: -54675290165.342262, T: 1536, Avg. loss: 915236408910015667244105728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 360269275626.20, NNZs: 2, Bias: -58311064214.945282, T: 1664, Avg. loss: 889192368910076238180122624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 122791566333.42, NNZs: 2, Bias: -50560848401.356941, T: 1792, Avg. loss: 889037206961838487041474560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 171054966896.39, NNZs: 2, Bias: -44157431934.312424, T: 1920, Avg. loss: 857545725450172461748322304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 310376168017.07, NNZs: 2, Bias: -31013938020.650703, T: 2048, Avg. loss: 826546583168013620914159616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 383167605091.04, NNZs: 2, Bias: -51013938020.650703, T: 2176, Avg. loss: 836055829211123783259127808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 301475881755.39, NNZs: 2, Bias: -40502651857.583992, T: 2304, Avg. loss: 920400190537038189463339008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 156268948656.14, NNZs: 2, Bias: -15657054816.461502, T: 2432, Avg. loss: 864734075869720338780651520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 352178361261.06, NNZs: 2, Bias: -18863545893.519455, T: 2560, Avg. loss: 977691528271989745026859008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 149846906186.81, NNZs: 2, Bias: -24063266074.325493, T: 2688, Avg. loss: 897762396853920034585575424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 70061243624.19, NNZs: 2, Bias: -25226550508.848469, T: 2816, Avg. loss: 34465276151161111009296384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 21148738111.92, NNZs: 2, Bias: -28306314976.840065, T: 2944, Avg. loss: 35852545005391127584440320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 28035457764.17, NNZs: 2, Bias: -26745591714.258461, T: 3072, Avg. loss: 30384933148284253280141312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2604424305.63, NNZs: 2, Bias: -25215339929.878967, T: 3200, Avg. loss: 30648756098533981299933184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 33497974667.28, NNZs: 2, Bias: -28003001528.194977, T: 3328, Avg. loss: 29054535352799381097021440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 58194130444.08, NNZs: 2, Bias: -30386749453.214268, T: 3456, Avg. loss: 31244287501356216784781312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 69215292374.58, NNZs: 2, Bias: -28247593148.100006, T: 3584, Avg. loss: 32883587012837138292015104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 57088471686.98, NNZs: 2, Bias: -26007997125.547852, T: 3712, Avg. loss: 34623658038967635229540352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 60531156837.39, NNZs: 2, Bias: -25117697827.832905, T: 3840, Avg. loss: 33698252961653792457097216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 38006906756.67, NNZs: 2, Bias: -24728350320.735863, T: 3968, Avg. loss: 35697766633347362179776512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 10151385954.13, NNZs: 2, Bias: -24847017491.342770, T: 4096, Avg. loss: 1055263674101451427151872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4285203646.66, NNZs: 2, Bias: -24910294496.168968, T: 4224, Avg. loss: 809979565144228942053376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 11052648608.12, NNZs: 2, Bias: -24885417947.351894, T: 4352, Avg. loss: 671164926505465717719040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9944875447.06, NNZs: 2, Bias: -24590983103.110619, T: 4480, Avg. loss: 771016963214087999717376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2926218450.51, NNZs: 2, Bias: -24766444070.260372, T: 4608, Avg. loss: 583499391686132879065088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2777680089.74, NNZs: 2, Bias: -24342941670.753693, T: 4736, Avg. loss: 583165686340260097687552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6541949600.70, NNZs: 2, Bias: -24453674363.707211, T: 4864, Avg. loss: 524620251052637436248064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4435312210.58, NNZs: 2, Bias: -24593150548.973991, T: 4992, Avg. loss: 661806728002430474125312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1437074062.12, NNZs: 2, Bias: -24377411329.316784, T: 5120, Avg. loss: 527014103506515379879936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3228334105.66, NNZs: 2, Bias: -23904981294.719296, T: 5248, Avg. loss: 648277819822486451126272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1608631949.03, NNZs: 2, Bias: -24211276064.072388, T: 5376, Avg. loss: 529577097151691395956736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4512925657.75, NNZs: 2, Bias: -24137479229.227604, T: 5504, Avg. loss: 544952238169293443825664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2087624652.94, NNZs: 2, Bias: -24093870385.478596, T: 5632, Avg. loss: 2895492754036877688832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 896308639.94, NNZs: 2, Bias: -24066451105.846344, T: 5760, Avg. loss: 732633804530380439552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 314855126.49, NNZs: 2, Bias: -24048974418.804295, T: 5888, Avg. loss: 225093246775249240064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 162648637.36, NNZs: 2, Bias: -24035925118.258202, T: 6016, Avg. loss: 97816215938851307520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 222425274.77, NNZs: 2, Bias: -24025171903.612770, T: 6144, Avg. loss: 69495918262065913856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 313132595.79, NNZs: 2, Bias: -24015604203.223743, T: 6272, Avg. loss: 59148920081140776960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 372077145.76, NNZs: 2, Bias: -24007269915.691013, T: 6400, Avg. loss: 52832307497472024576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 369803742.04, NNZs: 2, Bias: -23999225945.019802, T: 6528, Avg. loss: 59635569995949899776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 383359305.61, NNZs: 2, Bias: -23991467580.711521, T: 6656, Avg. loss: 55265930821606105088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 378437666.30, NNZs: 2, Bias: -23983508274.395267, T: 6784, Avg. loss: 61352452625950138368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 359007459.45, NNZs: 2, Bias: -23975479473.897198, T: 6912, Avg. loss: 60566477324241797120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 370541817.85, NNZs: 2, Bias: -23966953740.272224, T: 7040, Avg. loss: 61762527276683411456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 367218900.41, NNZs: 2, Bias: -23965411672.025974, T: 7168, Avg. loss: 48320295764488282112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 367584675.60, NNZs: 2, Bias: -23963809427.409409, T: 7296, Avg. loss: 48232820204467920896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 372184641.84, NNZs: 2, Bias: -23962131790.623013, T: 7424, Avg. loss: 48578517527265656832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 379245408.58, NNZs: 2, Bias: -23960431140.552822, T: 7552, Avg. loss: 47919646530687500288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 374496290.41, NNZs: 2, Bias: -23958872304.226326, T: 7680, Avg. loss: 49432806031892701184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 373434145.63, NNZs: 2, Bias: -23957337640.425476, T: 7808, Avg. loss: 46912017972042874880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 383735627.96, NNZs: 2, Bias: -23955587120.434528, T: 7936, Avg. loss: 47852449194603749376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 375124187.71, NNZs: 2, Bias: -23954103237.152073, T: 8064, Avg. loss: 49121002892152422400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 382391086.85, NNZs: 2, Bias: -23952373991.846714, T: 8192, Avg. loss: 48689108900533092352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 382467631.47, NNZs: 2, Bias: -23950741819.405727, T: 8320, Avg. loss: 49389355938373795840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 381878673.99, NNZs: 2, Bias: -23949156167.277264, T: 8448, Avg. loss: 48249285025045938176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 381448599.89, NNZs: 2, Bias: -23948840577.389244, T: 8576, Avg. loss: 47440376840669282304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 380951004.26, NNZs: 2, Bias: -23948526504.528816, T: 8704, Avg. loss: 47375453131299946496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 380081904.66, NNZs: 2, Bias: -23948218797.987103, T: 8832, Avg. loss: 47306553892962877440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 380980546.57, NNZs: 2, Bias: -23947882531.791161, T: 8960, Avg. loss: 47361320490240614400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 380310743.23, NNZs: 2, Bias: -23947571293.421741, T: 9088, Avg. loss: 47359571888032194560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 71 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 597074369644.80, NNZs: 2, Bias: -16455950662.742378, T: 128, Avg. loss: 22259490494892547191317987328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1838158827602.93, NNZs: 2, Bias: -1250079370.255341, T: 256, Avg. loss: 23199491951965228178985713664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1871817992196.19, NNZs: 2, Bias: -11230325228.057602, T: 384, Avg. loss: 23347559093665000132987322368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1076950932177.51, NNZs: 2, Bias: -8911714917.671700, T: 512, Avg. loss: 25623722611986469652552220672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2117870572114.69, NNZs: 2, Bias: -64413381394.827240, T: 640, Avg. loss: 21360051407287890404091887616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1554065718529.86, NNZs: 2, Bias: -164413381394.827240, T: 768, Avg. loss: 23178906997897449275318599680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1299711654034.33, NNZs: 2, Bias: -124413381394.827240, T: 896, Avg. loss: 22888538547503896047468412928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 204638949156.99, NNZs: 2, Bias: -144413381394.827240, T: 1024, Avg. loss: 23704082820478991481419333632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 958483551623.53, NNZs: 2, Bias: -147793289269.105896, T: 1152, Avg. loss: 24024504368090965020355067904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1258147583297.61, NNZs: 2, Bias: -76628778103.664032, T: 1280, Avg. loss: 22837490189966992395997282304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 313743822234.18, NNZs: 2, Bias: -86058337078.396790, T: 1408, Avg. loss: 1216171524437428730675068928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 88558571596.40, NNZs: 2, Bias: -88397319275.600021, T: 1536, Avg. loss: 934305418078947344553869312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 280787644666.68, NNZs: 2, Bias: -99128726851.907516, T: 1664, Avg. loss: 881456769155702917743771648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 315642031929.19, NNZs: 2, Bias: -117874530917.464722, T: 1792, Avg. loss: 908688576723589057589805056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 325290013350.21, NNZs: 2, Bias: -120657393953.812668, T: 1920, Avg. loss: 898139699464671993389907968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 280653462086.53, NNZs: 2, Bias: -116674569988.078888, T: 2048, Avg. loss: 882992360455461598935384064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 150194169947.33, NNZs: 2, Bias: -124690050805.092117, T: 2176, Avg. loss: 871465021787420316487647232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 432471387415.30, NNZs: 2, Bias: -128180542814.410263, T: 2304, Avg. loss: 837143649001387815117783040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 290381331777.84, NNZs: 2, Bias: -111966022576.961838, T: 2432, Avg. loss: 1003138752551282711218618368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 311841081629.06, NNZs: 2, Bias: -111774683554.148895, T: 2560, Avg. loss: 942898859786537635663577088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 296391513464.77, NNZs: 2, Bias: -115312759653.610733, T: 2688, Avg. loss: 932822800004834956048072704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 31265322954.17, NNZs: 2, Bias: -111365026967.416534, T: 2816, Avg. loss: 883207050036002442966990848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 272977835044.57, NNZs: 2, Bias: -120391080979.731155, T: 2944, Avg. loss: 867225494718718186893606912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 47774096126.40, NNZs: 2, Bias: -120178377101.409821, T: 3072, Avg. loss: 57425734897154272056573952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 16882088922.37, NNZs: 2, Bias: -120649332378.599335, T: 3200, Avg. loss: 36276990189347640495308800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 52863199644.89, NNZs: 2, Bias: -120377579909.792648, T: 3328, Avg. loss: 34471243750835982704836608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 110678630816.50, NNZs: 2, Bias: -119046520840.909363, T: 3456, Avg. loss: 37028690552555051138678784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 67146832878.83, NNZs: 2, Bias: -118441346560.321167, T: 3584, Avg. loss: 37126089466913659889385472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 89960536031.31, NNZs: 2, Bias: -118258468277.409683, T: 3712, Avg. loss: 35667635641258785336459264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 66099455366.99, NNZs: 2, Bias: -117483493243.335541, T: 3840, Avg. loss: 36084894970344904801124352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 63635464526.41, NNZs: 2, Bias: -117141619620.568558, T: 3968, Avg. loss: 38652081806566254308229120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 18613426350.83, NNZs: 2, Bias: -117915727390.380051, T: 4096, Avg. loss: 1362108435666352184754176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4979266201.25, NNZs: 2, Bias: -117979044706.351410, T: 4224, Avg. loss: 719095727308942077853696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1115166563.48, NNZs: 2, Bias: -117726091188.688599, T: 4352, Avg. loss: 755889760121005444956160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6359611993.12, NNZs: 2, Bias: -117487922711.667709, T: 4480, Avg. loss: 810991214492650863329280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 7330066090.18, NNZs: 2, Bias: -117498787417.179092, T: 4608, Avg. loss: 756572729332106782572544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4582290358.00, NNZs: 2, Bias: -117261843289.657578, T: 4736, Avg. loss: 723829302087350258499584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1798192057.79, NNZs: 2, Bias: -116859946499.694122, T: 4864, Avg. loss: 737545054147607684710400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 597315610.91, NNZs: 2, Bias: -116806628724.850327, T: 4992, Avg. loss: 2189415480845177454592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1105976437.68, NNZs: 2, Bias: -116760859711.015778, T: 5120, Avg. loss: 1410040532635783790592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1274465374.07, NNZs: 2, Bias: -116722276721.909225, T: 5248, Avg. loss: 1292557387839808995328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1479578979.19, NNZs: 2, Bias: -116685085894.669525, T: 5376, Avg. loss: 1195193676129042169856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1601518456.49, NNZs: 2, Bias: -116649056238.815506, T: 5504, Avg. loss: 1202719839993306546176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1675061911.11, NNZs: 2, Bias: -116614106888.686096, T: 5632, Avg. loss: 1218643951796732559360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1678794454.00, NNZs: 2, Bias: -116578951453.210526, T: 5760, Avg. loss: 1233597699716035379200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1659973078.88, NNZs: 2, Bias: -116544732883.475311, T: 5888, Avg. loss: 1223657583472640524288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1745184024.68, NNZs: 2, Bias: -116509087940.235168, T: 6016, Avg. loss: 1202566282724533075968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1695331029.71, NNZs: 2, Bias: -116502979863.367508, T: 6144, Avg. loss: 1008855144707481141248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1712773907.33, NNZs: 2, Bias: -116495839818.091278, T: 6272, Avg. loss: 1011839984719970566144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1697888261.60, NNZs: 2, Bias: -116489201461.544922, T: 6400, Avg. loss: 1006865707778627469312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1695923071.80, NNZs: 2, Bias: -116482355556.485535, T: 6528, Avg. loss: 1009750118693908774912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1709035772.83, NNZs: 2, Bias: -116475400727.567032, T: 6656, Avg. loss: 991361729672763539456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1718077408.49, NNZs: 2, Bias: -116468495970.845139, T: 6784, Avg. loss: 993992264756980482048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1693549070.61, NNZs: 2, Bias: -116462035943.510986, T: 6912, Avg. loss: 999455265361719721984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1725542557.69, NNZs: 2, Bias: -116454743635.253418, T: 7040, Avg. loss: 1001309031965552541696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1711496623.83, NNZs: 2, Bias: -116448215631.759247, T: 7168, Avg. loss: 988912179722596909056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1707536545.68, NNZs: 2, Bias: -116441426417.227814, T: 7296, Avg. loss: 1005215130733851705344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1726094762.67, NNZs: 2, Bias: -116434320212.058807, T: 7424, Avg. loss: 1001526551134523359232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1720568039.14, NNZs: 2, Bias: -116427690024.331406, T: 7552, Avg. loss: 983464048583035191296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1714668597.31, NNZs: 2, Bias: -116420935455.383331, T: 7680, Avg. loss: 1004597935596554027008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1699838533.52, NNZs: 2, Bias: -116414368350.467667, T: 7808, Avg. loss: 995866452780644171776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1735530470.09, NNZs: 2, Bias: -116407193830.945526, T: 7936, Avg. loss: 971831941578820288512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1723984573.25, NNZs: 2, Bias: -116400572482.822540, T: 8064, Avg. loss: 997952469055090065408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1737130986.27, NNZs: 2, Bias: -116393571194.233353, T: 8192, Avg. loss: 997623179744809975808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1718138978.60, NNZs: 2, Bias: -116387030283.565628, T: 8320, Avg. loss: 1002102623409117462528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1712012483.45, NNZs: 2, Bias: -116380368969.829712, T: 8448, Avg. loss: 989178438968910807040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1760698190.39, NNZs: 2, Bias: -116372974956.454712, T: 8576, Avg. loss: 977090965737740042240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1728572976.02, NNZs: 2, Bias: -116372084943.052124, T: 8704, Avg. loss: 981301815874840559616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1736774937.51, NNZs: 2, Bias: -116370622661.699112, T: 8832, Avg. loss: 957316545764780539904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1729315427.78, NNZs: 2, Bias: -116369380699.356857, T: 8960, Avg. loss: 966915277494130966528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1726665366.60, NNZs: 2, Bias: -116368069836.881897, T: 9088, Avg. loss: 964722379769970163712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1729472723.37, NNZs: 2, Bias: -116366673063.639206, T: 9216, Avg. loss: 968140627920428728320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1736947981.00, NNZs: 2, Bias: -116365212149.972290, T: 9344, Avg. loss: 963959421424183541760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1730741383.68, NNZs: 2, Bias: -116363949797.468231, T: 9472, Avg. loss: 968168344776589705216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 74 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1625975359499.97, NNZs: 2, Bias: 9724461520.183899, T: 128, Avg. loss: 21632609967101322228182024192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 876504585027.04, NNZs: 2, Bias: 69724461520.183899, T: 256, Avg. loss: 21872014147409677591282450432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2518735183070.86, NNZs: 2, Bias: 55301413013.530914, T: 384, Avg. loss: 19476859849148597773610778624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2156170838670.75, NNZs: 2, Bias: 103405322594.738159, T: 512, Avg. loss: 20546689080756176735352913920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1466448922770.79, NNZs: 2, Bias: -36594677405.261841, T: 640, Avg. loss: 22950840309375325806329331712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 896069658196.28, NNZs: 2, Bias: 29635434440.654137, T: 768, Avg. loss: 23092601014917931433516335104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1857592309711.11, NNZs: 2, Bias: 44611735430.822998, T: 896, Avg. loss: 20085933054940984375196516352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2863443083680.80, NNZs: 2, Bias: 59493002158.540604, T: 1024, Avg. loss: 19910394143262455510067052544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 245286137860.34, NNZs: 2, Bias: 40392011229.210289, T: 1152, Avg. loss: 4091890855183576832694812672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 410313656153.05, NNZs: 2, Bias: 36964218250.382919, T: 1280, Avg. loss: 837111225648063831238246400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 373859340400.79, NNZs: 2, Bias: 44247810810.157433, T: 1408, Avg. loss: 861353332671929922938208256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 505289956270.70, NNZs: 2, Bias: 49945494569.682518, T: 1536, Avg. loss: 819278842133252020111409152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 233713719136.31, NNZs: 2, Bias: 66591896255.919052, T: 1664, Avg. loss: 882854714781369062609911808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 333108000350.60, NNZs: 2, Bias: 58171379578.600243, T: 1792, Avg. loss: 887177768196932849320853504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 317696513477.41, NNZs: 2, Bias: 79636041401.794037, T: 1920, Avg. loss: 820640784867557534225924096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 221795234704.85, NNZs: 2, Bias: 87771224449.773392, T: 2048, Avg. loss: 864743070223025040454057984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 364153298684.30, NNZs: 2, Bias: 99514753228.516739, T: 2176, Avg. loss: 871997519257548009588654080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 74285838098.95, NNZs: 2, Bias: 95072252338.478058, T: 2304, Avg. loss: 42393250588208232409333760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 65875938277.05, NNZs: 2, Bias: 94531955156.181351, T: 2432, Avg. loss: 30582404348935043817668608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 48346976407.11, NNZs: 2, Bias: 93551917456.571014, T: 2560, Avg. loss: 29745134213907050584342528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 34693036033.82, NNZs: 2, Bias: 93365109270.989182, T: 2688, Avg. loss: 33514487968211036505374720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 24917821557.14, NNZs: 2, Bias: 94100812978.978729, T: 2816, Avg. loss: 31879880518627985559912448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 30442101489.45, NNZs: 2, Bias: 92415543534.473938, T: 2944, Avg. loss: 32564923970453842916540416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 42290371481.05, NNZs: 2, Bias: 92002992082.431534, T: 3072, Avg. loss: 34981022813457649533714432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 58272027340.85, NNZs: 2, Bias: 92475386779.426514, T: 3200, Avg. loss: 30984321050966996180533248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 9071019116.94, NNZs: 2, Bias: 91982201500.055237, T: 3328, Avg. loss: 1565400615192809718153216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4132474549.13, NNZs: 2, Bias: 91593076066.663071, T: 3456, Avg. loss: 537063218586603608866816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 18275741683.33, NNZs: 2, Bias: 91508940714.036453, T: 3584, Avg. loss: 538733845954801147314176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3162485893.73, NNZs: 2, Bias: 90969102068.199966, T: 3712, Avg. loss: 731587789517227527503872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 6706825525.90, NNZs: 2, Bias: 90764592609.638245, T: 3840, Avg. loss: 652811399560835308191744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2126490037.84, NNZs: 2, Bias: 90645261279.923447, T: 3968, Avg. loss: 563634607860847506096128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2855081351.85, NNZs: 2, Bias: 90626195743.954819, T: 4096, Avg. loss: 587409910635048407662592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1251629718.17, NNZs: 2, Bias: 90572400432.025375, T: 4224, Avg. loss: 2683359173545182101504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1348619057.36, NNZs: 2, Bias: 90538126798.065659, T: 4352, Avg. loss: 899528547918147485696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1371983831.10, NNZs: 2, Bias: 90506622545.485809, T: 4480, Avg. loss: 851642997534347886592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1399973393.54, NNZs: 2, Bias: 90475977783.672501, T: 4608, Avg. loss: 812205836723005685760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1400914794.71, NNZs: 2, Bias: 90443894474.132370, T: 4736, Avg. loss: 919744589292830982144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1456217705.95, NNZs: 2, Bias: 90411093834.144058, T: 4864, Avg. loss: 906883127670387113984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1410185962.51, NNZs: 2, Bias: 90378526063.203156, T: 4992, Avg. loss: 912241363085545308160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1418014481.24, NNZs: 2, Bias: 90345502322.288574, T: 5120, Avg. loss: 919055330159513174016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1436735148.41, NNZs: 2, Bias: 90313014723.143585, T: 5248, Avg. loss: 870806707552320487424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1421690687.37, NNZs: 2, Bias: 90306809981.255508, T: 5376, Avg. loss: 732905813884621422592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1433177030.47, NNZs: 2, Bias: 90300318358.581665, T: 5504, Avg. loss: 717652908129192116224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1435867523.19, NNZs: 2, Bias: 90293867688.830933, T: 5632, Avg. loss: 727453470302368038912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1424780097.73, NNZs: 2, Bias: 90287686192.383560, T: 5760, Avg. loss: 723150527926503604224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1421599444.85, NNZs: 2, Bias: 90281388972.694168, T: 5888, Avg. loss: 722749409877473755136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1447608763.59, NNZs: 2, Bias: 90274603757.129623, T: 6016, Avg. loss: 723780144476732391424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1447287294.79, NNZs: 2, Bias: 90268403336.149918, T: 6144, Avg. loss: 703772199614813175808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1448283783.63, NNZs: 2, Bias: 90261995952.154922, T: 6272, Avg. loss: 726456468706741977088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1450671085.07, NNZs: 2, Bias: 90255574009.317886, T: 6400, Avg. loss: 725979369937231806464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1438761202.41, NNZs: 2, Bias: 90249430678.540604, T: 6528, Avg. loss: 720643330221559906304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1439191482.97, NNZs: 2, Bias: 90242976156.556839, T: 6656, Avg. loss: 733362480920146870272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1428739488.45, NNZs: 2, Bias: 90236789895.635651, T: 6784, Avg. loss: 722094258483600556032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1435919129.29, NNZs: 2, Bias: 90235406848.388184, T: 6912, Avg. loss: 702681417202421596160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1433999860.01, NNZs: 2, Bias: 90234169203.062866, T: 7040, Avg. loss: 702573128791603937280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1433121549.32, NNZs: 2, Bias: 90232915867.410690, T: 7168, Avg. loss: 701991849544919547904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1434769665.80, NNZs: 2, Bias: 90231621551.532928, T: 7296, Avg. loss: 702363299157369946112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1437508190.93, NNZs: 2, Bias: 90230311537.745560, T: 7424, Avg. loss: 701385342888008613888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1436170243.58, NNZs: 2, Bias: 90229064679.108765, T: 7552, Avg. loss: 702484456185015566336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1436451946.92, NNZs: 2, Bias: 90227791746.535141, T: 7680, Avg. loss: 702603903351064363008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1432512105.91, NNZs: 2, Bias: 90226590757.048767, T: 7808, Avg. loss: 700122200714958602240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1434540879.62, NNZs: 2, Bias: 90225290948.047867, T: 7936, Avg. loss: 702007600947053068288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1439576263.03, NNZs: 2, Bias: 90223942988.968918, T: 8064, Avg. loss: 701974233327448489984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1433909953.48, NNZs: 2, Bias: 90222770596.270905, T: 8192, Avg. loss: 699458744893458087936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1436977827.54, NNZs: 2, Bias: 90221452892.146912, T: 8320, Avg. loss: 702713980544059047936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1436479127.40, NNZs: 2, Bias: 90220193153.721710, T: 8448, Avg. loss: 702175680294941229056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1437505449.20, NNZs: 2, Bias: 90218907986.586823, T: 8576, Avg. loss: 702717871462895452160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1437778741.47, NNZs: 2, Bias: 90217636912.569656, T: 8704, Avg. loss: 701482696796969369600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1439508054.80, NNZs: 2, Bias: 90216340973.738724, T: 8832, Avg. loss: 702373166979874291712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 69 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 618707118443.18, NNZs: 2, Bias: 117684597102.040604, T: 128, Avg. loss: 19525926063919717519888220160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1926573719391.38, NNZs: 2, Bias: 78116213851.822647, T: 256, Avg. loss: 17627413850813611362966568960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 716504167339.62, NNZs: 2, Bias: 97170913412.882217, T: 384, Avg. loss: 21408086049118764214681337856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1711007534452.67, NNZs: 2, Bias: 147738424812.007294, T: 512, Avg. loss: 21334315806227054506796908544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1279471561400.47, NNZs: 2, Bias: 207738424812.007294, T: 640, Avg. loss: 20871152549541630409814573056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1131665607224.39, NNZs: 2, Bias: 94896608786.367035, T: 768, Avg. loss: 19032469206441697688453906432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 246258128813.16, NNZs: 2, Bias: -6359679876.797882, T: 896, Avg. loss: 21192617346597782560897499136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 443680110820.81, NNZs: 2, Bias: -30426312771.172726, T: 1024, Avg. loss: 719978723055868842552066048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 129527479741.53, NNZs: 2, Bias: -31411329833.368076, T: 1152, Avg. loss: 756316604320966010462011392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 182899580187.52, NNZs: 2, Bias: -31773676303.564163, T: 1280, Avg. loss: 844360705753670210264498176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 434353373030.03, NNZs: 2, Bias: -15580701630.528698, T: 1408, Avg. loss: 743423275228051777129545728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 116838484977.06, NNZs: 2, Bias: -25476880310.034214, T: 1536, Avg. loss: 832673212858405632235012096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 298531587209.94, NNZs: 2, Bias: -14138920277.423542, T: 1664, Avg. loss: 728421191876766433961574400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 13030693465.12, NNZs: 2, Bias: -8376131015.576598, T: 1792, Avg. loss: 41080813852411245933625344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 61715011874.55, NNZs: 2, Bias: -7861498850.789454, T: 1920, Avg. loss: 28009134932734048823410688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 54939617666.40, NNZs: 2, Bias: -5085000800.176803, T: 2048, Avg. loss: 26807073031472356947656704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 66199729601.47, NNZs: 2, Bias: -7409568343.965421, T: 2176, Avg. loss: 29528785674010473223159808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 23716807462.25, NNZs: 2, Bias: -7147255983.779857, T: 2304, Avg. loss: 28302268906903332018192384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 50927582154.24, NNZs: 2, Bias: -9041727818.292780, T: 2432, Avg. loss: 29542469525141509894045696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 53702058095.66, NNZs: 2, Bias: -10140923980.937334, T: 2560, Avg. loss: 27137977336876258291613696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 19511810672.23, NNZs: 2, Bias: -11723478036.160295, T: 2688, Avg. loss: 30904832275585803319508992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 781715395.92, NNZs: 2, Bias: -11451914563.394947, T: 2816, Avg. loss: 562504031920130503999488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 3075526589.69, NNZs: 2, Bias: -11345142801.884584, T: 2944, Avg. loss: 303562536334079928827904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 354716201.50, NNZs: 2, Bias: -11318346006.262018, T: 3072, Avg. loss: 410332801824328324743168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 486115908.84, NNZs: 2, Bias: -11150406211.769218, T: 3200, Avg. loss: 345788830664652681641984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2152883354.29, NNZs: 2, Bias: -11026695695.792273, T: 3328, Avg. loss: 566290781090760533999616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 5300133836.23, NNZs: 2, Bias: -10859565055.136782, T: 3456, Avg. loss: 493146974273452776620032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 7153024199.43, NNZs: 2, Bias: -10807617912.093470, T: 3584, Avg. loss: 312297882282734913585152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1105148261.16, NNZs: 2, Bias: -10783696630.778358, T: 3712, Avg. loss: 11243977751288570970112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 646324605.62, NNZs: 2, Bias: -10786206769.018847, T: 3840, Avg. loss: 121443595270626459648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 396736830.17, NNZs: 2, Bias: -10786376249.696241, T: 3968, Avg. loss: 42147724986606411776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 282310601.81, NNZs: 2, Bias: -10784221228.720306, T: 4096, Avg. loss: 22244395577946005504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 226686552.97, NNZs: 2, Bias: -10781770059.485506, T: 4224, Avg. loss: 13119619679843860480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 201653989.92, NNZs: 2, Bias: -10778503126.978128, T: 4352, Avg. loss: 12978785885988433920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 175026229.40, NNZs: 2, Bias: -10774967868.417025, T: 4480, Avg. loss: 13935327201419603968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 172849153.52, NNZs: 2, Bias: -10771283257.793337, T: 4608, Avg. loss: 12712881244038574080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 165086493.80, NNZs: 2, Bias: -10767648801.506620, T: 4736, Avg. loss: 12396323906992214016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 162875429.74, NNZs: 2, Bias: -10763873593.846815, T: 4864, Avg. loss: 12555143874415476736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 177135882.57, NNZs: 2, Bias: -10760100244.066164, T: 4992, Avg. loss: 11464020668606603264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 173481951.06, NNZs: 2, Bias: -10756550186.023981, T: 5120, Avg. loss: 12101842291833858048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 171515429.19, NNZs: 2, Bias: -10753009659.537769, T: 5248, Avg. loss: 11568445333862727680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 169028617.68, NNZs: 2, Bias: -10749258137.575340, T: 5376, Avg. loss: 12641316664882837504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 174524420.21, NNZs: 2, Bias: -10745337087.380226, T: 5504, Avg. loss: 12655971114185074688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 175365198.62, NNZs: 2, Bias: -10741722971.939463, T: 5632, Avg. loss: 12440792171687409664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 169476191.56, NNZs: 2, Bias: -10741121013.095192, T: 5760, Avg. loss: 9452041935119153152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 169050574.72, NNZs: 2, Bias: -10740416687.522587, T: 5888, Avg. loss: 9659394775590612992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 168584837.74, NNZs: 2, Bias: -10739703341.579988, T: 6016, Avg. loss: 9776360033319090176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 170542445.74, NNZs: 2, Bias: -10738940094.785378, T: 6144, Avg. loss: 9924358669470916608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 170011961.32, NNZs: 2, Bias: -10738232859.255167, T: 6272, Avg. loss: 9727229582219890688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 170150143.40, NNZs: 2, Bias: -10737515597.891747, T: 6400, Avg. loss: 9689105610381363200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 170688096.28, NNZs: 2, Bias: -10737361966.082573, T: 6528, Avg. loss: 9567617741502119936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 171290796.17, NNZs: 2, Bias: -10737207806.136225, T: 6656, Avg. loss: 9531348021671565312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 171159223.46, NNZs: 2, Bias: -10737065095.130375, T: 6784, Avg. loss: 9551685973953816576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 171559697.76, NNZs: 2, Bias: -10736914315.996616, T: 6912, Avg. loss: 9520673545524744192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 171419139.87, NNZs: 2, Bias: -10736771654.116514, T: 7040, Avg. loss: 9557141108736430080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 55 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1156685151786.12, NNZs: 2, Bias: -24001577338.761864, T: 128, Avg. loss: 18739654177766056184248270848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 777482424742.90, NNZs: 2, Bias: -64001577338.761871, T: 256, Avg. loss: 19254190732996057647470870528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1134452589174.33, NNZs: 2, Bias: -53413041760.454041, T: 384, Avg. loss: 19999145700222193547580801024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1492094430341.37, NNZs: 2, Bias: -12894370929.454941, T: 512, Avg. loss: 20261360691157054012591702016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 598599330230.14, NNZs: 2, Bias: 7105629070.545059, T: 640, Avg. loss: 21128828238372898470031785984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 597317309450.49, NNZs: 2, Bias: 28657945929.486481, T: 768, Avg. loss: 20221623909897911393704738816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 104853564404.38, NNZs: 2, Bias: 10922956506.865047, T: 896, Avg. loss: 858337930663199653668847616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 270501114495.57, NNZs: 2, Bias: 1558545336.610994, T: 1024, Avg. loss: 799419384079415938354511872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 80753611330.63, NNZs: 2, Bias: 4919372883.411127, T: 1152, Avg. loss: 812762759031708847546826752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 337013998343.23, NNZs: 2, Bias: 10156349166.333803, T: 1280, Avg. loss: 851943705648055669969911808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 296222039683.27, NNZs: 2, Bias: 13730569106.151237, T: 1408, Avg. loss: 740705741845075621987745792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 144346743179.32, NNZs: 2, Bias: 32510704086.515625, T: 1536, Avg. loss: 928890328821407762031312896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 367367403149.29, NNZs: 2, Bias: 33125120282.772392, T: 1664, Avg. loss: 871827761382435563667193856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 380144878295.02, NNZs: 2, Bias: 30799261168.993958, T: 1792, Avg. loss: 759344890481723122024185856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 141281519167.58, NNZs: 2, Bias: 31117851541.877392, T: 1920, Avg. loss: 838973833122317645595541504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 156110830418.33, NNZs: 2, Bias: 48484524722.858131, T: 2048, Avg. loss: 757335136526242429876043776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 48682496695.81, NNZs: 2, Bias: 47873400697.828468, T: 2176, Avg. loss: 32004619518535115294638080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 62485216620.38, NNZs: 2, Bias: 47319408427.637245, T: 2304, Avg. loss: 33961546022467293985898496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 67063988379.59, NNZs: 2, Bias: 48163423021.710564, T: 2432, Avg. loss: 31810102181242192812572672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 51822020920.70, NNZs: 2, Bias: 45752283662.608078, T: 2560, Avg. loss: 31988914306372161989771264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 39807763329.74, NNZs: 2, Bias: 45540544604.089218, T: 2688, Avg. loss: 31241098246218620300427264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 60507055146.18, NNZs: 2, Bias: 47175774977.786316, T: 2816, Avg. loss: 30768959207841250779594752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 42556751515.34, NNZs: 2, Bias: 47754924177.250031, T: 2944, Avg. loss: 29579303494668997674139648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 31959778681.65, NNZs: 2, Bias: 48785362484.603973, T: 3072, Avg. loss: 31200022258383700052934656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 29253515558.06, NNZs: 2, Bias: 45222565772.503387, T: 3200, Avg. loss: 34429714145917075820904448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2865008311.01, NNZs: 2, Bias: 45696169185.840385, T: 3328, Avg. loss: 33294077501360308056227840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 40158001337.28, NNZs: 2, Bias: 46638194282.369011, T: 3456, Avg. loss: 29919145682949697970372608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 37255862980.60, NNZs: 2, Bias: 47743195867.209579, T: 3584, Avg. loss: 29900391318872482880946176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9163322948.40, NNZs: 2, Bias: 47638114869.934433, T: 3712, Avg. loss: 858023213982367478710272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 7936337546.86, NNZs: 2, Bias: 47575049248.114594, T: 3840, Avg. loss: 517744872998270190747648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11678512479.21, NNZs: 2, Bias: 47563140866.504623, T: 3968, Avg. loss: 402131226119727940108288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 7487218362.29, NNZs: 2, Bias: 47428460852.811821, T: 4096, Avg. loss: 567547200191383572840448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8462902530.71, NNZs: 2, Bias: 47531791702.602280, T: 4224, Avg. loss: 647105328625063020199936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4225360364.83, NNZs: 2, Bias: 47588488854.363235, T: 4352, Avg. loss: 691308451327379991691264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1146316629.41, NNZs: 2, Bias: 47410822948.837273, T: 4480, Avg. loss: 517873558039274090135552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 7763967239.73, NNZs: 2, Bias: 47503180623.206116, T: 4608, Avg. loss: 385101819143378689851392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 14201894410.19, NNZs: 2, Bias: 47786058509.220879, T: 4736, Avg. loss: 593523446645106910691328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4874031993.13, NNZs: 2, Bias: 48124747897.297592, T: 4864, Avg. loss: 612722888254673322508288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 5436916898.68, NNZs: 2, Bias: 48363273463.446007, T: 4992, Avg. loss: 550567523894408823963648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1744912869.88, NNZs: 2, Bias: 48329291265.222137, T: 5120, Avg. loss: 483173500223267262169088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2252969412.58, NNZs: 2, Bias: 48152708216.058464, T: 5248, Avg. loss: 473972755407254927179776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1364634454.01, NNZs: 2, Bias: 48137592350.743668, T: 5376, Avg. loss: 849459395715678339072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1122655869.97, NNZs: 2, Bias: 48125962392.071762, T: 5504, Avg. loss: 280397480286354178048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 985218218.15, NNZs: 2, Bias: 48112531708.167473, T: 5632, Avg. loss: 248830751877824479232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 924174765.40, NNZs: 2, Bias: 48098761770.941658, T: 5760, Avg. loss: 221190871600805150720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 920755436.74, NNZs: 2, Bias: 48084708502.632729, T: 5888, Avg. loss: 205304456931607543808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 849170685.81, NNZs: 2, Bias: 48070477626.948601, T: 6016, Avg. loss: 236680230068699987968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 826961971.55, NNZs: 2, Bias: 48055939741.408966, T: 6144, Avg. loss: 225208832273257332736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 850720356.62, NNZs: 2, Bias: 48041202437.321037, T: 6272, Avg. loss: 208120210756555636736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 819360608.47, NNZs: 2, Bias: 48027153741.666115, T: 6400, Avg. loss: 220524722295618273280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 844727200.10, NNZs: 2, Bias: 48011693151.316742, T: 6528, Avg. loss: 211922995241233252352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 850912589.89, NNZs: 2, Bias: 48008540491.162270, T: 6656, Avg. loss: 184058074211570483200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 848623886.61, NNZs: 2, Bias: 48005574434.079506, T: 6784, Avg. loss: 182048233114880868352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 860047914.43, NNZs: 2, Bias: 48002411940.494003, T: 6912, Avg. loss: 179034936904885534720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 849200187.68, NNZs: 2, Bias: 47999540766.120613, T: 7040, Avg. loss: 186003686150712393728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 849542171.67, NNZs: 2, Bias: 47996504178.398399, T: 7168, Avg. loss: 183641241767140556800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 842554672.18, NNZs: 2, Bias: 47993634159.656448, T: 7296, Avg. loss: 181139871635836928000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 838449909.81, NNZs: 2, Bias: 47990762330.901489, T: 7424, Avg. loss: 178256168774099468288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 845055756.61, NNZs: 2, Bias: 47987609099.823746, T: 7552, Avg. loss: 183894554956726108160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 832169858.36, NNZs: 2, Bias: 47984843359.094727, T: 7680, Avg. loss: 181363999084103598080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 836508633.63, NNZs: 2, Bias: 47981711423.892929, T: 7808, Avg. loss: 185250286115245916160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 832613442.38, NNZs: 2, Bias: 47978805061.052315, T: 7936, Avg. loss: 179779243809335279616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 837520667.90, NNZs: 2, Bias: 47975707653.368332, T: 8064, Avg. loss: 182290716019434094592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 836127604.19, NNZs: 2, Bias: 47975132176.806053, T: 8192, Avg. loss: 176715232728166596608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 837422371.18, NNZs: 2, Bias: 47974510064.575684, T: 8320, Avg. loss: 176588862472946155520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 837256888.78, NNZs: 2, Bias: 47973912070.113129, T: 8448, Avg. loss: 177029209656921030656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 836605795.17, NNZs: 2, Bias: 47973322661.020775, T: 8576, Avg. loss: 176987006292257013760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 836609146.96, NNZs: 2, Bias: 47972723269.886810, T: 8704, Avg. loss: 176533358879045877760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 839494592.47, NNZs: 2, Bias: 47972076134.571747, T: 8832, Avg. loss: 175714334477301907456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 837004811.54, NNZs: 2, Bias: 47971518603.945847, T: 8960, Avg. loss: 177090071975820460032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 839042335.30, NNZs: 2, Bias: 47970884662.595139, T: 9088, Avg. loss: 176225050001042112512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 838566523.08, NNZs: 2, Bias: 47970293825.935013, T: 9216, Avg. loss: 176499944006879248384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 836572253.76, NNZs: 2, Bias: 47969727739.760452, T: 9344, Avg. loss: 177033317522280153088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 837280767.24, NNZs: 2, Bias: 47969114957.017715, T: 9472, Avg. loss: 176846632449281359872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 74 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1052857942828.30, NNZs: 2, Bias: 9965190058.779518, T: 128, Avg. loss: 21138198325380622108390850560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1260883825636.98, NNZs: 2, Bias: 69965190058.779510, T: 256, Avg. loss: 23757987237584308683120050176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1732140435342.15, NNZs: 2, Bias: 51665817571.960037, T: 384, Avg. loss: 23767861427808781425319084032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1445465454845.72, NNZs: 2, Bias: 11665817571.960037, T: 512, Avg. loss: 21265393412666558175997067264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1358972233280.87, NNZs: 2, Bias: -8334182428.039963, T: 640, Avg. loss: 21796798529902963030119940096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1757132331350.07, NNZs: 2, Bias: -28334182428.039963, T: 768, Avg. loss: 23266109857898528541725687808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 225595185223.25, NNZs: 2, Bias: -18182199535.593304, T: 896, Avg. loss: 1556025346873379222129213440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 364307898812.83, NNZs: 2, Bias: -42065207272.183426, T: 1024, Avg. loss: 896690921498169774484488192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 166705360248.02, NNZs: 2, Bias: -45271289012.476021, T: 1152, Avg. loss: 932878919959396129794162688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 234816358387.67, NNZs: 2, Bias: -51699112666.993637, T: 1280, Avg. loss: 905787696354796697085280256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 508814151842.29, NNZs: 2, Bias: -39369005977.931931, T: 1408, Avg. loss: 856619383965164453429772288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 222653872393.98, NNZs: 2, Bias: -32688193742.841469, T: 1536, Avg. loss: 911871815233032236927287296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 458855305318.92, NNZs: 2, Bias: -3708879458.220113, T: 1664, Avg. loss: 913879007152679644181823488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 102889729896.31, NNZs: 2, Bias: -18782276562.569801, T: 1792, Avg. loss: 890071278087927969586610176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 24100003582.05, NNZs: 2, Bias: -27813372873.349133, T: 1920, Avg. loss: 919463605361672267380031488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 370965484582.58, NNZs: 2, Bias: -29668549097.889732, T: 2048, Avg. loss: 895724313657683294833082368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 9382290208.39, NNZs: 2, Bias: -30807840122.837029, T: 2176, Avg. loss: 70873411712929137871028224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 33092977365.41, NNZs: 2, Bias: -28678032322.101509, T: 2304, Avg. loss: 32499920222609062779420672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 33041387784.01, NNZs: 2, Bias: -27588929194.820934, T: 2432, Avg. loss: 33289927185860761741164544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 66225166562.12, NNZs: 2, Bias: -28448278635.842709, T: 2560, Avg. loss: 31548872701260878768504832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 23627629597.02, NNZs: 2, Bias: -28972016796.598953, T: 2688, Avg. loss: 34030000687765497768312832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 25258290451.23, NNZs: 2, Bias: -30922282818.384327, T: 2816, Avg. loss: 31984279994594129558372352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 15853133456.05, NNZs: 2, Bias: -31243888124.191860, T: 2944, Avg. loss: 32575638147216500936671232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 86337093564.42, NNZs: 2, Bias: -30767318697.537632, T: 3072, Avg. loss: 36690988175668312599953408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 51044196779.19, NNZs: 2, Bias: -23390018862.640202, T: 3200, Avg. loss: 34058711696440540354576384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8557391787.82, NNZs: 2, Bias: -22782786095.850079, T: 3328, Avg. loss: 1289431234083884697124864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 9378118217.45, NNZs: 2, Bias: -22465796463.122227, T: 3456, Avg. loss: 730069231877272549457920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1223013521.80, NNZs: 2, Bias: -22491383279.259022, T: 3584, Avg. loss: 590471061419083832492032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2170457447.12, NNZs: 2, Bias: -22150690206.126324, T: 3712, Avg. loss: 695976889540023972528128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8013505654.16, NNZs: 2, Bias: -21741354056.591835, T: 3840, Avg. loss: 634999381741608061894656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 17975582597.61, NNZs: 2, Bias: -21522376321.318981, T: 3968, Avg. loss: 560862172518508281200640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4566916468.25, NNZs: 2, Bias: -21412914548.357059, T: 4096, Avg. loss: 723319598306734699970560.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5820318734.85, NNZs: 2, Bias: -21192530556.864323, T: 4224, Avg. loss: 596148534021433356976128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8764192643.53, NNZs: 2, Bias: -21164977968.062641, T: 4352, Avg. loss: 855022428231150595997696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11501476809.27, NNZs: 2, Bias: -20876910841.006176, T: 4480, Avg. loss: 600862719650194509529088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1859351288.66, NNZs: 2, Bias: -21088340263.345356, T: 4608, Avg. loss: 699508893159749937266688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 927969290.41, NNZs: 2, Bias: -21084205612.552937, T: 4736, Avg. loss: 580570971665857970176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 629801946.22, NNZs: 2, Bias: -21082099043.336758, T: 4864, Avg. loss: 93713022763764088832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 473646450.19, NNZs: 2, Bias: -21077009482.592106, T: 4992, Avg. loss: 66576279811097542656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 390252198.92, NNZs: 2, Bias: -21071215889.631107, T: 5120, Avg. loss: 54615295139330088960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 378946432.96, NNZs: 2, Bias: -21064217125.126759, T: 5248, Avg. loss: 48302058020767293440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 372208326.36, NNZs: 2, Bias: -21057389100.624832, T: 5376, Avg. loss: 45805585964522856448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 349720195.45, NNZs: 2, Bias: -21050345660.776592, T: 5504, Avg. loss: 51692445406636359680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 338106838.85, NNZs: 2, Bias: -21043479799.437889, T: 5632, Avg. loss: 46092554533300649984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 332738426.75, NNZs: 2, Bias: -21036978696.330204, T: 5760, Avg. loss: 44189563964734423040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 330742565.24, NNZs: 2, Bias: -21029854016.995476, T: 5888, Avg. loss: 45840699703618240512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 331940108.45, NNZs: 2, Bias: -21022661723.822517, T: 6016, Avg. loss: 48154166106374529024.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 332530830.00, NNZs: 2, Bias: -21015638240.333237, T: 6144, Avg. loss: 44875369208696987648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 349928371.88, NNZs: 2, Bias: -21008016479.091228, T: 6272, Avg. loss: 45988190115466395648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 329699006.59, NNZs: 2, Bias: -21001167958.604290, T: 6400, Avg. loss: 46969405730260533248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 320763770.58, NNZs: 2, Bias: -20999901671.957787, T: 6528, Avg. loss: 37275926973047930880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 320623851.49, NNZs: 2, Bias: -20998511386.566315, T: 6656, Avg. loss: 36838814642866929664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 321299710.22, NNZs: 2, Bias: -20997066080.424015, T: 6784, Avg. loss: 38066863199560884224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 325040768.80, NNZs: 2, Bias: -20995569134.449947, T: 6912, Avg. loss: 38206454566794518528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 323105337.88, NNZs: 2, Bias: -20994191701.160488, T: 7040, Avg. loss: 37289187775697543168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 328155977.18, NNZs: 2, Bias: -20992733930.638283, T: 7168, Avg. loss: 36456536093896896512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 328210210.28, NNZs: 2, Bias: -20991297612.861313, T: 7296, Avg. loss: 38080828563619274752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 329338539.66, NNZs: 2, Bias: -20989859790.305016, T: 7424, Avg. loss: 37659427465086296064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 322608153.89, NNZs: 2, Bias: -20988582570.945217, T: 7552, Avg. loss: 36639181257458003968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 326423987.82, NNZs: 2, Bias: -20987097964.694805, T: 7680, Avg. loss: 37733595820250095616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 324257059.68, NNZs: 2, Bias: -20985710484.141342, T: 7808, Avg. loss: 37687086651811536896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 327536641.93, NNZs: 2, Bias: -20985376519.216679, T: 7936, Avg. loss: 36453433550824370176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 327049159.02, NNZs: 2, Bias: -20985101535.055870, T: 8064, Avg. loss: 36425991314945081344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 328697025.72, NNZs: 2, Bias: -20984795398.363464, T: 8192, Avg. loss: 36121765554592653312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 327347127.57, NNZs: 2, Bias: -20984533535.648167, T: 8320, Avg. loss: 36482700120904310784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 327083191.80, NNZs: 2, Bias: -20984255142.138027, T: 8448, Avg. loss: 36413419374992416768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 327905281.60, NNZs: 2, Bias: -20983961169.975815, T: 8576, Avg. loss: 36227666032212320256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 326457579.58, NNZs: 2, Bias: -20983701935.068214, T: 8704, Avg. loss: 36330046067102277632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 326831964.01, NNZs: 2, Bias: -20983413999.048759, T: 8832, Avg. loss: 36354033862206943232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 69 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1580338238747.49, NNZs: 2, Bias: 12036687836.695190, T: 128, Avg. loss: 24199902678809274189220937728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 650289310994.23, NNZs: 2, Bias: -27963312163.304810, T: 256, Avg. loss: 23618942375516561133075955712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1158959328283.86, NNZs: 2, Bias: -145471386259.669922, T: 384, Avg. loss: 23794324169835297310907564032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2143028552369.08, NNZs: 2, Bias: -66514252622.498474, T: 512, Avg. loss: 24894018509384021291749605376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 683849618173.79, NNZs: 2, Bias: -85397338025.204269, T: 640, Avg. loss: 25700876741168679582638800896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1913680841436.76, NNZs: 2, Bias: -85397338025.204269, T: 768, Avg. loss: 21510147631824286454684581888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 599456983367.67, NNZs: 2, Bias: -122688843080.014343, T: 896, Avg. loss: 25981298553238041010313887744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 450002108562.52, NNZs: 2, Bias: -90680994108.065796, T: 1024, Avg. loss: 25217700475866534165677604864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 505570065615.29, NNZs: 2, Bias: -150680994108.065796, T: 1152, Avg. loss: 23024334498433861361176936448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 443303658316.47, NNZs: 2, Bias: -90680994108.065796, T: 1280, Avg. loss: 22130878596704645344313475072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1415799249582.49, NNZs: 2, Bias: -138030869117.729156, T: 1408, Avg. loss: 24292360595330673103343714304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 173600980107.77, NNZs: 2, Bias: -120611144395.584610, T: 1536, Avg. loss: 1659592748483362412969328640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 201272254086.34, NNZs: 2, Bias: -107748993151.427338, T: 1664, Avg. loss: 910001923009677125264343040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 501854857936.63, NNZs: 2, Bias: -116304643086.752472, T: 1792, Avg. loss: 864178581603882919903887360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 362033517305.21, NNZs: 2, Bias: -121164016021.477097, T: 1920, Avg. loss: 956552599654304346162593792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 555482778366.87, NNZs: 2, Bias: -118472257388.007919, T: 2048, Avg. loss: 957749916815638538208935936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 372139197473.79, NNZs: 2, Bias: -118266728896.304718, T: 2176, Avg. loss: 985264307641077196132450304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 132988646645.41, NNZs: 2, Bias: -118891257036.941559, T: 2304, Avg. loss: 986770618113980908080988160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 325725597704.73, NNZs: 2, Bias: -114397564694.541153, T: 2432, Avg. loss: 901984824617890994047680512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 48689683688.06, NNZs: 2, Bias: -116269949149.104401, T: 2560, Avg. loss: 63695999789876353408434176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 54900675125.22, NNZs: 2, Bias: -116118261953.745667, T: 2688, Avg. loss: 33937549260206047101976576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 50120519100.13, NNZs: 2, Bias: -115199782836.010452, T: 2816, Avg. loss: 32859092311848138064265216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 91672902900.65, NNZs: 2, Bias: -114447399073.891922, T: 2944, Avg. loss: 33043746356087973490982912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 35626699472.37, NNZs: 2, Bias: -116122233852.820190, T: 3072, Avg. loss: 33415703741962771603914752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 48435093306.20, NNZs: 2, Bias: -119207036662.459793, T: 3200, Avg. loss: 35240159430055742408753152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 32503840593.55, NNZs: 2, Bias: -118163118684.647079, T: 3328, Avg. loss: 36084602628670553772261376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 54819013230.94, NNZs: 2, Bias: -117914995955.625992, T: 3456, Avg. loss: 33397901369399802865909760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 5496955208.85, NNZs: 2, Bias: -117571551689.532166, T: 3584, Avg. loss: 1013580586174155621138432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 5212583072.34, NNZs: 2, Bias: -117428628515.539230, T: 3712, Avg. loss: 727236993255792304979968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3494456626.86, NNZs: 2, Bias: -117454298762.006989, T: 3840, Avg. loss: 835923069027119179759616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4825414986.18, NNZs: 2, Bias: -117445951581.164810, T: 3968, Avg. loss: 659209132854884972888064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4899141533.49, NNZs: 2, Bias: -117229218400.166168, T: 4096, Avg. loss: 575864283331846381502464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2267740241.90, NNZs: 2, Bias: -117157743194.882538, T: 4224, Avg. loss: 723031248594141427269632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7954849621.61, NNZs: 2, Bias: -117319647978.577820, T: 4352, Avg. loss: 688527734067110910885888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 8357497297.29, NNZs: 2, Bias: -116983730590.141953, T: 4480, Avg. loss: 644810123639906099003392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 8323194279.59, NNZs: 2, Bias: -116516072767.238632, T: 4608, Avg. loss: 694178594416004930994176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4801081842.47, NNZs: 2, Bias: -116101123496.732269, T: 4736, Avg. loss: 785149541295609759137792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 610283996.11, NNZs: 2, Bias: -116071695054.851257, T: 4864, Avg. loss: 4536085998800330555392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1042906005.35, NNZs: 2, Bias: -116027370626.599884, T: 4992, Avg. loss: 1376172232334080737280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1386722969.98, NNZs: 2, Bias: -115988497984.886154, T: 5120, Avg. loss: 1190989224538449379328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1561369103.92, NNZs: 2, Bias: -115952339274.646835, T: 5248, Avg. loss: 1159961228961997258752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1579614013.75, NNZs: 2, Bias: -115917499064.287689, T: 5376, Avg. loss: 1190439489939236454400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1604790361.69, NNZs: 2, Bias: -115881957879.887207, T: 5504, Avg. loss: 1232574275703834148864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1704279436.53, NNZs: 2, Bias: -115848518624.880920, T: 5632, Avg. loss: 1120695987379882688512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1701193726.45, NNZs: 2, Bias: -115816047195.674652, T: 5760, Avg. loss: 1155736984685538967552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1796427267.62, NNZs: 2, Bias: -115781345306.613647, T: 5888, Avg. loss: 1142359980128409354240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1724010400.63, NNZs: 2, Bias: -115748514980.136475, T: 6016, Avg. loss: 1212849033717441626112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1632820073.09, NNZs: 2, Bias: -115716774354.249130, T: 6144, Avg. loss: 1159331131545683886080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1714840545.89, NNZs: 2, Bias: -115681552661.594498, T: 6272, Avg. loss: 1192094297075126108160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1704315183.72, NNZs: 2, Bias: -115675070068.773239, T: 6400, Avg. loss: 966408438848468680704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1696968237.28, NNZs: 2, Bias: -115668416234.453125, T: 6528, Avg. loss: 985306711716305698816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1691190097.81, NNZs: 2, Bias: -115661859490.932083, T: 6656, Avg. loss: 966442428189451223040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1702345567.32, NNZs: 2, Bias: -115655017395.786957, T: 6784, Avg. loss: 971821546404164009984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1699356021.23, NNZs: 2, Bias: -115648335208.660995, T: 6912, Avg. loss: 981710486286443872256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1700476684.86, NNZs: 2, Bias: -115641633616.200638, T: 7040, Avg. loss: 973374647286585229312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1697820770.31, NNZs: 2, Bias: -115640325488.745514, T: 7168, Avg. loss: 956597690172039888896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1695954635.47, NNZs: 2, Bias: -115639007362.347733, T: 7296, Avg. loss: 955317818632375107584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1698858118.34, NNZs: 2, Bias: -115637628307.159378, T: 7424, Avg. loss: 948655632705097433088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1696821816.56, NNZs: 2, Bias: -115636312898.442581, T: 7552, Avg. loss: 955187647496744599552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1703186955.47, NNZs: 2, Bias: -115634878737.363083, T: 7680, Avg. loss: 951517849160666841088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1702353573.77, NNZs: 2, Bias: -115633546816.946777, T: 7808, Avg. loss: 954350927066655490048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1701423386.84, NNZs: 2, Bias: -115632217116.050720, T: 7936, Avg. loss: 953765269182015733760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1702491634.70, NNZs: 2, Bias: -115630857071.838760, T: 8064, Avg. loss: 954368794667813044224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 63 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 447642088723.91, NNZs: 2, Bias: -15881386595.043945, T: 128, Avg. loss: 18792441870708136229979815936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 674298917601.08, NNZs: 2, Bias: -49755955704.675903, T: 256, Avg. loss: 18922048626959068227734339584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1182650909369.44, NNZs: 2, Bias: -61852912402.547226, T: 384, Avg. loss: 21333741053578542091276910592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1115719773069.02, NNZs: 2, Bias: -61852912402.547226, T: 512, Avg. loss: 22369003245499267331674603520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 680972342541.46, NNZs: 2, Bias: -21768643.869156, T: 640, Avg. loss: 21337180548809392828264218624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 658057636871.69, NNZs: 2, Bias: 39978231356.130844, T: 768, Avg. loss: 20141721561109733881996640256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 434295898622.34, NNZs: 2, Bias: 30361009918.027779, T: 896, Avg. loss: 863812004542812679277903872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 227826006669.71, NNZs: 2, Bias: 39116539131.046478, T: 1024, Avg. loss: 912569696402758494559666176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 323072121838.99, NNZs: 2, Bias: 67670482361.329781, T: 1152, Avg. loss: 851403034746938072152145920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 193333160427.52, NNZs: 2, Bias: 48520704228.506866, T: 1280, Avg. loss: 879113509634570530687287296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 94777948034.65, NNZs: 2, Bias: 46352755591.125404, T: 1408, Avg. loss: 860221530736051246143111168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 142829617587.66, NNZs: 2, Bias: 55463821753.753250, T: 1536, Avg. loss: 856266073299025491275022336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 281621201286.18, NNZs: 2, Bias: 63334024421.784203, T: 1664, Avg. loss: 955241012083866305831108608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 465057293656.39, NNZs: 2, Bias: 60451349089.774788, T: 1792, Avg. loss: 834581755878113075485736960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 303807790695.29, NNZs: 2, Bias: 32998901793.391624, T: 1920, Avg. loss: 920525137465938493183098880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 366313533463.22, NNZs: 2, Bias: 37174469116.857224, T: 2048, Avg. loss: 839278114917435616280969216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 427970417659.65, NNZs: 2, Bias: 47880556269.468590, T: 2176, Avg. loss: 813831293790116801494908928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 195561670687.93, NNZs: 2, Bias: 30709575773.417015, T: 2304, Avg. loss: 959225199950434902466363392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 120541202019.76, NNZs: 2, Bias: 22203391717.975296, T: 2432, Avg. loss: 846596533144957277119184896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 124618480905.20, NNZs: 2, Bias: 26203391717.975296, T: 2560, Avg. loss: 860118184977544049359585280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 134084977201.83, NNZs: 2, Bias: 4194000312.796333, T: 2688, Avg. loss: 871033795522204761325568000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 190253854638.82, NNZs: 2, Bias: 16909445874.027424, T: 2816, Avg. loss: 789090224101071764825571328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 100554406467.25, NNZs: 2, Bias: 1281637276.180765, T: 2944, Avg. loss: 920866597427815116533923840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 549838700690.49, NNZs: 2, Bias: -14360548884.295927, T: 3072, Avg. loss: 873874585455691023872163840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 258438280447.25, NNZs: 2, Bias: -4398051955.014139, T: 3200, Avg. loss: 789855324101917737433956352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 371956149863.08, NNZs: 2, Bias: -12468335223.046841, T: 3328, Avg. loss: 877169111155309770805608448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 149118979367.13, NNZs: 2, Bias: 1312383781.789371, T: 3456, Avg. loss: 917821691351725448242397184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 82424342379.84, NNZs: 2, Bias: 4393807075.301734, T: 3584, Avg. loss: 35738191843372342366437376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 56779256713.74, NNZs: 2, Bias: 2112655054.617356, T: 3712, Avg. loss: 35325257520358452019331072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 13133795186.55, NNZs: 2, Bias: 941772469.389692, T: 3840, Avg. loss: 32369914435813854880464896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 59718037009.74, NNZs: 2, Bias: 657581077.449856, T: 3968, Avg. loss: 32917740556999536343515136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 53078886847.27, NNZs: 2, Bias: 3548193342.568334, T: 4096, Avg. loss: 29881590329846147527475200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 32392002619.92, NNZs: 2, Bias: 4301045951.178425, T: 4224, Avg. loss: 32397682941817568563822592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 14653782432.44, NNZs: 2, Bias: 1179428910.414247, T: 4352, Avg. loss: 33081590685280629384282112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 21460971285.15, NNZs: 2, Bias: 4055250740.059079, T: 4480, Avg. loss: 32929091820208734085316608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 97410477893.51, NNZs: 2, Bias: 4632153194.137648, T: 4608, Avg. loss: 33784477205653396004012032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 79933948635.81, NNZs: 2, Bias: 1167430909.882580, T: 4736, Avg. loss: 33116727220240219247738880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6346209060.91, NNZs: 2, Bias: 1427879437.689340, T: 4864, Avg. loss: 2728870285805011494502400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 207414035.24, NNZs: 2, Bias: 1196704227.711298, T: 4992, Avg. loss: 524954267218888492056576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 17009645238.42, NNZs: 2, Bias: 1241630709.577170, T: 5120, Avg. loss: 458687566102401709506560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2912783245.98, NNZs: 2, Bias: 933475226.816783, T: 5248, Avg. loss: 815317695581252334125056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 8360014144.75, NNZs: 2, Bias: 842271858.386892, T: 5376, Avg. loss: 492326767039957430173696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 5799881654.79, NNZs: 2, Bias: 818856914.759052, T: 5504, Avg. loss: 591483230562482282037248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 6526632431.59, NNZs: 2, Bias: 953244905.520848, T: 5632, Avg. loss: 590943375374869025783808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 803405189.17, NNZs: 2, Bias: 997696845.708164, T: 5760, Avg. loss: 429322107075450548256768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4443980043.52, NNZs: 2, Bias: 931348885.454751, T: 5888, Avg. loss: 650276493923198852661248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 14750722529.05, NNZs: 2, Bias: 620052893.905113, T: 6016, Avg. loss: 370820418552552312799232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4538961888.76, NNZs: 2, Bias: 778606901.566266, T: 6144, Avg. loss: 572106841376133019074560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 11025893120.28, NNZs: 2, Bias: 781085895.646086, T: 6272, Avg. loss: 454022176625999891922944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4291255112.79, NNZs: 2, Bias: 941006405.744569, T: 6400, Avg. loss: 356800944656925868425216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 248042259.42, NNZs: 2, Bias: 886655287.065278, T: 6528, Avg. loss: 511988623578967524245504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 5553635680.50, NNZs: 2, Bias: 730903759.166742, T: 6656, Avg. loss: 402161513911445631270912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9725495465.67, NNZs: 2, Bias: 1311186634.662860, T: 6784, Avg. loss: 611992322449747818315776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 11971453136.32, NNZs: 2, Bias: 1111115117.193101, T: 6912, Avg. loss: 478174488652265155461120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 5239217519.07, NNZs: 2, Bias: 897571899.350157, T: 7040, Avg. loss: 525571887097487470624768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1429121163.37, NNZs: 2, Bias: 945650033.579050, T: 7168, Avg. loss: 4312423391151051505664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 754243014.33, NNZs: 2, Bias: 955263650.514822, T: 7296, Avg. loss: 240605008184621039616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 380711353.63, NNZs: 2, Bias: 960262695.874429, T: 7424, Avg. loss: 68063448492083257344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 187349762.65, NNZs: 2, Bias: 962738335.769233, T: 7552, Avg. loss: 17385367005382561792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 103716108.15, NNZs: 2, Bias: 963620447.112266, T: 7680, Avg. loss: 3805174373581575168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 61502853.78, NNZs: 2, Bias: 963969192.692613, T: 7808, Avg. loss: 1044015791225705088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 39675170.31, NNZs: 2, Bias: 963982176.092836, T: 7936, Avg. loss: 370189939898390656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 31002407.61, NNZs: 2, Bias: 963804525.924910, T: 8064, Avg. loss: 159858884785332800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 25742834.23, NNZs: 2, Bias: 963575367.230215, T: 8192, Avg. loss: 123191003105379200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 23120834.44, NNZs: 2, Bias: 963283532.845541, T: 8320, Avg. loss: 111988315992780576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 21083923.51, NNZs: 2, Bias: 962989714.765268, T: 8448, Avg. loss: 101333973191803664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 21093294.51, NNZs: 2, Bias: 962642565.601906, T: 8576, Avg. loss: 99807232129027040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 21355457.87, NNZs: 2, Bias: 962293256.043442, T: 8704, Avg. loss: 103742917464514400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 21433919.92, NNZs: 2, Bias: 961942434.926704, T: 8832, Avg. loss: 102927916069595392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 20968658.76, NNZs: 2, Bias: 961619841.282843, T: 8960, Avg. loss: 99518222220210976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 21237871.62, NNZs: 2, Bias: 961274015.565410, T: 9088, Avg. loss: 100188742805863696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 21027829.96, NNZs: 2, Bias: 960935623.190038, T: 9216, Avg. loss: 100253466456028960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 21289012.64, NNZs: 2, Bias: 960587853.407012, T: 9344, Avg. loss: 98353784695613280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 20886833.51, NNZs: 2, Bias: 960256871.910933, T: 9472, Avg. loss: 99197642579622560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 21622171.41, NNZs: 2, Bias: 959905218.701200, T: 9600, Avg. loss: 97781964952785296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 20460535.58, NNZs: 2, Bias: 959570314.097756, T: 9728, Avg. loss: 109494293653781376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 21665997.57, NNZs: 2, Bias: 959237792.764697, T: 9856, Avg. loss: 86612518060469472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 20351209.43, NNZs: 2, Bias: 958931024.115336, T: 9984, Avg. loss: 102326056794427024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 21097578.68, NNZs: 2, Bias: 958552507.489576, T: 10112, Avg. loss: 105040857248984224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 21242915.77, NNZs: 2, Bias: 958204935.287516, T: 10240, Avg. loss: 99916372028986784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 20901267.85, NNZs: 2, Bias: 957857166.305774, T: 10368, Avg. loss: 105846836544848560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 20709173.05, NNZs: 2, Bias: 957505794.085347, T: 10496, Avg. loss: 106188389991859248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 20618271.93, NNZs: 2, Bias: 957439363.638318, T: 10624, Avg. loss: 82415233559928672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 20612641.71, NNZs: 2, Bias: 957372704.102473, T: 10752, Avg. loss: 80377722824298176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 20788009.51, NNZs: 2, Bias: 957302256.368644, T: 10880, Avg. loss: 80098333588223200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 20713331.57, NNZs: 2, Bias: 957236430.464515, T: 11008, Avg. loss: 81532881284552096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 20722139.64, NNZs: 2, Bias: 957168387.936393, T: 11136, Avg. loss: 81667582585495760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 20782146.07, NNZs: 2, Bias: 957099550.041461, T: 11264, Avg. loss: 81386996000055568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 20834704.76, NNZs: 2, Bias: 957030839.931364, T: 11392, Avg. loss: 81354538191660640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 20855529.71, NNZs: 2, Bias: 956963678.271529, T: 11520, Avg. loss: 80346243363017120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 20837413.90, NNZs: 2, Bias: 956950603.575589, T: 11648, Avg. loss: 79125536099839696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 20804310.26, NNZs: 2, Bias: 956937905.692579, T: 11776, Avg. loss: 78831856826690448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 20856344.04, NNZs: 2, Bias: 956923334.319012, T: 11904, Avg. loss: 78905864582127920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 20832165.83, NNZs: 2, Bias: 956910455.499139, T: 12032, Avg. loss: 78753274670860288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 20826128.92, NNZs: 2, Bias: 956897150.672328, T: 12160, Avg. loss: 78920158892644656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 20835445.35, NNZs: 2, Bias: 956883491.285761, T: 12288, Avg. loss: 79034570412578784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 20807699.78, NNZs: 2, Bias: 956870692.399233, T: 12416, Avg. loss: 78725670349746848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 20859132.16, NNZs: 2, Bias: 956856176.282898, T: 12544, Avg. loss: 78649415012139200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 20848318.62, NNZs: 2, Bias: 956842973.915150, T: 12672, Avg. loss: 78930397549952592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 20837146.01, NNZs: 2, Bias: 956829783.629043, T: 12800, Avg. loss: 78900969683481552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epsoft/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Norm: 2018390529715.24, NNZs: 2, Bias: 36071507803.255814, T: 128, Avg. loss: 19454348551668811376806068224.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 878677274912.91, NNZs: 2, Bias: 2554038961.882656, T: 256, Avg. loss: 22710010111748180379221098496.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1055585191328.91, NNZs: 2, Bias: -4786310302.795456, T: 384, Avg. loss: 21752491506211831210924048384.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456422258998.38, NNZs: 2, Bias: -643019863.182304, T: 512, Avg. loss: 20175683676262941049697075200.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 861696309941.62, NNZs: 2, Bias: -2083373874.145256, T: 640, Avg. loss: 18488843835371544966527451136.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1159222371946.04, NNZs: 2, Bias: 21624940235.321419, T: 768, Avg. loss: 18689721222071936743148355584.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 290458979265.80, NNZs: 2, Bias: -73462978227.625565, T: 896, Avg. loss: 20540584525112167967716540416.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 671609290332.33, NNZs: 2, Bias: -113462978227.625549, T: 1024, Avg. loss: 22417454032021506804236156928.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 858280726322.87, NNZs: 2, Bias: -257295983688.989746, T: 1152, Avg. loss: 18958304719102567854991474688.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 410571001035.02, NNZs: 2, Bias: -356511717255.679504, T: 1280, Avg. loss: 18868348281517526741917106176.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 366470143436.66, NNZs: 2, Bias: -363420850711.996399, T: 1408, Avg. loss: 801381050957039007954894848.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 208343629087.94, NNZs: 2, Bias: -369508172812.419739, T: 1536, Avg. loss: 736616505941528214625058816.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 179688085827.58, NNZs: 2, Bias: -370574949241.004761, T: 1664, Avg. loss: 844720006056446561074806784.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 307397402799.68, NNZs: 2, Bias: -349764535761.952881, T: 1792, Avg. loss: 809132431789066240263192576.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 410489046857.53, NNZs: 2, Bias: -352935750678.027344, T: 1920, Avg. loss: 730292530741744014901379072.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 66761747925.41, NNZs: 2, Bias: -350066098372.039978, T: 2048, Avg. loss: 748411517228798268449751040.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 116175538101.57, NNZs: 2, Bias: -343997217103.470093, T: 2176, Avg. loss: 777961327604904425812918272.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 40694077441.08, NNZs: 2, Bias: -319554029671.960632, T: 2304, Avg. loss: 748965358757247888568352768.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 353678998213.70, NNZs: 2, Bias: -330867865196.713196, T: 2432, Avg. loss: 696390275624313166130839552.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 252791941218.40, NNZs: 2, Bias: -338175634328.498474, T: 2560, Avg. loss: 860288384991268838068715520.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 221783360053.18, NNZs: 2, Bias: -346870569412.705994, T: 2688, Avg. loss: 779902578086015038337843200.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 156291049913.69, NNZs: 2, Bias: -326304537041.156555, T: 2816, Avg. loss: 882348304622201646759280640.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 248970138214.08, NNZs: 2, Bias: -322515012635.537781, T: 2944, Avg. loss: 707604519719799593898082304.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 141526304088.74, NNZs: 2, Bias: -327861080588.446838, T: 3072, Avg. loss: 826381056757383318667788288.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 60535480433.65, NNZs: 2, Bias: -331504098272.843079, T: 3200, Avg. loss: 29311818665976909260652544.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 16909833618.13, NNZs: 2, Bias: -328434655266.658142, T: 3328, Avg. loss: 29210699977360761082085376.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 93315137831.53, NNZs: 2, Bias: -327220441974.386597, T: 3456, Avg. loss: 27339043466334561443512320.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 71973340391.67, NNZs: 2, Bias: -326436033317.726990, T: 3584, Avg. loss: 31141028868141969655726080.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 78260085715.58, NNZs: 2, Bias: -322090004935.174133, T: 3712, Avg. loss: 30350236270688129622474752.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 64201861488.67, NNZs: 2, Bias: -321200502724.899963, T: 3840, Avg. loss: 30398163757791262657216512.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 54963093082.52, NNZs: 2, Bias: -320785646657.888794, T: 3968, Avg. loss: 31754634793177042128994304.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 49891352947.36, NNZs: 2, Bias: -321922782482.651123, T: 4096, Avg. loss: 27901992405513283661987840.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 13779072299.46, NNZs: 2, Bias: -321797757529.299561, T: 4224, Avg. loss: 861783878277658163806208.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8783505453.28, NNZs: 2, Bias: -321424346085.268188, T: 4352, Avg. loss: 637401164324863156944896.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4126221091.07, NNZs: 2, Bias: -320739551510.809875, T: 4480, Avg. loss: 610871076623566547976192.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 10974275333.65, NNZs: 2, Bias: -319775562994.437378, T: 4608, Avg. loss: 683155710594520564367360.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8244587637.44, NNZs: 2, Bias: -319078415095.960083, T: 4736, Avg. loss: 582480104491933207887872.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8824624277.46, NNZs: 2, Bias: -318600426267.194031, T: 4864, Avg. loss: 595241284560970993106944.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 5404926378.97, NNZs: 2, Bias: -318386248828.745911, T: 4992, Avg. loss: 607649823895507995459584.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9697922005.65, NNZs: 2, Bias: -317708886376.434326, T: 5120, Avg. loss: 649725920063480502681600.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 15272945310.61, NNZs: 2, Bias: -317273030308.346313, T: 5248, Avg. loss: 503798304132107727798272.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 13673973694.07, NNZs: 2, Bias: -316971048147.069763, T: 5376, Avg. loss: 601402524269438885167104.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 8687053598.15, NNZs: 2, Bias: -316333208881.877563, T: 5504, Avg. loss: 816739117047926291955712.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4153263178.19, NNZs: 2, Bias: -315665536020.008179, T: 5632, Avg. loss: 636891859560369137647616.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 13699624211.03, NNZs: 2, Bias: -314908084046.529846, T: 5760, Avg. loss: 719758372615407511011328.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 7273722171.72, NNZs: 2, Bias: -314454578282.377014, T: 5888, Avg. loss: 621579310940798867996672.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3353318666.21, NNZs: 2, Bias: -314348987272.477478, T: 6016, Avg. loss: 17766756897827768500224.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4186063268.82, NNZs: 2, Bias: -314239445744.508545, T: 6144, Avg. loss: 9557184541213901979648.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4361870539.23, NNZs: 2, Bias: -314130527053.457825, T: 6272, Avg. loss: 10388935035026134794240.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4751388835.28, NNZs: 2, Bias: -314018175177.388489, T: 6400, Avg. loss: 10284960344412568682496.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4841339007.44, NNZs: 2, Bias: -313915016012.415588, T: 6528, Avg. loss: 9830912815070602854400.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4896639482.84, NNZs: 2, Bias: -313803438407.744873, T: 6656, Avg. loss: 10753187056741972443136.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4586144125.07, NNZs: 2, Bias: -313703008495.987427, T: 6784, Avg. loss: 10458595363876946051072.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4805682576.70, NNZs: 2, Bias: -313676546988.101074, T: 6912, Avg. loss: 9167579920938634838016.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4911827675.17, NNZs: 2, Bias: -313653732748.961975, T: 7040, Avg. loss: 8376775340238546403328.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4907543943.04, NNZs: 2, Bias: -313632596994.653137, T: 7168, Avg. loss: 8400628198569780707328.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 5022777136.44, NNZs: 2, Bias: -313609733855.859863, T: 7296, Avg. loss: 8329716795470072774656.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 5016839053.20, NNZs: 2, Bias: -313588678769.849792, T: 7424, Avg. loss: 8378847639294449811456.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 5047171674.21, NNZs: 2, Bias: -313567405319.419617, T: 7552, Avg. loss: 8211800106444817170432.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 5009459305.91, NNZs: 2, Bias: -313547052051.917725, T: 7680, Avg. loss: 8329682362358528212992.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 5003343913.26, NNZs: 2, Bias: -313525850276.196411, T: 7808, Avg. loss: 8444277722451072253952.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 5037628413.68, NNZs: 2, Bias: -313504288937.206787, T: 7936, Avg. loss: 8307281911774197055488.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4917341002.92, NNZs: 2, Bias: -313485200853.237732, T: 8064, Avg. loss: 8327673098372701487104.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4945401857.15, NNZs: 2, Bias: -313463389401.961731, T: 8192, Avg. loss: 8463846585383423836160.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4980300554.80, NNZs: 2, Bias: -313458593787.423706, T: 8320, Avg. loss: 8166391164471812816896.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4985892139.51, NNZs: 2, Bias: -313454276625.701355, T: 8448, Avg. loss: 8140471521786644660224.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4982646284.00, NNZs: 2, Bias: -313450099678.554565, T: 8576, Avg. loss: 8143323417243952349184.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4988524087.31, NNZs: 2, Bias: -313445789147.297852, T: 8704, Avg. loss: 8118202862770662146048.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4980383170.59, NNZs: 2, Bias: -313441699948.074707, T: 8832, Avg. loss: 8125346470345846030336.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4990667272.55, NNZs: 2, Bias: -313437317823.497864, T: 8960, Avg. loss: 8120948963571035799552.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4991741783.16, NNZs: 2, Bias: -313433075303.398743, T: 9088, Avg. loss: 8135090291129879363584.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 5005639512.40, NNZs: 2, Bias: -313428637884.580627, T: 9216, Avg. loss: 8114302592028710535168.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 5002504447.78, NNZs: 2, Bias: -313424470412.863403, T: 9344, Avg. loss: 8119886393743751774208.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 4993074148.85, NNZs: 2, Bias: -313420394557.325806, T: 9472, Avg. loss: 8137787528680210169856.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 4991702728.56, NNZs: 2, Bias: -313416192462.195862, T: 9600, Avg. loss: 8132409928301481558016.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 5006718515.32, NNZs: 2, Bias: -313411737585.919373, T: 9728, Avg. loss: 8113017285814513565696.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 4975766437.59, NNZs: 2, Bias: -313408073095.917725, T: 9856, Avg. loss: 8007656785083572944896.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 4993533546.40, NNZs: 2, Bias: -313403555106.298462, T: 9984, Avg. loss: 8150470076564280180736.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 4999518715.15, NNZs: 2, Bias: -313399233819.665283, T: 10112, Avg. loss: 8134590917193769156608.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 5008973341.53, NNZs: 2, Bias: -313394862651.416016, T: 10240, Avg. loss: 8123273604347060027392.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 5008339611.17, NNZs: 2, Bias: -313390648922.396790, T: 10368, Avg. loss: 8130727621558160850944.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 5009175220.22, NNZs: 2, Bias: -313386415127.229004, T: 10496, Avg. loss: 8125411336604500361216.000000\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 82 epochs took 0.03 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1710298640563.38, NNZs: 2, Bias: 10090145525.208008, T: 128, Avg. loss: 21496735011858808494979284992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1134981985226.38, NNZs: 2, Bias: 52725098232.323181, T: 256, Avg. loss: 21863195044745830991786934272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1912615155694.82, NNZs: 2, Bias: 72725098232.323181, T: 384, Avg. loss: 21709316319770619961665388544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 495202385386.90, NNZs: 2, Bias: 32725098232.323181, T: 512, Avg. loss: 23411006690317339024315908096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2270032750651.77, NNZs: 2, Bias: 72725098232.323181, T: 640, Avg. loss: 20162336093410652088086560768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1520998970856.81, NNZs: 2, Bias: 111590321103.680542, T: 768, Avg. loss: 19260763993538007018665672704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2062448864152.61, NNZs: 2, Bias: 191590321103.680542, T: 896, Avg. loss: 19847132456931285498933018624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1381208777772.63, NNZs: 2, Bias: 251590321103.680542, T: 1024, Avg. loss: 19959629198219281295606808576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 436697489284.58, NNZs: 2, Bias: 291590321103.680542, T: 1152, Avg. loss: 20140017043429692412295905280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 268261528754.45, NNZs: 2, Bias: 293394010723.685669, T: 1280, Avg. loss: 20741536425397984588220858368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1800702129224.05, NNZs: 2, Bias: 348649640837.262146, T: 1408, Avg. loss: 19055384499996502162824757248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1262245609989.87, NNZs: 2, Bias: 333012954390.783081, T: 1536, Avg. loss: 21974224818020859620003676160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1805851304574.71, NNZs: 2, Bias: 314193667939.817688, T: 1664, Avg. loss: 19563471066469018142297292800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 3334263242995.97, NNZs: 2, Bias: 294193667939.817688, T: 1792, Avg. loss: 19642618111500372331515084800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1880608416154.11, NNZs: 2, Bias: 374193667939.817688, T: 1920, Avg. loss: 19449173541453361986878308352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 366402824955.20, NNZs: 2, Bias: 367965687741.118958, T: 2048, Avg. loss: 19995733322784213865366290432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 542772641320.38, NNZs: 2, Bias: 347779726758.024048, T: 2176, Avg. loss: 765107954349715564785565696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 250660670516.14, NNZs: 2, Bias: 340658729727.631409, T: 2304, Avg. loss: 862459175420286010296107008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 281414504670.94, NNZs: 2, Bias: 330666906423.339417, T: 2432, Avg. loss: 872367714768524373634580480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 125154724606.23, NNZs: 2, Bias: 314764384657.080627, T: 2560, Avg. loss: 829151246749110485345370112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 37327088045.06, NNZs: 2, Bias: 305671280566.187012, T: 2688, Avg. loss: 816074812035604546668462080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 111227211111.32, NNZs: 2, Bias: 312933222175.277832, T: 2816, Avg. loss: 887916115850608525050904576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 19731263666.35, NNZs: 2, Bias: 307696184782.648010, T: 2944, Avg. loss: 35671133195322105324896256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 65724892716.45, NNZs: 2, Bias: 306587898080.060913, T: 3072, Avg. loss: 28633515882628763755741184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 9150257697.51, NNZs: 2, Bias: 305157758201.671326, T: 3200, Avg. loss: 31387650209269747218907136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 49246240245.45, NNZs: 2, Bias: 310590531580.701843, T: 3328, Avg. loss: 30078293788684138978476032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 21706876419.66, NNZs: 2, Bias: 309848036669.889465, T: 3456, Avg. loss: 30465063033629626404438016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 49629353794.55, NNZs: 2, Bias: 306264088820.863586, T: 3584, Avg. loss: 33128601911195685535875072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 33202315952.64, NNZs: 2, Bias: 305092627900.148254, T: 3712, Avg. loss: 29324564782039869675274240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5989340800.08, NNZs: 2, Bias: 304662905624.607422, T: 3840, Avg. loss: 817968858291080938913792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 9272461409.06, NNZs: 2, Bias: 304572575263.265076, T: 3968, Avg. loss: 620902296757405212475392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 17528704215.81, NNZs: 2, Bias: 304132624542.503296, T: 4096, Avg. loss: 582941260165656352915456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 11332586579.41, NNZs: 2, Bias: 303817718099.788513, T: 4224, Avg. loss: 602258223503288496553984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6112022164.80, NNZs: 2, Bias: 303210336047.845337, T: 4352, Avg. loss: 615353122555379102777344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1170710414.14, NNZs: 2, Bias: 303001061300.615479, T: 4480, Avg. loss: 694604317321839222194176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 15664883376.54, NNZs: 2, Bias: 302588248406.214661, T: 4608, Avg. loss: 651296120213726539284480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 12410498587.53, NNZs: 2, Bias: 302219117242.139465, T: 4736, Avg. loss: 645747438873941597224960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3682832381.29, NNZs: 2, Bias: 302018127394.998047, T: 4864, Avg. loss: 69193894171842015395840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4494075008.95, NNZs: 2, Bias: 301907269649.397461, T: 4992, Avg. loss: 8978061410942400331776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4892081810.71, NNZs: 2, Bias: 301805610406.146973, T: 5120, Avg. loss: 8816942928030755454976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4975274221.81, NNZs: 2, Bias: 301706259671.066833, T: 5248, Avg. loss: 8865321267015003930624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 5310895799.85, NNZs: 2, Bias: 301602881563.921997, T: 5376, Avg. loss: 9261592697085803626496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 5291617620.33, NNZs: 2, Bias: 301511276931.027466, T: 5504, Avg. loss: 8446540961853958258688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5226247073.69, NNZs: 2, Bias: 301422542377.195862, T: 5632, Avg. loss: 8557465843433131212800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 5208702802.90, NNZs: 2, Bias: 301330706746.277527, T: 5760, Avg. loss: 8595883342885689491456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 5058233647.96, NNZs: 2, Bias: 301241190085.369873, T: 5888, Avg. loss: 8468396121211386462208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 5328592833.32, NNZs: 2, Bias: 301137811134.554749, T: 6016, Avg. loss: 8865062187898429767680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 5144923991.82, NNZs: 2, Bias: 301046267207.593933, T: 6144, Avg. loss: 8787390738969840844800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 5178448354.63, NNZs: 2, Bias: 301026605481.778992, T: 6272, Avg. loss: 7244795611338780966912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 5269763661.77, NNZs: 2, Bias: 301006067991.180786, T: 6400, Avg. loss: 7186268845178752073728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 5233081322.74, NNZs: 2, Bias: 300987613183.186218, T: 6528, Avg. loss: 7257494945825086767104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 5201928886.79, NNZs: 2, Bias: 300969377779.837402, T: 6656, Avg. loss: 7129759884705261420544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 5176839837.50, NNZs: 2, Bias: 300951050739.331238, T: 6784, Avg. loss: 7132170732811720851456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 5176871594.68, NNZs: 2, Bias: 300932209019.529785, T: 6912, Avg. loss: 7145416699087215919104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 5146973803.05, NNZs: 2, Bias: 300913846118.966003, T: 7040, Avg. loss: 7167161828740052287488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 5166201222.48, NNZs: 2, Bias: 300894490889.546997, T: 7168, Avg. loss: 7222044072149159772160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 5226018654.23, NNZs: 2, Bias: 300874449603.621094, T: 7296, Avg. loss: 7207992593264044670976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 5209747323.05, NNZs: 2, Bias: 300870960002.985718, T: 7424, Avg. loss: 6970811864516995842048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 5195541523.42, NNZs: 2, Bias: 300867452662.654053, T: 7552, Avg. loss: 6935370479636657995776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 5216504007.53, NNZs: 2, Bias: 300863340606.014038, T: 7680, Avg. loss: 6923680681374136664064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 5198934664.38, NNZs: 2, Bias: 300859881524.908386, T: 7808, Avg. loss: 6955305435688341602304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 5206206166.32, NNZs: 2, Bias: 300855988352.697693, T: 7936, Avg. loss: 6959015206283177361408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 5217067957.74, NNZs: 2, Bias: 300852044713.439575, T: 8064, Avg. loss: 6936489726366869094400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 5203170297.64, NNZs: 2, Bias: 300848522710.981445, T: 8192, Avg. loss: 6953547833354517217280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 5212163356.29, NNZs: 2, Bias: 300844604731.210938, T: 8320, Avg. loss: 6949284752074736664576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 65 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1582239502754.60, NNZs: 2, Bias: -67941753140.672653, T: 128, Avg. loss: 20826416045477545826716745728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2191416947081.17, NNZs: 2, Bias: -47941753140.672653, T: 256, Avg. loss: 23777863647384150894182400000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1860573928860.35, NNZs: 2, Bias: -27941753140.672653, T: 384, Avg. loss: 23406517274355371804859564032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2418115421019.46, NNZs: 2, Bias: 72058246859.327347, T: 512, Avg. loss: 24048238672265809339866939392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 367129560370.21, NNZs: 2, Bias: 72058246859.327347, T: 640, Avg. loss: 24000277550411825613801259008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2120843439425.89, NNZs: 2, Bias: 92058246859.327347, T: 768, Avg. loss: 23738052372624008293252071424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 253922733320.75, NNZs: 2, Bias: 102061473475.279282, T: 896, Avg. loss: 2063340609754783528182087680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 131293241799.39, NNZs: 2, Bias: 84119753876.361847, T: 1024, Avg. loss: 936992788097619785204891648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 216569105369.80, NNZs: 2, Bias: 80691738317.826279, T: 1152, Avg. loss: 941377703469763498319282176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 511963398428.69, NNZs: 2, Bias: 66535576534.619591, T: 1280, Avg. loss: 796294486024682463823921152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 373849076944.11, NNZs: 2, Bias: 78567091359.408173, T: 1408, Avg. loss: 962112102827488202907975680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 377015034678.08, NNZs: 2, Bias: 85308778139.494400, T: 1536, Avg. loss: 990096818749676899457302528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 271099676353.81, NNZs: 2, Bias: 85590030338.067505, T: 1664, Avg. loss: 896239650303357915156709376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 172320021103.44, NNZs: 2, Bias: 75285471614.481216, T: 1792, Avg. loss: 963015345858662947438460928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 261470440984.02, NNZs: 2, Bias: 86056924987.677124, T: 1920, Avg. loss: 913496310812480650331815936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 92788109729.77, NNZs: 2, Bias: 85818794915.368668, T: 2048, Avg. loss: 56159231546010909351608320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 26588648138.08, NNZs: 2, Bias: 85065089829.708847, T: 2176, Avg. loss: 31818540128227271072808960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 52104668910.59, NNZs: 2, Bias: 86561232781.401520, T: 2304, Avg. loss: 33682093428845940475691008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 85099435951.11, NNZs: 2, Bias: 83660056698.437347, T: 2432, Avg. loss: 33818052766890165685714944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 99069539042.45, NNZs: 2, Bias: 85187459455.683899, T: 2560, Avg. loss: 32764821347205373755392000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 50826468406.40, NNZs: 2, Bias: 84283654727.638855, T: 2688, Avg. loss: 33996824753055755701059584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 55806133398.60, NNZs: 2, Bias: 82925735905.249527, T: 2816, Avg. loss: 34551627618965683441762304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4746959068.67, NNZs: 2, Bias: 83748180849.673935, T: 2944, Avg. loss: 1205824631068938280632320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 650599013.93, NNZs: 2, Bias: 83839666860.865616, T: 3072, Avg. loss: 739053843342114391326720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2129777567.36, NNZs: 2, Bias: 83689545178.180176, T: 3200, Avg. loss: 536820734475536355557376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 5836901415.96, NNZs: 2, Bias: 83639437442.569336, T: 3328, Avg. loss: 699760099883112510521344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 5737387418.21, NNZs: 2, Bias: 83392872618.947296, T: 3456, Avg. loss: 570171755618018858631168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4612216968.70, NNZs: 2, Bias: 83421590744.481384, T: 3584, Avg. loss: 640397528055331803889664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 12934501012.39, NNZs: 2, Bias: 83363334864.334732, T: 3712, Avg. loss: 674643272043606059253760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2288824837.00, NNZs: 2, Bias: 82792138384.281815, T: 3840, Avg. loss: 569194116213177323618304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1664799790.91, NNZs: 2, Bias: 82766562221.367981, T: 3968, Avg. loss: 1158360245422755020800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1533543475.65, NNZs: 2, Bias: 82741321463.836945, T: 4096, Avg. loss: 733325225390810595328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1430629349.27, NNZs: 2, Bias: 82715593402.009308, T: 4224, Avg. loss: 716161274417013063680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1447839584.22, NNZs: 2, Bias: 82688278636.646027, T: 4352, Avg. loss: 718834664767981879296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1374780399.38, NNZs: 2, Bias: 82662429491.298721, T: 4480, Avg. loss: 709137166407844233216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1282146894.67, NNZs: 2, Bias: 82636470369.554749, T: 4608, Avg. loss: 693904022626925936640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1264712640.24, NNZs: 2, Bias: 82609422631.808960, T: 4736, Avg. loss: 700148699250498732032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1302398937.09, NNZs: 2, Bias: 82580893467.797607, T: 4864, Avg. loss: 717146128488950923264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1286616521.97, NNZs: 2, Bias: 82550667796.245651, T: 4992, Avg. loss: 794610230149885460480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1350072072.17, NNZs: 2, Bias: 82522211720.187012, T: 5120, Avg. loss: 692312833284157865984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1351226983.09, NNZs: 2, Bias: 82494325123.671112, T: 5248, Avg. loss: 711780997651773128704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1302252315.70, NNZs: 2, Bias: 82466704716.637009, T: 5376, Avg. loss: 731348944730565902336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1380675525.41, NNZs: 2, Bias: 82439602888.651199, T: 5504, Avg. loss: 664783305665777238016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1324859307.21, NNZs: 2, Bias: 82413365819.996597, T: 5632, Avg. loss: 717552173820477046784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1337566212.22, NNZs: 2, Bias: 82385402941.645859, T: 5760, Avg. loss: 715885933038657339392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1423836023.79, NNZs: 2, Bias: 82356574908.038071, T: 5888, Avg. loss: 701598685924058857472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1349216395.55, NNZs: 2, Bias: 82330477261.103622, T: 6016, Avg. loss: 704869294446307704832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1330372676.61, NNZs: 2, Bias: 82302673315.222763, T: 6144, Avg. loss: 732645207077605343232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1324571535.79, NNZs: 2, Bias: 82297192613.210098, T: 6272, Avg. loss: 580534206053412700160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1309091865.10, NNZs: 2, Bias: 82291838731.924347, T: 6400, Avg. loss: 582764187143950434304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1307843893.79, NNZs: 2, Bias: 82286226087.894775, T: 6528, Avg. loss: 586379083494971604992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1304357351.21, NNZs: 2, Bias: 82280720270.466919, T: 6656, Avg. loss: 578912490924963856384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1290196769.67, NNZs: 2, Bias: 82275327816.410034, T: 6784, Avg. loss: 585294976309539045376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1308178393.38, NNZs: 2, Bias: 82269484260.343979, T: 6912, Avg. loss: 577770345022284038144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1297984131.02, NNZs: 2, Bias: 82264093720.255188, T: 7040, Avg. loss: 577841001111141482496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1292904172.68, NNZs: 2, Bias: 82258585759.229019, T: 7168, Avg. loss: 580982366836623605760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1306989121.25, NNZs: 2, Bias: 82252849837.842987, T: 7296, Avg. loss: 573163989813780742144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1309028054.12, NNZs: 2, Bias: 82247286039.676575, T: 7424, Avg. loss: 574413098787717971968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1280986681.81, NNZs: 2, Bias: 82242483898.241837, T: 7552, Avg. loss: 543227480970138681344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1297507187.30, NNZs: 2, Bias: 82236630672.971115, T: 7680, Avg. loss: 579145609124470718464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1283945608.65, NNZs: 2, Bias: 82231318071.028656, T: 7808, Avg. loss: 574961452250054721536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1277866492.39, NNZs: 2, Bias: 82225783366.505951, T: 7936, Avg. loss: 585823510210080538624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1289235604.03, NNZs: 2, Bias: 82220014670.104233, T: 8064, Avg. loss: 580970099879257767936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1284675295.27, NNZs: 2, Bias: 82214503330.913544, T: 8192, Avg. loss: 580219446029637976064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1287355998.91, NNZs: 2, Bias: 82213359477.717072, T: 8320, Avg. loss: 556312842718175690752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1281944293.51, NNZs: 2, Bias: 82212339858.870483, T: 8448, Avg. loss: 557740791703380099072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1279708754.42, NNZs: 2, Bias: 82211274959.893021, T: 8576, Avg. loss: 555288138252262768640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1278508464.27, NNZs: 2, Bias: 82210191443.132492, T: 8704, Avg. loss: 556628960191030165504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1280993927.82, NNZs: 2, Bias: 82209045593.073730, T: 8832, Avg. loss: 558967820872574828544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 69 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 410599815257.74, NNZs: 2, Bias: 39867247427.213600, T: 128, Avg. loss: 22437243429138234168387305472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1237836308354.83, NNZs: 2, Bias: 34599209977.445496, T: 256, Avg. loss: 22912125568708199826323406848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2261664613892.43, NNZs: 2, Bias: 74149215588.127777, T: 384, Avg. loss: 23155090716137100983519936512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1226358795304.79, NNZs: 2, Bias: 94149215588.127777, T: 512, Avg. loss: 24521214902473962378693181440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 843657242652.20, NNZs: 2, Bias: 79932865123.680450, T: 640, Avg. loss: 22917966567715899736967872512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1150032579539.90, NNZs: 2, Bias: 140891108205.627411, T: 768, Avg. loss: 23129709409763915119747661824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 424411298687.86, NNZs: 2, Bias: 171056974422.181732, T: 896, Avg. loss: 1132471681929067565175275520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 389096404703.47, NNZs: 2, Bias: 177805828957.552307, T: 1024, Avg. loss: 972706224994474724824186880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 347033264046.97, NNZs: 2, Bias: 191704598747.253265, T: 1152, Avg. loss: 907392658136866062564589568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 415853388978.30, NNZs: 2, Bias: 189112526901.814819, T: 1280, Avg. loss: 905324268998541210875330560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 394103739852.14, NNZs: 2, Bias: 193626365096.203766, T: 1408, Avg. loss: 946697761016504336663969792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 357938235879.69, NNZs: 2, Bias: 188561742828.898926, T: 1536, Avg. loss: 908391618397294919539490816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 390139799834.82, NNZs: 2, Bias: 190454751430.460785, T: 1664, Avg. loss: 910201623329062241708277760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 253697720189.73, NNZs: 2, Bias: 206138830197.132690, T: 1792, Avg. loss: 966266844984265823831982080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 211387522268.52, NNZs: 2, Bias: 195102333353.930878, T: 1920, Avg. loss: 1014764105832268386992652288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 51520352626.91, NNZs: 2, Bias: 193772482139.748749, T: 2048, Avg. loss: 37788156470024515423830016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 8192868978.28, NNZs: 2, Bias: 193824422010.605530, T: 2176, Avg. loss: 33777565356556584671510528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 54494921214.47, NNZs: 2, Bias: 192756897379.190887, T: 2304, Avg. loss: 32835930006918284512854016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 64757629131.19, NNZs: 2, Bias: 193426804887.762207, T: 2432, Avg. loss: 34190911967713442597437440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 82373169896.12, NNZs: 2, Bias: 193770144048.894409, T: 2560, Avg. loss: 34083079821763887174254592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8288894790.64, NNZs: 2, Bias: 193289482464.394592, T: 2688, Avg. loss: 33958726068853442917433344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 66554712470.14, NNZs: 2, Bias: 192619722425.009369, T: 2816, Avg. loss: 35894676896388655070838784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 24194843360.90, NNZs: 2, Bias: 192544852283.404877, T: 2944, Avg. loss: 32693245731935948592119808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 11429151139.75, NNZs: 2, Bias: 191144202932.015717, T: 3072, Avg. loss: 33605345081942077022928896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 25651670581.45, NNZs: 2, Bias: 189374925056.043396, T: 3200, Avg. loss: 36778270694856045168164864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 52885646520.80, NNZs: 2, Bias: 185473190750.069916, T: 3328, Avg. loss: 37167036064005041300701184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 92613928200.63, NNZs: 2, Bias: 188110779654.554382, T: 3456, Avg. loss: 37930722911485015680352256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 62938939775.25, NNZs: 2, Bias: 185109515932.431305, T: 3584, Avg. loss: 34964879908003208794996736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 21970012857.20, NNZs: 2, Bias: 185919914365.850220, T: 3712, Avg. loss: 1201631681016555620007936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1069191931.31, NNZs: 2, Bias: 186063721873.917206, T: 3840, Avg. loss: 801281789218559625265152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6890613665.99, NNZs: 2, Bias: 185610431812.009735, T: 3968, Avg. loss: 707209016072979934609408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11513211240.12, NNZs: 2, Bias: 185008133488.759338, T: 4096, Avg. loss: 689278811910663860912128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3733585533.28, NNZs: 2, Bias: 184552309454.325470, T: 4224, Avg. loss: 762531559703528358281216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2103225335.31, NNZs: 2, Bias: 184365863692.998352, T: 4352, Avg. loss: 626650588440942295908352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11927470807.48, NNZs: 2, Bias: 183766094213.455566, T: 4480, Avg. loss: 809160641147849498689536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 5193495922.64, NNZs: 2, Bias: 183861336933.150238, T: 4608, Avg. loss: 707363535785109393244160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 7415520623.00, NNZs: 2, Bias: 183564247636.700714, T: 4736, Avg. loss: 579321127562018906177536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8182716603.09, NNZs: 2, Bias: 183400907111.571625, T: 4864, Avg. loss: 744929234373404988014592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2469795988.23, NNZs: 2, Bias: 183336604905.965149, T: 4992, Avg. loss: 789735963390937017614336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 11369407097.84, NNZs: 2, Bias: 182990701111.837219, T: 5120, Avg. loss: 728969002533621197701120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2074149907.93, NNZs: 2, Bias: 183036729803.534637, T: 5248, Avg. loss: 654626585515779923378176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 10728005638.02, NNZs: 2, Bias: 182475523852.980255, T: 5376, Avg. loss: 816480931182990715781120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2229389419.32, NNZs: 2, Bias: 182460985874.291840, T: 5504, Avg. loss: 30593207012475581497344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2488235049.50, NNZs: 2, Bias: 182405222831.228394, T: 5632, Avg. loss: 2854633676092333359104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2655479364.54, NNZs: 2, Bias: 182353082434.030792, T: 5760, Avg. loss: 2727278342031125512192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2548917315.60, NNZs: 2, Bias: 182301909640.582367, T: 5888, Avg. loss: 2916618724161236238336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2643377678.00, NNZs: 2, Bias: 182248058162.232452, T: 6016, Avg. loss: 2932580180380875751424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2716112021.87, NNZs: 2, Bias: 182192188736.373016, T: 6144, Avg. loss: 3169268079914186178560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2644145422.55, NNZs: 2, Bias: 182139080629.920807, T: 6272, Avg. loss: 3019388443361537425408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2724728870.76, NNZs: 2, Bias: 182084860020.887115, T: 6400, Avg. loss: 2905796573826492923904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2679781375.60, NNZs: 2, Bias: 182074960088.083557, T: 6528, Avg. loss: 2427954702522795950080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2644611519.15, NNZs: 2, Bias: 182064861138.055389, T: 6656, Avg. loss: 2436707659507051790336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2713573780.50, NNZs: 2, Bias: 182053370642.373993, T: 6784, Avg. loss: 2401829877828893016064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2680859052.98, NNZs: 2, Bias: 182043264626.587006, T: 6912, Avg. loss: 2429192818483694403584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2667120737.35, NNZs: 2, Bias: 182032815017.860840, T: 7040, Avg. loss: 2444922026025527803904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2731525762.37, NNZs: 2, Bias: 182021464499.523651, T: 7168, Avg. loss: 2378831532064383696896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2688789129.91, NNZs: 2, Bias: 182011492001.667389, T: 7296, Avg. loss: 2433099516757369421824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2679908863.53, NNZs: 2, Bias: 182001044875.146271, T: 7424, Avg. loss: 2425153016977043226624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2714646404.73, NNZs: 2, Bias: 181989960559.160461, T: 7552, Avg. loss: 2419660559230899847168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2677623323.03, NNZs: 2, Bias: 181979943846.267822, T: 7680, Avg. loss: 2424361106364933079040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2661196615.72, NNZs: 2, Bias: 181969744368.565979, T: 7808, Avg. loss: 2396452802645836955648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2693230021.46, NNZs: 2, Bias: 181967131548.013519, T: 7936, Avg. loss: 2391218075407408431104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2685935234.19, NNZs: 2, Bias: 181965126189.144714, T: 8064, Avg. loss: 2361466218934398091264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2699848202.21, NNZs: 2, Bias: 181962814692.727386, T: 8192, Avg. loss: 2351970406153966583808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2698065466.23, NNZs: 2, Bias: 181960723580.053040, T: 8320, Avg. loss: 2366210662675468255232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2687867183.20, NNZs: 2, Bias: 181958761793.331299, T: 8448, Avg. loss: 2361277230845379739648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2690462568.85, NNZs: 2, Bias: 181956607328.110352, T: 8576, Avg. loss: 2364147811349255159808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2691327448.49, NNZs: 2, Bias: 181954485507.952148, T: 8704, Avg. loss: 2356621758806226108416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2695042138.81, NNZs: 2, Bias: 181952317574.491425, T: 8832, Avg. loss: 2360811423491671457792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 69 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 638652450162.67, NNZs: 2, Bias: 54225360837.119919, T: 128, Avg. loss: 20625349990473323907230203904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1072610068168.12, NNZs: 2, Bias: 34225360837.119919, T: 256, Avg. loss: 20386571910222455376684515328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1703389646809.27, NNZs: 2, Bias: 104795393277.766022, T: 384, Avg. loss: 20983661708205461365158051840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1849039775065.13, NNZs: 2, Bias: 84945571805.557587, T: 512, Avg. loss: 21829471821238823040260767744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2086868669970.92, NNZs: 2, Bias: 142291150186.336578, T: 640, Avg. loss: 20711871004118927836241199104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1755244570779.43, NNZs: 2, Bias: 94188964706.021088, T: 768, Avg. loss: 22307408367068005774330429440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1979408689881.90, NNZs: 2, Bias: 84020455299.637207, T: 896, Avg. loss: 20078007522252535944110407680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 533969292448.40, NNZs: 2, Bias: 33751014359.743561, T: 1024, Avg. loss: 21194380861436249915072184320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1180734829807.36, NNZs: 2, Bias: -56457412681.878174, T: 1152, Avg. loss: 21209418659902197064037040128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 813028415410.80, NNZs: 2, Bias: -136457412681.878174, T: 1280, Avg. loss: 21677133430346905841546821632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1442151033949.68, NNZs: 2, Bias: -54602794991.949142, T: 1408, Avg. loss: 20717264946032771785048457216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1559620679860.32, NNZs: 2, Bias: -85292629877.301697, T: 1536, Avg. loss: 22728380931725750182000721920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 159485193271.24, NNZs: 2, Bias: -74546846870.589966, T: 1664, Avg. loss: 1348951371017425415177240576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 473327122913.87, NNZs: 2, Bias: -84919206958.408035, T: 1792, Avg. loss: 802140431397427141029134336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 104428598233.40, NNZs: 2, Bias: -87802982521.396942, T: 1920, Avg. loss: 905488946916332719577235456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 146497570307.89, NNZs: 2, Bias: -77728979308.036697, T: 2048, Avg. loss: 869353644858072014379810816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 297829873047.08, NNZs: 2, Bias: -70221388263.772842, T: 2176, Avg. loss: 816119148814293602331000832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 277719562545.49, NNZs: 2, Bias: -67180966375.964752, T: 2304, Avg. loss: 936144210059445640777170944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 79082973337.62, NNZs: 2, Bias: -70742116526.525818, T: 2432, Avg. loss: 1012382075621900936389066752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 58724855552.98, NNZs: 2, Bias: -70843175334.412811, T: 2560, Avg. loss: 33734928059624544817643520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 108632945431.70, NNZs: 2, Bias: -71252939941.515503, T: 2688, Avg. loss: 30869761993388628750893056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 80067185731.08, NNZs: 2, Bias: -71192012153.076736, T: 2816, Avg. loss: 30722327446646883818143744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 40284244662.11, NNZs: 2, Bias: -73801234921.645172, T: 2944, Avg. loss: 30679354421965174528278528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 17510960034.82, NNZs: 2, Bias: -71844861492.879364, T: 3072, Avg. loss: 31449574199637929912958976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100920470541.38, NNZs: 2, Bias: -73047108916.406784, T: 3200, Avg. loss: 30657896631141977762562048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 41072295013.51, NNZs: 2, Bias: -69361988089.658417, T: 3328, Avg. loss: 31446977797312870443122688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 70934900596.64, NNZs: 2, Bias: -71903045472.404312, T: 3456, Avg. loss: 32208651046391476454948864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 93011269663.29, NNZs: 2, Bias: -72100224876.985245, T: 3584, Avg. loss: 32514226989433871314976768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 7801022364.38, NNZs: 2, Bias: -68832582938.628937, T: 3712, Avg. loss: 36539435026281339518189568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 19365228472.54, NNZs: 2, Bias: -68403605588.035416, T: 3840, Avg. loss: 31290512927375671611621376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2688267195.56, NNZs: 2, Bias: -68727979322.378693, T: 3968, Avg. loss: 727557403724959451185152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5061814772.23, NNZs: 2, Bias: -68665000400.517059, T: 4096, Avg. loss: 588574047723313929650176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3697189700.42, NNZs: 2, Bias: -68579575877.879089, T: 4224, Avg. loss: 575019326694070027288576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8780647112.13, NNZs: 2, Bias: -68749814815.533798, T: 4352, Avg. loss: 574248982238310336299008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 17423240621.98, NNZs: 2, Bias: -68490948545.197952, T: 4480, Avg. loss: 630839621949560562122752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2103789418.21, NNZs: 2, Bias: -68348554948.283401, T: 4608, Avg. loss: 593434528173867900338176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9370462243.65, NNZs: 2, Bias: -68257000705.548401, T: 4736, Avg. loss: 521638055198564768808960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 10056911385.37, NNZs: 2, Bias: -68651115429.548866, T: 4864, Avg. loss: 463653770472487766720512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 16263668937.12, NNZs: 2, Bias: -68435529963.975662, T: 4992, Avg. loss: 491987293071269234212864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1895285965.70, NNZs: 2, Bias: -68489165606.054184, T: 5120, Avg. loss: 540234385491433220997120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 7763685139.61, NNZs: 2, Bias: -68365851530.403122, T: 5248, Avg. loss: 642615010860172591497216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 15402278553.45, NNZs: 2, Bias: -68562023652.369171, T: 5376, Avg. loss: 396312648651758001717248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4500733829.05, NNZs: 2, Bias: -68625201804.246773, T: 5504, Avg. loss: 673983823122935826087936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3326910310.06, NNZs: 2, Bias: -68655756767.735565, T: 5632, Avg. loss: 586260773694371805528064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 7627992773.55, NNZs: 2, Bias: -68829383917.135086, T: 5760, Avg. loss: 707104286923407059058688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1909233482.43, NNZs: 2, Bias: -68149165342.175049, T: 5888, Avg. loss: 613079519373397285928960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 6927081974.83, NNZs: 2, Bias: -68084232460.654053, T: 6016, Avg. loss: 554185309820740381442048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1756592803.16, NNZs: 2, Bias: -68045683022.522903, T: 6144, Avg. loss: 8403371429453326450688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 437595579.17, NNZs: 2, Bias: -68000488893.269920, T: 6272, Avg. loss: 1315763774404282548224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 672906360.43, NNZs: 2, Bias: -67966742318.280800, T: 6400, Avg. loss: 623017792207112896512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 869456012.26, NNZs: 2, Bias: -67937598083.555588, T: 6528, Avg. loss: 534018669528465997824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 930645742.64, NNZs: 2, Bias: -67912428599.468742, T: 6656, Avg. loss: 502558863759046082560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 988581920.79, NNZs: 2, Bias: -67887463640.945976, T: 6784, Avg. loss: 503233886262425354240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1052427261.67, NNZs: 2, Bias: -67862105693.430313, T: 6912, Avg. loss: 497083808383026397184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1114342690.52, NNZs: 2, Bias: -67837446670.266647, T: 7040, Avg. loss: 472957944509724950528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1087128974.54, NNZs: 2, Bias: -67814130940.862732, T: 7168, Avg. loss: 499331070418171854848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1105383956.83, NNZs: 2, Bias: -67790455421.114388, T: 7296, Avg. loss: 493283262948181344256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1098661783.37, NNZs: 2, Bias: -67765608891.733154, T: 7424, Avg. loss: 528067262543982690304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1070527063.05, NNZs: 2, Bias: -67741298028.784081, T: 7552, Avg. loss: 520822208290078392320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1072216851.39, NNZs: 2, Bias: -67716440195.389397, T: 7680, Avg. loss: 519244277082261028864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1092400666.11, NNZs: 2, Bias: -67711214034.689171, T: 7808, Avg. loss: 417065683805016162304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1106076070.49, NNZs: 2, Bias: -67706229915.979393, T: 7936, Avg. loss: 406305990118001410048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1086956246.91, NNZs: 2, Bias: -67701760747.682503, T: 8064, Avg. loss: 408639485270413017088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1093369934.27, NNZs: 2, Bias: -67696851105.048279, T: 8192, Avg. loss: 409380689433936789504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1097397813.76, NNZs: 2, Bias: -67692024334.952499, T: 8320, Avg. loss: 406219649438506090496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1101210769.85, NNZs: 2, Bias: -67687283834.134300, T: 8448, Avg. loss: 397320457122065154048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1098804664.98, NNZs: 2, Bias: -67682590915.298302, T: 8576, Avg. loss: 403272883250871468032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1113862060.53, NNZs: 2, Bias: -67677687368.609009, T: 8704, Avg. loss: 397110886993125965824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1103456901.92, NNZs: 2, Bias: -67673035401.192970, T: 8832, Avg. loss: 411690064044638273536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1100917376.88, NNZs: 2, Bias: -67668293956.285461, T: 8960, Avg. loss: 408063048678500466688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1101618804.98, NNZs: 2, Bias: -67663599417.667053, T: 9088, Avg. loss: 398918562845929242624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1105965331.38, NNZs: 2, Bias: -67658759930.185707, T: 9216, Avg. loss: 406683129058394046464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1094232330.03, NNZs: 2, Bias: -67654132299.699944, T: 9344, Avg. loss: 410890263050608902144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1096770327.30, NNZs: 2, Bias: -67653139719.128365, T: 9472, Avg. loss: 395191600872334360576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1098306575.98, NNZs: 2, Bias: -67652163416.823624, T: 9600, Avg. loss: 395126415969601454080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1100267989.85, NNZs: 2, Bias: -67651181051.049141, T: 9728, Avg. loss: 394709496916944617472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1101029898.07, NNZs: 2, Bias: -67650218008.248466, T: 9856, Avg. loss: 394832147867547467776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1102463961.29, NNZs: 2, Bias: -67649247938.409134, T: 9984, Avg. loss: 393151795441958912000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1098330396.75, NNZs: 2, Bias: -67648365342.456520, T: 10112, Avg. loss: 394588970975842664448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1098119533.37, NNZs: 2, Bias: -67647419368.265015, T: 10240, Avg. loss: 394338871032306991104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1096215125.22, NNZs: 2, Bias: -67646503589.347878, T: 10368, Avg. loss: 393228996156228567040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1098676979.55, NNZs: 2, Bias: -67645511462.306664, T: 10496, Avg. loss: 395391726075369357312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 1099379752.71, NNZs: 2, Bias: -67644549568.481453, T: 10624, Avg. loss: 394758084530269192192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 83 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1925448498715.03, NNZs: 2, Bias: 34644409794.045425, T: 128, Avg. loss: 17522176180062310490259324928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1792295498011.67, NNZs: 2, Bias: 34644409794.045425, T: 256, Avg. loss: 18036923455687536255350865920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1117963428225.60, NNZs: 2, Bias: 64677250819.934784, T: 384, Avg. loss: 20202519756299934729712435200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1051796262854.92, NNZs: 2, Bias: 21651142463.009491, T: 512, Avg. loss: 19104302742165523562410016768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2131512631525.21, NNZs: 2, Bias: 61651142463.009491, T: 640, Avg. loss: 18456822871075745190899613696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1765201302361.06, NNZs: 2, Bias: 122833965341.190613, T: 768, Avg. loss: 18643300713154416092481847296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 359656978753.12, NNZs: 2, Bias: 121828946278.392487, T: 896, Avg. loss: 1656547503796785625107005440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 265549044052.71, NNZs: 2, Bias: 123365220711.718643, T: 1024, Avg. loss: 838615000640313967333343232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 93326322641.84, NNZs: 2, Bias: 109804794334.654846, T: 1152, Avg. loss: 754592397967548716366692352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 337438738246.39, NNZs: 2, Bias: 113242958837.143372, T: 1280, Avg. loss: 818431805001002223658860544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 150444476910.07, NNZs: 2, Bias: 115497922017.282120, T: 1408, Avg. loss: 848434003006691680624574464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 232594224057.42, NNZs: 2, Bias: 112443737090.207291, T: 1536, Avg. loss: 804752304058702778154876928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 139481530158.82, NNZs: 2, Bias: 123441250111.314270, T: 1664, Avg. loss: 791935563397964360916664320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 299914891056.34, NNZs: 2, Bias: 124604731193.083420, T: 1792, Avg. loss: 704108917448858737370464256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 142542192391.93, NNZs: 2, Bias: 141889512160.028595, T: 1920, Avg. loss: 823370615529418407230308352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 193768436505.35, NNZs: 2, Bias: 151432281154.424835, T: 2048, Avg. loss: 733707347786228605558718464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 137282476667.41, NNZs: 2, Bias: 144126784097.794800, T: 2176, Avg. loss: 755389700231528446322278400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 58398804346.76, NNZs: 2, Bias: 136347779016.494202, T: 2304, Avg. loss: 760897947225979759081029632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 203426691053.97, NNZs: 2, Bias: 130931811283.874115, T: 2432, Avg. loss: 769327989816514387204112384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 57469853840.39, NNZs: 2, Bias: 130785096620.850891, T: 2560, Avg. loss: 37456151294769530197245952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 53556593197.15, NNZs: 2, Bias: 130124679130.041656, T: 2688, Avg. loss: 26871259679584806219284480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 33336476688.91, NNZs: 2, Bias: 129290722759.706589, T: 2816, Avg. loss: 28827367770217263600238592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 24502487762.36, NNZs: 2, Bias: 127865617864.320923, T: 2944, Avg. loss: 29918953921344389802622976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 71076976567.74, NNZs: 2, Bias: 128899774283.103958, T: 3072, Avg. loss: 26638431414257193528066048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 35147281046.44, NNZs: 2, Bias: 128278086725.109238, T: 3200, Avg. loss: 33015424514840590051966976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 25969380224.92, NNZs: 2, Bias: 127955339801.718857, T: 3328, Avg. loss: 28661245949562501302583296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 70284157818.86, NNZs: 2, Bias: 127188140489.148315, T: 3456, Avg. loss: 32981912648595670527115264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 78898808386.22, NNZs: 2, Bias: 125600718220.992111, T: 3584, Avg. loss: 29378092034794749345923072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 23958895848.55, NNZs: 2, Bias: 127489254635.834686, T: 3712, Avg. loss: 30601054939996474442776576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4374450821.20, NNZs: 2, Bias: 127231484072.565338, T: 3840, Avg. loss: 563067455725253045518336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11431303219.55, NNZs: 2, Bias: 126742196533.807129, T: 3968, Avg. loss: 506743245680094490918912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11595918040.27, NNZs: 2, Bias: 126838262339.703094, T: 4096, Avg. loss: 559656397423639275765760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7899753860.82, NNZs: 2, Bias: 126743578239.633102, T: 4224, Avg. loss: 582342383469415693811712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1541563102.74, NNZs: 2, Bias: 126736591036.065140, T: 4352, Avg. loss: 620691590930606940225536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 15509738258.81, NNZs: 2, Bias: 126874443098.012833, T: 4480, Avg. loss: 470828316259048834990080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2324521826.78, NNZs: 2, Bias: 127038598386.184280, T: 4608, Avg. loss: 401664107809510956990464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 11829043087.79, NNZs: 2, Bias: 126943569119.897003, T: 4736, Avg. loss: 479211400962866254184448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9719587335.56, NNZs: 2, Bias: 126791345206.179291, T: 4864, Avg. loss: 453070946002020513873920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2802584719.87, NNZs: 2, Bias: 126942669263.671417, T: 4992, Avg. loss: 582544921493948109684736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 5194906458.49, NNZs: 2, Bias: 126508810037.098083, T: 5120, Avg. loss: 395743993251301253185536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1910571122.90, NNZs: 2, Bias: 126299725970.224121, T: 5248, Avg. loss: 470506606141080292294656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3314602600.81, NNZs: 2, Bias: 125937396410.469864, T: 5376, Avg. loss: 423116735789499385118720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 18184829703.20, NNZs: 2, Bias: 125685993291.747467, T: 5504, Avg. loss: 575062677693478765330432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 8250109005.92, NNZs: 2, Bias: 125977896468.802734, T: 5632, Avg. loss: 570212304764722705596416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 10589406970.68, NNZs: 2, Bias: 125964774194.416061, T: 5760, Avg. loss: 469142854501556503445504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1466255496.20, NNZs: 2, Bias: 125857548680.090073, T: 5888, Avg. loss: 37467311666122157195264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1716369041.82, NNZs: 2, Bias: 125810209941.611694, T: 6016, Avg. loss: 1615609670985986342912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1959024092.02, NNZs: 2, Bias: 125765374575.969849, T: 6144, Avg. loss: 1571159127135415173120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1998276654.55, NNZs: 2, Bias: 125722677500.684464, T: 6272, Avg. loss: 1601419956516282957824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1997702964.96, NNZs: 2, Bias: 125681714045.687195, T: 6400, Avg. loss: 1523523554641848827904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2102938654.48, NNZs: 2, Bias: 125639202991.341721, T: 6528, Avg. loss: 1559294628069115166720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2052449304.42, NNZs: 2, Bias: 125595801415.442612, T: 6656, Avg. loss: 1747720322425704415232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2058275788.18, NNZs: 2, Bias: 125553220536.457718, T: 6784, Avg. loss: 1607621200840985411584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2024568194.39, NNZs: 2, Bias: 125510628189.068604, T: 6912, Avg. loss: 1649825597015541940224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2018296168.79, NNZs: 2, Bias: 125465724032.101944, T: 7040, Avg. loss: 1713105179199518015488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1981258141.04, NNZs: 2, Bias: 125458062821.590881, T: 7168, Avg. loss: 1308407444685658783744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2019362481.03, NNZs: 2, Bias: 125448794159.247604, T: 7296, Avg. loss: 1371315320756417855488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2041450076.48, NNZs: 2, Bias: 125440319660.692444, T: 7424, Avg. loss: 1281107865830899580928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2033168947.34, NNZs: 2, Bias: 125431968876.593231, T: 7552, Avg. loss: 1345370663091645972480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2044729147.46, NNZs: 2, Bias: 125423526428.972778, T: 7680, Avg. loss: 1306600095165467066368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2032203120.82, NNZs: 2, Bias: 125415223919.950226, T: 7808, Avg. loss: 1349244648912475652096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2009678865.97, NNZs: 2, Bias: 125407040416.107178, T: 7936, Avg. loss: 1355066421119888654336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1999558131.77, NNZs: 2, Bias: 125398642481.504761, T: 8064, Avg. loss: 1356732746264283971584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2017891266.53, NNZs: 2, Bias: 125396636304.980865, T: 8192, Avg. loss: 1318433892167942668288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2017660531.29, NNZs: 2, Bias: 125394950503.968414, T: 8320, Avg. loss: 1301558942910406721536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2025198573.36, NNZs: 2, Bias: 125393142645.101288, T: 8448, Avg. loss: 1298811533875885113344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2022920333.36, NNZs: 2, Bias: 125391488343.444138, T: 8576, Avg. loss: 1302986597998041759744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2019298066.86, NNZs: 2, Bias: 125389855710.055771, T: 8704, Avg. loss: 1302858591296745373696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 68 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1381734543179.66, NNZs: 2, Bias: -30225790.862839, T: 128, Avg. loss: 19298166775707360563348635648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 811566292744.53, NNZs: 2, Bias: 4997465287.489826, T: 256, Avg. loss: 19227245648376593346463793152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1685809838757.18, NNZs: 2, Bias: 4997465287.489822, T: 384, Avg. loss: 19002443056983360227279634432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2452437163121.49, NNZs: 2, Bias: 20477158195.810867, T: 512, Avg. loss: 20192312213171093232838246400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 572683963033.79, NNZs: 2, Bias: 120477158195.810867, T: 640, Avg. loss: 20757335713769091088905142272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 104669689516.30, NNZs: 2, Bias: 152190376216.738892, T: 768, Avg. loss: 20149697881224868755056623616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1965309741252.53, NNZs: 2, Bias: 97789869938.650085, T: 896, Avg. loss: 23169288281850599627147968512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 955672338176.67, NNZs: 2, Bias: 117789869938.650085, T: 1024, Avg. loss: 22237936774536262761570107392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 199806920129.35, NNZs: 2, Bias: 153624399318.805603, T: 1152, Avg. loss: 791616250276383217288216576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 170695679309.23, NNZs: 2, Bias: 141977472046.249359, T: 1280, Avg. loss: 903232129108790714130497536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 231363481376.49, NNZs: 2, Bias: 153004081268.063995, T: 1408, Avg. loss: 697324384731279118309523456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 214022384877.25, NNZs: 2, Bias: 152399361050.400543, T: 1536, Avg. loss: 796396518432548038920634368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 253039887695.18, NNZs: 2, Bias: 149994882504.688812, T: 1664, Avg. loss: 798519605983001239065985024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 381399733769.67, NNZs: 2, Bias: 151749641646.249512, T: 1792, Avg. loss: 824972442656380170123870208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 425743352164.60, NNZs: 2, Bias: 163998194054.199005, T: 1920, Avg. loss: 783137903063019990636560384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 539747886055.65, NNZs: 2, Bias: 152972347937.818787, T: 2048, Avg. loss: 851380232585986696179351552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 22746405411.53, NNZs: 2, Bias: 155810517050.098724, T: 2176, Avg. loss: 163779958799065753204031488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 28155686042.07, NNZs: 2, Bias: 151130070351.126282, T: 2304, Avg. loss: 30423748380890637046644736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 45898585850.68, NNZs: 2, Bias: 149976106756.927582, T: 2432, Avg. loss: 29775517878937851724300288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 30823497101.61, NNZs: 2, Bias: 151158477295.392090, T: 2560, Avg. loss: 32393295013239830337290240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 36553928860.24, NNZs: 2, Bias: 148793875571.225159, T: 2688, Avg. loss: 31040161537678427895627776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 49753217414.84, NNZs: 2, Bias: 142333881217.667572, T: 2816, Avg. loss: 30200629523927765729935360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 18846240590.04, NNZs: 2, Bias: 143912467146.245758, T: 2944, Avg. loss: 30688449501863845784715264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 59650942990.47, NNZs: 2, Bias: 144481653296.097809, T: 3072, Avg. loss: 29388842376527098889109504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 71295095484.73, NNZs: 2, Bias: 142069521025.298248, T: 3200, Avg. loss: 30829656377425895891140608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 12616330851.68, NNZs: 2, Bias: 142982519894.095337, T: 3328, Avg. loss: 29690573481603500685131776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 51374025690.26, NNZs: 2, Bias: 143665715223.828827, T: 3456, Avg. loss: 31823789450171494831226880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 38263382031.95, NNZs: 2, Bias: 148230152260.949768, T: 3584, Avg. loss: 29155799530210884572938240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 27912263169.60, NNZs: 2, Bias: 151584746725.994598, T: 3712, Avg. loss: 33534096059821503193022464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 28382787288.29, NNZs: 2, Bias: 150345899689.775818, T: 3840, Avg. loss: 28801715069673046668214272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 36431576417.70, NNZs: 2, Bias: 150487541997.916412, T: 3968, Avg. loss: 29093630900886471199162368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 76119481277.01, NNZs: 2, Bias: 147382655105.742340, T: 4096, Avg. loss: 30476404888465396048330752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 3950835350.78, NNZs: 2, Bias: 146349103448.278748, T: 4224, Avg. loss: 30511597609641794416410624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 47060918422.90, NNZs: 2, Bias: 146863109504.939911, T: 4352, Avg. loss: 28712243113069727040143360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 35888331103.79, NNZs: 2, Bias: 146303663090.862518, T: 4480, Avg. loss: 28223174855295538271617024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 68959216595.38, NNZs: 2, Bias: 145142804515.127930, T: 4608, Avg. loss: 30596031319396937606627328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 33022562207.64, NNZs: 2, Bias: 145805316879.386963, T: 4736, Avg. loss: 29542699704215140218961920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 58618824359.47, NNZs: 2, Bias: 141807098330.367340, T: 4864, Avg. loss: 29731557325514170592919552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 19319963803.69, NNZs: 2, Bias: 139929402357.095764, T: 4992, Avg. loss: 30011228716567080116158464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 21578216207.44, NNZs: 2, Bias: 139842326831.703644, T: 5120, Avg. loss: 28765043512136418715500544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 6203706884.06, NNZs: 2, Bias: 139522291077.087708, T: 5248, Avg. loss: 791618652685697814626304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4718141005.23, NNZs: 2, Bias: 139221736762.995544, T: 5376, Avg. loss: 518877658962205155000320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 6540336001.40, NNZs: 2, Bias: 138818469884.002533, T: 5504, Avg. loss: 666061424033147352252416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 7455756173.20, NNZs: 2, Bias: 138683733189.900543, T: 5632, Avg. loss: 589787374660187936784384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3911860278.68, NNZs: 2, Bias: 138200279086.177643, T: 5760, Avg. loss: 746650771841044455620608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 7422357009.18, NNZs: 2, Bias: 137848484589.765106, T: 5888, Avg. loss: 460893072545539512336384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 7168355213.82, NNZs: 2, Bias: 137862571744.732025, T: 6016, Avg. loss: 660189181741387160223744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 5453332621.71, NNZs: 2, Bias: 137785827351.992706, T: 6144, Avg. loss: 521852846852684614991872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1184627593.20, NNZs: 2, Bias: 137688313325.119995, T: 6272, Avg. loss: 790544172735006416830464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 8486668873.45, NNZs: 2, Bias: 137419307965.053253, T: 6400, Avg. loss: 554191695973286217252864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 6557076968.33, NNZs: 2, Bias: 137399851976.573151, T: 6528, Avg. loss: 653598127041297717919744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2642933540.57, NNZs: 2, Bias: 137326078604.912582, T: 6656, Avg. loss: 12319996236698451181568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2475544626.32, NNZs: 2, Bias: 137286302941.784149, T: 6784, Avg. loss: 1807505220757442527232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2330057528.57, NNZs: 2, Bias: 137244473512.531357, T: 6912, Avg. loss: 1905671192835803316224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2457543281.02, NNZs: 2, Bias: 137197835223.958252, T: 7040, Avg. loss: 1827113906982232522752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2514361088.91, NNZs: 2, Bias: 137154745960.651291, T: 7168, Avg. loss: 1810967461521564893184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2562343325.20, NNZs: 2, Bias: 137113176725.366913, T: 7296, Avg. loss: 1688112099748235444224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2535029948.84, NNZs: 2, Bias: 137071459812.856796, T: 7424, Avg. loss: 1832143838004501020672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2456705702.63, NNZs: 2, Bias: 137029317252.619293, T: 7552, Avg. loss: 1858042315926231842816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2387892789.01, NNZs: 2, Bias: 136984658856.695938, T: 7680, Avg. loss: 1923091676833064419328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2465240389.16, NNZs: 2, Bias: 136940373539.447601, T: 7808, Avg. loss: 1763855117812673544192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2358029215.89, NNZs: 2, Bias: 136900610553.676453, T: 7936, Avg. loss: 1749809460155986739200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2338817917.51, NNZs: 2, Bias: 136892268500.355881, T: 8064, Avg. loss: 1497035023380740571136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2336363537.66, NNZs: 2, Bias: 136883795957.491791, T: 8192, Avg. loss: 1473606619543398252544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2354333841.20, NNZs: 2, Bias: 136874970410.295395, T: 8320, Avg. loss: 1468788895335381991424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2345441857.55, NNZs: 2, Bias: 136866485716.170715, T: 8448, Avg. loss: 1492073391295119228928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2340898973.51, NNZs: 2, Bias: 136857970620.303741, T: 8576, Avg. loss: 1481905532076715671552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2344162460.35, NNZs: 2, Bias: 136849350375.053833, T: 8704, Avg. loss: 1479322538096996646912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2333249025.96, NNZs: 2, Bias: 136841060112.815857, T: 8832, Avg. loss: 1461613946373179703296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2353802368.03, NNZs: 2, Bias: 136832067614.358887, T: 8960, Avg. loss: 1490015854822335709184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2347298504.08, NNZs: 2, Bias: 136823608429.077698, T: 9088, Avg. loss: 1481118261939660390400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2349184686.89, NNZs: 2, Bias: 136814938034.870193, T: 9216, Avg. loss: 1489728684390626885632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2361364831.45, NNZs: 2, Bias: 136806094955.702545, T: 9344, Avg. loss: 1489609518687614402560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2349963711.38, NNZs: 2, Bias: 136797647337.330872, T: 9472, Avg. loss: 1492881100854944595968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2358165729.28, NNZs: 2, Bias: 136795786204.763870, T: 9600, Avg. loss: 1444681494209714716672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2356201065.45, NNZs: 2, Bias: 136794111705.630905, T: 9728, Avg. loss: 1435332105144656199680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2365177927.85, NNZs: 2, Bias: 136792252167.867706, T: 9856, Avg. loss: 1431634505499394703360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2364272786.24, NNZs: 2, Bias: 136790555665.890869, T: 9984, Avg. loss: 1438336609368488542208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2366907123.18, NNZs: 2, Bias: 136788799189.676392, T: 10112, Avg. loss: 1437160307249668685824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2364683207.34, NNZs: 2, Bias: 136787129713.394928, T: 10240, Avg. loss: 1434884903543789584384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 2374069940.29, NNZs: 2, Bias: 136785262531.109528, T: 10368, Avg. loss: 1431509110259385892864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 2368537715.20, NNZs: 2, Bias: 136783652376.312622, T: 10496, Avg. loss: 1433493700605792747520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 2367306130.82, NNZs: 2, Bias: 136781960548.127808, T: 10624, Avg. loss: 1439246304011032461312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 2361565103.04, NNZs: 2, Bias: 136780353660.077850, T: 10752, Avg. loss: 1433541121385267200000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 2374384240.06, NNZs: 2, Bias: 136778425480.117310, T: 10880, Avg. loss: 1432537879253069070336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 2366687763.88, NNZs: 2, Bias: 136776856573.179871, T: 11008, Avg. loss: 1430552111029405876224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 2370674397.16, NNZs: 2, Bias: 136775075252.149292, T: 11136, Avg. loss: 1438148479511006019584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 2365888409.59, NNZs: 2, Bias: 136773453728.239868, T: 11264, Avg. loss: 1431805602760621031424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 2376587514.62, NNZs: 2, Bias: 136771570355.801743, T: 11392, Avg. loss: 1425602927382687121408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 2373871504.74, NNZs: 2, Bias: 136769904687.853653, T: 11520, Avg. loss: 1439026902905017597952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 2374139228.24, NNZs: 2, Bias: 136768188612.577606, T: 11648, Avg. loss: 1437557251049870065664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 2369067392.59, NNZs: 2, Bias: 136766573005.368698, T: 11776, Avg. loss: 1431367918508355616768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 2374411077.64, NNZs: 2, Bias: 136764769615.798935, T: 11904, Avg. loss: 1436740620337977491456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 2367833333.21, NNZs: 2, Bias: 136763176300.619720, T: 12032, Avg. loss: 1434316648831463194624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 94 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1596204674275.60, NNZs: 2, Bias: -94052677492.322693, T: 128, Avg. loss: 22961288381969847046601965568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1145428867430.57, NNZs: 2, Bias: -134052677492.322693, T: 256, Avg. loss: 22478150751532423219725205504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 744696788518.54, NNZs: 2, Bias: -221527476062.703583, T: 384, Avg. loss: 23021783990406612678697025536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1679629378879.71, NNZs: 2, Bias: -196879344170.343750, T: 512, Avg. loss: 23740528296027390814868996096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2480102168176.26, NNZs: 2, Bias: -258483752551.180542, T: 640, Avg. loss: 22324054443161101975599185920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1120346209175.12, NNZs: 2, Bias: -318483752551.180542, T: 768, Avg. loss: 24476719333850047857888854016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1169899596036.04, NNZs: 2, Bias: -303478185562.477722, T: 896, Avg. loss: 23751923581175578019458187264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1051450993231.10, NNZs: 2, Bias: -263478185562.477722, T: 1024, Avg. loss: 26750058147984706830692515840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 995541120213.67, NNZs: 2, Bias: -200476761482.606140, T: 1152, Avg. loss: 21323551843305396726730326016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 426931184105.08, NNZs: 2, Bias: -211083264008.335449, T: 1280, Avg. loss: 23010349805715803583180439552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2554549664730.61, NNZs: 2, Bias: -211214604714.919373, T: 1408, Avg. loss: 23258066030375734982792445952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2336775900313.49, NNZs: 2, Bias: -191214604714.919373, T: 1536, Avg. loss: 21941101065433259094468198400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1789202319894.80, NNZs: 2, Bias: -151214604714.919373, T: 1664, Avg. loss: 23361669879529800212945043456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 2082826817205.17, NNZs: 2, Bias: -271214604714.919373, T: 1792, Avg. loss: 22405595169558225723137720320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 312499026252.02, NNZs: 2, Bias: -231214604714.919373, T: 1920, Avg. loss: 1278852464313504085170978816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 89559269618.96, NNZs: 2, Bias: -218919780704.252014, T: 2048, Avg. loss: 919604825162249860001300480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 228690613284.08, NNZs: 2, Bias: -229882179942.474426, T: 2176, Avg. loss: 846912173307297577335521280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 552973560740.81, NNZs: 2, Bias: -202527975297.214478, T: 2304, Avg. loss: 897492825457278916986142720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 328282328717.50, NNZs: 2, Bias: -204946510709.389648, T: 2432, Avg. loss: 882664909648498729093693440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 129011320835.19, NNZs: 2, Bias: -195188882908.942017, T: 2560, Avg. loss: 999504622422113104101900288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 491283254929.47, NNZs: 2, Bias: -197692892730.325409, T: 2688, Avg. loss: 875368871862842283173871616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 300102786959.49, NNZs: 2, Bias: -198721072036.717682, T: 2816, Avg. loss: 929327920191279193831505920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 17178496603.39, NNZs: 2, Bias: -198757339281.901031, T: 2944, Avg. loss: 58450549697540004473995264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 93554206137.31, NNZs: 2, Bias: -196020216399.786774, T: 3072, Avg. loss: 34548266410497607322304512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 71861315722.35, NNZs: 2, Bias: -192464253397.023132, T: 3200, Avg. loss: 33642263019249892996415488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 69812109407.69, NNZs: 2, Bias: -193533214199.938202, T: 3328, Avg. loss: 32989775960014165469298688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 53914795174.71, NNZs: 2, Bias: -188705673572.100708, T: 3456, Avg. loss: 32341428310606371826434048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 44591263978.07, NNZs: 2, Bias: -190494193573.567474, T: 3584, Avg. loss: 35252226054251424421773312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 47486600266.78, NNZs: 2, Bias: -191218212167.534912, T: 3712, Avg. loss: 32405176346992978786516992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 82494174415.02, NNZs: 2, Bias: -191077078772.442139, T: 3840, Avg. loss: 29878672907275496524349440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 12767212452.48, NNZs: 2, Bias: -189671621476.293549, T: 3968, Avg. loss: 33676185506699567375056896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 36571817007.91, NNZs: 2, Bias: -189087089738.451111, T: 4096, Avg. loss: 31764739747919196395143168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 54409940563.46, NNZs: 2, Bias: -188207954439.637756, T: 4224, Avg. loss: 32407976114356260591108096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 93991657759.87, NNZs: 2, Bias: -186404255955.619507, T: 4352, Avg. loss: 31675317848231457545256960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 77086663245.35, NNZs: 2, Bias: -185831958877.360352, T: 4480, Avg. loss: 34741342100408439507255296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1375146775.49, NNZs: 2, Bias: -184646801722.312744, T: 4608, Avg. loss: 2748172300656675580280832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1952132811.39, NNZs: 2, Bias: -184183230951.734894, T: 4736, Avg. loss: 854638789366289763663872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6904311824.13, NNZs: 2, Bias: -183728242225.847565, T: 4864, Avg. loss: 771225640167740702457856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6601256604.73, NNZs: 2, Bias: -183580229228.530975, T: 4992, Avg. loss: 685362059361586597855232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 11625165172.49, NNZs: 2, Bias: -183082795261.847321, T: 5120, Avg. loss: 661836958554858025123840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9645684720.77, NNZs: 2, Bias: -183065511694.320801, T: 5248, Avg. loss: 824614630847343807692800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 5648667541.38, NNZs: 2, Bias: -183175396005.097504, T: 5376, Avg. loss: 838779275754543775744000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 11406252606.70, NNZs: 2, Bias: -183082628713.133362, T: 5504, Avg. loss: 708156550607221035106304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 789477485.60, NNZs: 2, Bias: -182826994522.553467, T: 5632, Avg. loss: 791688753628179752550400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 10353290225.35, NNZs: 2, Bias: -182804389912.874725, T: 5760, Avg. loss: 701151793922672338927616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 6561309809.93, NNZs: 2, Bias: -182790501011.459564, T: 5888, Avg. loss: 13073461956120347148288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4753692866.44, NNZs: 2, Bias: -182754760658.045654, T: 6016, Avg. loss: 5931384261477658525696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3845623622.29, NNZs: 2, Bias: -182708373762.811890, T: 6144, Avg. loss: 4057609897418652385280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3208214080.33, NNZs: 2, Bias: -182658883759.191162, T: 6272, Avg. loss: 3790655301449951477760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2840904047.03, NNZs: 2, Bias: -182604500744.974335, T: 6400, Avg. loss: 3553555698601925541888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2867585550.29, NNZs: 2, Bias: -182541620574.556946, T: 6528, Avg. loss: 3507222336369500618752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2748092091.82, NNZs: 2, Bias: -182484128023.419891, T: 6656, Avg. loss: 3364264545593989267456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2721373640.80, NNZs: 2, Bias: -182422810200.545898, T: 6784, Avg. loss: 3494167187301400576000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2916223514.09, NNZs: 2, Bias: -182356254213.707825, T: 6912, Avg. loss: 3696072538887656833024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2958644536.17, NNZs: 2, Bias: -182293909720.388641, T: 7040, Avg. loss: 3460466458351067201536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2854402314.55, NNZs: 2, Bias: -182235314123.325653, T: 7168, Avg. loss: 3520488544593593761792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2940473609.35, NNZs: 2, Bias: -182171473255.913544, T: 7296, Avg. loss: 3508779886667304009728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2900863981.41, NNZs: 2, Bias: -182159718819.111664, T: 7424, Avg. loss: 2857502906892996837376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2854665959.13, NNZs: 2, Bias: -182148044327.587189, T: 7552, Avg. loss: 2858934994928330604544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2889871509.45, NNZs: 2, Bias: -182135183596.899292, T: 7680, Avg. loss: 2834718708938266116096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2861130185.86, NNZs: 2, Bias: -182123461556.509247, T: 7808, Avg. loss: 2802142137623368433664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2894976449.41, NNZs: 2, Bias: -182110872463.059845, T: 7936, Avg. loss: 2767386854047220760576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2891725380.42, NNZs: 2, Bias: -182098696728.075806, T: 8064, Avg. loss: 2813086983637813952512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2853808072.46, NNZs: 2, Bias: -182086970479.934448, T: 8192, Avg. loss: 2841470206278537052160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2857672330.11, NNZs: 2, Bias: -182074887735.258209, T: 8320, Avg. loss: 2760139705276327002112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2881670431.72, NNZs: 2, Bias: -182062240101.771667, T: 8448, Avg. loss: 2815949474128397860864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2894929240.12, NNZs: 2, Bias: -182049853839.740723, T: 8576, Avg. loss: 2803576433273168461824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2855953482.94, NNZs: 2, Bias: -182038095903.055023, T: 8704, Avg. loss: 2849020839315707527168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2887247165.43, NNZs: 2, Bias: -182025300954.832275, T: 8832, Avg. loss: 2824879451155622002688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2837739799.41, NNZs: 2, Bias: -182013859511.095459, T: 8960, Avg. loss: 2810550134731139710976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2869279341.85, NNZs: 2, Bias: -182010903707.770752, T: 9088, Avg. loss: 2749723199769426788352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2866154606.62, NNZs: 2, Bias: -182008503119.136932, T: 9216, Avg. loss: 2739127136183703830528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2863480516.55, NNZs: 2, Bias: -182006096976.886597, T: 9344, Avg. loss: 2737447173899490951168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2873465385.71, NNZs: 2, Bias: -182003521324.873322, T: 9472, Avg. loss: 2703346535907515170816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2864385752.58, NNZs: 2, Bias: -182001223494.438385, T: 9600, Avg. loss: 2729759205488852467712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2858927577.25, NNZs: 2, Bias: -181998864264.176086, T: 9728, Avg. loss: 2734134598162762956800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2872201124.72, NNZs: 2, Bias: -181996209991.182434, T: 9856, Avg. loss: 2732959989295085518848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2866894217.57, NNZs: 2, Bias: -181993843756.756958, T: 9984, Avg. loss: 2739302515064610750464.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2858166622.73, NNZs: 2, Bias: -181991540565.663361, T: 10112, Avg. loss: 2728930951272342749184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 79 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 164285660507.61, NNZs: 2, Bias: 11010145728.415268, T: 128, Avg. loss: 24445711023822987236707663872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1140870237037.02, NNZs: 2, Bias: 71010145728.415268, T: 256, Avg. loss: 23517687336737333411884040192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 311764865493.45, NNZs: 2, Bias: 51010145728.415268, T: 384, Avg. loss: 23839445736422967036149235712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1111505770408.57, NNZs: 2, Bias: 111010145728.415268, T: 512, Avg. loss: 22525043248312975067153694720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1005972882319.19, NNZs: 2, Bias: 111010145728.415268, T: 640, Avg. loss: 21578295999324501502546935808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1196782148482.91, NNZs: 2, Bias: 71010145728.415283, T: 768, Avg. loss: 22820410111520683421775953920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1133780931901.06, NNZs: 2, Bias: 15048714533.890350, T: 896, Avg. loss: 24930984165744480065182236672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1751255507681.25, NNZs: 2, Bias: -24951285466.109650, T: 1024, Avg. loss: 24635513563381115192801755136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1368337250025.68, NNZs: 2, Bias: -3778047429.754219, T: 1152, Avg. loss: 23850821859772702828645056512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1550562346637.47, NNZs: 2, Bias: -18690326598.071045, T: 1280, Avg. loss: 23663411975010164109903659008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 246932936383.42, NNZs: 2, Bias: -3815949743.250921, T: 1408, Avg. loss: 1487011697817146950751879168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 176819576197.16, NNZs: 2, Bias: -6300041477.882317, T: 1536, Avg. loss: 986794768114925178323992576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 55425851247.82, NNZs: 2, Bias: -15344444468.570114, T: 1664, Avg. loss: 966936040074860843382079488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 266226113408.05, NNZs: 2, Bias: -20408979501.026375, T: 1792, Avg. loss: 931617856054187584661749760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 355695207022.56, NNZs: 2, Bias: -24442640545.614300, T: 1920, Avg. loss: 859337339088641545283305472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 439721477095.15, NNZs: 2, Bias: -26762523483.488342, T: 2048, Avg. loss: 894967739830652445837492224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 204167817493.66, NNZs: 2, Bias: -22688652379.546257, T: 2176, Avg. loss: 968727951273103471994208256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 245510483559.90, NNZs: 2, Bias: -20037325492.736732, T: 2304, Avg. loss: 1004659334182450675020988416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 106076213425.61, NNZs: 2, Bias: -27352344338.770981, T: 2432, Avg. loss: 986111284237683389961863168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 270939554410.59, NNZs: 2, Bias: -35983077765.164108, T: 2560, Avg. loss: 910754837599200721678368768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 103730806044.75, NNZs: 2, Bias: -43362887495.368187, T: 2688, Avg. loss: 37147087529147130613596160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 55627155984.07, NNZs: 2, Bias: -45634321079.729988, T: 2816, Avg. loss: 34420354357036950113746944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 110339323176.59, NNZs: 2, Bias: -47763364404.336914, T: 2944, Avg. loss: 36261006361355318795960320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 67823585315.34, NNZs: 2, Bias: -44392977563.651299, T: 3072, Avg. loss: 36219999692209943526506496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 70812682536.32, NNZs: 2, Bias: -48580665083.648651, T: 3200, Avg. loss: 37994417415204223716425728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 71341191665.81, NNZs: 2, Bias: -47500684874.217010, T: 3328, Avg. loss: 33995698074978444805931008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 56462320173.26, NNZs: 2, Bias: -48387772032.386063, T: 3456, Avg. loss: 33598176725552072853815296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 47706404453.98, NNZs: 2, Bias: -50679379576.643250, T: 3584, Avg. loss: 34567671263035852282920960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 49124849200.01, NNZs: 2, Bias: -51021589466.457275, T: 3712, Avg. loss: 36554430764864077280837632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 71937601576.78, NNZs: 2, Bias: -54470183706.278191, T: 3840, Avg. loss: 32713608903630608819814400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 78639441301.41, NNZs: 2, Bias: -51512305432.894058, T: 3968, Avg. loss: 35504007694153478175719424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 31939900932.90, NNZs: 2, Bias: -51139315369.678185, T: 4096, Avg. loss: 33797880320268382960091136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 20516572524.54, NNZs: 2, Bias: -53037314191.405930, T: 4224, Avg. loss: 33493244303171768402575360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 101834248040.64, NNZs: 2, Bias: -53903286570.525620, T: 4352, Avg. loss: 34208575597980057841172480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6628038913.68, NNZs: 2, Bias: -54996236247.480988, T: 4480, Avg. loss: 37369672834401766830243840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 10423620865.51, NNZs: 2, Bias: -54875155193.523849, T: 4608, Avg. loss: 612158865958295234936832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2389952886.07, NNZs: 2, Bias: -54863478629.522408, T: 4736, Avg. loss: 745536250043158870622208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1246033171.44, NNZs: 2, Bias: -54868142952.642159, T: 4864, Avg. loss: 828241004590226254856192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 11865078039.58, NNZs: 2, Bias: -54901497330.415359, T: 4992, Avg. loss: 695112512563424863977472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 14336660570.77, NNZs: 2, Bias: -55520738416.542671, T: 5120, Avg. loss: 818411456659454339055616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 7624583459.82, NNZs: 2, Bias: -55329139463.557739, T: 5248, Avg. loss: 643404681642836852998144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1109925533.50, NNZs: 2, Bias: -55347047942.189117, T: 5376, Avg. loss: 14333053467775528337408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1001181994.19, NNZs: 2, Bias: -55332122579.005203, T: 5504, Avg. loss: 297571982592852754432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 874404246.46, NNZs: 2, Bias: -55318103662.200111, T: 5632, Avg. loss: 272606324568382111744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 886989837.35, NNZs: 2, Bias: -55301739766.975822, T: 5760, Avg. loss: 268332026364309733376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 836178968.74, NNZs: 2, Bias: -55285223880.103180, T: 5888, Avg. loss: 296668507136092143616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 858705818.83, NNZs: 2, Bias: -55268707663.233261, T: 6016, Avg. loss: 274103724452867571712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 861151473.49, NNZs: 2, Bias: -55252580933.894791, T: 6144, Avg. loss: 280855304316176498688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 805618989.39, NNZs: 2, Bias: -55236625433.448776, T: 6272, Avg. loss: 290054234779159232512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 774505546.49, NNZs: 2, Bias: -55221400548.144348, T: 6400, Avg. loss: 256922031762629918720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 832688137.24, NNZs: 2, Bias: -55205282918.467278, T: 6528, Avg. loss: 249667352060442771456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 830330542.05, NNZs: 2, Bias: -55188132995.138382, T: 6656, Avg. loss: 290679260289776615424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 839534871.43, NNZs: 2, Bias: -55172296435.255173, T: 6784, Avg. loss: 271934993556233158656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 831410923.93, NNZs: 2, Bias: -55156340153.960838, T: 6912, Avg. loss: 268840532300653297664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 812040423.43, NNZs: 2, Bias: -55139792422.812561, T: 7040, Avg. loss: 277143064121919733760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 808677314.47, NNZs: 2, Bias: -55124797703.120583, T: 7168, Avg. loss: 244044248566800842752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 811051617.35, NNZs: 2, Bias: -55108310951.502548, T: 7296, Avg. loss: 273349750345526509568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 811190751.33, NNZs: 2, Bias: -55092032114.716232, T: 7424, Avg. loss: 271982193339607515136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 828383369.23, NNZs: 2, Bias: -55074721627.658691, T: 7552, Avg. loss: 289083778192981753856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 817154412.31, NNZs: 2, Bias: -55057796932.030685, T: 7680, Avg. loss: 296396050476992692224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 797676881.98, NNZs: 2, Bias: -55041768111.151382, T: 7808, Avg. loss: 263934513332755988480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 809158021.91, NNZs: 2, Bias: -55038366421.016624, T: 7936, Avg. loss: 223774977386817748992.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 810671332.98, NNZs: 2, Bias: -55035150944.508774, T: 8064, Avg. loss: 220835687452251914240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 818089256.74, NNZs: 2, Bias: -55031814104.850830, T: 8192, Avg. loss: 223289009156141547520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 810375767.31, NNZs: 2, Bias: -55028762104.262161, T: 8320, Avg. loss: 219176472799935692800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 815554138.13, NNZs: 2, Bias: -55025469650.249222, T: 8448, Avg. loss: 223207918050947203072.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 823424579.46, NNZs: 2, Bias: -55022209794.301643, T: 8576, Avg. loss: 216969276855276929024.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 817362628.33, NNZs: 2, Bias: -55019063001.186226, T: 8704, Avg. loss: 224220092060340813824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 806470546.46, NNZs: 2, Bias: -55015981545.411163, T: 8832, Avg. loss: 224770254240575029248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 807340266.77, NNZs: 2, Bias: -55012787604.024376, T: 8960, Avg. loss: 220225566995285475328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 800593149.67, NNZs: 2, Bias: -55009690600.233795, T: 9088, Avg. loss: 221187832895892127744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 805676990.93, NNZs: 2, Bias: -55006404387.238441, T: 9216, Avg. loss: 222244972639439126528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 812682693.76, NNZs: 2, Bias: -55005661264.628380, T: 9344, Avg. loss: 215726051435529011200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 810109564.69, NNZs: 2, Bias: -55005059057.167877, T: 9472, Avg. loss: 215929433554108350464.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 809919773.72, NNZs: 2, Bias: -55004422473.202682, T: 9600, Avg. loss: 215627116012230508544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 807260569.80, NNZs: 2, Bias: -55003825152.331734, T: 9728, Avg. loss: 214636603687754006528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 810113958.99, NNZs: 2, Bias: -55003142148.673088, T: 9856, Avg. loss: 216125298545610620928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 811906555.48, NNZs: 2, Bias: -55002475672.373840, T: 9984, Avg. loss: 215810383025210720256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 809324458.77, NNZs: 2, Bias: -55001877171.999092, T: 10112, Avg. loss: 214674653215479758848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 809885179.39, NNZs: 2, Bias: -55001227863.083984, T: 10240, Avg. loss: 216179745373560274944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 812799720.61, NNZs: 2, Bias: -55000544725.616089, T: 10368, Avg. loss: 215822087019066228736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 81 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 608603937362.30, NNZs: 2, Bias: -2272446450.706009, T: 128, Avg. loss: 18711468499884205068701925376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1269773084420.37, NNZs: 2, Bias: -10523445881.047470, T: 256, Avg. loss: 22195555073098063853154992128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2178416752687.18, NNZs: 2, Bias: 6187986645.285187, T: 384, Avg. loss: 20551533164262527885683720192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 148622013609.28, NNZs: 2, Bias: -51162014863.175018, T: 512, Avg. loss: 26258666221319527388380397568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2582769068960.72, NNZs: 2, Bias: 8837985136.824982, T: 640, Avg. loss: 19764837515304387646584782848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 418579721179.77, NNZs: 2, Bias: 28837985136.824982, T: 768, Avg. loss: 20747282539407700700050751488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 443249240817.41, NNZs: 2, Bias: 13295810343.907431, T: 896, Avg. loss: 862729553257135020519194624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 44821930417.41, NNZs: 2, Bias: -4522688217.925718, T: 1024, Avg. loss: 967904311025478615085088768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 146977721426.92, NNZs: 2, Bias: -4120693298.164572, T: 1152, Avg. loss: 824483560349294986721755136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 325188090229.72, NNZs: 2, Bias: -13604970229.522917, T: 1280, Avg. loss: 830861760620030246237765632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 114660989800.13, NNZs: 2, Bias: -11120216789.020023, T: 1408, Avg. loss: 772011387442227218269339648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 365701849896.68, NNZs: 2, Bias: -6131224078.026640, T: 1536, Avg. loss: 866398270824668813764591616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 215364529414.76, NNZs: 2, Bias: -15238847002.205153, T: 1664, Avg. loss: 812295609155276058226851840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 207615197823.47, NNZs: 2, Bias: -48463172722.935257, T: 1792, Avg. loss: 807138897762669926759268352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 523308079135.25, NNZs: 2, Bias: -49727562831.166016, T: 1920, Avg. loss: 879800802599153890981052416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 168837448584.84, NNZs: 2, Bias: -73179876469.481659, T: 2048, Avg. loss: 928253423019358902682648576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 5316231378.59, NNZs: 2, Bias: -73071084248.463638, T: 2176, Avg. loss: 38763306637706502720192512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 51907382124.25, NNZs: 2, Bias: -71746871156.963486, T: 2304, Avg. loss: 32933670538634736607166464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 22524638542.61, NNZs: 2, Bias: -74105986977.843521, T: 2432, Avg. loss: 29355066121270368216809472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 15543588190.71, NNZs: 2, Bias: -74227076996.312927, T: 2560, Avg. loss: 30597097532131825925750784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 7913298578.83, NNZs: 2, Bias: -73445004384.615158, T: 2688, Avg. loss: 34972543891196128784285696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 68141321470.80, NNZs: 2, Bias: -71558810725.835114, T: 2816, Avg. loss: 30574025640316413163864064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 16321068505.85, NNZs: 2, Bias: -70742170046.050644, T: 2944, Avg. loss: 33518574862438170963738624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 54118380266.47, NNZs: 2, Bias: -70271845382.766342, T: 3072, Avg. loss: 31621800981740087049977856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 13074625960.00, NNZs: 2, Bias: -69906550509.874222, T: 3200, Avg. loss: 1007101210741384828420096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8730388067.78, NNZs: 2, Bias: -69216066559.151367, T: 3328, Avg. loss: 611341326343881038495744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 6921357984.55, NNZs: 2, Bias: -68920283775.918411, T: 3456, Avg. loss: 438409933375996805775360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1643956515.15, NNZs: 2, Bias: -68858495638.665924, T: 3584, Avg. loss: 604320565367680261947392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4321080898.34, NNZs: 2, Bias: -68685164896.579285, T: 3712, Avg. loss: 512550143441809667260416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5098983614.94, NNZs: 2, Bias: -68577046922.306412, T: 3840, Avg. loss: 329513917145434671808512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10379228454.69, NNZs: 2, Bias: -68676864871.025963, T: 3968, Avg. loss: 634228963204387628384256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8065885473.10, NNZs: 2, Bias: -68553134106.842232, T: 4096, Avg. loss: 505686194153571286515712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 15143324558.66, NNZs: 2, Bias: -68343337199.549698, T: 4224, Avg. loss: 519959642743628292423680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 5609008256.60, NNZs: 2, Bias: -68321715128.323700, T: 4352, Avg. loss: 535770560402696647475200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11268973047.96, NNZs: 2, Bias: -68294231320.232796, T: 4480, Avg. loss: 472877659359431324860416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 716984694.80, NNZs: 2, Bias: -68198788940.544914, T: 4608, Avg. loss: 37218675836964455841792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 849632177.11, NNZs: 2, Bias: -68172512715.731819, T: 4736, Avg. loss: 481921288715166351360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 981696081.75, NNZs: 2, Bias: -68146261889.734001, T: 4864, Avg. loss: 497251035184574431232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1051675815.71, NNZs: 2, Bias: -68121274433.573196, T: 4992, Avg. loss: 499242780182980329472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1020027322.29, NNZs: 2, Bias: -68097593441.803101, T: 5120, Avg. loss: 515115244057219497984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1110633356.53, NNZs: 2, Bias: -68073551308.192230, T: 5248, Avg. loss: 467741079446868852736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1150721955.19, NNZs: 2, Bias: -68050059697.492226, T: 5376, Avg. loss: 459850945380902305792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1127377193.17, NNZs: 2, Bias: -68027010917.486549, T: 5504, Avg. loss: 471460290418588516352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1189635280.78, NNZs: 2, Bias: -68003586579.850380, T: 5632, Avg. loss: 436587062808477827072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1151824976.94, NNZs: 2, Bias: -67981335338.410446, T: 5760, Avg. loss: 489051469498793984000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1076067639.29, NNZs: 2, Bias: -67956929075.318565, T: 5888, Avg. loss: 551349536769054736384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1029003668.24, NNZs: 2, Bias: -67934143426.718849, T: 6016, Avg. loss: 480872324039913963520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1041192096.92, NNZs: 2, Bias: -67909869742.904602, T: 6144, Avg. loss: 502471330054375538688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1018167733.94, NNZs: 2, Bias: -67886992735.904030, T: 6272, Avg. loss: 473245692449427750912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1056606687.78, NNZs: 2, Bias: -67881284586.090027, T: 6400, Avg. loss: 437472879259472429056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1061858285.83, NNZs: 2, Bias: -67876480265.571152, T: 6528, Avg. loss: 403015046426581729280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1079105715.36, NNZs: 2, Bias: -67871526495.550514, T: 6656, Avg. loss: 398393450224772972544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1073729680.35, NNZs: 2, Bias: -67866839538.321945, T: 6784, Avg. loss: 407158854184557215744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1077189087.85, NNZs: 2, Bias: -67862023376.439362, T: 6912, Avg. loss: 405565902379191304192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1084268811.70, NNZs: 2, Bias: -67857094949.201996, T: 7040, Avg. loss: 410615068815454502912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1077129016.63, NNZs: 2, Bias: -67852470000.367531, T: 7168, Avg. loss: 405178046945706639360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1085374238.53, NNZs: 2, Bias: -67847554209.215080, T: 7296, Avg. loss: 408173968977394597888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1079558974.31, NNZs: 2, Bias: -67846701694.691513, T: 7424, Avg. loss: 393333716707421454336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1082216302.88, NNZs: 2, Bias: -67845702702.575371, T: 7552, Avg. loss: 397836506607525822464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1079680192.28, NNZs: 2, Bias: -67844790989.797073, T: 7680, Avg. loss: 396110092321320271872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1085322277.84, NNZs: 2, Bias: -67843748177.574173, T: 7808, Avg. loss: 396103212432059793408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1085042131.70, NNZs: 2, Bias: -67842797752.484108, T: 7936, Avg. loss: 397173232870690652160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1086787598.36, NNZs: 2, Bias: -67841817825.182976, T: 8064, Avg. loss: 395854592360053735424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 63 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 559936467370.37, NNZs: 2, Bias: 41365188375.404366, T: 128, Avg. loss: 17956226987264497668723834880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 571449867724.54, NNZs: 2, Bias: 116599185564.346771, T: 256, Avg. loss: 20503080922877783529219948544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 400302780815.34, NNZs: 2, Bias: 82963777637.639313, T: 384, Avg. loss: 18623277436690229805589725184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 830899600442.83, NNZs: 2, Bias: 108973705078.432617, T: 512, Avg. loss: 19634864554206787773705224192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1087915770206.92, NNZs: 2, Bias: 124772171862.296814, T: 640, Avg. loss: 20647387067237850236325986304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1382863938927.11, NNZs: 2, Bias: 84772171862.296814, T: 768, Avg. loss: 18802570803063625635038494720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 271218093585.19, NNZs: 2, Bias: 102220251969.199966, T: 896, Avg. loss: 1054194901520422923661213696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 117657816762.05, NNZs: 2, Bias: 107793841034.573471, T: 1024, Avg. loss: 834614811169952209171382272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 277539274272.00, NNZs: 2, Bias: 107472809592.024155, T: 1152, Avg. loss: 763483409490032574280499200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 296641390895.84, NNZs: 2, Bias: 114671838160.060715, T: 1280, Avg. loss: 810154236709831900802318336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 247418457786.06, NNZs: 2, Bias: 119403872501.093063, T: 1408, Avg. loss: 806594817214588108104794112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 198006284338.76, NNZs: 2, Bias: 113963829097.718887, T: 1536, Avg. loss: 802705136984962799585198080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 189243553653.43, NNZs: 2, Bias: 131829588980.155106, T: 1664, Avg. loss: 802482089731392434385977344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 263842479403.20, NNZs: 2, Bias: 139653019569.191315, T: 1792, Avg. loss: 771105525301962853417222144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 59590936292.89, NNZs: 2, Bias: 138399054384.148041, T: 1920, Avg. loss: 45970529092510160707911680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 81026329585.59, NNZs: 2, Bias: 135936823678.582809, T: 2048, Avg. loss: 27894881896173477157666816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 44694156591.92, NNZs: 2, Bias: 136593337036.101151, T: 2176, Avg. loss: 34049393638545840450568192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 75136392541.30, NNZs: 2, Bias: 135049077255.903412, T: 2304, Avg. loss: 26172647331964181370896384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 32388689535.20, NNZs: 2, Bias: 135131848992.355682, T: 2432, Avg. loss: 31434817591231333269504000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 42592860469.43, NNZs: 2, Bias: 132641062135.180862, T: 2560, Avg. loss: 29279168722954997003714560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 33366215103.86, NNZs: 2, Bias: 129115231450.948471, T: 2688, Avg. loss: 29995243972455713034207232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 35825236169.54, NNZs: 2, Bias: 130335675751.405487, T: 2816, Avg. loss: 29288188032778036693696512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 21235801243.57, NNZs: 2, Bias: 128490251709.772491, T: 2944, Avg. loss: 26926541567285291814748160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4987022422.59, NNZs: 2, Bias: 128145799004.742432, T: 3072, Avg. loss: 600153907373395513704448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 3657168837.67, NNZs: 2, Bias: 128150940139.249252, T: 3200, Avg. loss: 527685821051082419208192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1398143057.79, NNZs: 2, Bias: 127986249540.911575, T: 3328, Avg. loss: 302899669917499509440512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 9092250099.28, NNZs: 2, Bias: 127794515324.570755, T: 3456, Avg. loss: 654148225596027022868480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9594438542.45, NNZs: 2, Bias: 127440722115.616135, T: 3584, Avg. loss: 551483896851464401715200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3552439390.30, NNZs: 2, Bias: 127357736691.048721, T: 3712, Avg. loss: 587436508326221202849792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4176486111.18, NNZs: 2, Bias: 127235929732.193085, T: 3840, Avg. loss: 540688563256887986880512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4286040356.50, NNZs: 2, Bias: 126544925108.758438, T: 3968, Avg. loss: 478566708152951724048384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 312153033.57, NNZs: 2, Bias: 126494826743.560104, T: 4096, Avg. loss: 5279784922788107649024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1090643006.86, NNZs: 2, Bias: 126435147826.587372, T: 4224, Avg. loss: 2011050166902509273088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1515127434.62, NNZs: 2, Bias: 126382511864.547745, T: 4352, Avg. loss: 1919517367487064440832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1828142299.07, NNZs: 2, Bias: 126333560855.796051, T: 4480, Avg. loss: 1752851832431986081792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1957911603.31, NNZs: 2, Bias: 126289095356.120972, T: 4608, Avg. loss: 1609109396125924458496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1851163579.38, NNZs: 2, Bias: 126243732425.286041, T: 4736, Avg. loss: 1869029052979066961920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2003497349.19, NNZs: 2, Bias: 126199348930.684784, T: 4864, Avg. loss: 1635715453225670279168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2177145245.47, NNZs: 2, Bias: 126155878707.027802, T: 4992, Avg. loss: 1587988778473014689792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2132842124.39, NNZs: 2, Bias: 126114146808.370590, T: 5120, Avg. loss: 1636378052026936852480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2081143983.28, NNZs: 2, Bias: 126069808429.661392, T: 5248, Avg. loss: 1758590280188560932864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1975624415.22, NNZs: 2, Bias: 126027885275.891022, T: 5376, Avg. loss: 1722195360332613419008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1888495498.58, NNZs: 2, Bias: 125985775567.952835, T: 5504, Avg. loss: 1761311669663370051584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2103633861.42, NNZs: 2, Bias: 125938819160.088394, T: 5632, Avg. loss: 1763853046626054045696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1992098953.75, NNZs: 2, Bias: 125931781750.671402, T: 5760, Avg. loss: 1412738008895153504256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2001380940.15, NNZs: 2, Bias: 125923315594.595856, T: 5888, Avg. loss: 1322269894494589550592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2008834067.37, NNZs: 2, Bias: 125914731159.146301, T: 6016, Avg. loss: 1344877254219407818752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2023685953.90, NNZs: 2, Bias: 125906195956.193588, T: 6144, Avg. loss: 1311219047716080058368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2025247601.43, NNZs: 2, Bias: 125897715341.299210, T: 6272, Avg. loss: 1341954788866666266624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1973485993.59, NNZs: 2, Bias: 125890070206.805725, T: 6400, Avg. loss: 1348020196647679819776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2013312504.55, NNZs: 2, Bias: 125880921130.337021, T: 6528, Avg. loss: 1348169739035966701568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1997192336.12, NNZs: 2, Bias: 125872543441.357834, T: 6656, Avg. loss: 1374621670381404291072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2003748699.91, NNZs: 2, Bias: 125863914680.628418, T: 6784, Avg. loss: 1351928479121673814016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2008173076.18, NNZs: 2, Bias: 125862146567.588928, T: 6912, Avg. loss: 1310317926618601357312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2005761752.05, NNZs: 2, Bias: 125860487111.605377, T: 7040, Avg. loss: 1310981301432576901120.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2005642513.92, NNZs: 2, Bias: 125858788174.102478, T: 7168, Avg. loss: 1313101958883426959360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2010660581.77, NNZs: 2, Bias: 125857012282.758331, T: 7296, Avg. loss: 1308978713784364564480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2013711651.34, NNZs: 2, Bias: 125855267120.768738, T: 7424, Avg. loss: 1309430605783546200064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2003471643.45, NNZs: 2, Bias: 125853732735.861282, T: 7552, Avg. loss: 1311201438938237763584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2001699391.74, NNZs: 2, Bias: 125852065180.105164, T: 7680, Avg. loss: 1309143716212955414528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2009851091.64, NNZs: 2, Bias: 125850236144.641388, T: 7808, Avg. loss: 1311187062584502910976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2009386053.65, NNZs: 2, Bias: 125848545273.688126, T: 7936, Avg. loss: 1311073527899616182272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 62 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1289164248636.59, NNZs: 2, Bias: -8222753232.041428, T: 128, Avg. loss: 20029606447679052043496980480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1662007421727.34, NNZs: 2, Bias: -8222753232.041428, T: 256, Avg. loss: 23152561432792320896141361152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1254942830929.07, NNZs: 2, Bias: -8222753232.041428, T: 384, Avg. loss: 21861523703864960732117336064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1150992557408.76, NNZs: 2, Bias: -48222753232.041428, T: 512, Avg. loss: 22490835853847660706985410560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1973464159382.48, NNZs: 2, Bias: 35816712708.432281, T: 640, Avg. loss: 21268044213214462766156349440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1773422020158.57, NNZs: 2, Bias: 24836366192.022354, T: 768, Avg. loss: 19747091504981000828401745920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 910897487677.14, NNZs: 2, Bias: 44836366192.022354, T: 896, Avg. loss: 22325089785697708744149827584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1722721288584.63, NNZs: 2, Bias: -71751983131.996246, T: 1024, Avg. loss: 21057542933138877568753074176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1744004783514.98, NNZs: 2, Bias: -76665812238.994629, T: 1152, Avg. loss: 22022858492065178939262238720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1502818235263.22, NNZs: 2, Bias: 43334187761.005371, T: 1280, Avg. loss: 21758214479520009454312488960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1771098516036.89, NNZs: 2, Bias: 158809799186.034027, T: 1408, Avg. loss: 20442543638585329995151835136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 94590982942.72, NNZs: 2, Bias: 156631693635.092926, T: 1536, Avg. loss: 1630507870405249810049269760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 449326928258.04, NNZs: 2, Bias: 154216773631.253510, T: 1664, Avg. loss: 825707210100038236576415744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 350864297397.41, NNZs: 2, Bias: 150269057077.890869, T: 1792, Avg. loss: 801401733289130202889191424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 219382485708.66, NNZs: 2, Bias: 145926159012.961395, T: 1920, Avg. loss: 870207439165705042876432384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 282696330232.07, NNZs: 2, Bias: 165190536347.083221, T: 2048, Avg. loss: 806836082831396681453404160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 129703990880.09, NNZs: 2, Bias: 176739303923.244202, T: 2176, Avg. loss: 888437681223139065386237952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 448490994539.53, NNZs: 2, Bias: 181212108534.376526, T: 2304, Avg. loss: 698675235702988506134478848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 554236735848.61, NNZs: 2, Bias: 185112250446.945221, T: 2432, Avg. loss: 836259580725710963576143872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 75503287245.48, NNZs: 2, Bias: 202552470996.368378, T: 2560, Avg. loss: 926983823533007067735392256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 216580852336.93, NNZs: 2, Bias: 209222670380.095551, T: 2688, Avg. loss: 805306816601935865773555712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 196628294585.89, NNZs: 2, Bias: 199140330749.912872, T: 2816, Avg. loss: 879519903966557145906806784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 386738025119.56, NNZs: 2, Bias: 206914530998.446716, T: 2944, Avg. loss: 718232229564517169615601664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 54033071968.30, NNZs: 2, Bias: 200387188376.643860, T: 3072, Avg. loss: 63676792363837252329013248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 60665139376.86, NNZs: 2, Bias: 198253265634.294250, T: 3200, Avg. loss: 30935245981117872831725568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 106691061146.97, NNZs: 2, Bias: 195520662754.678528, T: 3328, Avg. loss: 32541619082412604111454208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 26313034400.52, NNZs: 2, Bias: 196328559746.606476, T: 3456, Avg. loss: 30890470766416456373501952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 55107477814.31, NNZs: 2, Bias: 196604932554.245178, T: 3584, Avg. loss: 30740393200616361762488320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 60217591248.64, NNZs: 2, Bias: 196809153502.036102, T: 3712, Avg. loss: 30109482178164723195838464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 51453386382.57, NNZs: 2, Bias: 192590908941.961090, T: 3840, Avg. loss: 31898974255961581228654592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 28438417894.16, NNZs: 2, Bias: 195168495180.751648, T: 3968, Avg. loss: 29032474458153868087787520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 47250779846.13, NNZs: 2, Bias: 192582478370.843964, T: 4096, Avg. loss: 34120922796717362812813312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 45829732718.62, NNZs: 2, Bias: 189240487732.569336, T: 4224, Avg. loss: 30276750479651745837350912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 34410154759.50, NNZs: 2, Bias: 187701627026.719116, T: 4352, Avg. loss: 34226554343196138546397184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 47181787893.80, NNZs: 2, Bias: 187643316052.982361, T: 4480, Avg. loss: 29211040596749491109888000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 62751682860.92, NNZs: 2, Bias: 186575075869.731628, T: 4608, Avg. loss: 30041475105187004191604736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2631372233.86, NNZs: 2, Bias: 185121084839.268829, T: 4736, Avg. loss: 1729446491728403106889728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2867498923.93, NNZs: 2, Bias: 184954601285.566467, T: 4864, Avg. loss: 616571660180547593830400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2680498621.90, NNZs: 2, Bias: 184603658958.830963, T: 4992, Avg. loss: 598912243740058929070080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7484381268.22, NNZs: 2, Bias: 183930230733.195709, T: 5120, Avg. loss: 580272791014494003265536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 7269452372.35, NNZs: 2, Bias: 183630579421.700104, T: 5248, Avg. loss: 707530736799074847031296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6001542461.07, NNZs: 2, Bias: 183614122618.841156, T: 5376, Avg. loss: 545500218905380331192320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 15730269554.82, NNZs: 2, Bias: 183449492812.162476, T: 5504, Avg. loss: 521589176620422099107840.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9642312712.38, NNZs: 2, Bias: 183414345397.891510, T: 5632, Avg. loss: 530658326397260868354048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2941642412.87, NNZs: 2, Bias: 183224029190.752106, T: 5760, Avg. loss: 620381607183148579291136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9567984440.80, NNZs: 2, Bias: 182910364437.102722, T: 5888, Avg. loss: 569476076830617977749504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 13459314162.65, NNZs: 2, Bias: 182690619964.389099, T: 6016, Avg. loss: 672846969410212799184896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1677524224.77, NNZs: 2, Bias: 182189567682.599854, T: 6144, Avg. loss: 585184802666436630675456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1339068299.23, NNZs: 2, Bias: 182112002761.682129, T: 6272, Avg. loss: 4066476665818479853568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2200848269.44, NNZs: 2, Bias: 182040425200.595337, T: 6400, Avg. loss: 3301785993681076486144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2665144118.54, NNZs: 2, Bias: 181976310706.593109, T: 6528, Avg. loss: 3101741286233402769408.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3032566944.49, NNZs: 2, Bias: 181914000922.084961, T: 6656, Avg. loss: 3056738186176165838848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3066062498.72, NNZs: 2, Bias: 181853455884.287079, T: 6784, Avg. loss: 3402460762045808640000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3102940353.50, NNZs: 2, Bias: 181793825302.438904, T: 6912, Avg. loss: 3296752349628412198912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3114607974.46, NNZs: 2, Bias: 181736977391.781708, T: 7040, Avg. loss: 3220921901787534327808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3042170437.28, NNZs: 2, Bias: 181678863016.661346, T: 7168, Avg. loss: 3403681056210056380416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3276708664.77, NNZs: 2, Bias: 181621792655.976776, T: 7296, Avg. loss: 2825595067847594213376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3126376460.15, NNZs: 2, Bias: 181567214399.452179, T: 7424, Avg. loss: 3190410874178152431616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3113742124.26, NNZs: 2, Bias: 181512812304.781097, T: 7552, Avg. loss: 2980729597658735312896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3162516667.44, NNZs: 2, Bias: 181457105709.299866, T: 7680, Avg. loss: 3151093293115667120128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3068039510.76, NNZs: 2, Bias: 181401517902.444061, T: 7808, Avg. loss: 3120045144878991540224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2868983385.18, NNZs: 2, Bias: 181346722478.341522, T: 7936, Avg. loss: 3385377380658175803392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2948064354.88, NNZs: 2, Bias: 181333754712.627014, T: 8064, Avg. loss: 2667539854946921349120.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2971442579.39, NNZs: 2, Bias: 181322078325.001556, T: 8192, Avg. loss: 2576675794706658492416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2983092797.25, NNZs: 2, Bias: 181310293828.040161, T: 8320, Avg. loss: 2649034328058606649344.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3043113266.23, NNZs: 2, Bias: 181298044026.049225, T: 8448, Avg. loss: 2561114024394857906176.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3039361735.21, NNZs: 2, Bias: 181286613202.905151, T: 8576, Avg. loss: 2621845617973550120960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3046850189.02, NNZs: 2, Bias: 181274964093.121521, T: 8704, Avg. loss: 2627295533646973763584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3070534860.01, NNZs: 2, Bias: 181263159981.521912, T: 8832, Avg. loss: 2604153493065101213696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3028566303.04, NNZs: 2, Bias: 181252545775.814880, T: 8960, Avg. loss: 2587343619041289830400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 3068280172.41, NNZs: 2, Bias: 181240618491.287292, T: 9088, Avg. loss: 2573485732100653449216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 3077231054.69, NNZs: 2, Bias: 181238199132.301605, T: 9216, Avg. loss: 2518677288437958574080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 3072422212.54, NNZs: 2, Bias: 181236010172.593201, T: 9344, Avg. loss: 2522705910309673500672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 3083696372.46, NNZs: 2, Bias: 181233547010.906311, T: 9472, Avg. loss: 2522936156737354858496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 3083333916.65, NNZs: 2, Bias: 181231279935.600281, T: 9600, Avg. loss: 2525332612826544472064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 3080968480.28, NNZs: 2, Bias: 181229046714.360779, T: 9728, Avg. loss: 2525670148330279141376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 3087262335.92, NNZs: 2, Bias: 181226668391.154755, T: 9856, Avg. loss: 2522686731241693118464.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 77 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1702906572833.81, NNZs: 2, Bias: 37261170096.079529, T: 128, Avg. loss: 20954343367777097476544135168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 370157124243.00, NNZs: 2, Bias: 33228257885.430878, T: 256, Avg. loss: 21719345772142046096067133440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1419663235567.86, NNZs: 2, Bias: 61496276016.087936, T: 384, Avg. loss: 22409484970880067028421443584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1868886197710.45, NNZs: 2, Bias: -55171225823.154327, T: 512, Avg. loss: 24783844851883079272469889024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1839915677223.45, NNZs: 2, Bias: -70890633796.903320, T: 640, Avg. loss: 22535183033574970423896965120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 896248765679.05, NNZs: 2, Bias: -90890633796.903320, T: 768, Avg. loss: 22639984843364012528309895168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 33203937552.65, NNZs: 2, Bias: -104255460196.269363, T: 896, Avg. loss: 975236502687382390177792000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 379686039601.28, NNZs: 2, Bias: -97890863025.074112, T: 1024, Avg. loss: 843432584797751216839852032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 92317336834.52, NNZs: 2, Bias: -83872004022.682449, T: 1152, Avg. loss: 904953321950950155639324672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 261462462162.65, NNZs: 2, Bias: -77412990023.243134, T: 1280, Avg. loss: 900269771991671226335494144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 163535504876.83, NNZs: 2, Bias: -78499510157.432053, T: 1408, Avg. loss: 967786251701733584694935552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 249019031070.59, NNZs: 2, Bias: -69071600499.928223, T: 1536, Avg. loss: 845319395512890562900393984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 133118686435.77, NNZs: 2, Bias: -64446409741.419594, T: 1664, Avg. loss: 904359631118547912109326336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 40541794081.75, NNZs: 2, Bias: -66077164752.650719, T: 1792, Avg. loss: 35908160029858813414735872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 23017534065.53, NNZs: 2, Bias: -66401777971.304642, T: 1920, Avg. loss: 32956911395518138804076544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 36121758364.01, NNZs: 2, Bias: -65863596979.046600, T: 2048, Avg. loss: 33744127723040440720556032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 84305393740.37, NNZs: 2, Bias: -68717900082.520676, T: 2176, Avg. loss: 31768430753415532904448000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 78845610060.29, NNZs: 2, Bias: -69785103023.793839, T: 2304, Avg. loss: 33279938505096560505782272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 31064059485.32, NNZs: 2, Bias: -68558510641.560349, T: 2432, Avg. loss: 33665506086109945710772224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 40359450053.92, NNZs: 2, Bias: -69937813783.385101, T: 2560, Avg. loss: 34125318021992706383806464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 73295905742.80, NNZs: 2, Bias: -70001786415.731415, T: 2688, Avg. loss: 30702516299905970970034176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 34088413207.73, NNZs: 2, Bias: -69603796093.583221, T: 2816, Avg. loss: 34223452197806540488441856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 19494752586.60, NNZs: 2, Bias: -65527608992.486855, T: 2944, Avg. loss: 33144858881643948485378048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 63322296402.85, NNZs: 2, Bias: -66304953869.389969, T: 3072, Avg. loss: 34484958800687754773528576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 28526443761.98, NNZs: 2, Bias: -64890640363.352165, T: 3200, Avg. loss: 33602591487070033019928576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 37952150071.44, NNZs: 2, Bias: -61708808764.933189, T: 3328, Avg. loss: 30263644322238435417915392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 51333196959.61, NNZs: 2, Bias: -62864580071.655617, T: 3456, Avg. loss: 35515747069191664103849984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 50500016997.50, NNZs: 2, Bias: -62510437249.005882, T: 3584, Avg. loss: 34845836270992254952275968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 59542286229.97, NNZs: 2, Bias: -66081910066.109703, T: 3712, Avg. loss: 30461198145059439933128704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 36951746904.43, NNZs: 2, Bias: -68261417002.065811, T: 3840, Avg. loss: 38094573471932130430812160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102996592143.50, NNZs: 2, Bias: -71418994032.748581, T: 3968, Avg. loss: 35369194091795117296844800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8936144560.85, NNZs: 2, Bias: -72639106694.243439, T: 4096, Avg. loss: 3203129118004513058324480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 10522548522.67, NNZs: 2, Bias: -72623984252.126175, T: 4224, Avg. loss: 561050512065252982521856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9965122251.42, NNZs: 2, Bias: -72599379950.672379, T: 4352, Avg. loss: 593163215780647484260352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7135346275.01, NNZs: 2, Bias: -72300414942.571564, T: 4480, Avg. loss: 622499172641338373963776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3614836980.79, NNZs: 2, Bias: -71954690253.319931, T: 4608, Avg. loss: 617584283004132510400512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4940180637.94, NNZs: 2, Bias: -71629623206.733368, T: 4736, Avg. loss: 556188172812946740609024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4184378438.68, NNZs: 2, Bias: -71732097201.121857, T: 4864, Avg. loss: 711295330252116551794688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 8604441047.32, NNZs: 2, Bias: -71425147251.259720, T: 4992, Avg. loss: 664361943843496777482240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2652842727.13, NNZs: 2, Bias: -71935725446.886780, T: 5120, Avg. loss: 674947369406018789310464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2184827819.47, NNZs: 2, Bias: -71939233293.018265, T: 5248, Avg. loss: 701360361177314827960320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 5174490342.17, NNZs: 2, Bias: -71618243407.107727, T: 5376, Avg. loss: 657743124170710253043712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2788950910.64, NNZs: 2, Bias: -71628461893.309036, T: 5504, Avg. loss: 3397252157974300327936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1888693810.61, NNZs: 2, Bias: -71617106970.226166, T: 5632, Avg. loss: 1029819898652096724992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1512985902.36, NNZs: 2, Bias: -71598247055.831314, T: 5760, Avg. loss: 660069282121653157888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1354020670.38, NNZs: 2, Bias: -71576095152.538315, T: 5888, Avg. loss: 587554500841742729216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1230673637.21, NNZs: 2, Bias: -71554408672.825851, T: 6016, Avg. loss: 529738705543943159808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1218355802.50, NNZs: 2, Bias: -71530428016.654831, T: 6144, Avg. loss: 569354334805091221504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1106952153.53, NNZs: 2, Bias: -71507601810.691193, T: 6272, Avg. loss: 547884073439841157120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1109540177.54, NNZs: 2, Bias: -71483996223.345856, T: 6400, Avg. loss: 514756117078304227328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1083589281.06, NNZs: 2, Bias: -71459235183.244598, T: 6528, Avg. loss: 561808003332419289088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1076692667.28, NNZs: 2, Bias: -71435974346.538406, T: 6656, Avg. loss: 514925328760252071936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1064252299.36, NNZs: 2, Bias: -71412679186.668747, T: 6784, Avg. loss: 525582262642235146240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1141734141.13, NNZs: 2, Bias: -71387666036.350479, T: 6912, Avg. loss: 519401727533160398848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1071004817.04, NNZs: 2, Bias: -71363740212.624542, T: 7040, Avg. loss: 560369015431689863168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1064322922.09, NNZs: 2, Bias: -71358961110.650711, T: 7168, Avg. loss: 439409974746042531840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1083494526.91, NNZs: 2, Bias: -71353831902.049835, T: 7296, Avg. loss: 434829509775047196672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1079246378.18, NNZs: 2, Bias: -71349210195.416061, T: 7424, Avg. loss: 420181903373695123456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1083634973.11, NNZs: 2, Bias: -71344294179.962128, T: 7552, Avg. loss: 436360109565221601280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1089983798.48, NNZs: 2, Bias: -71339328343.859543, T: 7680, Avg. loss: 437583547505196793856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1086292090.32, NNZs: 2, Bias: -71334561163.333206, T: 7808, Avg. loss: 434197103016132739072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1088755359.98, NNZs: 2, Bias: -71329723767.650711, T: 7936, Avg. loss: 431343106392736858112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1106136565.94, NNZs: 2, Bias: -71324668615.792648, T: 8064, Avg. loss: 430090579735357292544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1090116092.57, NNZs: 2, Bias: -71323939174.885635, T: 8192, Avg. loss: 427575255492959993856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1094351299.43, NNZs: 2, Bias: -71322917192.507751, T: 8320, Avg. loss: 418627236608785383424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1094051118.02, NNZs: 2, Bias: -71321960573.044312, T: 8448, Avg. loss: 420509040524637634560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1089884811.92, NNZs: 2, Bias: -71321063121.319870, T: 8576, Avg. loss: 420663429331063406592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1090223891.56, NNZs: 2, Bias: -71320098606.835983, T: 8704, Avg. loss: 419677648318065737728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1092069709.88, NNZs: 2, Bias: -71319110876.504364, T: 8832, Avg. loss: 419700112455551287296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1087523136.37, NNZs: 2, Bias: -71318228106.299759, T: 8960, Avg. loss: 416674590416622452736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1091564060.07, NNZs: 2, Bias: -71317204643.226288, T: 9088, Avg. loss: 420648721998733901824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1091973567.06, NNZs: 2, Bias: -71316236815.357635, T: 9216, Avg. loss: 420625333824651984896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1094586686.03, NNZs: 2, Bias: -71315235422.036194, T: 9344, Avg. loss: 420489455738638893056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1090736904.54, NNZs: 2, Bias: -71314337974.211853, T: 9472, Avg. loss: 418456418884534337536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1098453184.85, NNZs: 2, Bias: -71313259365.649399, T: 9600, Avg. loss: 419807365981569155072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 783553121088.25, NNZs: 2, Bias: 1128657729.526894, T: 128, Avg. loss: 23141005706270619861335932928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 740689293465.35, NNZs: 2, Bias: -62409193704.479248, T: 256, Avg. loss: 23324260587991503166605623296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1840536922548.71, NNZs: 2, Bias: -47054733624.301758, T: 384, Avg. loss: 23914755467560317535362482176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 937013177624.80, NNZs: 2, Bias: 3178928935.764610, T: 512, Avg. loss: 24581112687539403139886088192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2182688346413.66, NNZs: 2, Bias: 63178928935.764618, T: 640, Avg. loss: 24475982930547917114530856960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 936358977656.80, NNZs: 2, Bias: 60541163749.813919, T: 768, Avg. loss: 23252082558585318025000386560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 226710776796.85, NNZs: 2, Bias: 74856764428.968643, T: 896, Avg. loss: 1169931314137868793236422656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 223517977061.77, NNZs: 2, Bias: 86202511382.612762, T: 1024, Avg. loss: 983676131377776373757116416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 410562323199.04, NNZs: 2, Bias: 78125377710.217407, T: 1152, Avg. loss: 905572583259161016175427584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 142948631666.14, NNZs: 2, Bias: 79566351742.063965, T: 1280, Avg. loss: 976637165403137331376947200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 311340919879.26, NNZs: 2, Bias: 69938160542.939545, T: 1408, Avg. loss: 882269484193988588412600320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 340386667975.63, NNZs: 2, Bias: 79007511386.962509, T: 1536, Avg. loss: 935189526558984297062072320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 130339493746.14, NNZs: 2, Bias: 87467891586.304840, T: 1664, Avg. loss: 993620304088500191497289728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 196977203433.27, NNZs: 2, Bias: 83091651099.565979, T: 1792, Avg. loss: 865510843792831074021670912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 154147136946.63, NNZs: 2, Bias: 76341171650.125336, T: 1920, Avg. loss: 833845104815399108566056960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 229238127866.95, NNZs: 2, Bias: 85559147361.229248, T: 2048, Avg. loss: 1010628333692993196286541824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 425292793769.62, NNZs: 2, Bias: 84559575692.152740, T: 2176, Avg. loss: 991451957790172336900538368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 334129909596.03, NNZs: 2, Bias: 90526520814.872543, T: 2304, Avg. loss: 989575196222509120808288256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 86710072873.27, NNZs: 2, Bias: 97925871247.196930, T: 2432, Avg. loss: 974195291360419729442340864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 241764204891.19, NNZs: 2, Bias: 94068873416.180923, T: 2560, Avg. loss: 894027834573219400402337792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 63743346376.95, NNZs: 2, Bias: 97340021389.705933, T: 2688, Avg. loss: 38674901092348603679113216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 32604863336.55, NNZs: 2, Bias: 95888242204.218338, T: 2816, Avg. loss: 32519005892082755983900672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 84391494085.88, NNZs: 2, Bias: 94497996216.837524, T: 2944, Avg. loss: 34816739761785343230083072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 57251500522.52, NNZs: 2, Bias: 93165009540.814987, T: 3072, Avg. loss: 38031170051506974327046144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 60054371517.74, NNZs: 2, Bias: 91345829825.409790, T: 3200, Avg. loss: 36659345476287837153263616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 35890541214.22, NNZs: 2, Bias: 92827741780.580582, T: 3328, Avg. loss: 36683421075556043000381440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 42667273866.25, NNZs: 2, Bias: 92324984990.536255, T: 3456, Avg. loss: 37508358041314410864050176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 17019114627.54, NNZs: 2, Bias: 92069491433.218842, T: 3584, Avg. loss: 1053145797306405017878528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8893619967.92, NNZs: 2, Bias: 91706820448.165405, T: 3712, Avg. loss: 726867014237448000503808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2364896131.18, NNZs: 2, Bias: 91722476157.641678, T: 3840, Avg. loss: 669408867184556292177920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2984419730.21, NNZs: 2, Bias: 91363362265.460831, T: 3968, Avg. loss: 660983486950904311054336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6138188552.57, NNZs: 2, Bias: 91048530483.460144, T: 4096, Avg. loss: 707900439894039321378816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 10621712368.48, NNZs: 2, Bias: 90763596091.565338, T: 4224, Avg. loss: 653573081349023743344640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 10172053472.84, NNZs: 2, Bias: 90783938336.187378, T: 4352, Avg. loss: 648323222013630543298560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 12751365997.49, NNZs: 2, Bias: 90541209883.167023, T: 4480, Avg. loss: 725927060763198160371712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4427219592.14, NNZs: 2, Bias: 90384006458.124954, T: 4608, Avg. loss: 673420551273243505328128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 7868992304.29, NNZs: 2, Bias: 90432567210.002319, T: 4736, Avg. loss: 611997077831851278598144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3241450208.31, NNZs: 2, Bias: 90429013253.741547, T: 4864, Avg. loss: 701674053228090303184896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3658756322.04, NNZs: 2, Bias: 90364560268.157700, T: 4992, Avg. loss: 684716092951755382325248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3357539247.52, NNZs: 2, Bias: 89955909459.296249, T: 5120, Avg. loss: 690212127063448066457600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1489783632.83, NNZs: 2, Bias: 90183091185.013290, T: 5248, Avg. loss: 684663254057650197889024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 5621368525.24, NNZs: 2, Bias: 90079934457.920639, T: 5376, Avg. loss: 712466202230488519671808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2502929626.74, NNZs: 2, Bias: 90002854815.356461, T: 5504, Avg. loss: 5915155849483270488064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 803719385.87, NNZs: 2, Bias: 89955384665.041473, T: 5632, Avg. loss: 2145163087122241945600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 412768205.48, NNZs: 2, Bias: 89916760939.674377, T: 5760, Avg. loss: 1054197562432264863744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 845692749.89, NNZs: 2, Bias: 89882689595.933365, T: 5888, Avg. loss: 796503332129382072320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1002843539.79, NNZs: 2, Bias: 89852901466.934692, T: 6016, Avg. loss: 770436631204649500672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1172675379.90, NNZs: 2, Bias: 89822557735.683212, T: 6144, Avg. loss: 770976961624293113856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1223841743.56, NNZs: 2, Bias: 89795393909.336807, T: 6272, Avg. loss: 742039155842240741376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1263588337.30, NNZs: 2, Bias: 89769920863.600464, T: 6400, Avg. loss: 663775394812465119232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1281413208.04, NNZs: 2, Bias: 89742210689.748840, T: 6528, Avg. loss: 753196832354547269632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1367101269.38, NNZs: 2, Bias: 89716456648.926392, T: 6656, Avg. loss: 644525257593170296832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1379391357.04, NNZs: 2, Bias: 89691056342.470917, T: 6784, Avg. loss: 679988131794230837248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1353848432.08, NNZs: 2, Bias: 89665587054.144958, T: 6912, Avg. loss: 723739502057790373888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1359216416.02, NNZs: 2, Bias: 89639153717.779465, T: 7040, Avg. loss: 711162554259676332032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1328270423.00, NNZs: 2, Bias: 89613891822.301605, T: 7168, Avg. loss: 687448338777834127360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1349514497.11, NNZs: 2, Bias: 89587786034.173782, T: 7296, Avg. loss: 691812361879000973312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1370895270.23, NNZs: 2, Bias: 89582123381.474655, T: 7424, Avg. loss: 602475510367265357824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1368143131.32, NNZs: 2, Bias: 89576916333.138596, T: 7552, Avg. loss: 592782869793113112576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1376035055.59, NNZs: 2, Bias: 89571715673.377151, T: 7680, Avg. loss: 571765694226713673728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1363431655.41, NNZs: 2, Bias: 89566690911.174561, T: 7808, Avg. loss: 588136075250136711168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1359509329.04, NNZs: 2, Bias: 89561557175.633041, T: 7936, Avg. loss: 585145490422089973760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1342744900.25, NNZs: 2, Bias: 89556598385.472244, T: 8064, Avg. loss: 588188499445978038272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1348532191.17, NNZs: 2, Bias: 89551261026.940277, T: 8192, Avg. loss: 592195575403011375104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1354900729.00, NNZs: 2, Bias: 89545921631.035995, T: 8320, Avg. loss: 591096585917112516608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1352226889.75, NNZs: 2, Bias: 89544918326.821503, T: 8448, Avg. loss: 573232493436955787264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1347789336.15, NNZs: 2, Bias: 89543948357.907028, T: 8576, Avg. loss: 569478346024605057024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1347224706.77, NNZs: 2, Bias: 89542913924.027512, T: 8704, Avg. loss: 572745799331404447744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1349493436.12, NNZs: 2, Bias: 89541836524.381989, T: 8832, Avg. loss: 572840128131393060864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1343549986.17, NNZs: 2, Bias: 89540888813.151169, T: 8960, Avg. loss: 569629843460563861504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1346708771.46, NNZs: 2, Bias: 89539796389.723969, T: 9088, Avg. loss: 573717873202215649280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1343613334.56, NNZs: 2, Bias: 89538803365.924820, T: 9216, Avg. loss: 570827965943446831104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 72 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2477660252918.51, NNZs: 2, Bias: -33173959108.893532, T: 128, Avg. loss: 19488531978217981193631039488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1778888155198.01, NNZs: 2, Bias: -17308768513.968414, T: 256, Avg. loss: 25545252492232524842477289472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1410135768656.36, NNZs: 2, Bias: -117308768513.968414, T: 384, Avg. loss: 21866232022915423025303126016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 909187774740.46, NNZs: 2, Bias: -77308768513.968414, T: 512, Avg. loss: 20936023635935000507638087680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 350837466698.49, NNZs: 2, Bias: -34594078910.994125, T: 640, Avg. loss: 19726147115928014482002935808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 674929710318.78, NNZs: 2, Bias: -86599062098.869186, T: 768, Avg. loss: 20311946287387333714069422080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 304201562617.28, NNZs: 2, Bias: -97762464044.527191, T: 896, Avg. loss: 799802322136920097866907648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 258265806470.11, NNZs: 2, Bias: -79836183519.107086, T: 1024, Avg. loss: 864414159762560850440749056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 243964019650.30, NNZs: 2, Bias: -70785056776.121811, T: 1152, Avg. loss: 776747469087549359359262720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 173437823157.21, NNZs: 2, Bias: -52861945143.267059, T: 1280, Avg. loss: 806935682584341686834429952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 98927789059.78, NNZs: 2, Bias: -56064308068.259644, T: 1408, Avg. loss: 837740967017112231129120768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 275557583492.99, NNZs: 2, Bias: -48119953084.836945, T: 1536, Avg. loss: 841842525620123310724481024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 346958584500.77, NNZs: 2, Bias: -39027825130.272148, T: 1664, Avg. loss: 782870042417574665558949888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 394710893198.52, NNZs: 2, Bias: -22425551325.652725, T: 1792, Avg. loss: 896488893561030400318373888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 79323952141.46, NNZs: 2, Bias: -25885358794.487663, T: 1920, Avg. loss: 73309766166749358680178688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 13713657309.60, NNZs: 2, Bias: -24767174663.633167, T: 2048, Avg. loss: 33275862533081915312832512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 34840703095.99, NNZs: 2, Bias: -21454504969.220528, T: 2176, Avg. loss: 31271491914130040807227392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 53544084843.68, NNZs: 2, Bias: -21947513776.911625, T: 2304, Avg. loss: 34226435968525934167851008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 91260884579.59, NNZs: 2, Bias: -21518118225.442764, T: 2432, Avg. loss: 30754651854528929874313216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 11300329962.66, NNZs: 2, Bias: -22835238685.610977, T: 2560, Avg. loss: 32248389215179819397939200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 23282140850.00, NNZs: 2, Bias: -25972158665.886608, T: 2688, Avg. loss: 32517372682908901260132352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 111360559637.87, NNZs: 2, Bias: -26069469161.815926, T: 2816, Avg. loss: 31791006690071268896538624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 34823963346.68, NNZs: 2, Bias: -25602351157.772076, T: 2944, Avg. loss: 35879549458997586971066368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 23590246517.39, NNZs: 2, Bias: -23238345183.171753, T: 3072, Avg. loss: 31661031734116049875894272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 5443755519.17, NNZs: 2, Bias: -23075093204.678337, T: 3200, Avg. loss: 762307548613265930059776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 2110349887.65, NNZs: 2, Bias: -22717394245.496830, T: 3328, Avg. loss: 579354933800873096118272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2679650831.33, NNZs: 2, Bias: -22752746043.756310, T: 3456, Avg. loss: 446234468306626052882432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 16354007039.02, NNZs: 2, Bias: -22688515962.432358, T: 3584, Avg. loss: 552661559673899098046464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 5340487707.44, NNZs: 2, Bias: -22672036415.946758, T: 3712, Avg. loss: 348285323808053363998720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2516523721.86, NNZs: 2, Bias: -22849453638.566185, T: 3840, Avg. loss: 565637926051416580816896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6715602287.06, NNZs: 2, Bias: -23079028793.733124, T: 3968, Avg. loss: 620190190047738913095680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 13893923858.73, NNZs: 2, Bias: -22990411171.038494, T: 4096, Avg. loss: 492066743782587410415616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 237434300.35, NNZs: 2, Bias: -23250262124.823341, T: 4224, Avg. loss: 462801118474592206192640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1605750914.66, NNZs: 2, Bias: -23238898551.256191, T: 4352, Avg. loss: 452524577355280255287296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 162938554.54, NNZs: 2, Bias: -23228347829.291527, T: 4480, Avg. loss: 886157622044726657024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 211232902.67, NNZs: 2, Bias: -23217064472.176888, T: 4608, Avg. loss: 70697537363293249536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 277516165.41, NNZs: 2, Bias: -23207250836.109196, T: 4736, Avg. loss: 62960305864767258624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 344882771.53, NNZs: 2, Bias: -23198378414.927750, T: 4864, Avg. loss: 56372745138223022080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 347761774.93, NNZs: 2, Bias: -23189998380.070240, T: 4992, Avg. loss: 58434688209415110656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 362419425.81, NNZs: 2, Bias: -23181681529.474140, T: 5120, Avg. loss: 57175539657570623488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 348125434.20, NNZs: 2, Bias: -23173171128.450356, T: 5248, Avg. loss: 63600378862339817472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 357310454.72, NNZs: 2, Bias: -23165021635.085697, T: 5376, Avg. loss: 58196829300225531904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 347325821.31, NNZs: 2, Bias: -23157062761.760750, T: 5504, Avg. loss: 56471494345382928384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 358111223.69, NNZs: 2, Bias: -23155230267.355881, T: 5632, Avg. loss: 48502328027207467008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 364871015.73, NNZs: 2, Bias: -23153517664.667114, T: 5760, Avg. loss: 46749406566050676736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 360367216.58, NNZs: 2, Bias: -23151960554.848145, T: 5888, Avg. loss: 47433706260531494912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 364853600.96, NNZs: 2, Bias: -23150261041.947933, T: 6016, Avg. loss: 47409780480952057856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 367082752.56, NNZs: 2, Bias: -23148603357.561028, T: 6144, Avg. loss: 47213752553232351232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 363821237.28, NNZs: 2, Bias: -23147030888.828125, T: 6272, Avg. loss: 47272890349121077248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 370395850.99, NNZs: 2, Bias: -23145317507.161083, T: 6400, Avg. loss: 46790468594809847808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 366719892.69, NNZs: 2, Bias: -23145049750.124008, T: 6528, Avg. loss: 46349110812849569792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 368802712.18, NNZs: 2, Bias: -23144693239.980774, T: 6656, Avg. loss: 45880792413181476864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 368689402.97, NNZs: 2, Bias: -23144369547.847649, T: 6784, Avg. loss: 46191676553996099584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 368168900.16, NNZs: 2, Bias: -23144052455.588596, T: 6912, Avg. loss: 46182925038016544768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 368095213.32, NNZs: 2, Bias: -23143727916.603149, T: 7040, Avg. loss: 46226261902962409472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 370904572.81, NNZs: 2, Bias: -23143364346.687794, T: 7168, Avg. loss: 45204364087607230464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 368361343.65, NNZs: 2, Bias: -23143079068.391781, T: 7296, Avg. loss: 46275351613304766464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 367584231.34, NNZs: 2, Bias: -23142766039.206055, T: 7424, Avg. loss: 46180885800505360384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 369613173.45, NNZs: 2, Bias: -23142409833.559647, T: 7552, Avg. loss: 45942574880293666816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 367136867.06, NNZs: 2, Bias: -23142125602.871674, T: 7680, Avg. loss: 45955768561699979264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 367731747.29, NNZs: 2, Bias: -23141790318.800381, T: 7808, Avg. loss: 46231709251862028288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 61 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1059074476354.97, NNZs: 2, Bias: -278616593.823036, T: 128, Avg. loss: 20514148096612824200893169664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 788276753174.89, NNZs: 2, Bias: 38022974141.769539, T: 256, Avg. loss: 19085017612088553517048922112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1049028721061.04, NNZs: 2, Bias: -20199884150.611984, T: 384, Avg. loss: 19934885718749162792944664576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1912158573860.40, NNZs: 2, Bias: -67070301940.870834, T: 512, Avg. loss: 18764388218264177087166283776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2415840871006.77, NNZs: 2, Bias: 9465742883.184174, T: 640, Avg. loss: 18525908022288541686133948416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1080092098090.82, NNZs: 2, Bias: 29465742883.184174, T: 768, Avg. loss: 19909811070871583683663364096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1763959863666.51, NNZs: 2, Bias: 17195991811.243744, T: 896, Avg. loss: 19647929368850155152531783680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1086244934332.54, NNZs: 2, Bias: 17195991811.243744, T: 1024, Avg. loss: 20636313453263115389505634304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2572161176209.17, NNZs: 2, Bias: -8403042849.748009, T: 1152, Avg. loss: 19732794778138424473343229952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 994474079527.39, NNZs: 2, Bias: -8403042849.748009, T: 1280, Avg. loss: 18390631917835362162932973568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1290798309592.84, NNZs: 2, Bias: 49897079257.916580, T: 1408, Avg. loss: 20402102801175949492558495744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1206558063881.09, NNZs: 2, Bias: 5358530405.627319, T: 1536, Avg. loss: 19969899785530207885653442560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 420853457651.12, NNZs: 2, Bias: 85358530405.627319, T: 1664, Avg. loss: 19433200101844523982807629824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1272769963016.55, NNZs: 2, Bias: 85358530405.627319, T: 1792, Avg. loss: 17734936807826114584028119040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 845190284791.32, NNZs: 2, Bias: 94289451341.418152, T: 1920, Avg. loss: 19879856252950124375054483456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 111082193596.69, NNZs: 2, Bias: 74289451341.418152, T: 2048, Avg. loss: 20266239562710550817854717952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 874927424057.39, NNZs: 2, Bias: 63256397777.768494, T: 2176, Avg. loss: 19419370471977344923173126144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 575415407093.41, NNZs: 2, Bias: 63256397777.768494, T: 2304, Avg. loss: 20643318698053384319822462976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1552555994504.21, NNZs: 2, Bias: -68860449196.756241, T: 2432, Avg. loss: 18425683673667489334533554176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 44108812461.37, NNZs: 2, Bias: -115123688392.054626, T: 2560, Avg. loss: 1308575962634118675336003584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 90627982435.25, NNZs: 2, Bias: -139620324282.159454, T: 2688, Avg. loss: 815866360154216530033246208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 122659136622.79, NNZs: 2, Bias: -143767322607.308014, T: 2816, Avg. loss: 678716891118810157096632320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 168694510104.68, NNZs: 2, Bias: -143751362698.730164, T: 2944, Avg. loss: 842557277706483237663014912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 325437706740.35, NNZs: 2, Bias: -145174577720.583862, T: 3072, Avg. loss: 795206640197675635290669056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 235048850754.28, NNZs: 2, Bias: -164626659160.477570, T: 3200, Avg. loss: 797542076071016557224919040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 414147954436.51, NNZs: 2, Bias: -157819595972.896362, T: 3328, Avg. loss: 808353103377554269217488896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 562260712940.47, NNZs: 2, Bias: -160150370167.301086, T: 3456, Avg. loss: 782530037132246922551099392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 50876010393.38, NNZs: 2, Bias: -156721220620.803619, T: 3584, Avg. loss: 134534570152455519093129216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 72896322744.67, NNZs: 2, Bias: -155721036492.411560, T: 3712, Avg. loss: 31506053783521631661981696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 22322786896.75, NNZs: 2, Bias: -155196195124.820679, T: 3840, Avg. loss: 31232744853609929311780864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 31430578409.05, NNZs: 2, Bias: -153026288497.219727, T: 3968, Avg. loss: 28797547253898815473713152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 80085544458.22, NNZs: 2, Bias: -153192644685.592072, T: 4096, Avg. loss: 27748025135702799659565056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 77181563344.97, NNZs: 2, Bias: -154903454150.606903, T: 4224, Avg. loss: 28854732450762401580580864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 71976564368.56, NNZs: 2, Bias: -152997292941.291534, T: 4352, Avg. loss: 28349943943284628880621568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 55634019860.07, NNZs: 2, Bias: -154197945662.429138, T: 4480, Avg. loss: 29038242014544328986198016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 22993747222.02, NNZs: 2, Bias: -154711230488.962677, T: 4608, Avg. loss: 23467900006584837424021504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 44487113386.44, NNZs: 2, Bias: -153856623087.716583, T: 4736, Avg. loss: 31211985829311889193041920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 70379915546.63, NNZs: 2, Bias: -150926014350.331421, T: 4864, Avg. loss: 28522716979498354231738368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 34476406863.58, NNZs: 2, Bias: -153909053399.978058, T: 4992, Avg. loss: 26936510235387697865687040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 23953854390.11, NNZs: 2, Bias: -154064655377.379059, T: 5120, Avg. loss: 27329561022283811139878912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 8842579932.64, NNZs: 2, Bias: -151817530848.173096, T: 5248, Avg. loss: 34367113281188457621749760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9937907331.13, NNZs: 2, Bias: -151732650231.647858, T: 5376, Avg. loss: 442435325577811963412480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2297361719.49, NNZs: 2, Bias: -151368455896.503998, T: 5504, Avg. loss: 515693464238398579408896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5028772363.17, NNZs: 2, Bias: -151275138160.428833, T: 5632, Avg. loss: 606295671707865517654016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 8990833909.96, NNZs: 2, Bias: -151091381011.399475, T: 5760, Avg. loss: 534551693724797687037952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2127262811.15, NNZs: 2, Bias: -150635939661.815613, T: 5888, Avg. loss: 543858786282217200943104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 6797527451.56, NNZs: 2, Bias: -150449176102.547424, T: 6016, Avg. loss: 496434800014592388890624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3607508245.96, NNZs: 2, Bias: -150394943698.773651, T: 6144, Avg. loss: 9697443790250873716736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3061684283.50, NNZs: 2, Bias: -150353746289.012878, T: 6272, Avg. loss: 2585670901181205446656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2589142880.47, NNZs: 2, Bias: -150311165689.512146, T: 6400, Avg. loss: 2511539801748999241728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2594756786.66, NNZs: 2, Bias: -150259921316.765808, T: 6528, Avg. loss: 2322324400385000734720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2445155513.71, NNZs: 2, Bias: -150208672672.596832, T: 6656, Avg. loss: 2533217026626031190016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2424882278.20, NNZs: 2, Bias: -150161602308.127045, T: 6784, Avg. loss: 2163777931396579852288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2424596893.06, NNZs: 2, Bias: -150113030122.544800, T: 6912, Avg. loss: 2225216304595383091200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2452961933.22, NNZs: 2, Bias: -150063344630.853424, T: 7040, Avg. loss: 2316316118263706943488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2540709279.22, NNZs: 2, Bias: -150013440827.234344, T: 7168, Avg. loss: 2207972086601851076608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2470803972.36, NNZs: 2, Bias: -149962386397.269165, T: 7296, Avg. loss: 2376817196226768273408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2376084599.39, NNZs: 2, Bias: -149911912121.275055, T: 7424, Avg. loss: 2327429843561091170304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2429930985.98, NNZs: 2, Bias: -149900937677.403809, T: 7552, Avg. loss: 1911921933324264931328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2392760880.80, NNZs: 2, Bias: -149891327225.726105, T: 7680, Avg. loss: 1932736031081772089344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2393754743.55, NNZs: 2, Bias: -149881215486.360687, T: 7808, Avg. loss: 1913172257829929877504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2428354674.47, NNZs: 2, Bias: -149870587056.148254, T: 7936, Avg. loss: 1896803857481119039488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2431835362.86, NNZs: 2, Bias: -149860325321.142181, T: 8064, Avg. loss: 1928100205234546540544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2421408234.51, NNZs: 2, Bias: -149850268840.723206, T: 8192, Avg. loss: 1940249457665531183104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2370811951.97, NNZs: 2, Bias: -149840907938.739899, T: 8320, Avg. loss: 1926378857440439959552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2400297998.36, NNZs: 2, Bias: -149830295447.060333, T: 8448, Avg. loss: 1918461232441409929216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2386672884.23, NNZs: 2, Bias: -149820516247.593689, T: 8576, Avg. loss: 1889879158764415221760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2401806877.09, NNZs: 2, Bias: -149809980032.737305, T: 8704, Avg. loss: 1946623298878104141824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2413526003.29, NNZs: 2, Bias: -149799755458.998627, T: 8832, Avg. loss: 1893268671131414429696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2390617598.44, NNZs: 2, Bias: -149789952148.719086, T: 8960, Avg. loss: 1927059285504657719296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2408107390.23, NNZs: 2, Bias: -149779584567.070312, T: 9088, Avg. loss: 1901966449677208911872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2376806542.12, NNZs: 2, Bias: -149769980397.729462, T: 9216, Avg. loss: 1912399310738440847360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2394575785.86, NNZs: 2, Bias: -149767639925.155884, T: 9344, Avg. loss: 1889593041032909422592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2412775447.33, NNZs: 2, Bias: -149765339498.679474, T: 9472, Avg. loss: 1844025429014915842048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2407181330.11, NNZs: 2, Bias: -149763406222.076569, T: 9600, Avg. loss: 1859585777254636453888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2415004914.94, NNZs: 2, Bias: -149761266266.978912, T: 9728, Avg. loss: 1850043763641919995904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2402304560.29, NNZs: 2, Bias: -149759449032.440765, T: 9856, Avg. loss: 1858141772293710544896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2406999204.39, NNZs: 2, Bias: -149757353968.435333, T: 9984, Avg. loss: 1855397476361839575040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2408103427.36, NNZs: 2, Bias: -149755313486.799316, T: 10112, Avg. loss: 1858475515872573390848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 79 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 744591156483.56, NNZs: 2, Bias: 116083200326.949341, T: 128, Avg. loss: 20701089377783736492938493952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 494739143030.55, NNZs: 2, Bias: 116083200326.949341, T: 256, Avg. loss: 20770603303398446285474234368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 678874337380.68, NNZs: 2, Bias: 188714420690.576477, T: 384, Avg. loss: 19764136191581196512686768128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1585762731312.54, NNZs: 2, Bias: 206592719541.907349, T: 512, Avg. loss: 20663826987661554960335634432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 884311241338.28, NNZs: 2, Bias: 207927199369.661804, T: 640, Avg. loss: 21008481909137367361858306048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2342556978484.15, NNZs: 2, Bias: 109799154366.272980, T: 768, Avg. loss: 18915697424943571298942976000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1802702436376.67, NNZs: 2, Bias: 108645105757.787872, T: 896, Avg. loss: 20722856124088770618841890816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1992353102195.42, NNZs: 2, Bias: 28645105757.787872, T: 1024, Avg. loss: 20179474232261655078742523904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1332739791235.16, NNZs: 2, Bias: 8645105757.787872, T: 1152, Avg. loss: 19706932400347200555145232384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2060669688583.01, NNZs: 2, Bias: 48645105757.787872, T: 1280, Avg. loss: 20566548782565009897180626944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 787391279528.75, NNZs: 2, Bias: 5950565083.108200, T: 1408, Avg. loss: 22412364092765104427220598784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 446040529177.79, NNZs: 2, Bias: 23950505249.284740, T: 1536, Avg. loss: 874145873915368166607814656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 411487711618.97, NNZs: 2, Bias: -2301075421.755526, T: 1664, Avg. loss: 857798945506782257287790592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 225360848532.12, NNZs: 2, Bias: -28036117771.335091, T: 1792, Avg. loss: 788981861617021548708757504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 126146807333.49, NNZs: 2, Bias: -28257291475.255642, T: 1920, Avg. loss: 901797555785777556993605632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 210619304707.86, NNZs: 2, Bias: -17533519316.861561, T: 2048, Avg. loss: 856840475858776664626429952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 230201036841.10, NNZs: 2, Bias: -28571220132.560265, T: 2176, Avg. loss: 843676760918749330693685248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 454742547100.58, NNZs: 2, Bias: -36961699433.161011, T: 2304, Avg. loss: 854996208106659614770069504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 317871803073.11, NNZs: 2, Bias: -33030883930.657784, T: 2432, Avg. loss: 763377212744055966840913920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 568201470857.96, NNZs: 2, Bias: -26423034182.813587, T: 2560, Avg. loss: 775982754328344780586614784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 252410826646.02, NNZs: 2, Bias: -28987092299.744156, T: 2688, Avg. loss: 915671619817449379933978624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 108065398215.03, NNZs: 2, Bias: -12453631870.067146, T: 2816, Avg. loss: 820257052661184539050115072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 339797615142.33, NNZs: 2, Bias: -16257777303.757954, T: 2944, Avg. loss: 851345920671513151212093440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 162017142252.66, NNZs: 2, Bias: -20157916776.705040, T: 3072, Avg. loss: 953088634652207425056145408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 11758117383.90, NNZs: 2, Bias: -19557813452.731636, T: 3200, Avg. loss: 34050516573044783303360512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 12188926074.19, NNZs: 2, Bias: -23547583581.563396, T: 3328, Avg. loss: 32924298133290111635292160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 68929744201.65, NNZs: 2, Bias: -24339032892.508617, T: 3456, Avg. loss: 28912251287552321795391488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 28895602891.38, NNZs: 2, Bias: -21765177287.035069, T: 3584, Avg. loss: 30440553161704728017502208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 14030395729.46, NNZs: 2, Bias: -24081110680.198898, T: 3712, Avg. loss: 32593168975930469327568896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 44484615852.92, NNZs: 2, Bias: -25126562743.495529, T: 3840, Avg. loss: 32368599518634769412784128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 30547729164.21, NNZs: 2, Bias: -21778197138.513821, T: 3968, Avg. loss: 29277415875564042255859712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 83372456852.18, NNZs: 2, Bias: -21760123339.487679, T: 4096, Avg. loss: 29737702850723228353036288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 10897802968.18, NNZs: 2, Bias: -22783536686.650658, T: 4224, Avg. loss: 2762749382636404463370240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 15735175087.59, NNZs: 2, Bias: -23024236635.674362, T: 4352, Avg. loss: 354846279215900857991168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4139386733.98, NNZs: 2, Bias: -22937898461.996223, T: 4480, Avg. loss: 607911354961750338306048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9281736578.42, NNZs: 2, Bias: -22765137416.476669, T: 4608, Avg. loss: 565398873075326855938048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 11294685046.67, NNZs: 2, Bias: -22715595087.393196, T: 4736, Avg. loss: 464943270977734998753280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4541291737.68, NNZs: 2, Bias: -22569605121.796627, T: 4864, Avg. loss: 696346256717111116169216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 942418366.18, NNZs: 2, Bias: -22457985035.581768, T: 4992, Avg. loss: 593881123535229644963840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 307101461.85, NNZs: 2, Bias: -22442136326.353329, T: 5120, Avg. loss: 225746921166533853184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 124743109.80, NNZs: 2, Bias: -22429805863.583385, T: 5248, Avg. loss: 90094149021225926656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 232046706.06, NNZs: 2, Bias: -22419854304.444332, T: 5376, Avg. loss: 57409343060148846592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 279442779.27, NNZs: 2, Bias: -22411810110.935699, T: 5504, Avg. loss: 48658019023777193984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 361977158.99, NNZs: 2, Bias: -22403868504.296692, T: 5632, Avg. loss: 43340410073812574208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 368793694.21, NNZs: 2, Bias: -22396516713.161140, T: 5760, Avg. loss: 50511367516678791168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 370405711.07, NNZs: 2, Bias: -22389646520.716118, T: 5888, Avg. loss: 47082251419315175424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 375490182.84, NNZs: 2, Bias: -22382871339.618999, T: 6016, Avg. loss: 44353011922181996544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 388565265.58, NNZs: 2, Bias: -22375787987.961140, T: 6144, Avg. loss: 47589397014466854912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 377547514.21, NNZs: 2, Bias: -22368825378.014805, T: 6272, Avg. loss: 50246576810563551232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 393225763.99, NNZs: 2, Bias: -22366989433.477997, T: 6400, Avg. loss: 44042705958524411904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 388590545.42, NNZs: 2, Bias: -22365671519.617130, T: 6528, Avg. loss: 39467725094558154752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 389234668.47, NNZs: 2, Bias: -22364303227.976112, T: 6656, Avg. loss: 38147360300014321664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 389999685.89, NNZs: 2, Bias: -22362918875.532478, T: 6784, Avg. loss: 38578842661843443712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 393804012.07, NNZs: 2, Bias: -22361450549.292274, T: 6912, Avg. loss: 39384589253198921728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 391789715.18, NNZs: 2, Bias: -22360084321.702324, T: 7040, Avg. loss: 39468313186986926080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 390893100.89, NNZs: 2, Bias: -22358723414.067482, T: 7168, Avg. loss: 38763159559795793920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 387433222.63, NNZs: 2, Bias: -22357384858.075279, T: 7296, Avg. loss: 39393317851150974976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 390659566.39, NNZs: 2, Bias: -22357045131.062836, T: 7424, Avg. loss: 38854526844002476032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 391057355.83, NNZs: 2, Bias: -22356757687.066589, T: 7552, Avg. loss: 38446591347739426816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 391276280.72, NNZs: 2, Bias: -22356473719.386959, T: 7680, Avg. loss: 38397831787302150144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 391146680.44, NNZs: 2, Bias: -22356195853.519680, T: 7808, Avg. loss: 38400664736956784640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 391294903.59, NNZs: 2, Bias: -22355913265.001945, T: 7936, Avg. loss: 38377495755370291200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 62 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 767282568200.70, NNZs: 2, Bias: -39221913569.859055, T: 128, Avg. loss: 23251876872415092587534221312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 487560116701.69, NNZs: 2, Bias: -62885682080.881866, T: 256, Avg. loss: 21401065630458106487358095360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1848589723855.68, NNZs: 2, Bias: -24999434791.772858, T: 384, Avg. loss: 21727938068483931843380379648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 825059088657.91, NNZs: 2, Bias: -22355665277.339882, T: 512, Avg. loss: 22743703851335675960717475840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1511465576684.14, NNZs: 2, Bias: 5914847517.582630, T: 640, Avg. loss: 21754261383080714707794919424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 911728517560.59, NNZs: 2, Bias: 34091185077.326897, T: 768, Avg. loss: 22740366362891247562736533504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1123746698096.85, NNZs: 2, Bias: 21641503681.704773, T: 896, Avg. loss: 21343042861455065794111078400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1069676244138.06, NNZs: 2, Bias: -18358496318.295227, T: 1024, Avg. loss: 22138405514660419374235516928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 930877522462.48, NNZs: 2, Bias: 23225752782.651299, T: 1152, Avg. loss: 23165673635783974398965317632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 600340773890.06, NNZs: 2, Bias: 3225752782.651299, T: 1280, Avg. loss: 22053782858701410373212307456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1992227667098.67, NNZs: 2, Bias: 31257377509.097427, T: 1408, Avg. loss: 25492564297778017727431049216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2073776567988.25, NNZs: 2, Bias: 24627058929.080040, T: 1536, Avg. loss: 21581589514248620174584315904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 261209740628.23, NNZs: 2, Bias: 23568241509.669815, T: 1664, Avg. loss: 3154962815388843206040879104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 287137216457.73, NNZs: 2, Bias: 30416147787.948723, T: 1792, Avg. loss: 916969204660427409592418304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 369405750132.37, NNZs: 2, Bias: 29112248082.005646, T: 1920, Avg. loss: 907563401742969851667808256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 230566386768.84, NNZs: 2, Bias: 46547923391.281860, T: 2048, Avg. loss: 889952776604164616844476416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 107989320839.89, NNZs: 2, Bias: 37455371621.761848, T: 2176, Avg. loss: 912563990151790915280175104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 325911872907.63, NNZs: 2, Bias: 33692822740.248520, T: 2304, Avg. loss: 916335620739269923820273664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 193171981567.88, NNZs: 2, Bias: 42881797023.011772, T: 2432, Avg. loss: 884545529191323768654397440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 134219593640.25, NNZs: 2, Bias: 42309379233.576004, T: 2560, Avg. loss: 847020659841103971326361600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 200467617875.68, NNZs: 2, Bias: 47991713061.353783, T: 2688, Avg. loss: 947862051384793642504814592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 87665920198.96, NNZs: 2, Bias: 46991678517.869522, T: 2816, Avg. loss: 986035607532376359989936128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 64945242748.90, NNZs: 2, Bias: 48308242424.318245, T: 2944, Avg. loss: 859831573402840966157565952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 88369033476.23, NNZs: 2, Bias: 45330063445.900848, T: 3072, Avg. loss: 903334165527030393540182016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 69852017093.96, NNZs: 2, Bias: 38080360850.487595, T: 3200, Avg. loss: 953510835311961235087425536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 92149298497.73, NNZs: 2, Bias: 36598096841.181122, T: 3328, Avg. loss: 31437382102800917105475584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 34721477199.32, NNZs: 2, Bias: 37853274961.284225, T: 3456, Avg. loss: 32155198364915430731022336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 63817769956.05, NNZs: 2, Bias: 40566911506.164246, T: 3584, Avg. loss: 36117256832808504839372800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 77183245824.43, NNZs: 2, Bias: 42154483017.005089, T: 3712, Avg. loss: 32524686399450519808507904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 17500131684.08, NNZs: 2, Bias: 37756306804.230484, T: 3840, Avg. loss: 35900751610368029894901760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 48410595340.69, NNZs: 2, Bias: 36536152018.765495, T: 3968, Avg. loss: 33100657940278346763993088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5674248698.02, NNZs: 2, Bias: 36053631830.636772, T: 4096, Avg. loss: 1355083175420293655035904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7204681411.13, NNZs: 2, Bias: 36012977578.712547, T: 4224, Avg. loss: 579997793578024160985088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3789039959.35, NNZs: 2, Bias: 36208418862.552933, T: 4352, Avg. loss: 657408702290935844700160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4476990110.58, NNZs: 2, Bias: 36388330649.636444, T: 4480, Avg. loss: 654368441111420067643392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1317293730.74, NNZs: 2, Bias: 36128616421.544334, T: 4608, Avg. loss: 534791077254644459634688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3199488904.41, NNZs: 2, Bias: 36397163487.545753, T: 4736, Avg. loss: 552044985113924981489664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1670210855.02, NNZs: 2, Bias: 36336624124.470772, T: 4864, Avg. loss: 704348019688649575628800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2614292376.81, NNZs: 2, Bias: 36563812459.505051, T: 4992, Avg. loss: 519233433917945439846400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2358667227.10, NNZs: 2, Bias: 37013900821.577545, T: 5120, Avg. loss: 604503757274280940797952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 990931713.97, NNZs: 2, Bias: 36910478820.374924, T: 5248, Avg. loss: 463440113811105800781824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 10196975849.43, NNZs: 2, Bias: 36918659393.540123, T: 5376, Avg. loss: 781738683201573921751040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 5526866029.67, NNZs: 2, Bias: 37248990472.396637, T: 5504, Avg. loss: 708659062967984680075264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3609785196.35, NNZs: 2, Bias: 37231281694.207947, T: 5632, Avg. loss: 703725403380781129138176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6661388900.81, NNZs: 2, Bias: 37130784689.295792, T: 5760, Avg. loss: 663396147986586115506176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 14424482902.40, NNZs: 2, Bias: 36980937251.723099, T: 5888, Avg. loss: 663894638423320058396672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1511571812.13, NNZs: 2, Bias: 37071984705.433937, T: 6016, Avg. loss: 51496586084674541977600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1094851308.64, NNZs: 2, Bias: 37066262541.570091, T: 6144, Avg. loss: 258864888825274892288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 870036362.20, NNZs: 2, Bias: 37057566387.169998, T: 6272, Avg. loss: 181427622145637941248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 707755711.66, NNZs: 2, Bias: 37047569477.607643, T: 6400, Avg. loss: 160735564172940574720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 662199222.78, NNZs: 2, Bias: 37035962878.844185, T: 6528, Avg. loss: 152705213945212534784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 630158765.60, NNZs: 2, Bias: 37023735932.009735, T: 6656, Avg. loss: 145418725036870877184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 612361265.46, NNZs: 2, Bias: 37011777526.065285, T: 6784, Avg. loss: 141838192286841257984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 591290901.50, NNZs: 2, Bias: 36999433765.947456, T: 6912, Avg. loss: 147370878953410396160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 583785405.33, NNZs: 2, Bias: 36987102525.268227, T: 7040, Avg. loss: 141048779147744296960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 576024396.76, NNZs: 2, Bias: 36975222264.045486, T: 7168, Avg. loss: 136355480376027316224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 587097620.26, NNZs: 2, Bias: 36963224120.885803, T: 7296, Avg. loss: 132655626931410911232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 587367980.50, NNZs: 2, Bias: 36950862092.427719, T: 7424, Avg. loss: 142154490010800603136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 593052290.80, NNZs: 2, Bias: 36938727346.902672, T: 7552, Avg. loss: 134625798249577611264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 585678199.38, NNZs: 2, Bias: 36925921925.892944, T: 7680, Avg. loss: 147475916662703226880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 595819990.45, NNZs: 2, Bias: 36913571821.587128, T: 7808, Avg. loss: 135389433759524110336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 545381820.32, NNZs: 2, Bias: 36901063222.241501, T: 7936, Avg. loss: 150999851005029253120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 548635814.94, NNZs: 2, Bias: 36898514411.045662, T: 8064, Avg. loss: 116491651060982874112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 558822477.14, NNZs: 2, Bias: 36895836558.025772, T: 8192, Avg. loss: 117299613537427243008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 565367650.92, NNZs: 2, Bias: 36893251145.889076, T: 8320, Avg. loss: 115446319217348755456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 567583813.76, NNZs: 2, Bias: 36890733393.824516, T: 8448, Avg. loss: 115518572870537412608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 562216164.96, NNZs: 2, Bias: 36888306974.510963, T: 8576, Avg. loss: 117059302840604950528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 570073860.72, NNZs: 2, Bias: 36885732128.092781, T: 8704, Avg. loss: 114096305126875840512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 568631190.23, NNZs: 2, Bias: 36883289054.249527, T: 8832, Avg. loss: 114863111013296603136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 569534365.94, NNZs: 2, Bias: 36880773861.006371, T: 8960, Avg. loss: 116385937541065113600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 581577087.67, NNZs: 2, Bias: 36878106125.170975, T: 9088, Avg. loss: 115018464933413421056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 568342170.94, NNZs: 2, Bias: 36875837523.346092, T: 9216, Avg. loss: 115431394440421670912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 574740066.12, NNZs: 2, Bias: 36873272371.549545, T: 9344, Avg. loss: 114617577137960779776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 574275008.41, NNZs: 2, Bias: 36872782866.381592, T: 9472, Avg. loss: 112384778878572822528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 574210873.29, NNZs: 2, Bias: 36872289179.844276, T: 9600, Avg. loss: 111886789468410609664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 574554850.29, NNZs: 2, Bias: 36871787655.766937, T: 9728, Avg. loss: 112234486236315484160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 572057215.01, NNZs: 2, Bias: 36871329991.652618, T: 9856, Avg. loss: 112340276229850054656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 572135572.94, NNZs: 2, Bias: 36870832001.420586, T: 9984, Avg. loss: 112379861967500705792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 570969798.45, NNZs: 2, Bias: 36870355457.771454, T: 10112, Avg. loss: 111899957286552453120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 574714600.96, NNZs: 2, Bias: 36869803181.318108, T: 10240, Avg. loss: 111715173364247707648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 574330925.79, NNZs: 2, Bias: 36869312835.618080, T: 10368, Avg. loss: 112277316500761427968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 575394681.84, NNZs: 2, Bias: 36868801994.993080, T: 10496, Avg. loss: 111768789295365193728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 573817347.50, NNZs: 2, Bias: 36868328895.837311, T: 10624, Avg. loss: 112604761798596542464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 572520423.37, NNZs: 2, Bias: 36867852734.156548, T: 10752, Avg. loss: 112280892257073872896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 573139060.18, NNZs: 2, Bias: 36867346112.733475, T: 10880, Avg. loss: 112407067042014806016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 85 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 317104270881.79, NNZs: 2, Bias: -20046750654.037361, T: 128, Avg. loss: 24538808260641925576834154496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2621564884886.01, NNZs: 2, Bias: -72923181900.366486, T: 256, Avg. loss: 23491148964718108483075964928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 486984771951.44, NNZs: 2, Bias: -90309900712.916763, T: 384, Avg. loss: 23747663398200654689717977088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1799339322503.78, NNZs: 2, Bias: -110309900712.916763, T: 512, Avg. loss: 22551150963352155498638999552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1872967657397.71, NNZs: 2, Bias: -158786755867.428833, T: 640, Avg. loss: 21720537207087537995405852672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1360733623773.97, NNZs: 2, Bias: -218786755867.428833, T: 768, Avg. loss: 23836300537340980315683815424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1436057839013.30, NNZs: 2, Bias: -158786755867.428833, T: 896, Avg. loss: 23307048623623745528938889216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1083934813152.30, NNZs: 2, Bias: -158786755867.428833, T: 1024, Avg. loss: 24160877623501117497974718464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2608599771648.52, NNZs: 2, Bias: -138786755867.428833, T: 1152, Avg. loss: 22470331681329646502452133888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 91596949373.99, NNZs: 2, Bias: -198786755867.428833, T: 1280, Avg. loss: 26552263071869440271981740032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 214543153450.49, NNZs: 2, Bias: -202176835908.543518, T: 1408, Avg. loss: 982613053859729001024585728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 327663374415.85, NNZs: 2, Bias: -213534609662.853577, T: 1536, Avg. loss: 997195900193512925159227392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 436327492676.30, NNZs: 2, Bias: -196337446364.874664, T: 1664, Avg. loss: 947356040664945572685283328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 166459782269.52, NNZs: 2, Bias: -187367461185.922394, T: 1792, Avg. loss: 1002462753156403745366474752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 333396879722.66, NNZs: 2, Bias: -200153212642.862793, T: 1920, Avg. loss: 874458306617100462838513664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 221669402067.89, NNZs: 2, Bias: -186036356562.874939, T: 2048, Avg. loss: 974236129534136516190666752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 323650584905.23, NNZs: 2, Bias: -167030717058.085114, T: 2176, Avg. loss: 919703124097378589220012032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 87652352711.95, NNZs: 2, Bias: -172863530692.521973, T: 2304, Avg. loss: 959146606961046360378310656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 264190906279.02, NNZs: 2, Bias: -185758228966.798218, T: 2432, Avg. loss: 995125813418570190801600512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 170738918051.06, NNZs: 2, Bias: -186320218165.932007, T: 2560, Avg. loss: 950820318075003003207680000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 81593006403.50, NNZs: 2, Bias: -182339689991.130737, T: 2688, Avg. loss: 43060754575930000695885824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 56209892205.53, NNZs: 2, Bias: -182797648730.682922, T: 2816, Avg. loss: 37169700366584401069342720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 81806139177.21, NNZs: 2, Bias: -180812868477.411499, T: 2944, Avg. loss: 34418170459564073161850880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 62607503314.14, NNZs: 2, Bias: -180055186698.758698, T: 3072, Avg. loss: 38895684957707662692188160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 36680477609.00, NNZs: 2, Bias: -181625230852.599884, T: 3200, Avg. loss: 34491498204796697951862784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 19269478965.06, NNZs: 2, Bias: -182116658219.858337, T: 3328, Avg. loss: 33886815604388673427079168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 31523732319.46, NNZs: 2, Bias: -177818647515.743286, T: 3456, Avg. loss: 36922950661908677340954624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 81332192954.00, NNZs: 2, Bias: -174824134387.870361, T: 3584, Avg. loss: 33011175788542922751737856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 33483795622.15, NNZs: 2, Bias: -172283233539.690033, T: 3712, Avg. loss: 33054787588272327650967552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 36915750232.11, NNZs: 2, Bias: -172798410574.745636, T: 3840, Avg. loss: 35847832536564141354123264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 19712339008.65, NNZs: 2, Bias: -172449150928.025024, T: 3968, Avg. loss: 37647191134299891546718208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 47516624532.53, NNZs: 2, Bias: -171378910495.933014, T: 4096, Avg. loss: 34535850437726275962404864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 39800746537.94, NNZs: 2, Bias: -174794877488.132782, T: 4224, Avg. loss: 36628346992423984091365376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1932638078.88, NNZs: 2, Bias: -174489249518.101685, T: 4352, Avg. loss: 1301709694516643542073344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1913072518.21, NNZs: 2, Bias: -173952359995.384552, T: 4480, Avg. loss: 581806003372862010818560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2992729890.42, NNZs: 2, Bias: -173790916924.856689, T: 4608, Avg. loss: 785321364167503200124928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 11431577940.76, NNZs: 2, Bias: -173733106095.414124, T: 4736, Avg. loss: 875589349241808394125312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 14631254014.18, NNZs: 2, Bias: -173832029125.790253, T: 4864, Avg. loss: 901538544660228427743232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 11886168240.09, NNZs: 2, Bias: -173839063031.745422, T: 4992, Avg. loss: 818682365258485850963968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1692490506.39, NNZs: 2, Bias: -173409124033.711426, T: 5120, Avg. loss: 830960658831465135472640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1553303814.28, NNZs: 2, Bias: -173327866878.142181, T: 5248, Avg. loss: 4229198150578783911936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2076970719.99, NNZs: 2, Bias: -173266834064.062683, T: 5376, Avg. loss: 2791505970166810804224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2267192711.84, NNZs: 2, Bias: -173213184976.257294, T: 5504, Avg. loss: 2617716007173294653440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2477148751.90, NNZs: 2, Bias: -173159110317.219269, T: 5632, Avg. loss: 2651276872204600475648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2608776421.56, NNZs: 2, Bias: -173106766570.131622, T: 5760, Avg. loss: 2669690250468313792512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2550011288.75, NNZs: 2, Bias: -173054605050.938385, T: 5888, Avg. loss: 2819547483321148637184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2439866393.69, NNZs: 2, Bias: -173005255914.149170, T: 6016, Avg. loss: 2665238267672839847936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2543160971.93, NNZs: 2, Bias: -172952234024.631531, T: 6144, Avg. loss: 2816146439096880857088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2653639283.89, NNZs: 2, Bias: -172940091420.010101, T: 6272, Avg. loss: 2285499958407133921280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2687923238.37, NNZs: 2, Bias: -172929618263.977661, T: 6400, Avg. loss: 2165353845654720348160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2659901829.82, NNZs: 2, Bias: -172919867170.983887, T: 6528, Avg. loss: 2222602438164640432128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2644532877.97, NNZs: 2, Bias: -172910128608.829803, T: 6656, Avg. loss: 2173832498860387729408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2621498824.71, NNZs: 2, Bias: -172900454085.671448, T: 6784, Avg. loss: 2188002012529735499776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2613918586.30, NNZs: 2, Bias: -172890433145.371155, T: 6912, Avg. loss: 2208848586222495334400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2620363440.48, NNZs: 2, Bias: -172880282545.708221, T: 7040, Avg. loss: 2190069803051281285120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2630502950.12, NNZs: 2, Bias: -172878128205.997406, T: 7168, Avg. loss: 2122734837547922620416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2624673920.80, NNZs: 2, Bias: -172876206288.819214, T: 7296, Avg. loss: 2134468604855180328960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2616636710.21, NNZs: 2, Bias: -172874319460.862091, T: 7424, Avg. loss: 2132556237787956772864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2612853973.71, NNZs: 2, Bias: -172872373619.681885, T: 7552, Avg. loss: 2126227138922667835392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2626775244.18, NNZs: 2, Bias: -172870156422.423828, T: 7680, Avg. loss: 2129047639109043748864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2622774821.24, NNZs: 2, Bias: -172868208840.454651, T: 7808, Avg. loss: 2131941853715337576448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 61 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1807976657172.46, NNZs: 2, Bias: -62320105449.780380, T: 128, Avg. loss: 21767246530449531992333615104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 666380078443.94, NNZs: 2, Bias: -82320105449.780380, T: 256, Avg. loss: 20890945568937200716051644416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2157458750197.69, NNZs: 2, Bias: -89339458311.355438, T: 384, Avg. loss: 20698622806629244942466154496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 414763681261.74, NNZs: 2, Bias: -223355863712.427063, T: 512, Avg. loss: 23129268592470657157306515456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 864359478880.59, NNZs: 2, Bias: -237483867832.645203, T: 640, Avg. loss: 21484068501147070223735586816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 576877482979.18, NNZs: 2, Bias: -229262633287.339539, T: 768, Avg. loss: 20999471812926227543230513152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2083411942237.30, NNZs: 2, Bias: -273309824892.861969, T: 896, Avg. loss: 22002185009343276987875065856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 856484737589.87, NNZs: 2, Bias: -230019694712.268524, T: 1024, Avg. loss: 23949143818890729819096481792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 504091053713.56, NNZs: 2, Bias: -202097304634.758392, T: 1152, Avg. loss: 975671533824135546642890752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 417858699674.52, NNZs: 2, Bias: -191018844543.890839, T: 1280, Avg. loss: 849595083809139168288702464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 301392311615.16, NNZs: 2, Bias: -175976685935.022644, T: 1408, Avg. loss: 831744744001052322375401472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 289665793952.22, NNZs: 2, Bias: -160263402074.541718, T: 1536, Avg. loss: 853934309052169710452342784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 220358114728.66, NNZs: 2, Bias: -156707753854.463684, T: 1664, Avg. loss: 887048695872637238767517696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 365856786588.75, NNZs: 2, Bias: -148147321098.400208, T: 1792, Avg. loss: 755738963953906823550992384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 130385192229.80, NNZs: 2, Bias: -138968515143.148621, T: 1920, Avg. loss: 915884155738507181660569600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 72340052904.00, NNZs: 2, Bias: -134179671334.794647, T: 2048, Avg. loss: 807588180325828848143826944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 396598415429.48, NNZs: 2, Bias: -131898418399.912109, T: 2176, Avg. loss: 838960522643005175192616960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 201324807206.02, NNZs: 2, Bias: -129878655405.527512, T: 2304, Avg. loss: 922765706110083294226808832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 111621122787.67, NNZs: 2, Bias: -154091876964.806549, T: 2432, Avg. loss: 877597475924262701487882240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 38149893640.77, NNZs: 2, Bias: -153441157967.406982, T: 2560, Avg. loss: 32185180153587005283893248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 25367096862.09, NNZs: 2, Bias: -150695669453.296783, T: 2688, Avg. loss: 34440093052323259427586048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 45749269411.17, NNZs: 2, Bias: -145865530156.327484, T: 2816, Avg. loss: 34254779256910776125882368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 22223397500.46, NNZs: 2, Bias: -149576569731.041016, T: 2944, Avg. loss: 32594006361221019159494656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 40632334539.06, NNZs: 2, Bias: -149309040034.989868, T: 3072, Avg. loss: 29807365034130684793323520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 35508873654.56, NNZs: 2, Bias: -149076313918.989594, T: 3200, Avg. loss: 38074294585281779807027200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 74560730314.34, NNZs: 2, Bias: -148200858337.021942, T: 3328, Avg. loss: 35504170496889712290037760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 25088373218.77, NNZs: 2, Bias: -148334056626.793915, T: 3456, Avg. loss: 35204454431267500494684160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 84147049250.25, NNZs: 2, Bias: -146320728577.449707, T: 3584, Avg. loss: 30586212659153105886117888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 19603536374.21, NNZs: 2, Bias: -142262531324.917816, T: 3712, Avg. loss: 32493069661720272783278080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1748147765.59, NNZs: 2, Bias: -142138669627.112976, T: 3840, Avg. loss: 744487486904998580715520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5877341970.77, NNZs: 2, Bias: -141528154309.138306, T: 3968, Avg. loss: 775146411966359989649408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3159241540.29, NNZs: 2, Bias: -141560272293.454193, T: 4096, Avg. loss: 544670562905128664301568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6324359818.01, NNZs: 2, Bias: -141419458160.097260, T: 4224, Avg. loss: 621968337018080779567104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 5663974853.86, NNZs: 2, Bias: -140918934717.488190, T: 4352, Avg. loss: 507787323453178814398464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 5174904176.84, NNZs: 2, Bias: -140682840195.691772, T: 4480, Avg. loss: 628752774473378974138368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9939648523.31, NNZs: 2, Bias: -140638232237.134705, T: 4608, Avg. loss: 755954951012639922192384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5830563581.09, NNZs: 2, Bias: -140788774028.073639, T: 4736, Avg. loss: 697554920976520249868288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1464284679.15, NNZs: 2, Bias: -140696878522.024231, T: 4864, Avg. loss: 760114908770220552224768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 8168270402.98, NNZs: 2, Bias: -140732794533.457336, T: 4992, Avg. loss: 554850064113516154978304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 909147157.70, NNZs: 2, Bias: -140684381201.568085, T: 5120, Avg. loss: 14291322270894897758208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1250655006.55, NNZs: 2, Bias: -140618019194.082153, T: 5248, Avg. loss: 2616594733410185904128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1945719789.11, NNZs: 2, Bias: -140554782276.219757, T: 5376, Avg. loss: 2203566957882144456704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2009840269.97, NNZs: 2, Bias: -140503897599.291046, T: 5504, Avg. loss: 2088204933245258170368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2285393493.44, NNZs: 2, Bias: -140449678600.235779, T: 5632, Avg. loss: 2123875468064990953472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2244927152.47, NNZs: 2, Bias: -140402485928.665680, T: 5760, Avg. loss: 2136375480689764597760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2307152977.44, NNZs: 2, Bias: -140352774925.095581, T: 5888, Avg. loss: 2078645523155477856256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2390159632.63, NNZs: 2, Bias: -140304587705.097931, T: 6016, Avg. loss: 1973310907741588422656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2549083139.71, NNZs: 2, Bias: -140257660081.752838, T: 6144, Avg. loss: 1788839078660959371264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2312453298.02, NNZs: 2, Bias: -140212452345.238342, T: 6272, Avg. loss: 2219162219992139694080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2266221200.12, NNZs: 2, Bias: -140161325790.886169, T: 6400, Avg. loss: 2318916554615823794176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2367045301.65, NNZs: 2, Bias: -140111813873.783051, T: 6528, Avg. loss: 1922726380026297319424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2318275054.71, NNZs: 2, Bias: -140063730959.221832, T: 6656, Avg. loss: 2097239916342746546176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2412828241.75, NNZs: 2, Bias: -140014473211.933624, T: 6784, Avg. loss: 2006565077557241446400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2303870136.56, NNZs: 2, Bias: -140006334786.652679, T: 6912, Avg. loss: 1767325712809302163456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2334946650.11, NNZs: 2, Bias: -139995944902.360199, T: 7040, Avg. loss: 1738733926927259926528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2315847721.17, NNZs: 2, Bias: -139986330183.659302, T: 7168, Avg. loss: 1754047222708618395648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2325645400.08, NNZs: 2, Bias: -139976268091.667511, T: 7296, Avg. loss: 1745789918244088315904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2274310683.95, NNZs: 2, Bias: -139967336911.692963, T: 7424, Avg. loss: 1721360927811140845568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2304496585.82, NNZs: 2, Bias: -139957002344.263519, T: 7552, Avg. loss: 1732450398576833986560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2310317299.31, NNZs: 2, Bias: -139946944424.322632, T: 7680, Avg. loss: 1755466560351048302592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2307142203.77, NNZs: 2, Bias: -139937034084.066193, T: 7808, Avg. loss: 1756740744495850061824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2306030262.87, NNZs: 2, Bias: -139927210691.704529, T: 7936, Avg. loss: 1735243432966217007104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2275236997.88, NNZs: 2, Bias: -139918106486.786285, T: 8064, Avg. loss: 1695453736359765475328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2329435587.04, NNZs: 2, Bias: -139907564472.480469, T: 8192, Avg. loss: 1701404334957755367424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2276224452.68, NNZs: 2, Bias: -139898705969.190796, T: 8320, Avg. loss: 1718852268575186485248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2301557220.25, NNZs: 2, Bias: -139888448793.375427, T: 8448, Avg. loss: 1732984407350861365248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2290625069.27, NNZs: 2, Bias: -139878710832.010925, T: 8576, Avg. loss: 1747402194392995856384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2315152164.04, NNZs: 2, Bias: -139868554674.798462, T: 8704, Avg. loss: 1716181976944719953920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2318622233.03, NNZs: 2, Bias: -139866542348.884430, T: 8832, Avg. loss: 1678425281963008983040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2312701349.96, NNZs: 2, Bias: -139864669030.967010, T: 8960, Avg. loss: 1693285091357390012416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2301460551.26, NNZs: 2, Bias: -139862897269.542297, T: 9088, Avg. loss: 1681347968528555442176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2307139275.21, NNZs: 2, Bias: -139860838139.936737, T: 9216, Avg. loss: 1687645888243746471936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2309873120.33, NNZs: 2, Bias: -139858827821.776215, T: 9344, Avg. loss: 1687352468248953094144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2306772839.65, NNZs: 2, Bias: -139856917196.469025, T: 9472, Avg. loss: 1684805686946501492736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 74 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1826267639616.58, NNZs: 2, Bias: 26584419043.794228, T: 128, Avg. loss: 19826843268772316870101434368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 361118065346.41, NNZs: 2, Bias: -2845358165.264343, T: 256, Avg. loss: 21234040534244439172438818816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 531158374467.57, NNZs: 2, Bias: -12682072610.032417, T: 384, Avg. loss: 21470519703673260915810107392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1822330317934.45, NNZs: 2, Bias: -12682072610.032417, T: 512, Avg. loss: 18745471071583065854227513344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 389714002418.24, NNZs: 2, Bias: 47317927389.967583, T: 640, Avg. loss: 21573958298659917565989486592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 427508113881.96, NNZs: 2, Bias: 47508123052.017899, T: 768, Avg. loss: 21346527704300445347960848384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1227128606770.28, NNZs: 2, Bias: 78558104969.307831, T: 896, Avg. loss: 19433152307823572277832712192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1681472476172.65, NNZs: 2, Bias: -28701516413.029144, T: 1024, Avg. loss: 21007878475905021800985133056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1813665193538.92, NNZs: 2, Bias: 11298483586.970856, T: 1152, Avg. loss: 17905164501967765452561055744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1442268427902.83, NNZs: 2, Bias: -37775642594.264381, T: 1280, Avg. loss: 22527394365609900093493739520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 414421101406.89, NNZs: 2, Bias: -37775642594.264374, T: 1408, Avg. loss: 20516760481503995561273982976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2383026468168.96, NNZs: 2, Bias: -21533265206.931801, T: 1536, Avg. loss: 17695419292923830621364551680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 620811486011.56, NNZs: 2, Bias: 98475777850.464279, T: 1664, Avg. loss: 20877638828717414823390871552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 445333441864.95, NNZs: 2, Bias: 30263121141.300720, T: 1792, Avg. loss: 19840460260028070258974654464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 592777253458.26, NNZs: 2, Bias: 75264916885.855301, T: 1920, Avg. loss: 20715526780024879318602612736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1929490579294.51, NNZs: 2, Bias: 115264916885.855301, T: 2048, Avg. loss: 18880839181112025238051225600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1832734291040.76, NNZs: 2, Bias: 80754008054.781036, T: 2176, Avg. loss: 18680273281447377326500216832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 127590111293.30, NNZs: 2, Bias: 91867477120.059692, T: 2304, Avg. loss: 1515633677108188486991609856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 411831210171.29, NNZs: 2, Bias: 82806860376.356293, T: 2432, Avg. loss: 751676138928823909063065600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 397361028396.90, NNZs: 2, Bias: 64092436923.443489, T: 2560, Avg. loss: 840472984258788383266963456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 232677902557.29, NNZs: 2, Bias: 66689012070.598747, T: 2688, Avg. loss: 777630862252368442211434496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 209790971940.27, NNZs: 2, Bias: 56643467745.990631, T: 2816, Avg. loss: 805040246379788320410435584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 292477108005.62, NNZs: 2, Bias: 75638315786.545166, T: 2944, Avg. loss: 802919036581307364721819648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 133798864422.53, NNZs: 2, Bias: 69705021487.322372, T: 3072, Avg. loss: 753765451808863559868219392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 25080136355.55, NNZs: 2, Bias: 65221807940.333519, T: 3200, Avg. loss: 30416857821586368524976128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 37954459390.90, NNZs: 2, Bias: 65354993637.092354, T: 3328, Avg. loss: 29668937502724574123393024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 17639497218.13, NNZs: 2, Bias: 64676139721.024323, T: 3456, Avg. loss: 29346062713096032913195008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 39927901999.02, NNZs: 2, Bias: 63115871712.270439, T: 3584, Avg. loss: 29704505090792590730592256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 38253939097.48, NNZs: 2, Bias: 65115573429.486977, T: 3712, Avg. loss: 29752834562758494402904064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 47243269249.83, NNZs: 2, Bias: 66510093347.778786, T: 3840, Avg. loss: 29086274913174170189692928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 19576978893.90, NNZs: 2, Bias: 66444401762.557968, T: 3968, Avg. loss: 28334260519899447206871040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 94737755319.89, NNZs: 2, Bias: 66939750413.085526, T: 4096, Avg. loss: 28356538665466875791540224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 23787104711.48, NNZs: 2, Bias: 71330883230.612900, T: 4224, Avg. loss: 30341516619505473717010432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 70293453352.20, NNZs: 2, Bias: 71214258760.587067, T: 4352, Avg. loss: 31327541257419987554926592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 92134950376.20, NNZs: 2, Bias: 67021874136.426674, T: 4480, Avg. loss: 28722410818526957797376000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 15864276014.71, NNZs: 2, Bias: 71672582236.787552, T: 4608, Avg. loss: 30196582422447469069598720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4309777612.77, NNZs: 2, Bias: 72147226477.133545, T: 4736, Avg. loss: 593669127985591656382464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3113834329.73, NNZs: 2, Bias: 72020949870.730179, T: 4864, Avg. loss: 344905455203254422994944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3237058903.46, NNZs: 2, Bias: 71810853012.096069, T: 4992, Avg. loss: 530220278254699332763648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2328851392.63, NNZs: 2, Bias: 71768499595.774734, T: 5120, Avg. loss: 499542966721113187418112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1724141401.08, NNZs: 2, Bias: 71545519726.893066, T: 5248, Avg. loss: 407771987662607021506560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4519512323.74, NNZs: 2, Bias: 71351500469.430634, T: 5376, Avg. loss: 419208587720722887999488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 5024821712.66, NNZs: 2, Bias: 71175857032.043655, T: 5504, Avg. loss: 464470244101601867333632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2019239979.16, NNZs: 2, Bias: 71183790226.888367, T: 5632, Avg. loss: 3875115493939809353728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1774161055.10, NNZs: 2, Bias: 71163596125.844437, T: 5760, Avg. loss: 626023694469357371392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1566596875.05, NNZs: 2, Bias: 71144017623.993469, T: 5888, Avg. loss: 540288058215204388864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1490432006.59, NNZs: 2, Bias: 71122503723.623520, T: 6016, Avg. loss: 544336740103510163456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1489442766.74, NNZs: 2, Bias: 71098797468.743179, T: 6144, Avg. loss: 509191574631579123712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1472331874.57, NNZs: 2, Bias: 71074143163.729996, T: 6272, Avg. loss: 554986333718830710784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1501159372.32, NNZs: 2, Bias: 71050769864.517639, T: 6400, Avg. loss: 495739280326098354176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1513108078.63, NNZs: 2, Bias: 71026059229.822403, T: 6528, Avg. loss: 551503147727378841600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1508494111.99, NNZs: 2, Bias: 71003020866.734299, T: 6656, Avg. loss: 516998419028861059072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1452063111.87, NNZs: 2, Bias: 70980187550.295013, T: 6784, Avg. loss: 563300753696229294080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1453235727.37, NNZs: 2, Bias: 70955831543.996704, T: 6912, Avg. loss: 526497855815726465024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1533312638.86, NNZs: 2, Bias: 70929542083.561920, T: 7040, Avg. loss: 535852604590396211200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1498726276.38, NNZs: 2, Bias: 70925360845.427139, T: 7168, Avg. loss: 442427887440739500032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1479758241.52, NNZs: 2, Bias: 70920933526.597382, T: 7296, Avg. loss: 433564325477748375552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1499618668.59, NNZs: 2, Bias: 70915755681.366638, T: 7424, Avg. loss: 426164325391987048448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1480436982.83, NNZs: 2, Bias: 70911291355.776535, T: 7552, Avg. loss: 437552694013399793664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1488404323.68, NNZs: 2, Bias: 70906360515.258118, T: 7680, Avg. loss: 426400163370563665920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1477631764.60, NNZs: 2, Bias: 70901753181.712173, T: 7808, Avg. loss: 433746530597467783168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1467671744.49, NNZs: 2, Bias: 70897319393.491577, T: 7936, Avg. loss: 415060105725345529856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1464691507.33, NNZs: 2, Bias: 70892616647.605850, T: 8064, Avg. loss: 427554062790334283776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1473697924.50, NNZs: 2, Bias: 70887668651.083557, T: 8192, Avg. loss: 426085754155287576576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1480423060.40, NNZs: 2, Bias: 70882797510.845001, T: 8320, Avg. loss: 423356682941517987840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1473717696.80, NNZs: 2, Bias: 70878133788.855835, T: 8448, Avg. loss: 430946832094165139456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1474200652.99, NNZs: 2, Bias: 70873376585.480637, T: 8576, Avg. loss: 424331122599753940992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1473654785.16, NNZs: 2, Bias: 70872431800.039200, T: 8704, Avg. loss: 416373856770541944832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1470802074.88, NNZs: 2, Bias: 70871535368.261642, T: 8832, Avg. loss: 416252013883939225600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1475864643.82, NNZs: 2, Bias: 70870483033.372055, T: 8960, Avg. loss: 412193519761622892544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1471001774.94, NNZs: 2, Bias: 70869626551.530243, T: 9088, Avg. loss: 417113305709976748032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1471673569.38, NNZs: 2, Bias: 70868657799.624344, T: 9216, Avg. loss: 415687803455241846784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1471625738.55, NNZs: 2, Bias: 70867704352.317123, T: 9344, Avg. loss: 415570721819459452928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1471970160.01, NNZs: 2, Bias: 70866745269.430115, T: 9472, Avg. loss: 414417604929667203072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1467194345.00, NNZs: 2, Bias: 70865894636.606277, T: 9600, Avg. loss: 413585260674978545664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1283392828980.17, NNZs: 2, Bias: 30385260847.248642, T: 128, Avg. loss: 19914562210223617918585798656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 908993231521.39, NNZs: 2, Bias: -9614739152.751358, T: 256, Avg. loss: 19509712037620930187840454656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2693054227821.26, NNZs: 2, Bias: -68114554436.137177, T: 384, Avg. loss: 20604890504048487348222033920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1374613624472.63, NNZs: 2, Bias: -68114554436.137177, T: 512, Avg. loss: 20312510729056941338418741248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2377189900215.43, NNZs: 2, Bias: -48114554436.137177, T: 640, Avg. loss: 21113919005932235538405785600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1076345822540.37, NNZs: 2, Bias: 11885445563.862823, T: 768, Avg. loss: 22659077174569815780244848640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1021392490175.76, NNZs: 2, Bias: 12048666692.623508, T: 896, Avg. loss: 20628549048439687317370699776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 114754332446.94, NNZs: 2, Bias: 4409019607.393328, T: 1024, Avg. loss: 1068855019737264415362252800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 217659448563.50, NNZs: 2, Bias: 11863926972.088697, T: 1152, Avg. loss: 766022053163331513730727936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 63942317941.39, NNZs: 2, Bias: -2699431522.998756, T: 1280, Avg. loss: 778455327163887066648936448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 106529138489.92, NNZs: 2, Bias: 7483002335.590065, T: 1408, Avg. loss: 872857480622713991547846656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 265574468824.81, NNZs: 2, Bias: 32051824395.706959, T: 1536, Avg. loss: 831137022493307633617862656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 374927178091.93, NNZs: 2, Bias: 31146513724.144379, T: 1664, Avg. loss: 877107350116163113755607040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 166903420188.65, NNZs: 2, Bias: 21071776776.703056, T: 1792, Avg. loss: 842470610998736511765053440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6307646625.96, NNZs: 2, Bias: 19984152031.100067, T: 1920, Avg. loss: 37069139730631544750997504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 46481514874.07, NNZs: 2, Bias: 22650001565.670898, T: 2048, Avg. loss: 29577477457694852437245952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 27580319502.29, NNZs: 2, Bias: 24491846836.429863, T: 2176, Avg. loss: 30557333010828944040001536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 60210938853.77, NNZs: 2, Bias: 20310579781.148521, T: 2304, Avg. loss: 30392284845819851926667264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 58768134594.76, NNZs: 2, Bias: 21092009692.549015, T: 2432, Avg. loss: 33592664280391735520002048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 12537657349.15, NNZs: 2, Bias: 18769141800.868118, T: 2560, Avg. loss: 27397121928554821074288640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 16779397565.75, NNZs: 2, Bias: 18505728725.572048, T: 2688, Avg. loss: 32075361748486336983072768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 49222190430.11, NNZs: 2, Bias: 19679434584.730801, T: 2816, Avg. loss: 28566462027485879832936448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 20806824607.35, NNZs: 2, Bias: 20873388012.540714, T: 2944, Avg. loss: 32962860548984132664819712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 84805631875.11, NNZs: 2, Bias: 20558158480.082951, T: 3072, Avg. loss: 34047648645692575847546880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 40916177470.31, NNZs: 2, Bias: 24196186328.924053, T: 3200, Avg. loss: 31208299376105175589584896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 900977366.42, NNZs: 2, Bias: 23458569124.234764, T: 3328, Avg. loss: 751562465604927529943040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 5091296248.91, NNZs: 2, Bias: 23212317131.497814, T: 3456, Avg. loss: 402557967351368965423104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2598273266.17, NNZs: 2, Bias: 22839026879.486366, T: 3584, Avg. loss: 465497174857647243919360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2438260302.35, NNZs: 2, Bias: 23185665739.427963, T: 3712, Avg. loss: 482799177512232972976128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2979969453.34, NNZs: 2, Bias: 22982388575.163712, T: 3840, Avg. loss: 421937172530717641408512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2516900049.33, NNZs: 2, Bias: 23212503684.238819, T: 3968, Avg. loss: 451432106089584179281920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2737696718.95, NNZs: 2, Bias: 23162833267.584713, T: 4096, Avg. loss: 543308104912487304921088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1620814118.54, NNZs: 2, Bias: 23173145233.317162, T: 4224, Avg. loss: 716491484142119682048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1115658757.26, NNZs: 2, Bias: 23176169019.553185, T: 4352, Avg. loss: 204109181392113598464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 871639996.37, NNZs: 2, Bias: 23173338705.730419, T: 4480, Avg. loss: 102165297135401058304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 737982020.58, NNZs: 2, Bias: 23168987086.868408, T: 4608, Avg. loss: 70403655290262462464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 670271335.45, NNZs: 2, Bias: 23162905544.371422, T: 4736, Avg. loss: 60476244833572511744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 632034096.30, NNZs: 2, Bias: 23156351913.614735, T: 4864, Avg. loss: 55510488372462182400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 607752476.04, NNZs: 2, Bias: 23149619088.950920, T: 4992, Avg. loss: 53059366519990165504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 606944199.84, NNZs: 2, Bias: 23142278440.410255, T: 5120, Avg. loss: 53516418492004655104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 600132790.09, NNZs: 2, Bias: 23135571535.754406, T: 5248, Avg. loss: 50492002022456238080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 601862444.36, NNZs: 2, Bias: 23128226774.173180, T: 5376, Avg. loss: 51813514830268014592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 607758436.24, NNZs: 2, Bias: 23121103342.170704, T: 5504, Avg. loss: 49633164760038170624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 580885529.48, NNZs: 2, Bias: 23114066884.780933, T: 5632, Avg. loss: 56405444073084551168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 583017153.06, NNZs: 2, Bias: 23106942698.595493, T: 5760, Avg. loss: 50707217398085885952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 595698879.49, NNZs: 2, Bias: 23099578292.120022, T: 5888, Avg. loss: 48576578304363044864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 587960325.84, NNZs: 2, Bias: 23092422889.925045, T: 6016, Avg. loss: 53237279837842595840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 596509703.86, NNZs: 2, Bias: 23084990757.308964, T: 6144, Avg. loss: 50880866062008860672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 594039103.54, NNZs: 2, Bias: 23077773875.822205, T: 6272, Avg. loss: 51534833290913349632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 592770429.38, NNZs: 2, Bias: 23070851988.411583, T: 6400, Avg. loss: 49666318708243382272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 587309242.06, NNZs: 2, Bias: 23063282663.025505, T: 6528, Avg. loss: 54194765102796709888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 588407776.59, NNZs: 2, Bias: 23061815900.614796, T: 6656, Avg. loss: 41854486767894200320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 589317889.21, NNZs: 2, Bias: 23060401029.546310, T: 6784, Avg. loss: 40379656917399838720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 589911652.01, NNZs: 2, Bias: 23058957405.038132, T: 6912, Avg. loss: 41572479787402584064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 591798882.18, NNZs: 2, Bias: 23057469375.919548, T: 7040, Avg. loss: 41819139095476305920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 589641298.71, NNZs: 2, Bias: 23056080933.291599, T: 7168, Avg. loss: 41979672358156689408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 589218512.01, NNZs: 2, Bias: 23054633605.848305, T: 7296, Avg. loss: 42435689486955167744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 590215258.16, NNZs: 2, Bias: 23053202438.421593, T: 7424, Avg. loss: 40845075508074250240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 591850345.52, NNZs: 2, Bias: 23052872461.867546, T: 7552, Avg. loss: 40763580073270288384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 591994811.87, NNZs: 2, Bias: 23052580288.886250, T: 7680, Avg. loss: 40838888396210724864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 592405138.63, NNZs: 2, Bias: 23052282160.918106, T: 7808, Avg. loss: 40712053959222411264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 591629571.83, NNZs: 2, Bias: 23052013376.327503, T: 7936, Avg. loss: 40885442256702578688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 591065382.59, NNZs: 2, Bias: 23051739706.582825, T: 8064, Avg. loss: 40799558457048203264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 63 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 557969109016.66, NNZs: 2, Bias: 64957602722.093018, T: 128, Avg. loss: 22989491513410355574987554816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1336870210751.03, NNZs: 2, Bias: 27797433133.428116, T: 256, Avg. loss: 22310828371168182035013435392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 381660205316.95, NNZs: 2, Bias: 47363161229.752106, T: 384, Avg. loss: 22784472941461737529719914496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1749170460928.62, NNZs: 2, Bias: 106684008872.351334, T: 512, Avg. loss: 22529612462130686277342724096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 966813005564.97, NNZs: 2, Bias: 148118459609.612549, T: 640, Avg. loss: 21346582946862248136808595456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2989043753913.44, NNZs: 2, Bias: 73581578160.062683, T: 768, Avg. loss: 21187852941317398792480227328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 806996015632.01, NNZs: 2, Bias: 13581578160.062683, T: 896, Avg. loss: 23513904574802727927598284800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214268013620.48, NNZs: 2, Bias: -7117028352.726974, T: 1024, Avg. loss: 23388775255438308655767748608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1309309196874.84, NNZs: 2, Bias: -107117028352.726974, T: 1152, Avg. loss: 22697876356684565689640419328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 280087455979.65, NNZs: 2, Bias: 12882971647.273026, T: 1280, Avg. loss: 23007727043468566704559226880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 752783536449.79, NNZs: 2, Bias: 52882971647.273026, T: 1408, Avg. loss: 23288865270326871759932882944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 219931342767.55, NNZs: 2, Bias: 58994955488.490753, T: 1536, Avg. loss: 1004010169549701630203527168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 249233648310.59, NNZs: 2, Bias: 48583555159.210030, T: 1664, Avg. loss: 884415288391669199574925312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 148528858763.24, NNZs: 2, Bias: 65329629218.535439, T: 1792, Avg. loss: 875545840908351835436220416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 318427961259.12, NNZs: 2, Bias: 50908024647.455177, T: 1920, Avg. loss: 911204487185813682205491200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 150921498709.05, NNZs: 2, Bias: 42880095855.333687, T: 2048, Avg. loss: 834551485624552957969170432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 203867637913.19, NNZs: 2, Bias: 60215345258.112885, T: 2176, Avg. loss: 876380733335503467700027392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 200769718814.80, NNZs: 2, Bias: 58511452689.143669, T: 2304, Avg. loss: 916122291190049178478706688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 495978683702.35, NNZs: 2, Bias: 63563402664.324371, T: 2432, Avg. loss: 872145558284190811827470336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 355904259834.23, NNZs: 2, Bias: 86547168275.999146, T: 2560, Avg. loss: 882647398428602033858674688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 436664350655.27, NNZs: 2, Bias: 103102253383.253937, T: 2688, Avg. loss: 870687217959404320759742464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 27919211075.56, NNZs: 2, Bias: 97448804031.182480, T: 2816, Avg. loss: 83523547610706692584505344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 75174911913.69, NNZs: 2, Bias: 97398949510.149124, T: 2944, Avg. loss: 32407416328458048846692352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 79361916119.27, NNZs: 2, Bias: 95045565529.545197, T: 3072, Avg. loss: 32357101904748782509096960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 69794146580.42, NNZs: 2, Bias: 98908245332.018951, T: 3200, Avg. loss: 31276891985832651949867008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 81437473536.53, NNZs: 2, Bias: 97280750247.188370, T: 3328, Avg. loss: 31938470326010443823316992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 84102592357.42, NNZs: 2, Bias: 97735387615.862411, T: 3456, Avg. loss: 34896510278687594286940160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 70364764801.91, NNZs: 2, Bias: 97506793672.687973, T: 3584, Avg. loss: 35301630890950830340440064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 110015568462.89, NNZs: 2, Bias: 100390939319.801636, T: 3712, Avg. loss: 33111816572578871352754176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 73246659436.89, NNZs: 2, Bias: 102018295671.032181, T: 3840, Avg. loss: 30240579797329616574611456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 55213195834.03, NNZs: 2, Bias: 100018284556.310822, T: 3968, Avg. loss: 31424403298024543431426048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 28903343360.63, NNZs: 2, Bias: 101248697689.834213, T: 4096, Avg. loss: 32329577238502417950048256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 93329340066.21, NNZs: 2, Bias: 102387446819.381531, T: 4224, Avg. loss: 34355469160841252020682752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 58964538128.27, NNZs: 2, Bias: 105081873883.045547, T: 4352, Avg. loss: 34034263504192962918612992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 16705521949.53, NNZs: 2, Bias: 103834800319.535095, T: 4480, Avg. loss: 38456187107365726799790080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4409465102.91, NNZs: 2, Bias: 103728704852.800323, T: 4608, Avg. loss: 773990630454860284166144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 10538385865.34, NNZs: 2, Bias: 103728594496.448120, T: 4736, Avg. loss: 743169810050281862332416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 11810803521.47, NNZs: 2, Bias: 103904273520.164856, T: 4864, Avg. loss: 661969568575471979855872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 11823654227.71, NNZs: 2, Bias: 103984398034.937790, T: 4992, Avg. loss: 842049865050477020839936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1168728886.79, NNZs: 2, Bias: 104126367386.927917, T: 5120, Avg. loss: 717563514676191101452288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4035075984.70, NNZs: 2, Bias: 104104365804.030884, T: 5248, Avg. loss: 599853748299963593392128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1655570918.21, NNZs: 2, Bias: 103848116945.159363, T: 5376, Avg. loss: 680795494518366119395328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9205010149.88, NNZs: 2, Bias: 103473720838.661240, T: 5504, Avg. loss: 653907959744460488704000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4318151827.78, NNZs: 2, Bias: 103383906182.690933, T: 5632, Avg. loss: 825469910017724567781376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6042415249.04, NNZs: 2, Bias: 102963223581.757263, T: 5760, Avg. loss: 567798701965355478155264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2173806966.75, NNZs: 2, Bias: 103016950947.105759, T: 5888, Avg. loss: 660170882812675713138688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 11894006535.95, NNZs: 2, Bias: 102991335295.872711, T: 6016, Avg. loss: 719088868663262961467392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 6182901705.47, NNZs: 2, Bias: 102969533298.716919, T: 6144, Avg. loss: 599870814001764000333824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 7713155274.52, NNZs: 2, Bias: 102647271564.858597, T: 6272, Avg. loss: 754425866711077742444544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3141940989.57, NNZs: 2, Bias: 102922369856.966690, T: 6400, Avg. loss: 830578721344247709040640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1924536806.61, NNZs: 2, Bias: 102897332458.135406, T: 6528, Avg. loss: 2022892994936018305024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1912526989.85, NNZs: 2, Bias: 102863131540.221786, T: 6656, Avg. loss: 1102380839225867370496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1856709737.87, NNZs: 2, Bias: 102831613530.344635, T: 6784, Avg. loss: 1030867842146208841728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1847942138.18, NNZs: 2, Bias: 102797536663.239975, T: 6912, Avg. loss: 1116053325398244720640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1797067935.55, NNZs: 2, Bias: 102765752751.252136, T: 7040, Avg. loss: 1075699132080612966400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1807446406.25, NNZs: 2, Bias: 102731791608.873459, T: 7168, Avg. loss: 1060256888691921256448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1865282673.21, NNZs: 2, Bias: 102696508853.695877, T: 7296, Avg. loss: 1070892470849281982464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1738300019.76, NNZs: 2, Bias: 102662295025.710037, T: 7424, Avg. loss: 1247778723946586963968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1753857799.09, NNZs: 2, Bias: 102654960123.735001, T: 7552, Avg. loss: 916200972755490177024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1756518597.33, NNZs: 2, Bias: 102647915939.267532, T: 7680, Avg. loss: 907971466089625550848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1752230686.96, NNZs: 2, Bias: 102641040114.851944, T: 7808, Avg. loss: 902177696650010820608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1749552043.46, NNZs: 2, Bias: 102634158375.507294, T: 7936, Avg. loss: 899596020106517413888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1750136391.07, NNZs: 2, Bias: 102627162603.951080, T: 8064, Avg. loss: 905409350680443092992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1762466721.19, NNZs: 2, Bias: 102620024760.845245, T: 8192, Avg. loss: 896602939945970434048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1750268188.77, NNZs: 2, Bias: 102613325246.209930, T: 8320, Avg. loss: 896591124028941795328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1770159453.54, NNZs: 2, Bias: 102606108527.364456, T: 8448, Avg. loss: 889695449792466911232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1756467217.96, NNZs: 2, Bias: 102599354375.513489, T: 8576, Avg. loss: 906221470273822785536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1768128936.89, NNZs: 2, Bias: 102592254621.537064, T: 8704, Avg. loss: 894246184131677126656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1761759877.98, NNZs: 2, Bias: 102585386446.168427, T: 8832, Avg. loss: 903848492933691867136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1746863074.92, NNZs: 2, Bias: 102578849769.261765, T: 8960, Avg. loss: 883020251372375375872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1737067018.97, NNZs: 2, Bias: 102572151791.946533, T: 9088, Avg. loss: 890546162370647556096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1747372742.39, NNZs: 2, Bias: 102565032768.753098, T: 9216, Avg. loss: 899506465797964693504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1724240379.63, NNZs: 2, Bias: 102558591422.046265, T: 9344, Avg. loss: 884565708072795897856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1753216605.20, NNZs: 2, Bias: 102551114125.745087, T: 9472, Avg. loss: 903803864210852151296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1759591534.16, NNZs: 2, Bias: 102544041110.208466, T: 9600, Avg. loss: 902287005881494536192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1749555437.47, NNZs: 2, Bias: 102542828040.498932, T: 9728, Avg. loss: 872931003627160076288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1748262355.64, NNZs: 2, Bias: 102541471342.278793, T: 9856, Avg. loss: 868453046395745992704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1740523915.71, NNZs: 2, Bias: 102540236941.029892, T: 9984, Avg. loss: 860842579712219545600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1744865051.75, NNZs: 2, Bias: 102538782298.108002, T: 10112, Avg. loss: 869619360713292775424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1744833797.85, NNZs: 2, Bias: 102537404662.652802, T: 10240, Avg. loss: 868074128802200027136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1746469057.25, NNZs: 2, Bias: 102536002968.803024, T: 10368, Avg. loss: 865251465165525090304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1749531439.86, NNZs: 2, Bias: 102534575779.649475, T: 10496, Avg. loss: 865913148658001772544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 1745981818.60, NNZs: 2, Bias: 102533258520.874329, T: 10624, Avg. loss: 867948466286397620224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 83 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1325551596128.72, NNZs: 2, Bias: 9573090349.974155, T: 128, Avg. loss: 24091841028232862420952940544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1770253397003.24, NNZs: 2, Bias: -1102916771.596603, T: 256, Avg. loss: 22655622963965298862796570624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 769799851837.86, NNZs: 2, Bias: -12162048138.336216, T: 384, Avg. loss: 22660465078554904803669966848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 538335571694.37, NNZs: 2, Bias: 20028822985.876465, T: 512, Avg. loss: 24151388301549180765245276160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 559132803292.89, NNZs: 2, Bias: 40028822985.876465, T: 640, Avg. loss: 24546869923543784433402249216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1278812480464.78, NNZs: 2, Bias: 80028822985.876465, T: 768, Avg. loss: 22782460611539410018128363520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 985674717562.91, NNZs: 2, Bias: 180028822985.876465, T: 896, Avg. loss: 24897110640554410600596242432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 119384466040.75, NNZs: 2, Bias: 174861487211.026184, T: 1024, Avg. loss: 1034860612058837202212225024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 266944798550.02, NNZs: 2, Bias: 200434221100.551758, T: 1152, Avg. loss: 992201870264031677696180224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 527683691773.24, NNZs: 2, Bias: 188527475383.964020, T: 1280, Avg. loss: 932590074786370219652677632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 163103240258.90, NNZs: 2, Bias: 185528646071.373505, T: 1408, Avg. loss: 1007878249587651737745883136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 52297967603.52, NNZs: 2, Bias: 186545957962.679779, T: 1536, Avg. loss: 930778837889210943233064960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 232597952489.55, NNZs: 2, Bias: 185280265817.538879, T: 1664, Avg. loss: 943031210025111843434921984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 393249691451.14, NNZs: 2, Bias: 191101378606.958221, T: 1792, Avg. loss: 801621014005612229695635456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 316344989314.51, NNZs: 2, Bias: 202450340021.405914, T: 1920, Avg. loss: 939598453714171444989001728.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 242329056259.04, NNZs: 2, Bias: 193545643606.277588, T: 2048, Avg. loss: 910011523400826578026889216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 291089380863.05, NNZs: 2, Bias: 179070249775.520996, T: 2176, Avg. loss: 1009324392358369744838983680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 39749471438.25, NNZs: 2, Bias: 184211992116.008850, T: 2304, Avg. loss: 969480545716838635111710720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 133600571183.68, NNZs: 2, Bias: 178250053761.838928, T: 2432, Avg. loss: 1007933034630155278504427520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 29241455740.30, NNZs: 2, Bias: 178876905228.016083, T: 2560, Avg. loss: 37720944979584773573836800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 71332908375.63, NNZs: 2, Bias: 175643315018.705658, T: 2688, Avg. loss: 32059612702705467936210944.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 56461451205.78, NNZs: 2, Bias: 176124301365.724487, T: 2816, Avg. loss: 33532728921764455994359808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 27560330463.38, NNZs: 2, Bias: 175958645498.886597, T: 2944, Avg. loss: 37351725933349253452660736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 58031402251.57, NNZs: 2, Bias: 175419348274.901001, T: 3072, Avg. loss: 38742131908135333312593920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 98024827532.53, NNZs: 2, Bias: 172764879369.857452, T: 3200, Avg. loss: 36119696706600133034246144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 54717884858.38, NNZs: 2, Bias: 175034156184.687103, T: 3328, Avg. loss: 37401006784439342776451072.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 5126966158.13, NNZs: 2, Bias: 174355212879.948822, T: 3456, Avg. loss: 1241084935178203772747776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 2770564790.99, NNZs: 2, Bias: 174377641012.779694, T: 3584, Avg. loss: 693670535251162948435968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 14401980902.49, NNZs: 2, Bias: 173881100356.226837, T: 3712, Avg. loss: 908684677948755866025984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 11676310722.15, NNZs: 2, Bias: 173712531104.726715, T: 3840, Avg. loss: 783651121995753262678016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5455933484.06, NNZs: 2, Bias: 173431282519.117859, T: 3968, Avg. loss: 787022116694087209844736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2734672976.34, NNZs: 2, Bias: 173255585810.948944, T: 4096, Avg. loss: 798122286095554798682112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4023033891.79, NNZs: 2, Bias: 172781940792.968689, T: 4224, Avg. loss: 782522762252404935098368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1872891216.29, NNZs: 2, Bias: 172739929751.242828, T: 4352, Avg. loss: 4259586559371678580736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2030415968.28, NNZs: 2, Bias: 172684092834.454285, T: 4480, Avg. loss: 2797512544055017340928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2319997426.83, NNZs: 2, Bias: 172631534981.058685, T: 4608, Avg. loss: 2411280062563783016448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2402296708.42, NNZs: 2, Bias: 172579974688.766541, T: 4736, Avg. loss: 2562675991058656002048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2518857790.03, NNZs: 2, Bias: 172528931536.986725, T: 4864, Avg. loss: 2610202027637953003520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2415292904.48, NNZs: 2, Bias: 172477931785.387970, T: 4992, Avg. loss: 2750171082387255984128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2776516847.49, NNZs: 2, Bias: 172424261070.083221, T: 5120, Avg. loss: 2523389488581580423168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2389402448.22, NNZs: 2, Bias: 172377251951.214386, T: 5248, Avg. loss: 2848135451465476997120.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2406970482.90, NNZs: 2, Bias: 172366848033.187347, T: 5376, Avg. loss: 2171119772139837456384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2433849591.34, NNZs: 2, Bias: 172356354844.130951, T: 5504, Avg. loss: 2164221363559691190272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2399161468.18, NNZs: 2, Bias: 172346832597.751831, T: 5632, Avg. loss: 2142140447174728089600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2414840368.46, NNZs: 2, Bias: 172336307906.886658, T: 5760, Avg. loss: 2204425621414734987264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2466948025.06, NNZs: 2, Bias: 172325319610.719696, T: 5888, Avg. loss: 2194099292428131631104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2391237981.63, NNZs: 2, Bias: 172316399212.407715, T: 6016, Avg. loss: 2139723307496266792960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2424965218.28, NNZs: 2, Bias: 172305790393.485352, T: 6144, Avg. loss: 2168689047326821974016.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2455683403.43, NNZs: 2, Bias: 172295146829.306213, T: 6272, Avg. loss: 2186307888020089995264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2445551683.82, NNZs: 2, Bias: 172285085289.406708, T: 6400, Avg. loss: 2185466423986960990208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2450014464.01, NNZs: 2, Bias: 172274772382.446564, T: 6528, Avg. loss: 2191762630598804635648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2432632835.35, NNZs: 2, Bias: 172264755326.095306, T: 6656, Avg. loss: 2199090186595423223808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2453976044.12, NNZs: 2, Bias: 172262401482.195221, T: 6784, Avg. loss: 2138458984089473777664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2463074870.77, NNZs: 2, Bias: 172260239375.123535, T: 6912, Avg. loss: 2118557771221674754048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2464957706.64, NNZs: 2, Bias: 172258183027.166077, T: 7040, Avg. loss: 2115980187362825076736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2464068758.42, NNZs: 2, Bias: 172256163915.466217, T: 7168, Avg. loss: 2118710668048326721536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2455517494.44, NNZs: 2, Bias: 172254258769.021667, T: 7296, Avg. loss: 2113972364071623983104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2460696850.06, NNZs: 2, Bias: 172252149322.248810, T: 7424, Avg. loss: 2122108260329577250816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2459155293.33, NNZs: 2, Bias: 172250139189.833954, T: 7552, Avg. loss: 2118734202528141672448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2461502436.82, NNZs: 2, Bias: 172248073386.137817, T: 7680, Avg. loss: 2118812578920015069184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2462382238.93, NNZs: 2, Bias: 172246029014.312164, T: 7808, Avg. loss: 2118241261479130038272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2453425654.21, NNZs: 2, Bias: 172244131016.288330, T: 7936, Avg. loss: 2112259954825397534720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2470235374.58, NNZs: 2, Bias: 172241861685.731354, T: 8064, Avg. loss: 2114660949612980338688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2464440226.61, NNZs: 2, Bias: 172239911250.416290, T: 8192, Avg. loss: 2120102685254905757696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2466448447.65, NNZs: 2, Bias: 172237851221.196991, T: 8320, Avg. loss: 2117393351150690107392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2465892991.75, NNZs: 2, Bias: 172235836502.073334, T: 8448, Avg. loss: 2108801918434283356160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2463773369.69, NNZs: 2, Bias: 172233837148.616821, T: 8576, Avg. loss: 2115851438920806694912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2462215466.73, NNZs: 2, Bias: 172231826733.273102, T: 8704, Avg. loss: 2119106629965603405824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2472777536.91, NNZs: 2, Bias: 172229648345.721222, T: 8832, Avg. loss: 2112652404268178079744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2462477594.71, NNZs: 2, Bias: 172227761311.890198, T: 8960, Avg. loss: 2121395027723653218304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2471656444.42, NNZs: 2, Bias: 172225601743.253601, T: 9088, Avg. loss: 2113432539792881483776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 71 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 785888798624.31, NNZs: 2, Bias: 17566073371.095692, T: 128, Avg. loss: 19995851724711418149107400704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1436103932810.14, NNZs: 2, Bias: 43814044188.397507, T: 256, Avg. loss: 21949600659200148368479223808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 291423233822.13, NNZs: 2, Bias: -19006528943.305382, T: 384, Avg. loss: 20702058468254845199936651264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1241634076134.42, NNZs: 2, Bias: -44614577085.013794, T: 512, Avg. loss: 21760019774508938297478217728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 371842222227.45, NNZs: 2, Bias: -106695646409.141235, T: 640, Avg. loss: 22862606008617765683511427072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 500403206746.86, NNZs: 2, Bias: -66695646409.141235, T: 768, Avg. loss: 23399024826069781545935175680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 69250494309.05, NNZs: 2, Bias: -66903715392.518372, T: 896, Avg. loss: 875131285169711167794315264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 392512248086.87, NNZs: 2, Bias: -57069560308.876762, T: 1024, Avg. loss: 771188471377652263768031232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 73717553853.55, NNZs: 2, Bias: -75684944860.406937, T: 1152, Avg. loss: 937891239545315395809312768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 237731930134.37, NNZs: 2, Bias: -62125735302.652084, T: 1280, Avg. loss: 877503060490730232071847936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 308969212349.56, NNZs: 2, Bias: -56700882024.088196, T: 1408, Avg. loss: 847235431893585804990087168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 127963737734.99, NNZs: 2, Bias: -39838919018.379555, T: 1536, Avg. loss: 839208761796424804570497024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 17159402748.91, NNZs: 2, Bias: -39634776938.496590, T: 1664, Avg. loss: 877422725826181530023624704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 64004094021.19, NNZs: 2, Bias: -40965515333.963104, T: 1792, Avg. loss: 32292023710207468009160704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 30999780421.19, NNZs: 2, Bias: -41197342074.321518, T: 1920, Avg. loss: 31495739625490818315321344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 70237548343.33, NNZs: 2, Bias: -41805952496.516464, T: 2048, Avg. loss: 36044084813014293136015360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 26463311860.71, NNZs: 2, Bias: -43244085197.052505, T: 2176, Avg. loss: 33205191102591917061308416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 61352608695.82, NNZs: 2, Bias: -44194354970.412468, T: 2304, Avg. loss: 30036359590540149394505728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 52156532191.70, NNZs: 2, Bias: -48710047563.004875, T: 2432, Avg. loss: 36271473709074736979378176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 100843092985.79, NNZs: 2, Bias: -47812630193.318459, T: 2560, Avg. loss: 27728037874978720753647616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 21297083345.23, NNZs: 2, Bias: -47686366347.726440, T: 2688, Avg. loss: 32281215687244983805411328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 58577230634.63, NNZs: 2, Bias: -50043129398.501892, T: 2816, Avg. loss: 29301226793724723381403648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 11841555685.00, NNZs: 2, Bias: -50821562133.643311, T: 2944, Avg. loss: 30421018780878502056951808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 101496885581.06, NNZs: 2, Bias: -50335597624.384789, T: 3072, Avg. loss: 30964707194567170428239872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 72842549432.19, NNZs: 2, Bias: -51277300380.112404, T: 3200, Avg. loss: 33158791117471339702648832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 7021843062.09, NNZs: 2, Bias: -51921566287.386948, T: 3328, Avg. loss: 2635750873215847729463296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 11059720084.26, NNZs: 2, Bias: -52056703417.889824, T: 3456, Avg. loss: 494213155338092323799040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3341842432.37, NNZs: 2, Bias: -52128300783.816956, T: 3584, Avg. loss: 618752398700044762480640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8689648806.00, NNZs: 2, Bias: -52294460265.191002, T: 3712, Avg. loss: 655212896181110567862272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4919178613.18, NNZs: 2, Bias: -52146110698.371613, T: 3840, Avg. loss: 526784107458394310311936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1306658821.16, NNZs: 2, Bias: -52087677176.760338, T: 3968, Avg. loss: 458611206228442034995200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 10641585393.55, NNZs: 2, Bias: -51865797191.645378, T: 4096, Avg. loss: 375127166396530042077184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1458766795.24, NNZs: 2, Bias: -51829313431.954506, T: 4224, Avg. loss: 649618154342788412473344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 790138680.34, NNZs: 2, Bias: -51920624743.072426, T: 4352, Avg. loss: 437071762013505680572416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 15352294751.34, NNZs: 2, Bias: -51702676324.048378, T: 4480, Avg. loss: 506384043224555795251200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 14220116565.86, NNZs: 2, Bias: -51362668086.186073, T: 4608, Avg. loss: 681644596603903719505920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1234779921.34, NNZs: 2, Bias: -51294596388.751785, T: 4736, Avg. loss: 624030692623157404106752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 990856579.24, NNZs: 2, Bias: -51280464375.823532, T: 4864, Avg. loss: 321373406231474208768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 857726081.64, NNZs: 2, Bias: -51263527153.126747, T: 4992, Avg. loss: 308939313463132225536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 863587534.31, NNZs: 2, Bias: -51246003697.132095, T: 5120, Avg. loss: 258152708535812751360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 883456694.49, NNZs: 2, Bias: -51227542991.719559, T: 5248, Avg. loss: 276891861744824025088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 794011791.80, NNZs: 2, Bias: -51210947364.106506, T: 5376, Avg. loss: 279688620421879889920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 806849579.43, NNZs: 2, Bias: -51192456829.785522, T: 5504, Avg. loss: 287702471987623526400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 801286209.18, NNZs: 2, Bias: -51175050130.285583, T: 5632, Avg. loss: 270734168161473626112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 792869550.66, NNZs: 2, Bias: -51155968102.140739, T: 5760, Avg. loss: 296757295522559557632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 794473023.34, NNZs: 2, Bias: -51152259698.141098, T: 5888, Avg. loss: 233973024788788707328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 812205910.99, NNZs: 2, Bias: -51148343465.455917, T: 6016, Avg. loss: 230191976813555548160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 805904246.54, NNZs: 2, Bias: -51144812960.050995, T: 6144, Avg. loss: 230526494582458482688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 803513384.51, NNZs: 2, Bias: -51141175343.891945, T: 6272, Avg. loss: 233276825448853766144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 801216873.07, NNZs: 2, Bias: -51137530192.471390, T: 6400, Avg. loss: 234038164704225198080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 800574336.05, NNZs: 2, Bias: -51133932275.195648, T: 6528, Avg. loss: 228354959622899367936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 798812760.55, NNZs: 2, Bias: -51130288684.630821, T: 6656, Avg. loss: 233126528299369398272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 796014215.49, NNZs: 2, Bias: -51126763364.992569, T: 6784, Avg. loss: 226365139931345813504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 805888477.92, NNZs: 2, Bias: -51122982713.697014, T: 6912, Avg. loss: 229658433626139918336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 796156640.31, NNZs: 2, Bias: -51119521087.505592, T: 7040, Avg. loss: 229727633292448235520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 815734926.07, NNZs: 2, Bias: -51115646602.626076, T: 7168, Avg. loss: 225698916335235661824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 796420149.98, NNZs: 2, Bias: -51112232234.765808, T: 7296, Avg. loss: 236665857991063896064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 802889435.34, NNZs: 2, Bias: -51108478171.422195, T: 7424, Avg. loss: 231494447517323493376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 797803905.59, NNZs: 2, Bias: -51104886784.061272, T: 7552, Avg. loss: 232883824172838748160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 798478963.92, NNZs: 2, Bias: -51101315493.541481, T: 7680, Avg. loss: 226216120123059535872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 795744358.59, NNZs: 2, Bias: -51097721892.982254, T: 7808, Avg. loss: 231018837564037398528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 802272165.96, NNZs: 2, Bias: -51096890070.047371, T: 7936, Avg. loss: 225599015535474212864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 799656659.02, NNZs: 2, Bias: -51096204860.290230, T: 8064, Avg. loss: 224600566799213821952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 799895297.76, NNZs: 2, Bias: -51095471914.876114, T: 8192, Avg. loss: 225511846501295325184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 799066389.97, NNZs: 2, Bias: -51094756757.845398, T: 8320, Avg. loss: 225191069676287688704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 797995731.64, NNZs: 2, Bias: -51094045903.588043, T: 8448, Avg. loss: 225002289124911808512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 801397666.00, NNZs: 2, Bias: -51093263652.571236, T: 8576, Avg. loss: 225396357056423067648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 801999364.85, NNZs: 2, Bias: -51092525711.796280, T: 8704, Avg. loss: 225262113503521734656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 68 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 528560652404.40, NNZs: 2, Bias: -7667877194.274956, T: 128, Avg. loss: 18581234328590837267688325120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 734435080714.80, NNZs: 2, Bias: -83542437388.922729, T: 256, Avg. loss: 20950953463761166494817320960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 404726706192.30, NNZs: 2, Bias: -143542437388.922729, T: 384, Avg. loss: 20443964993839591552842727424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 664237814184.27, NNZs: 2, Bias: -203542437388.922729, T: 512, Avg. loss: 19692525631071353393052123136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1126875100458.54, NNZs: 2, Bias: -203542437388.922729, T: 640, Avg. loss: 20942273203523161235950403584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 736618603973.63, NNZs: 2, Bias: -143542437388.922729, T: 768, Avg. loss: 20057943849952085431510106112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 153423787770.28, NNZs: 2, Bias: -137150773510.511658, T: 896, Avg. loss: 818369919249701769677111296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 211192371467.65, NNZs: 2, Bias: -122655149652.606262, T: 1024, Avg. loss: 791172448760640413332668416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 280186153303.88, NNZs: 2, Bias: -131382222614.337555, T: 1152, Avg. loss: 846739606863260930306736128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 272462128263.76, NNZs: 2, Bias: -125785533250.669769, T: 1280, Avg. loss: 873302612711456441339215872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 269983148992.65, NNZs: 2, Bias: -118685605826.604355, T: 1408, Avg. loss: 738443092984549017552683008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 238923959356.18, NNZs: 2, Bias: -132869107784.997452, T: 1536, Avg. loss: 796953988811972481990524928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 209021204321.59, NNZs: 2, Bias: -134773355493.322327, T: 1664, Avg. loss: 839865407318035391869616128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 51820798491.08, NNZs: 2, Bias: -140217435317.171783, T: 1792, Avg. loss: 780776780248676324104732672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 383269469116.02, NNZs: 2, Bias: -138972684101.234528, T: 1920, Avg. loss: 825514762454200053974171648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 123358743694.76, NNZs: 2, Bias: -147024100029.469727, T: 2048, Avg. loss: 799918613735602391827349504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 16902901732.59, NNZs: 2, Bias: -147028965245.353424, T: 2176, Avg. loss: 27543152488712089771180032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 86117289219.21, NNZs: 2, Bias: -145788077541.673096, T: 2304, Avg. loss: 27153418233126979322773504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 39446069437.46, NNZs: 2, Bias: -144570013202.362305, T: 2432, Avg. loss: 29672861008679490627305472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 53786648527.15, NNZs: 2, Bias: -144738201717.675507, T: 2560, Avg. loss: 32195389152883015669514240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 36655684725.57, NNZs: 2, Bias: -144915708948.546082, T: 2688, Avg. loss: 31013604467490251941609472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 79448782540.32, NNZs: 2, Bias: -141634853946.603882, T: 2816, Avg. loss: 27743274483076196328275968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 19088762018.07, NNZs: 2, Bias: -140091747524.290802, T: 2944, Avg. loss: 28549777761826133038333952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 8913727605.89, NNZs: 2, Bias: -140045267354.538757, T: 3072, Avg. loss: 650843262349346672214016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1464477619.67, NNZs: 2, Bias: -139855943397.695068, T: 3200, Avg. loss: 617327176003437838991360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 3942218830.48, NNZs: 2, Bias: -139369135051.237976, T: 3328, Avg. loss: 543992751727603510935552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4453673647.59, NNZs: 2, Bias: -139050190000.632629, T: 3456, Avg. loss: 437599632738845705895936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 17832617225.98, NNZs: 2, Bias: -138855592805.394958, T: 3584, Avg. loss: 651798006963178506813440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 5863339972.60, NNZs: 2, Bias: -138561123368.681152, T: 3712, Avg. loss: 574012498565745615044608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2607890110.55, NNZs: 2, Bias: -138615562138.105743, T: 3840, Avg. loss: 430516906897012227571712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4707118152.11, NNZs: 2, Bias: -138504765415.037750, T: 3968, Avg. loss: 544935068951386611777536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4760942620.03, NNZs: 2, Bias: -138340514339.285828, T: 4096, Avg. loss: 563374391386169617154048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5011942923.80, NNZs: 2, Bias: -138238371968.292114, T: 4224, Avg. loss: 619653029679162214842368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 14258126300.18, NNZs: 2, Bias: -137820565778.615662, T: 4352, Avg. loss: 392693834229845957017600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2037186371.58, NNZs: 2, Bias: -137932291236.254242, T: 4480, Avg. loss: 545870924869755021033472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3707116557.06, NNZs: 2, Bias: -137838455056.030334, T: 4608, Avg. loss: 482681068952229230149632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4723649955.26, NNZs: 2, Bias: -137727046335.695404, T: 4736, Avg. loss: 496783314691595761090560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 12077678355.40, NNZs: 2, Bias: -137655181841.251953, T: 4864, Avg. loss: 499916550508087145922560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4169345231.00, NNZs: 2, Bias: -137400351908.728485, T: 4992, Avg. loss: 570745820809816518426624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3058978840.33, NNZs: 2, Bias: -137367685285.114532, T: 5120, Avg. loss: 2779352469679800057856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2606533857.80, NNZs: 2, Bias: -137329328192.469040, T: 5248, Avg. loss: 2057802263767928799232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2289351636.02, NNZs: 2, Bias: -137289994396.355698, T: 5376, Avg. loss: 1937914988971706548224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2146117055.60, NNZs: 2, Bias: -137246968559.658325, T: 5504, Avg. loss: 1924885087995797438464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2013190091.61, NNZs: 2, Bias: -137200846103.788223, T: 5632, Avg. loss: 2056850877079802347520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2090038634.66, NNZs: 2, Bias: -137153299015.948120, T: 5760, Avg. loss: 1873528242467804545024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2176201204.47, NNZs: 2, Bias: -137103401153.142761, T: 5888, Avg. loss: 2102059585204122812416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2184131890.68, NNZs: 2, Bias: -137054947322.920227, T: 6016, Avg. loss: 2129762845452517507072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2219108318.68, NNZs: 2, Bias: -137009917492.724686, T: 6144, Avg. loss: 1838032723425416970240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2153388008.89, NNZs: 2, Bias: -136962585028.486023, T: 6272, Avg. loss: 2015739118684354641920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2179890288.72, NNZs: 2, Bias: -136914673233.675461, T: 6400, Avg. loss: 1958605701438492114944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2162625485.54, NNZs: 2, Bias: -136867527592.877563, T: 6528, Avg. loss: 1971721102249903521792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2054269921.14, NNZs: 2, Bias: -136819861432.746902, T: 6656, Avg. loss: 2015892022726871220224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2032438180.53, NNZs: 2, Bias: -136771824493.626831, T: 6784, Avg. loss: 2063337666819721527296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2056038433.21, NNZs: 2, Bias: -136762212449.466156, T: 6912, Avg. loss: 1577161572376389091328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2056599033.30, NNZs: 2, Bias: -136752796131.243530, T: 7040, Avg. loss: 1602058993518057357312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2052029988.59, NNZs: 2, Bias: -136743393444.331177, T: 7168, Avg. loss: 1612944700154729725952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2077376128.39, NNZs: 2, Bias: -136733544447.619919, T: 7296, Avg. loss: 1611978092425183494144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2109878619.46, NNZs: 2, Bias: -136723607564.048492, T: 7424, Avg. loss: 1608199643381466398720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2082179162.00, NNZs: 2, Bias: -136714582179.284912, T: 7552, Avg. loss: 1612516658968742592512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2083239222.60, NNZs: 2, Bias: -136712698796.808273, T: 7680, Avg. loss: 1545934626373884968960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2077860866.71, NNZs: 2, Bias: -136710918086.391693, T: 7808, Avg. loss: 1542282192184561106944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2081052239.12, NNZs: 2, Bias: -136708995944.167114, T: 7936, Avg. loss: 1551173883144855093248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2081348190.20, NNZs: 2, Bias: -136707121570.755554, T: 8064, Avg. loss: 1548209268739161456640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2088524702.94, NNZs: 2, Bias: -136705136551.879059, T: 8192, Avg. loss: 1552718055106705358848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2092671739.53, NNZs: 2, Bias: -136703200237.073395, T: 8320, Avg. loss: 1550505427246270382080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2098347053.05, NNZs: 2, Bias: -136701245196.722504, T: 8448, Avg. loss: 1546263387467140300800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 66 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 677755363003.63, NNZs: 2, Bias: 51704956615.990715, T: 128, Avg. loss: 22359413234355649234239225856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 837146443191.94, NNZs: 2, Bias: 50389409758.935516, T: 256, Avg. loss: 18212825587634559303601356800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1053348577830.57, NNZs: 2, Bias: 70389409758.935516, T: 384, Avg. loss: 18945517630685422147749281792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2006002073005.05, NNZs: 2, Bias: 68762354167.254013, T: 512, Avg. loss: 19594662156365779977138864128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 569131032685.53, NNZs: 2, Bias: 31739386651.234100, T: 640, Avg. loss: 23113213199583143969402388480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 898720925189.73, NNZs: 2, Bias: 10801801576.408966, T: 768, Avg. loss: 20441996087109736755821019136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 581743193540.44, NNZs: 2, Bias: 10801801576.408966, T: 896, Avg. loss: 21528838480210255572597997568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 229290644433.97, NNZs: 2, Bias: 5652083590.214823, T: 1024, Avg. loss: 762930211959437871005302784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 270913558810.34, NNZs: 2, Bias: 3984736348.903746, T: 1152, Avg. loss: 811367566554605711200878592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 299825343569.02, NNZs: 2, Bias: 20605891749.945034, T: 1280, Avg. loss: 813473737232242739247054848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 203103448054.49, NNZs: 2, Bias: 13929766657.186024, T: 1408, Avg. loss: 789030495869941494212198400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 165015471168.86, NNZs: 2, Bias: -4191605046.284809, T: 1536, Avg. loss: 894465093601398889652420608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 34326822828.03, NNZs: 2, Bias: -19405533890.852406, T: 1664, Avg. loss: 877797720485488820521795584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 38562770007.32, NNZs: 2, Bias: -19788608253.466816, T: 1792, Avg. loss: 32039241676279204085235712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 55337685566.29, NNZs: 2, Bias: -20028792288.537720, T: 1920, Avg. loss: 30823088802858249043836928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 13058894925.17, NNZs: 2, Bias: -20413808645.011471, T: 2048, Avg. loss: 31709969029568768222691328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 78649283577.34, NNZs: 2, Bias: -23156473718.023884, T: 2176, Avg. loss: 31319857109515767881138176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1893789711.74, NNZs: 2, Bias: -25071010061.431133, T: 2304, Avg. loss: 30824397573927533228851200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 24048421407.26, NNZs: 2, Bias: -25348921020.854736, T: 2432, Avg. loss: 27289551980070092293537792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10900804183.43, NNZs: 2, Bias: -25840454424.328987, T: 2560, Avg. loss: 35251669908473674054238208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 66109878722.73, NNZs: 2, Bias: -27074459561.884911, T: 2688, Avg. loss: 30840701438617269957558272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 67480167490.40, NNZs: 2, Bias: -27010710450.950680, T: 2816, Avg. loss: 31880703733052741175476224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 25971069753.13, NNZs: 2, Bias: -26307457958.958481, T: 2944, Avg. loss: 27584577011990096448061440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 20922821290.65, NNZs: 2, Bias: -23198136780.775433, T: 3072, Avg. loss: 30412772869666504720777216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 8248765047.62, NNZs: 2, Bias: -23677702528.815994, T: 3200, Avg. loss: 629880467926122909138944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 19926287022.17, NNZs: 2, Bias: -23588081165.421940, T: 3328, Avg. loss: 526052131695157324021760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 6871223004.73, NNZs: 2, Bias: -23818070792.524761, T: 3456, Avg. loss: 738927590231445891710976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3935596592.43, NNZs: 2, Bias: -23629551144.212223, T: 3584, Avg. loss: 477733789965318843531264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 763491224.33, NNZs: 2, Bias: -23494607502.649704, T: 3712, Avg. loss: 485772987796364850102272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3185693035.47, NNZs: 2, Bias: -23610829258.933651, T: 3840, Avg. loss: 479619379866835498303488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 179092909.61, NNZs: 2, Bias: -23633265526.995358, T: 3968, Avg. loss: 398035698785162893459456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8038727445.43, NNZs: 2, Bias: -23572448871.362877, T: 4096, Avg. loss: 406888176052428177670144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 12673304313.15, NNZs: 2, Bias: -23496388730.526726, T: 4224, Avg. loss: 418310224133136368795648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 11956387847.00, NNZs: 2, Bias: -23107380125.100048, T: 4352, Avg. loss: 470832897649953873068032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1921900850.64, NNZs: 2, Bias: -23167617811.134262, T: 4480, Avg. loss: 375928698720508411117568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6423236209.12, NNZs: 2, Bias: -23098444347.242664, T: 4608, Avg. loss: 434924503404670103846912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1889846843.59, NNZs: 2, Bias: -22887850198.575832, T: 4736, Avg. loss: 438744870084845687013376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5249726458.88, NNZs: 2, Bias: -23066570327.474079, T: 4864, Avg. loss: 407691551102905629016064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 5442339485.25, NNZs: 2, Bias: -23107266619.573891, T: 4992, Avg. loss: 596144229991672006574080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 637173312.86, NNZs: 2, Bias: -22689831942.013062, T: 5120, Avg. loss: 507573409494757367873536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 206409626.72, NNZs: 2, Bias: -22673286789.247990, T: 5248, Avg. loss: 157823484317894836224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 146888180.59, NNZs: 2, Bias: -22662066361.036591, T: 5376, Avg. loss: 75629428003231203328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 263075134.49, NNZs: 2, Bias: -22652726353.162315, T: 5504, Avg. loss: 53618428083240042496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 321465257.50, NNZs: 2, Bias: -22644686312.966511, T: 5632, Avg. loss: 47340637352890531840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 352075366.77, NNZs: 2, Bias: -22636854330.953976, T: 5760, Avg. loss: 49075642156534325248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 353565737.93, NNZs: 2, Bias: -22629525810.951855, T: 5888, Avg. loss: 49814018921278963712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 366913879.80, NNZs: 2, Bias: -22621910671.116993, T: 6016, Avg. loss: 51178164856293048320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 376416424.39, NNZs: 2, Bias: -22614605015.704353, T: 6144, Avg. loss: 46922390661499953152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 367575340.07, NNZs: 2, Bias: -22607671330.675133, T: 6272, Avg. loss: 47963329538300583936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 379610824.44, NNZs: 2, Bias: -22600275316.294914, T: 6400, Avg. loss: 48906002727917920256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 381021507.49, NNZs: 2, Bias: -22593130023.944077, T: 6528, Avg. loss: 49880988537542025216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 376587616.42, NNZs: 2, Bias: -22585808329.890404, T: 6656, Avg. loss: 51418178658232164352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 366514844.76, NNZs: 2, Bias: -22578598023.278049, T: 6784, Avg. loss: 49885437514156916736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 370861836.94, NNZs: 2, Bias: -22577070859.708363, T: 6912, Avg. loss: 40739686729532170240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 369556007.68, NNZs: 2, Bias: -22575658839.724251, T: 7040, Avg. loss: 40059345367780556800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 367226086.34, NNZs: 2, Bias: -22574300324.651546, T: 7168, Avg. loss: 39027097236771315712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 374646555.12, NNZs: 2, Bias: -22572715247.546803, T: 7296, Avg. loss: 40854472169914073088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 377709965.08, NNZs: 2, Bias: -22571221918.686741, T: 7424, Avg. loss: 40295914043571789824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 376590379.97, NNZs: 2, Bias: -22569803735.169090, T: 7552, Avg. loss: 40270022926164975616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 378814790.16, NNZs: 2, Bias: -22568320495.592892, T: 7680, Avg. loss: 40379653279237742592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 376590416.93, NNZs: 2, Bias: -22566958455.130550, T: 7808, Avg. loss: 39172228876856623104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 377768136.34, NNZs: 2, Bias: -22566650423.152027, T: 7936, Avg. loss: 39233354572354207744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 377010694.21, NNZs: 2, Bias: -22566377333.384560, T: 8064, Avg. loss: 38887886554775068672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 378144901.15, NNZs: 2, Bias: -22566070169.889446, T: 8192, Avg. loss: 39210617047518314496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 377731129.77, NNZs: 2, Bias: -22565789425.774456, T: 8320, Avg. loss: 39145376638867357696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 378773405.04, NNZs: 2, Bias: -22565484518.217289, T: 8448, Avg. loss: 39104626775487520768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 379568716.14, NNZs: 2, Bias: -22565184113.804180, T: 8576, Avg. loss: 39053374829981622272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 378036427.82, NNZs: 2, Bias: -22564921848.568390, T: 8704, Avg. loss: 39195829777193164800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 68 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 390153510175.03, NNZs: 2, Bias: 59418927137.172699, T: 128, Avg. loss: 20297955381090499738948599808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1702120131050.09, NNZs: 2, Bias: 95608069358.907516, T: 256, Avg. loss: 21870714394397241530707345408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1551481483120.63, NNZs: 2, Bias: 155608069358.907532, T: 384, Avg. loss: 23194284613685033953644249088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 790565352164.15, NNZs: 2, Bias: 208791633291.289795, T: 512, Avg. loss: 21348535275112353016051662848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1780972642890.06, NNZs: 2, Bias: 237379610925.583649, T: 640, Avg. loss: 21955381318963512910429552640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1500322219325.17, NNZs: 2, Bias: 248616691863.834778, T: 768, Avg. loss: 22451749509128397674743070720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 119678117776.16, NNZs: 2, Bias: 245806739973.337280, T: 896, Avg. loss: 1223915979034919802098417664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 348639151064.73, NNZs: 2, Bias: 220987353495.313263, T: 1024, Avg. loss: 812471086139807432515256320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 160080288400.37, NNZs: 2, Bias: 225340206851.356140, T: 1152, Avg. loss: 916225973747731266417983488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 86474014375.58, NNZs: 2, Bias: 207850116962.436462, T: 1280, Avg. loss: 936390867620570591637012480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 485878725461.02, NNZs: 2, Bias: 211574425393.933380, T: 1408, Avg. loss: 834192410953416736531021824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 289914866210.73, NNZs: 2, Bias: 216100199556.300690, T: 1536, Avg. loss: 875315966054397822971674624.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 115836879639.98, NNZs: 2, Bias: 238383765334.036255, T: 1664, Avg. loss: 918601320667154414647115776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 15886482169.67, NNZs: 2, Bias: 238976678078.854736, T: 1792, Avg. loss: 35007395929667002699874304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 41561160016.04, NNZs: 2, Bias: 236347292169.873383, T: 1920, Avg. loss: 35530757989310292197113856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 44458677330.70, NNZs: 2, Bias: 234399046127.045288, T: 2048, Avg. loss: 31604161033134113508294656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 21655952082.42, NNZs: 2, Bias: 235366447500.214417, T: 2176, Avg. loss: 32688103579996529247649792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 47719873048.57, NNZs: 2, Bias: 236585165086.080231, T: 2304, Avg. loss: 31356418705435135259443200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 61026057638.18, NNZs: 2, Bias: 237023290112.966736, T: 2432, Avg. loss: 32746100105464286657118208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28682882483.89, NNZs: 2, Bias: 236251024817.601654, T: 2560, Avg. loss: 34280511218372818954616832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 75982642929.46, NNZs: 2, Bias: 233682086073.737274, T: 2688, Avg. loss: 34010935345292678365446144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 47660398631.33, NNZs: 2, Bias: 225434043085.048737, T: 2816, Avg. loss: 33896108005343795907395584.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 58218283370.64, NNZs: 2, Bias: 224453435265.840973, T: 2944, Avg. loss: 33464973067210558187503616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 9859989114.45, NNZs: 2, Bias: 224456247978.202423, T: 3072, Avg. loss: 1539653526102847994724352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10294145171.65, NNZs: 2, Bias: 224215652957.664764, T: 3200, Avg. loss: 686942585400612062494720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10024420008.28, NNZs: 2, Bias: 224011129076.829987, T: 3328, Avg. loss: 715212147190416474636288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 7338084997.58, NNZs: 2, Bias: 223727904064.113495, T: 3456, Avg. loss: 797981522115734217424896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 16952989250.56, NNZs: 2, Bias: 223148855398.687256, T: 3584, Avg. loss: 669560653075745620361216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2614706769.64, NNZs: 2, Bias: 223219960546.245361, T: 3712, Avg. loss: 812283424382444560711680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3365457702.32, NNZs: 2, Bias: 222770559164.551910, T: 3840, Avg. loss: 538281318012942353956864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5640467247.48, NNZs: 2, Bias: 222418942133.587494, T: 3968, Avg. loss: 714299740450103280795648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2571421590.95, NNZs: 2, Bias: 222129924564.106628, T: 4096, Avg. loss: 649607450054253780926464.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2190136215.24, NNZs: 2, Bias: 221499706352.885376, T: 4224, Avg. loss: 805000686814765210664960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3049543824.78, NNZs: 2, Bias: 221098305287.100311, T: 4352, Avg. loss: 730362979059742277632000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2105514330.13, NNZs: 2, Bias: 220683765529.032440, T: 4480, Avg. loss: 836905010245780665008128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 3000976424.55, NNZs: 2, Bias: 220595743597.217804, T: 4608, Avg. loss: 4872272835317119057920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3168586093.81, NNZs: 2, Bias: 220516733390.186615, T: 4736, Avg. loss: 5273791725861061263360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3202284852.44, NNZs: 2, Bias: 220436393111.566681, T: 4864, Avg. loss: 5475683445085626695680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3154595604.56, NNZs: 2, Bias: 220360144249.970520, T: 4992, Avg. loss: 5228230711341211451392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3407129437.23, NNZs: 2, Bias: 220281157481.483551, T: 5120, Avg. loss: 5030463814377596256256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 3611811852.99, NNZs: 2, Bias: 220206975185.010986, T: 5248, Avg. loss: 4483137243445800730624.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3472257808.63, NNZs: 2, Bias: 220133891499.901825, T: 5376, Avg. loss: 4958232198708995293184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 3426974241.64, NNZs: 2, Bias: 220056294617.682983, T: 5504, Avg. loss: 5265317542118437158912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3331922266.59, NNZs: 2, Bias: 219987349802.636719, T: 5632, Avg. loss: 4629247578457990234112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3421863172.72, NNZs: 2, Bias: 219910963894.840637, T: 5760, Avg. loss: 4993490324289559199744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3313414404.16, NNZs: 2, Bias: 219836756649.300201, T: 5888, Avg. loss: 4947531335558088359936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3329679506.17, NNZs: 2, Bias: 219821523646.505280, T: 6016, Avg. loss: 4096718202357933408256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3338323236.53, NNZs: 2, Bias: 219806298943.842926, T: 6144, Avg. loss: 4129731276632293900288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3307295046.61, NNZs: 2, Bias: 219791978543.966980, T: 6272, Avg. loss: 4042646546872583847936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3348358061.38, NNZs: 2, Bias: 219776065597.381653, T: 6400, Avg. loss: 4181103081561928499200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3321464832.85, NNZs: 2, Bias: 219761417653.040588, T: 6528, Avg. loss: 4123881743668040695808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3345553986.86, NNZs: 2, Bias: 219745908865.057709, T: 6656, Avg. loss: 4147355994101223784448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3340482249.00, NNZs: 2, Bias: 219731049519.501343, T: 6784, Avg. loss: 4090489840130421948416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3317059510.03, NNZs: 2, Bias: 219716336453.960419, T: 6912, Avg. loss: 4129157865614582743040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3353815453.70, NNZs: 2, Bias: 219712759901.917755, T: 7040, Avg. loss: 4015054886980819615744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3345312851.97, NNZs: 2, Bias: 219709895072.267365, T: 7168, Avg. loss: 3985021732088634146816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3358875214.30, NNZs: 2, Bias: 219706698013.902466, T: 7296, Avg. loss: 3977267992885683290112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3353262259.16, NNZs: 2, Bias: 219703786800.407135, T: 7424, Avg. loss: 3987910835286384312320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3358285318.56, NNZs: 2, Bias: 219700717035.451874, T: 7552, Avg. loss: 3981773640583458324480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3352796261.55, NNZs: 2, Bias: 219697799232.358612, T: 7680, Avg. loss: 3994370356122139230208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3350477998.88, NNZs: 2, Bias: 219694839615.723755, T: 7808, Avg. loss: 3984935853556280852480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3356369922.81, NNZs: 2, Bias: 219691752688.437225, T: 7936, Avg. loss: 3987224316212277149696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 62 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 432290196721.70, NNZs: 2, Bias: -49954945414.986435, T: 128, Avg. loss: 24231719061459644594645893120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 936565013278.74, NNZs: 2, Bias: -13793857838.982269, T: 256, Avg. loss: 23020243707189946118253314048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1774354956826.88, NNZs: 2, Bias: -73693621171.196045, T: 384, Avg. loss: 24441373269791495383716724736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1216754971798.18, NNZs: 2, Bias: -78277604511.759567, T: 512, Avg. loss: 24341796892010547096714215424.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 917760472403.08, NNZs: 2, Bias: -36526871947.626099, T: 640, Avg. loss: 23399326940115442695447511040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1141306209706.41, NNZs: 2, Bias: -66981493292.939331, T: 768, Avg. loss: 23630221291529467300981768192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 642126092193.16, NNZs: 2, Bias: -173812522739.114960, T: 896, Avg. loss: 23283253025736822039919984640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 115988157417.72, NNZs: 2, Bias: -191693625655.191223, T: 1024, Avg. loss: 978246749549865534207557632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 473720352173.28, NNZs: 2, Bias: -193631148408.045593, T: 1152, Avg. loss: 862952493940673354680762368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 389140454282.49, NNZs: 2, Bias: -187489028111.889282, T: 1280, Avg. loss: 888481748963750826024632320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 89204665782.49, NNZs: 2, Bias: -194110023463.318817, T: 1408, Avg. loss: 888073675426216176397582336.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 121178348599.59, NNZs: 2, Bias: -183322685550.457947, T: 1536, Avg. loss: 946506452014915792092004352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 140787316270.32, NNZs: 2, Bias: -192235333179.608734, T: 1664, Avg. loss: 1018967020992793272987418624.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 124450220207.61, NNZs: 2, Bias: -191389093846.776123, T: 1792, Avg. loss: 885704908807584180221247488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 82421977730.67, NNZs: 2, Bias: -191135106184.035706, T: 1920, Avg. loss: 37406537837783865010159616.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 53075909588.75, NNZs: 2, Bias: -187286432986.802399, T: 2048, Avg. loss: 37514615962319538765168640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 36916116266.53, NNZs: 2, Bias: -185721005587.786621, T: 2176, Avg. loss: 34857798649043043414441984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 10698930039.82, NNZs: 2, Bias: -186505157818.646729, T: 2304, Avg. loss: 39484741142823055990456320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 40176551585.92, NNZs: 2, Bias: -185320571993.107605, T: 2432, Avg. loss: 40626380553937033208266752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 18952441666.50, NNZs: 2, Bias: -182102176996.250275, T: 2560, Avg. loss: 39659304367638092080742400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 48745782761.44, NNZs: 2, Bias: -179684868659.116425, T: 2688, Avg. loss: 37207768193618124478611456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 35596752518.30, NNZs: 2, Bias: -179314769005.380005, T: 2816, Avg. loss: 40617383433658036872282112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 9895674917.23, NNZs: 2, Bias: -178985459458.363861, T: 2944, Avg. loss: 899161552182759351386112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 6625991076.86, NNZs: 2, Bias: -178920959829.767273, T: 3072, Avg. loss: 777477394249087392415744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 14875545116.70, NNZs: 2, Bias: -178706417215.401794, T: 3200, Avg. loss: 782969272083347981467648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 19014037781.81, NNZs: 2, Bias: -178510621569.570190, T: 3328, Avg. loss: 825216351255848615411712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 6965640762.27, NNZs: 2, Bias: -178682510277.775757, T: 3456, Avg. loss: 917213915139606791061504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 6375800540.04, NNZs: 2, Bias: -178532462312.850159, T: 3584, Avg. loss: 689675818576796062842880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 11244087085.48, NNZs: 2, Bias: -178451763140.161438, T: 3712, Avg. loss: 808170172114456872484864.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 12408273782.90, NNZs: 2, Bias: -178208722594.565918, T: 3840, Avg. loss: 826805343861326101872640.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4799931949.72, NNZs: 2, Bias: -177992341701.524658, T: 3968, Avg. loss: 569783287022528193626112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6741764818.19, NNZs: 2, Bias: -177504271324.520416, T: 4096, Avg. loss: 741771835949441934688256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 5352505500.19, NNZs: 2, Bias: -177056151067.971466, T: 4224, Avg. loss: 687087450160104313192448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3085096877.90, NNZs: 2, Bias: -176277526187.600677, T: 4352, Avg. loss: 807401750732989930668032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3731637623.17, NNZs: 2, Bias: -176025475568.372009, T: 4480, Avg. loss: 746401946667619792715776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 12973184818.48, NNZs: 2, Bias: -176275764368.166656, T: 4608, Avg. loss: 727202013069676392742912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1622873109.12, NNZs: 2, Bias: -176148247642.144165, T: 4736, Avg. loss: 80623354589010978668544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2027301691.88, NNZs: 2, Bias: -176088257882.001862, T: 4864, Avg. loss: 2815064128733861380096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2168651094.28, NNZs: 2, Bias: -176033574545.300415, T: 4992, Avg. loss: 2801014814313223290880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2392412341.18, NNZs: 2, Bias: -175977786879.346222, T: 5120, Avg. loss: 2721753873220735860736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2355791299.68, NNZs: 2, Bias: -175925927524.321747, T: 5248, Avg. loss: 2721718274289965203456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2573678075.35, NNZs: 2, Bias: -175871157231.575439, T: 5376, Avg. loss: 2708079101901543571456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2504397665.64, NNZs: 2, Bias: -175820049831.218140, T: 5504, Avg. loss: 2754876001625530957824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2437858114.46, NNZs: 2, Bias: -175768815466.957855, T: 5632, Avg. loss: 2798665453316354342912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2373174705.73, NNZs: 2, Bias: -175718525474.841278, T: 5760, Avg. loss: 2653496253133104873472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2440079091.45, NNZs: 2, Bias: -175665843173.595306, T: 5888, Avg. loss: 2732388398232503320576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2521062604.41, NNZs: 2, Bias: -175611810889.631897, T: 6016, Avg. loss: 2685175920497928437760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2473374606.18, NNZs: 2, Bias: -175560895474.279327, T: 6144, Avg. loss: 2822242916979574833152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2555812218.37, NNZs: 2, Bias: -175509823519.227173, T: 6272, Avg. loss: 2611011542382721630208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2636711017.97, NNZs: 2, Bias: -175457418313.828461, T: 6400, Avg. loss: 2668377450116902551552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2460379289.82, NNZs: 2, Bias: -175408387349.583160, T: 6528, Avg. loss: 2743914390410027335680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2578397386.67, NNZs: 2, Bias: -175353210757.967529, T: 6656, Avg. loss: 2871891727249383096320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2585654567.41, NNZs: 2, Bias: -175301350850.482452, T: 6784, Avg. loss: 2726059124915818201088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2596397400.56, NNZs: 2, Bias: -175251844283.978455, T: 6912, Avg. loss: 2576462868376305795072.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2438931296.26, NNZs: 2, Bias: -175201452880.816620, T: 7040, Avg. loss: 2816757786579196968960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2523134003.58, NNZs: 2, Bias: -175148296519.810120, T: 7168, Avg. loss: 2684661992200692826112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2400655365.68, NNZs: 2, Bias: -175096228451.906067, T: 7296, Avg. loss: 2887181091381491269632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2467900221.41, NNZs: 2, Bias: -175049050118.838013, T: 7424, Avg. loss: 2410461197255990837248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2455461866.42, NNZs: 2, Bias: -174999458647.590668, T: 7552, Avg. loss: 2552402306669616300032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2477848202.08, NNZs: 2, Bias: -174948044390.127808, T: 7680, Avg. loss: 2753924226505024995328.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2381097338.56, NNZs: 2, Bias: -174894479011.779358, T: 7808, Avg. loss: 3014758533841774182400.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2406880101.81, NNZs: 2, Bias: -174843412362.656067, T: 7936, Avg. loss: 2609673368468322254848.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2545614198.63, NNZs: 2, Bias: -174787845621.138885, T: 8064, Avg. loss: 2739839931691395186688.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2491057830.95, NNZs: 2, Bias: -174778369313.811340, T: 8192, Avg. loss: 2233398837610874142720.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2503930653.78, NNZs: 2, Bias: -174767967272.403748, T: 8320, Avg. loss: 2221986265716176191488.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2532373093.23, NNZs: 2, Bias: -174757321267.627533, T: 8448, Avg. loss: 2227533981028560142336.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2464247026.66, NNZs: 2, Bias: -174748116474.515625, T: 8576, Avg. loss: 2214653124805419335680.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2511140898.17, NNZs: 2, Bias: -174737254529.525391, T: 8704, Avg. loss: 2214234311807630573568.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2535782325.24, NNZs: 2, Bias: -174726687767.336517, T: 8832, Avg. loss: 2215593829074527584256.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2519502876.78, NNZs: 2, Bias: -174716582039.399689, T: 8960, Avg. loss: 2249782593080028561408.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2469757276.81, NNZs: 2, Bias: -174706892365.471130, T: 9088, Avg. loss: 2262831326960898801664.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2520293209.88, NNZs: 2, Bias: -174695968954.269775, T: 9216, Avg. loss: 2214405197229533167616.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2547107008.04, NNZs: 2, Bias: -174685302656.474915, T: 9344, Avg. loss: 2229260865141191737344.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2510737738.91, NNZs: 2, Bias: -174683742334.350555, T: 9472, Avg. loss: 2213325160129629257728.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2506782236.92, NNZs: 2, Bias: -174681741851.783875, T: 9600, Avg. loss: 2179641739453709418496.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2510585688.83, NNZs: 2, Bias: -174679631448.209625, T: 9728, Avg. loss: 2177735189805781221376.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2510887816.25, NNZs: 2, Bias: -174677570739.248779, T: 9856, Avg. loss: 2178498554584301043712.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 2513084173.25, NNZs: 2, Bias: -174675481736.119446, T: 9984, Avg. loss: 2179484759775933366272.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 2514023506.78, NNZs: 2, Bias: -174673410853.291473, T: 10112, Avg. loss: 2179472375227212103680.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 2510257536.23, NNZs: 2, Bias: -174671411131.245911, T: 10240, Avg. loss: 2175907693248722763776.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 2506165173.10, NNZs: 2, Bias: -174669415970.301239, T: 10368, Avg. loss: 2176087901987822108672.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 2511381795.06, NNZs: 2, Bias: -174667282217.342499, T: 10496, Avg. loss: 2180743637212886728704.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 2516307904.68, NNZs: 2, Bias: -174665155449.676056, T: 10624, Avg. loss: 2177553838238101929984.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 2508687763.22, NNZs: 2, Bias: -174663207488.980377, T: 10752, Avg. loss: 2179818643755018485760.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 2508581468.02, NNZs: 2, Bias: -174661151136.225922, T: 10880, Avg. loss: 2179918642138073792512.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 85 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1951889641363.15, NNZs: 2, Bias: 59562478141.716949, T: 128, Avg. loss: 21139383183485263434622173184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1865982959425.77, NNZs: 2, Bias: 127652898279.592896, T: 256, Avg. loss: 21630692043753314087465910272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1605845021176.87, NNZs: 2, Bias: 127652898279.592896, T: 384, Avg. loss: 22488400288952289773848887296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1985160180266.88, NNZs: 2, Bias: 90231567594.654419, T: 512, Avg. loss: 20373216679884231157225619456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 704024356650.54, NNZs: 2, Bias: 107789372664.676270, T: 640, Avg. loss: 21650802087817085250743304192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1560686325377.63, NNZs: 2, Bias: 127789372664.676270, T: 768, Avg. loss: 20431176351774982869186772992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1085505185166.55, NNZs: 2, Bias: 136207303123.464142, T: 896, Avg. loss: 22432527262834858705521999872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 895111219383.49, NNZs: 2, Bias: 132277618938.075439, T: 1024, Avg. loss: 22143497848287396703422644224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1195882774136.29, NNZs: 2, Bias: 172277618938.075439, T: 1152, Avg. loss: 21351680667225023321336709120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 424504995273.41, NNZs: 2, Bias: 180670344047.085815, T: 1280, Avg. loss: 1332120037533857282690908160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 110074369722.55, NNZs: 2, Bias: 180008850822.230316, T: 1408, Avg. loss: 768099739094672468156088320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 130450828944.75, NNZs: 2, Bias: 179364256614.923187, T: 1536, Avg. loss: 856346037439933738806935552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 152134089055.60, NNZs: 2, Bias: 172813936872.115601, T: 1664, Avg. loss: 871759282745789888556171264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 301924260412.00, NNZs: 2, Bias: 159360401124.940308, T: 1792, Avg. loss: 917632067224914225449140224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 305054803609.09, NNZs: 2, Bias: 161599484543.269196, T: 1920, Avg. loss: 958369236052903050510073856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 133226111292.55, NNZs: 2, Bias: 150509942628.454071, T: 2048, Avg. loss: 805700334842129234024988672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 22330305603.79, NNZs: 2, Bias: 150673954634.616882, T: 2176, Avg. loss: 33229870609207065739001856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 15507293941.66, NNZs: 2, Bias: 149078631173.947845, T: 2304, Avg. loss: 33190773076698347327193088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 23572343330.39, NNZs: 2, Bias: 150892080323.262085, T: 2432, Avg. loss: 31317031806740339733037056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 79929132555.82, NNZs: 2, Bias: 151156459836.598389, T: 2560, Avg. loss: 30654002150065560698748928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 34249753368.74, NNZs: 2, Bias: 154250997077.658203, T: 2688, Avg. loss: 35445463097484634778238976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 38289091282.67, NNZs: 2, Bias: 153117769000.252502, T: 2816, Avg. loss: 33181307567464260854349824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 21079809605.32, NNZs: 2, Bias: 152622221152.024933, T: 2944, Avg. loss: 29600545867575214565490688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 47912270863.48, NNZs: 2, Bias: 153270410829.759918, T: 3072, Avg. loss: 30682799481268396829442048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 27816347616.01, NNZs: 2, Bias: 147939247123.111969, T: 3200, Avg. loss: 33625899718992806411239424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10946108565.78, NNZs: 2, Bias: 147219742795.532410, T: 3328, Avg. loss: 30928531792420765656154112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 91004010939.01, NNZs: 2, Bias: 150405258158.859802, T: 3456, Avg. loss: 32211033606868046182350848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 15123544728.99, NNZs: 2, Bias: 149899822018.627960, T: 3584, Avg. loss: 33574268699851159129554944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9511268863.75, NNZs: 2, Bias: 149510337638.349670, T: 3712, Avg. loss: 741530875525449040003072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 6295256066.02, NNZs: 2, Bias: 149291649247.971375, T: 3840, Avg. loss: 548506930985778892767232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 7340834759.00, NNZs: 2, Bias: 149104377384.750580, T: 3968, Avg. loss: 780393641062258016518144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3570506500.87, NNZs: 2, Bias: 148743900996.127472, T: 4096, Avg. loss: 629560914034954480910336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6059700530.80, NNZs: 2, Bias: 148427971184.189423, T: 4224, Avg. loss: 626226253787094872752128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6034452356.65, NNZs: 2, Bias: 148136051781.485199, T: 4352, Avg. loss: 621343590308632548343808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1881194738.43, NNZs: 2, Bias: 148061314632.893402, T: 4480, Avg. loss: 612892410106901520449536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 667935481.54, NNZs: 2, Bias: 147971633107.102936, T: 4608, Avg. loss: 4356298536387766910976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1512327520.08, NNZs: 2, Bias: 147902917413.548553, T: 4736, Avg. loss: 2623924987167690457088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2059983671.74, NNZs: 2, Bias: 147844346361.899902, T: 4864, Avg. loss: 2204904072279999381504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2117350041.17, NNZs: 2, Bias: 147790417089.502991, T: 4992, Avg. loss: 2312873926275973251072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2197842014.86, NNZs: 2, Bias: 147736639344.504242, T: 5120, Avg. loss: 2327726489814401286144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2373713907.12, NNZs: 2, Bias: 147681390077.431976, T: 5248, Avg. loss: 2238605739186686525440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2152382241.36, NNZs: 2, Bias: 147630475803.069305, T: 5376, Avg. loss: 2507043303574322806784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2053435482.58, NNZs: 2, Bias: 147579930031.883423, T: 5504, Avg. loss: 2269355416598253142016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2144670025.36, NNZs: 2, Bias: 147567973799.879242, T: 5632, Avg. loss: 1957888171844886593536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2143988659.56, NNZs: 2, Bias: 147557463416.910492, T: 5760, Avg. loss: 1932053737709865271296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2160513565.16, NNZs: 2, Bias: 147546603241.774506, T: 5888, Avg. loss: 1952231623949808041984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2193630272.10, NNZs: 2, Bias: 147535484626.538116, T: 6016, Avg. loss: 1950806067126617767936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2193986337.15, NNZs: 2, Bias: 147524924410.993622, T: 6144, Avg. loss: 1936118145206135029760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2285094438.10, NNZs: 2, Bias: 147513166279.816803, T: 6272, Avg. loss: 1898140752403047907328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2233556556.35, NNZs: 2, Bias: 147503362425.062653, T: 6400, Avg. loss: 1951950995814557417472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2241025408.31, NNZs: 2, Bias: 147492868780.605255, T: 6528, Avg. loss: 1903636931264226525184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2277828083.28, NNZs: 2, Bias: 147482034546.686066, T: 6656, Avg. loss: 1883568898256006021120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2262766657.32, NNZs: 2, Bias: 147471691329.110931, T: 6784, Avg. loss: 1940073774217733603328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2295607947.24, NNZs: 2, Bias: 147460640263.361298, T: 6912, Avg. loss: 1936316870562108407808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2286071999.31, NNZs: 2, Bias: 147450392316.376404, T: 7040, Avg. loss: 1909481096444772876288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2288218471.53, NNZs: 2, Bias: 147439871352.953796, T: 7168, Avg. loss: 1924234888938751787008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2312708293.66, NNZs: 2, Bias: 147429111034.393707, T: 7296, Avg. loss: 1900658148006521208832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2294222424.08, NNZs: 2, Bias: 147427285391.523438, T: 7424, Avg. loss: 1892295290291694600192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2289959418.81, NNZs: 2, Bias: 147425252991.053192, T: 7552, Avg. loss: 1877295732525675053056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2290198125.79, NNZs: 2, Bias: 147423152867.550446, T: 7680, Avg. loss: 1875007139338982260736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2290931883.27, NNZs: 2, Bias: 147421044629.711823, T: 7808, Avg. loss: 1875317660467315343360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2290378146.22, NNZs: 2, Bias: 147418961197.709991, T: 7936, Avg. loss: 1870989579842017034240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2291920793.65, NNZs: 2, Bias: 147416842743.516602, T: 8064, Avg. loss: 1872853455780413702144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2290314023.11, NNZs: 2, Bias: 147414772339.151703, T: 8192, Avg. loss: 1873705302136860966912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2289098046.25, NNZs: 2, Bias: 147412692852.774109, T: 8320, Avg. loss: 1876512771551340003328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2297083765.59, NNZs: 2, Bias: 147410471315.233154, T: 8448, Avg. loss: 1875080551560556576768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2293838782.42, NNZs: 2, Bias: 147408424636.921875, T: 8576, Avg. loss: 1875532473758837899264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 67 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1250076400126.87, NNZs: 2, Bias: 32551329843.301498, T: 128, Avg. loss: 20787273436537413505654980608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 746720228439.86, NNZs: 2, Bias: -87923067494.706192, T: 256, Avg. loss: 20282861646908726175613321216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 207954451404.07, NNZs: 2, Bias: -100754406660.215927, T: 384, Avg. loss: 21382952864291773285639651328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 445175990286.42, NNZs: 2, Bias: -88714887488.446487, T: 512, Avg. loss: 20908248875781485216760070144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1243017746823.11, NNZs: 2, Bias: -130781223825.230865, T: 640, Avg. loss: 20891017326813661984528007168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1251023879436.69, NNZs: 2, Bias: -215346318692.722900, T: 768, Avg. loss: 19170745962235532699263565824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 837339853683.27, NNZs: 2, Bias: -115346318692.722900, T: 896, Avg. loss: 20317910947379024799098470400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 498538519470.68, NNZs: 2, Bias: -94677155858.186432, T: 1024, Avg. loss: 18132025340353559249433919488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1566510869488.14, NNZs: 2, Bias: -75452605139.666809, T: 1152, Avg. loss: 22123071363169700791908827136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1276095135837.81, NNZs: 2, Bias: -15246588304.869507, T: 1280, Avg. loss: 21152701511795776469669511168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2037639006934.40, NNZs: 2, Bias: -34781072081.980988, T: 1408, Avg. loss: 18389639155806345496683872256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2657904161895.79, NNZs: 2, Bias: -43138837748.857681, T: 1536, Avg. loss: 18565091923404948142641119232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 620966555500.28, NNZs: 2, Bias: -31842858939.999222, T: 1664, Avg. loss: 24177609987776567062319595520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 105040186464.56, NNZs: 2, Bias: -37426242651.610794, T: 1792, Avg. loss: 822387774882455325352394752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 311330301148.28, NNZs: 2, Bias: -35256107237.514221, T: 1920, Avg. loss: 719178752497826602604822528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 281010374908.44, NNZs: 2, Bias: -33646057400.126541, T: 2048, Avg. loss: 762836786710361253255053312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 252096966809.55, NNZs: 2, Bias: -33202647141.970058, T: 2176, Avg. loss: 750049334918302139961835520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 243717418457.68, NNZs: 2, Bias: -20103817094.324585, T: 2304, Avg. loss: 842091657714538271773556736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 338953902425.44, NNZs: 2, Bias: -28575212515.460289, T: 2432, Avg. loss: 786450268318129821518397440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 160003317145.27, NNZs: 2, Bias: -42271331468.655670, T: 2560, Avg. loss: 837159113159145642797301760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 3036601625.16, NNZs: 2, Bias: -43314986119.709900, T: 2688, Avg. loss: 33556906740283699867156480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 13216639554.11, NNZs: 2, Bias: -41526592931.926758, T: 2816, Avg. loss: 29780856854371222864003072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 21353983192.98, NNZs: 2, Bias: -41897016377.374359, T: 2944, Avg. loss: 31050722862583514681835520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 45612201206.54, NNZs: 2, Bias: -40334178750.488564, T: 3072, Avg. loss: 29492569872017684898512896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 82335506707.21, NNZs: 2, Bias: -41724950023.106689, T: 3200, Avg. loss: 28999435652262231529226240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 28041752445.63, NNZs: 2, Bias: -40786269889.037880, T: 3328, Avg. loss: 27831887507523118611562496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 24683529551.28, NNZs: 2, Bias: -40795778523.262161, T: 3456, Avg. loss: 31171834861949987856580608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 36834803137.91, NNZs: 2, Bias: -38666788182.389458, T: 3584, Avg. loss: 29143196289445006845935616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 76871501909.64, NNZs: 2, Bias: -37592889601.032402, T: 3712, Avg. loss: 29006430822233213702766592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 21162488032.49, NNZs: 2, Bias: -39767617241.818542, T: 3840, Avg. loss: 29090811854929574917832704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 108526564396.12, NNZs: 2, Bias: -38638705705.698158, T: 3968, Avg. loss: 28253884033610358288547840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 5152137711.43, NNZs: 2, Bias: -39085096134.902809, T: 4096, Avg. loss: 3447688895434640303587328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 615823993.41, NNZs: 2, Bias: -38786611505.332977, T: 4224, Avg. loss: 418729488346333422026752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6927104539.42, NNZs: 2, Bias: -38566027523.210419, T: 4352, Avg. loss: 358920023142477135347712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6254523517.12, NNZs: 2, Bias: -38349116838.111084, T: 4480, Avg. loss: 326273751314045060775936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1488991656.51, NNZs: 2, Bias: -38189257587.281250, T: 4608, Avg. loss: 336366370628454414548992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 5561458039.37, NNZs: 2, Bias: -37933883287.347008, T: 4736, Avg. loss: 324532339769176680824832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3646610274.50, NNZs: 2, Bias: -38054112881.405281, T: 4864, Avg. loss: 474604333051658551427072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1926522181.20, NNZs: 2, Bias: -37701008494.733421, T: 4992, Avg. loss: 603164908992193632403456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3707184015.32, NNZs: 2, Bias: -37698186646.605179, T: 5120, Avg. loss: 458210167142872896241664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1423745067.53, NNZs: 2, Bias: -37436420949.929535, T: 5248, Avg. loss: 622021982749230513520640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 508128972.69, NNZs: 2, Bias: -37296598591.858620, T: 5376, Avg. loss: 529370994011981047922688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 513251331.04, NNZs: 2, Bias: -37283289618.801552, T: 5504, Avg. loss: 158798764761621823488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 592465938.44, NNZs: 2, Bias: -37271147171.163773, T: 5632, Avg. loss: 124108463643315011584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 575871749.06, NNZs: 2, Bias: -37258327681.620674, T: 5760, Avg. loss: 148877405761786773504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 575058578.26, NNZs: 2, Bias: -37245547901.129555, T: 5888, Avg. loss: 141394984889349783552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 575258968.27, NNZs: 2, Bias: -37232826111.111153, T: 6016, Avg. loss: 142414539652250337280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 583236698.74, NNZs: 2, Bias: -37219088620.833572, T: 6144, Avg. loss: 154892078089631465472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 592471628.13, NNZs: 2, Bias: -37205767187.126595, T: 6272, Avg. loss: 150147956348523249664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 585803245.90, NNZs: 2, Bias: -37203317997.470169, T: 6400, Avg. loss: 118693735573247508480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 591810587.03, NNZs: 2, Bias: -37200663386.913971, T: 6528, Avg. loss: 118618769040922116096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 591131612.28, NNZs: 2, Bias: -37198129561.166458, T: 6656, Avg. loss: 117926199332938350592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 593604122.14, NNZs: 2, Bias: -37195543562.418648, T: 6784, Avg. loss: 118024026694539476992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 592251345.25, NNZs: 2, Bias: -37193039809.853386, T: 6912, Avg. loss: 116963050098935939072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 581639528.60, NNZs: 2, Bias: -37190652391.291946, T: 7040, Avg. loss: 118604464022306897920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 591947323.51, NNZs: 2, Bias: -37187934740.599815, T: 7168, Avg. loss: 118310196709497618432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 593059866.19, NNZs: 2, Bias: -37185368118.035782, T: 7296, Avg. loss: 118109338113746059264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 582771392.98, NNZs: 2, Bias: -37182985193.048195, T: 7424, Avg. loss: 118218537798358794240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 585942403.44, NNZs: 2, Bias: -37180390961.127876, T: 7552, Avg. loss: 117828754199085481984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 588281810.72, NNZs: 2, Bias: -37179846610.253815, T: 7680, Avg. loss: 114385329068702613504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 588387727.69, NNZs: 2, Bias: -37179337059.180992, T: 7808, Avg. loss: 114523846839153950720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 586656334.73, NNZs: 2, Bias: -37178857384.173538, T: 7936, Avg. loss: 114342269861223923712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 587233874.38, NNZs: 2, Bias: -37178340673.993927, T: 8064, Avg. loss: 114447995435381702656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 587809176.40, NNZs: 2, Bias: -37177824553.857498, T: 8192, Avg. loss: 114308498756813258752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 586547998.47, NNZs: 2, Bias: -37177337148.099770, T: 8320, Avg. loss: 114405799840036306944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 586677517.09, NNZs: 2, Bias: -37176828264.210739, T: 8448, Avg. loss: 114269315750648659968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 588113307.59, NNZs: 2, Bias: -37176298483.816780, T: 8576, Avg. loss: 114312640324290756608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 587721075.65, NNZs: 2, Bias: -37175796707.281693, T: 8704, Avg. loss: 114551106780756754432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 585878691.09, NNZs: 2, Bias: -37175318057.854080, T: 8832, Avg. loss: 114506160018025119744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 583665963.54, NNZs: 2, Bias: -37174849232.037254, T: 8960, Avg. loss: 113563301096318681088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 586771728.08, NNZs: 2, Bias: -37174291938.343010, T: 9088, Avg. loss: 114587411177034579968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 588589538.07, NNZs: 2, Bias: -37173756535.667641, T: 9216, Avg. loss: 114205024406048866304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 586818442.70, NNZs: 2, Bias: -37173276272.099770, T: 9344, Avg. loss: 114613278442148085760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 587391672.66, NNZs: 2, Bias: -37172761396.574066, T: 9472, Avg. loss: 114017579371624022016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 587829279.37, NNZs: 2, Bias: -37172247402.954918, T: 9600, Avg. loss: 114315357657408339968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 75 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1112592717622.94, NNZs: 2, Bias: 19082621546.064804, T: 128, Avg. loss: 19847605513752196389567201280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2006354920376.10, NNZs: 2, Bias: 75421461072.756561, T: 256, Avg. loss: 21152675494243315886065713152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 616631008156.45, NNZs: 2, Bias: 74252960190.585159, T: 384, Avg. loss: 22243466015757636621257670656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2046538499125.97, NNZs: 2, Bias: 53253681908.987411, T: 512, Avg. loss: 19700925303717157687653302272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1278324208572.57, NNZs: 2, Bias: 43358704288.964752, T: 640, Avg. loss: 22357298114443621111171121152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 531735729857.29, NNZs: 2, Bias: 86006229484.920761, T: 768, Avg. loss: 20964944560687544173741473792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1336980211396.61, NNZs: 2, Bias: 121841680494.164734, T: 896, Avg. loss: 21290743951087014407999324160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 320746381925.19, NNZs: 2, Bias: 200366545220.723389, T: 1024, Avg. loss: 23534242498897566875061846016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 754703015877.02, NNZs: 2, Bias: 216565216181.898041, T: 1152, Avg. loss: 20661049442870308114798739456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4410220947.96, NNZs: 2, Bias: 224421697566.818512, T: 1280, Avg. loss: 895214883591483687457259520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 461556551958.30, NNZs: 2, Bias: 222974348520.024017, T: 1408, Avg. loss: 767977212625552285968105472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 164540538906.59, NNZs: 2, Bias: 211751860666.938568, T: 1536, Avg. loss: 841421495517738938564345856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 157932782325.02, NNZs: 2, Bias: 236059606521.237396, T: 1664, Avg. loss: 791159727340178099660652544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 338395009031.29, NNZs: 2, Bias: 240868832970.956970, T: 1792, Avg. loss: 791216830974569547300864000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 171220134999.92, NNZs: 2, Bias: 243766536312.119965, T: 1920, Avg. loss: 861073372912955350092611584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 439986570363.96, NNZs: 2, Bias: 244306626633.915405, T: 2048, Avg. loss: 810135551488245125812846592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 29002539136.36, NNZs: 2, Bias: 248915502866.367218, T: 2176, Avg. loss: 88528565923631329970225152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 74621022172.70, NNZs: 2, Bias: 246213692759.825836, T: 2304, Avg. loss: 29919751221976573639917568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 79801542993.69, NNZs: 2, Bias: 248382122500.461121, T: 2432, Avg. loss: 29058028318684348634103808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 61579097052.61, NNZs: 2, Bias: 248216781791.640289, T: 2560, Avg. loss: 30954591357577884780724224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 19915098636.03, NNZs: 2, Bias: 248621278304.197540, T: 2688, Avg. loss: 31608544091874998620258304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 31135804705.28, NNZs: 2, Bias: 248469909897.421844, T: 2816, Avg. loss: 28440595494550617970442240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 56496733644.84, NNZs: 2, Bias: 247669319756.356323, T: 2944, Avg. loss: 31152949073142063822798848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 16075327057.29, NNZs: 2, Bias: 249771498718.511688, T: 3072, Avg. loss: 29833764603293508105666560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 11002316586.56, NNZs: 2, Bias: 250730453665.992340, T: 3200, Avg. loss: 31126826740897646148321280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 28194495662.44, NNZs: 2, Bias: 250845719208.958313, T: 3328, Avg. loss: 32776794739866965821620224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 64160222289.60, NNZs: 2, Bias: 249322384274.708374, T: 3456, Avg. loss: 29170747899390360297668608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 10423348402.43, NNZs: 2, Bias: 250132263155.964813, T: 3584, Avg. loss: 1159833771741423484272640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 6068150896.63, NNZs: 2, Bias: 250059441814.591980, T: 3712, Avg. loss: 588214338070115958915072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1070841464.59, NNZs: 2, Bias: 249733943203.777863, T: 3840, Avg. loss: 675187566116575129894912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2478401192.18, NNZs: 2, Bias: 249333167992.450653, T: 3968, Avg. loss: 569667853377780817330176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3990795224.35, NNZs: 2, Bias: 249079783463.961487, T: 4096, Avg. loss: 677564039116798151360512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8848079880.76, NNZs: 2, Bias: 248649739820.594757, T: 4224, Avg. loss: 582289753400878296989696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 12252808824.58, NNZs: 2, Bias: 247994594562.354187, T: 4352, Avg. loss: 585443551662168984256512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 13489214944.80, NNZs: 2, Bias: 247601975377.656494, T: 4480, Avg. loss: 590279907894781777281024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1714855125.96, NNZs: 2, Bias: 247407633733.797089, T: 4608, Avg. loss: 726926076673629643341824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2758353958.41, NNZs: 2, Bias: 247309221272.840332, T: 4736, Avg. loss: 6331192537538431549440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3694680815.39, NNZs: 2, Bias: 247216058924.324249, T: 4864, Avg. loss: 5575540296172518244352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3934482909.61, NNZs: 2, Bias: 247129276998.557800, T: 4992, Avg. loss: 6048648302298305396736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4295899298.12, NNZs: 2, Bias: 247045011199.562164, T: 5120, Avg. loss: 5795854657991209910272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4141459367.35, NNZs: 2, Bias: 246964164088.461273, T: 5248, Avg. loss: 6316530410677104279552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4168968714.49, NNZs: 2, Bias: 246885571748.638062, T: 5376, Avg. loss: 5842942973039665479680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4127288683.92, NNZs: 2, Bias: 246803309454.242310, T: 5504, Avg. loss: 6338842271608975917056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4095527312.44, NNZs: 2, Bias: 246788163376.154694, T: 5632, Avg. loss: 4801636498270214684672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4132147339.93, NNZs: 2, Bias: 246772027081.082001, T: 5760, Avg. loss: 4750760237084347203584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4112097739.10, NNZs: 2, Bias: 246756553156.500275, T: 5888, Avg. loss: 4842624069630398824448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4142327280.81, NNZs: 2, Bias: 246740603269.089844, T: 6016, Avg. loss: 4738012574546283986944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4166613343.80, NNZs: 2, Bias: 246724366817.494843, T: 6144, Avg. loss: 4847252984265043869696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4176937812.33, NNZs: 2, Bias: 246708716704.688965, T: 6272, Avg. loss: 4733053022954131030016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4159414442.09, NNZs: 2, Bias: 246693085794.150085, T: 6400, Avg. loss: 4879249126252492095488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4136519498.91, NNZs: 2, Bias: 246677593459.911499, T: 6528, Avg. loss: 4864883925821803200512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4149998399.39, NNZs: 2, Bias: 246662350769.404572, T: 6656, Avg. loss: 4601241666464356237312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4192476033.84, NNZs: 2, Bias: 246645977989.494080, T: 6784, Avg. loss: 4793207418682666385408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4220763616.27, NNZs: 2, Bias: 246629753512.006042, T: 6912, Avg. loss: 4820481625525589114880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4149112708.49, NNZs: 2, Bias: 246615263116.600281, T: 7040, Avg. loss: 4815841784203048910848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4178982430.68, NNZs: 2, Bias: 246598972760.316467, T: 7168, Avg. loss: 4825626739020720504832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4179986024.19, NNZs: 2, Bias: 246583417683.812134, T: 7296, Avg. loss: 4750258628213231058944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4198005506.47, NNZs: 2, Bias: 246579975695.256561, T: 7424, Avg. loss: 4672129222757256790016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4187104900.36, NNZs: 2, Bias: 246577026629.355133, T: 7552, Avg. loss: 4672127608777674850304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4205560268.69, NNZs: 2, Bias: 246573594063.792297, T: 7680, Avg. loss: 4645469040609978220544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4188394820.96, NNZs: 2, Bias: 246570747845.758484, T: 7808, Avg. loss: 4678451028510255349760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4186119055.19, NNZs: 2, Bias: 246567649442.018463, T: 7936, Avg. loss: 4675271048463565979648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 62 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2136344892649.01, NNZs: 2, Bias: -72014815205.510162, T: 128, Avg. loss: 22990963979653452344015716352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 520209267460.68, NNZs: 2, Bias: -75432277340.559723, T: 256, Avg. loss: 23112936610125659910682181632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 287894953261.39, NNZs: 2, Bias: -100581262552.023438, T: 384, Avg. loss: 21942227352656605391678865408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1697205819135.20, NNZs: 2, Bias: -140652395215.394470, T: 512, Avg. loss: 21502206498974939513651986432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1126825821053.68, NNZs: 2, Bias: -100652395215.394470, T: 640, Avg. loss: 21799754306119967506209701888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 625833169945.16, NNZs: 2, Bias: -100652395215.394470, T: 768, Avg. loss: 23780477621587753852309864448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 319598585883.00, NNZs: 2, Bias: -150664939662.779388, T: 896, Avg. loss: 23336735982122470638396375040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2277336628515.91, NNZs: 2, Bias: -102578865191.228455, T: 1024, Avg. loss: 22855850273762696635931951104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1424042203660.24, NNZs: 2, Bias: -182578865191.228455, T: 1152, Avg. loss: 22876798503897007799329095680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 399896933662.73, NNZs: 2, Bias: -163399802908.316071, T: 1280, Avg. loss: 1255487262153416540619276288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 459923623337.43, NNZs: 2, Bias: -162986348000.669525, T: 1408, Avg. loss: 806648409198278733524369408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 193834627317.65, NNZs: 2, Bias: -169717465148.651611, T: 1536, Avg. loss: 914170621093770218331701248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 75853631257.97, NNZs: 2, Bias: -166294063331.603607, T: 1664, Avg. loss: 903397051341372695880138752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 60519130368.48, NNZs: 2, Bias: -179570805276.937988, T: 1792, Avg. loss: 894378152350181060234969088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 158942865695.87, NNZs: 2, Bias: -189027198506.101227, T: 1920, Avg. loss: 950161152166713657323945984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 350071800968.45, NNZs: 2, Bias: -177341291578.522003, T: 2048, Avg. loss: 817280544159313127345750016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 14880204757.83, NNZs: 2, Bias: -174936370536.732086, T: 2176, Avg. loss: 54894098473469869694124032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 51984627812.99, NNZs: 2, Bias: -176143978488.807434, T: 2304, Avg. loss: 31870437322402867628212224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 45023817926.29, NNZs: 2, Bias: -173757634704.013763, T: 2432, Avg. loss: 32745291198336889855672320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 12657384268.83, NNZs: 2, Bias: -172120822324.960724, T: 2560, Avg. loss: 32342149362148352605552640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 39427321991.15, NNZs: 2, Bias: -170191866692.125000, T: 2688, Avg. loss: 36803297822404614973030400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 35530485733.38, NNZs: 2, Bias: -169865306617.955475, T: 2816, Avg. loss: 32885360602502594413199360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 8001257516.99, NNZs: 2, Bias: -172632160183.003479, T: 2944, Avg. loss: 34248576726157698432761856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10843014442.69, NNZs: 2, Bias: -172507388921.222931, T: 3072, Avg. loss: 783417762163864744493056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 3005249948.98, NNZs: 2, Bias: -172042301423.299500, T: 3200, Avg. loss: 771485503063125443739648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 7510297207.86, NNZs: 2, Bias: -171800492500.497040, T: 3328, Avg. loss: 561619729206186872930304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 11135138139.93, NNZs: 2, Bias: -171787625397.815369, T: 3456, Avg. loss: 699200859926169649152000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 8814969690.20, NNZs: 2, Bias: -171423242215.229980, T: 3584, Avg. loss: 720454182735651889217536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 10996552931.84, NNZs: 2, Bias: -171408178107.152557, T: 3712, Avg. loss: 701369446780949523070976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2248564674.43, NNZs: 2, Bias: -170768850049.340424, T: 3840, Avg. loss: 772375688360808065007616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11590108730.02, NNZs: 2, Bias: -170441854754.964691, T: 3968, Avg. loss: 621792102755436318425088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2523350943.75, NNZs: 2, Bias: -170428992450.042938, T: 4096, Avg. loss: 32182154657232148496384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2525200647.39, NNZs: 2, Bias: -170370971279.723999, T: 4224, Avg. loss: 3145721397782876520448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2542416878.70, NNZs: 2, Bias: -170311900266.792725, T: 4352, Avg. loss: 2998213371736304910336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2474946172.62, NNZs: 2, Bias: -170254665937.493347, T: 4480, Avg. loss: 3044365994622079991808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2670407637.94, NNZs: 2, Bias: -170194312181.866882, T: 4608, Avg. loss: 3048116390315843649536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2566900419.73, NNZs: 2, Bias: -170136103185.938141, T: 4736, Avg. loss: 3249657005158238781440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2670940994.98, NNZs: 2, Bias: -170076389649.509857, T: 4864, Avg. loss: 3024786151533596639232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2697594464.26, NNZs: 2, Bias: -170016581097.135284, T: 4992, Avg. loss: 3126151947070947721216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2670018291.04, NNZs: 2, Bias: -170005331678.900421, T: 5120, Avg. loss: 2480344399073192706048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2656719415.80, NNZs: 2, Bias: -169993972031.728821, T: 5248, Avg. loss: 2453983233325105414144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2673911134.16, NNZs: 2, Bias: -169982363382.295044, T: 5376, Avg. loss: 2398778617969898422272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2663172352.55, NNZs: 2, Bias: -169971079648.157837, T: 5504, Avg. loss: 2424014926847309512704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2662016416.79, NNZs: 2, Bias: -169959531611.042694, T: 5632, Avg. loss: 2447807496754798526464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2634662336.95, NNZs: 2, Bias: -169948348047.274200, T: 5760, Avg. loss: 2462508854814778589184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2659757169.63, NNZs: 2, Bias: -169936324028.624023, T: 5888, Avg. loss: 2459824729327530409984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2680139342.62, NNZs: 2, Bias: -169924466101.097565, T: 6016, Avg. loss: 2445790966021566758912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2653124946.99, NNZs: 2, Bias: -169922555083.404846, T: 6144, Avg. loss: 2408795851349541519360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2642783506.82, NNZs: 2, Bias: -169920403848.621124, T: 6272, Avg. loss: 2384284046489496322048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2651720064.87, NNZs: 2, Bias: -169917953984.451172, T: 6400, Avg. loss: 2381178955345513938944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2652881281.37, NNZs: 2, Bias: -169915625807.156677, T: 6528, Avg. loss: 2381124126145653506048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2644800147.08, NNZs: 2, Bias: -169913438755.749390, T: 6656, Avg. loss: 2384785822731825840128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2632692104.81, NNZs: 2, Bias: -169911322241.255066, T: 6784, Avg. loss: 2375939069021386702848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2641632541.34, NNZs: 2, Bias: -169908866050.453644, T: 6912, Avg. loss: 2388143432551266516992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2640415821.67, NNZs: 2, Bias: -169906572176.481628, T: 7040, Avg. loss: 2384205150315091591168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2636955644.45, NNZs: 2, Bias: -169904312899.107086, T: 7168, Avg. loss: 2384414498129408688128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2641023081.16, NNZs: 2, Bias: -169901937996.506317, T: 7296, Avg. loss: 2382568960567661821952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2635632236.08, NNZs: 2, Bias: -169899709172.591370, T: 7424, Avg. loss: 2383994330131090898944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 58 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2508473495416.37, NNZs: 2, Bias: -91929570325.001114, T: 128, Avg. loss: 21426161528781954634253074432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1989807511862.74, NNZs: 2, Bias: -31929570325.001114, T: 256, Avg. loss: 24391296046182956844472860672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1692933823745.51, NNZs: 2, Bias: 19171279674.615311, T: 384, Avg. loss: 23244412093956344577808924672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 968613249094.13, NNZs: 2, Bias: 68039950025.189362, T: 512, Avg. loss: 22886192960012585277100916736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 946211778271.00, NNZs: 2, Bias: 68039950025.189362, T: 640, Avg. loss: 24929811553663577292544147456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1794941092677.01, NNZs: 2, Bias: 108039950025.189362, T: 768, Avg. loss: 21765152189033694293703786496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 367136416387.03, NNZs: 2, Bias: 133972401077.969574, T: 896, Avg. loss: 1676181350965112002310045696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 160225165000.40, NNZs: 2, Bias: 135504484732.633728, T: 1024, Avg. loss: 988027502526442172707766272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 236745312741.52, NNZs: 2, Bias: 139461779540.094177, T: 1152, Avg. loss: 972194045810047434526556160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 372446065501.22, NNZs: 2, Bias: 122550208664.367767, T: 1280, Avg. loss: 868905499377011382336618496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 98896400163.15, NNZs: 2, Bias: 110912745525.203506, T: 1408, Avg. loss: 953676733638833012538867712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 96939938386.64, NNZs: 2, Bias: 103543663519.388336, T: 1536, Avg. loss: 994550367917692174225899520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 528489454505.34, NNZs: 2, Bias: 118798741873.421402, T: 1664, Avg. loss: 882016052859302900381253632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 266334815328.50, NNZs: 2, Bias: 123563724890.426544, T: 1792, Avg. loss: 1033169797988872107319099392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 392110460613.93, NNZs: 2, Bias: 114166972048.182892, T: 1920, Avg. loss: 1090895130299768067793616896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 46283196697.96, NNZs: 2, Bias: 118490974607.887100, T: 2048, Avg. loss: 76405622389970361596772352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42384025388.57, NNZs: 2, Bias: 117629126684.428162, T: 2176, Avg. loss: 34704141160664973543735296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 15943039149.37, NNZs: 2, Bias: 117183659834.340332, T: 2304, Avg. loss: 36934532585136900922146816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 23719200854.41, NNZs: 2, Bias: 118387027312.693787, T: 2432, Avg. loss: 35707859293393289708830720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 20318879892.46, NNZs: 2, Bias: 117273968160.594406, T: 2560, Avg. loss: 34826889027973302445932544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 31816057416.05, NNZs: 2, Bias: 117420985303.869370, T: 2688, Avg. loss: 35345623264064689426923520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 30611749115.89, NNZs: 2, Bias: 119884047871.213715, T: 2816, Avg. loss: 35775365624022534505627648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 6560071226.72, NNZs: 2, Bias: 119399656187.885666, T: 2944, Avg. loss: 907056716337877125955584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 3899935305.85, NNZs: 2, Bias: 119379952288.654617, T: 3072, Avg. loss: 843941706175945233137664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 7567588055.10, NNZs: 2, Bias: 119435818670.754166, T: 3200, Avg. loss: 770239756179798642130944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 16869580254.25, NNZs: 2, Bias: 119457229870.931061, T: 3328, Avg. loss: 686531446765409225670656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 8452881935.75, NNZs: 2, Bias: 118770304136.415695, T: 3456, Avg. loss: 716787709510158737473536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 6306054419.21, NNZs: 2, Bias: 118759126104.530991, T: 3584, Avg. loss: 759584006140490843947008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 12972002041.75, NNZs: 2, Bias: 119070749722.476288, T: 3712, Avg. loss: 761992015525189594906624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1877676538.13, NNZs: 2, Bias: 118928596601.440170, T: 3840, Avg. loss: 874793536494806495133696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 6011597278.71, NNZs: 2, Bias: 118949119471.822586, T: 3968, Avg. loss: 585754817995619830857728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 7426259734.06, NNZs: 2, Bias: 118794173063.370575, T: 4096, Avg. loss: 680501060621791437783040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 13679584836.14, NNZs: 2, Bias: 118605207543.611923, T: 4224, Avg. loss: 717140046679277322633216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2193962975.67, NNZs: 2, Bias: 118683139385.302017, T: 4352, Avg. loss: 873125731074439328563200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 8977101751.10, NNZs: 2, Bias: 118575069140.213806, T: 4480, Avg. loss: 815719391150098832424960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11208568164.50, NNZs: 2, Bias: 118288361409.422974, T: 4608, Avg. loss: 802412464182752368918528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6830166949.23, NNZs: 2, Bias: 118313926798.156921, T: 4736, Avg. loss: 12473747185549617135616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4462486148.89, NNZs: 2, Bias: 118312044954.312943, T: 4864, Avg. loss: 4823209470713701335040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 3362850380.97, NNZs: 2, Bias: 118292452355.931427, T: 4992, Avg. loss: 2207553588128393199616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2841092534.45, NNZs: 2, Bias: 118266571134.380371, T: 5120, Avg. loss: 1560508189924725620736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2544488409.63, NNZs: 2, Bias: 118235394846.797089, T: 5248, Avg. loss: 1460172305401497780224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2312190838.79, NNZs: 2, Bias: 118204963914.998932, T: 5376, Avg. loss: 1326849640539917647872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2204734785.38, NNZs: 2, Bias: 118171862652.048386, T: 5504, Avg. loss: 1290120687000621940736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2128862164.71, NNZs: 2, Bias: 118139370319.424286, T: 5632, Avg. loss: 1215190274162190712832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2158887560.46, NNZs: 2, Bias: 118104745013.142990, T: 5760, Avg. loss: 1224398941344311279616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2171070240.02, NNZs: 2, Bias: 118069936523.329758, T: 5888, Avg. loss: 1249770847679589384192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2159799960.88, NNZs: 2, Bias: 118037264746.346298, T: 6016, Avg. loss: 1173368737614552891392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2178948874.76, NNZs: 2, Bias: 118003070160.377243, T: 6144, Avg. loss: 1246455872545527955456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2131476109.98, NNZs: 2, Bias: 117969866976.107819, T: 6272, Avg. loss: 1258237395876404527104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2113724748.07, NNZs: 2, Bias: 117938331080.081100, T: 6400, Avg. loss: 1101152003007257378816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2040140574.88, NNZs: 2, Bias: 117905112378.067490, T: 6528, Avg. loss: 1260085630239068389376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2135515035.80, NNZs: 2, Bias: 117868498061.974838, T: 6656, Avg. loss: 1238148847840603930624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2099411830.31, NNZs: 2, Bias: 117832732852.894257, T: 6784, Avg. loss: 1349600644249959530496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2137054129.84, NNZs: 2, Bias: 117799307082.204636, T: 6912, Avg. loss: 1148997430729675374592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2147844217.29, NNZs: 2, Bias: 117766979131.235413, T: 7040, Avg. loss: 1192123111536136290304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2217895892.29, NNZs: 2, Bias: 117758359311.459549, T: 7168, Avg. loss: 1086504130856242905088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2204953203.37, NNZs: 2, Bias: 117751701076.954346, T: 7296, Avg. loss: 1024751639282402983936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2216813357.91, NNZs: 2, Bias: 117744757415.517807, T: 7424, Avg. loss: 996770545644560973824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2182773660.77, NNZs: 2, Bias: 117738458464.291565, T: 7552, Avg. loss: 1028603239688230273024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2189526625.21, NNZs: 2, Bias: 117731410522.237900, T: 7680, Avg. loss: 1028527158921697951744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2176574504.53, NNZs: 2, Bias: 117724733915.877365, T: 7808, Avg. loss: 1027445798735140880384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2184698900.94, NNZs: 2, Bias: 117717719920.472839, T: 7936, Avg. loss: 1018989244300769886208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2179493540.31, NNZs: 2, Bias: 117710874492.841080, T: 8064, Avg. loss: 1030588520033186217984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2172208197.19, NNZs: 2, Bias: 117709638780.340683, T: 8192, Avg. loss: 990757019868955672576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2170821605.00, NNZs: 2, Bias: 117708298266.720184, T: 8320, Avg. loss: 987589659071129845760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2167703970.43, NNZs: 2, Bias: 117706990036.192368, T: 8448, Avg. loss: 987231859422233493504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2169458320.64, NNZs: 2, Bias: 117705588687.806198, T: 8576, Avg. loss: 989548728635363819520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2173289161.26, NNZs: 2, Bias: 117704149907.609177, T: 8704, Avg. loss: 988683308092802072576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2173145871.32, NNZs: 2, Bias: 117702785687.005280, T: 8832, Avg. loss: 987921580319422676992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2175330303.18, NNZs: 2, Bias: 117701379409.992218, T: 8960, Avg. loss: 987138869162743562240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2170067772.79, NNZs: 2, Bias: 117700107823.268768, T: 9088, Avg. loss: 989513434979382722560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 2174042840.41, NNZs: 2, Bias: 117698672401.924347, T: 9216, Avg. loss: 984098122872903958528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 2171325329.46, NNZs: 2, Bias: 117697358476.806290, T: 9344, Avg. loss: 986079438343260602368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 2170212854.65, NNZs: 2, Bias: 117696009334.840775, T: 9472, Avg. loss: 989986072163616817152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 2170291475.00, NNZs: 2, Bias: 117694639696.320801, T: 9600, Avg. loss: 988810748701972496384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 2172944860.35, NNZs: 2, Bias: 117693223639.262314, T: 9728, Avg. loss: 987916928547611213824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 2176469047.44, NNZs: 2, Bias: 117691795200.750931, T: 9856, Avg. loss: 985152001464860278784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 77 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 738379676055.12, NNZs: 2, Bias: 35634803171.223953, T: 128, Avg. loss: 19935111297984569073161207808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 978135088685.80, NNZs: 2, Bias: 43126648779.748413, T: 256, Avg. loss: 21463227194134464368767664128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2307472266883.73, NNZs: 2, Bias: 23126648779.748413, T: 384, Avg. loss: 21163732698956562010019463168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 290077638849.08, NNZs: 2, Bias: 5704892992.123108, T: 512, Avg. loss: 21422421385912586626838560768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1269363748236.33, NNZs: 2, Bias: -32463328431.832993, T: 640, Avg. loss: 23348816220664147246263042048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2445747061182.82, NNZs: 2, Bias: -6328637674.859772, T: 768, Avg. loss: 20394727645255920076432867328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 139818677574.03, NNZs: 2, Bias: 1671362325.140228, T: 896, Avg. loss: 2609498038655373407326044160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 252746634939.96, NNZs: 2, Bias: 34025921766.274536, T: 1024, Avg. loss: 833526277115290062996635648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 66619126919.77, NNZs: 2, Bias: 22608751813.757133, T: 1152, Avg. loss: 901992064973506632455553024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 311329581827.35, NNZs: 2, Bias: 27272170494.961746, T: 1280, Avg. loss: 830190227339800389280071680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 312121938248.01, NNZs: 2, Bias: 17351572369.239819, T: 1408, Avg. loss: 783041144249042621041737728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 425645499352.69, NNZs: 2, Bias: 14928489823.123705, T: 1536, Avg. loss: 885799542033421254457819136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 428576574642.05, NNZs: 2, Bias: -7429439204.561462, T: 1664, Avg. loss: 891421016455447330320023552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 81258768686.36, NNZs: 2, Bias: -10612552957.593626, T: 1792, Avg. loss: 853816197877902727517831168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 322649648130.87, NNZs: 2, Bias: -10792495670.020914, T: 1920, Avg. loss: 854081621230994612981596160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 76090110645.58, NNZs: 2, Bias: -10239815445.988462, T: 2048, Avg. loss: 808100147084640026126974976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42054910684.32, NNZs: 2, Bias: -8643962978.123169, T: 2176, Avg. loss: 34280883437499403668029440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 77914676824.60, NNZs: 2, Bias: -8429143686.385283, T: 2304, Avg. loss: 31411665090818815475843072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 73317534612.76, NNZs: 2, Bias: -10276435589.995338, T: 2432, Avg. loss: 30301536283982580053704704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 16740125295.44, NNZs: 2, Bias: -13395061544.277634, T: 2560, Avg. loss: 33430079032693985338458112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 28069048170.62, NNZs: 2, Bias: -15306363066.257456, T: 2688, Avg. loss: 31707519000204282895007744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 24457593453.58, NNZs: 2, Bias: -10143884058.574883, T: 2816, Avg. loss: 33611083523936891283963904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 21322649624.23, NNZs: 2, Bias: -11452808608.983145, T: 2944, Avg. loss: 33413290543366089968975872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 67910221851.69, NNZs: 2, Bias: -11774944115.508104, T: 3072, Avg. loss: 34350728277920110576926720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1855456892.46, NNZs: 2, Bias: -11822165510.341827, T: 3200, Avg. loss: 1718224453226066132074496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1301488898.52, NNZs: 2, Bias: -11732412574.537155, T: 3328, Avg. loss: 409929638432904279228416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 11223403721.39, NNZs: 2, Bias: -11412114845.057671, T: 3456, Avg. loss: 414817580782510046969856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 5035058030.88, NNZs: 2, Bias: -11440417506.573208, T: 3584, Avg. loss: 567781812499572374634496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 6082864048.89, NNZs: 2, Bias: -11239404937.050283, T: 3712, Avg. loss: 587024491309397448851456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4346507174.91, NNZs: 2, Bias: -11152039162.319530, T: 3840, Avg. loss: 513345254406379850956800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11829894076.87, NNZs: 2, Bias: -10933197903.898090, T: 3968, Avg. loss: 399596948578300447424512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1504492331.13, NNZs: 2, Bias: -10541221819.266268, T: 4096, Avg. loss: 604649089974643523059712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1392081714.63, NNZs: 2, Bias: -10504036641.056973, T: 4224, Avg. loss: 616844381595715820847104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 10807978893.87, NNZs: 2, Bias: -10478771616.914900, T: 4352, Avg. loss: 582328168937169881137152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 5930861989.58, NNZs: 2, Bias: -10508735507.870087, T: 4480, Avg. loss: 234042386139020777226240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1371064893.97, NNZs: 2, Bias: -10163176538.125235, T: 4608, Avg. loss: 590764914105924699815936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2476359215.51, NNZs: 2, Bias: -10125756075.407763, T: 4736, Avg. loss: 611223717480880108732416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5146266717.24, NNZs: 2, Bias: -10147598068.634710, T: 4864, Avg. loss: 625832652126848718733312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6639951979.66, NNZs: 2, Bias: -10583415960.230574, T: 4992, Avg. loss: 607540464333281877295104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3526817866.76, NNZs: 2, Bias: -10532827017.367392, T: 5120, Avg. loss: 715068275877123712876544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2083751933.46, NNZs: 2, Bias: -10507441253.654318, T: 5248, Avg. loss: 1325831562097081974784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1459322027.48, NNZs: 2, Bias: -10490716099.804958, T: 5376, Avg. loss: 399644108371841974272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1312131512.99, NNZs: 2, Bias: -10479984490.286594, T: 5504, Avg. loss: 96208064417540128768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1286876617.86, NNZs: 2, Bias: -10473537011.449516, T: 5632, Avg. loss: 29478512797479444480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1286658840.10, NNZs: 2, Bias: -10468350692.937126, T: 5760, Avg. loss: 15773380135506819072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1290274772.36, NNZs: 2, Bias: -10463944926.726122, T: 5888, Avg. loss: 11933233222287669248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1291997489.60, NNZs: 2, Bias: -10460100848.961693, T: 6016, Avg. loss: 11135702972878159872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1294266115.54, NNZs: 2, Bias: -10456220833.125509, T: 6144, Avg. loss: 11021289706833678336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1295023162.60, NNZs: 2, Bias: -10452354132.926781, T: 6272, Avg. loss: 11919315691867049984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1294916660.53, NNZs: 2, Bias: -10448638279.172312, T: 6400, Avg. loss: 11814965466218582016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1296645292.65, NNZs: 2, Bias: -10444983182.293697, T: 6528, Avg. loss: 10944135977331339264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1296613963.91, NNZs: 2, Bias: -10441297501.040672, T: 6656, Avg. loss: 11567994189111271424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1296603088.45, NNZs: 2, Bias: -10437693556.077610, T: 6784, Avg. loss: 11516122895380125696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1295637442.77, NNZs: 2, Bias: -10434130121.328436, T: 6912, Avg. loss: 11980174824381419520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1294953926.26, NNZs: 2, Bias: -10430790968.597950, T: 7040, Avg. loss: 11250807708295135232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1293883050.81, NNZs: 2, Bias: -10427149009.077070, T: 7168, Avg. loss: 12270101834691823616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1294471258.26, NNZs: 2, Bias: -10426349306.162889, T: 7296, Avg. loss: 9534273582060425216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1294547280.10, NNZs: 2, Bias: -10425606955.317284, T: 7424, Avg. loss: 9624488647245113344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1294464853.95, NNZs: 2, Bias: -10424874075.646294, T: 7552, Avg. loss: 9756180135540490240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1294272944.29, NNZs: 2, Bias: -10424156634.197538, T: 7680, Avg. loss: 9741920433967456256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1294565033.36, NNZs: 2, Bias: -10423383179.288916, T: 7808, Avg. loss: 9668897587264661504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1294256032.93, NNZs: 2, Bias: -10422693745.611788, T: 7936, Avg. loss: 9556458187046625280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1294550815.96, NNZs: 2, Bias: -10422506099.680876, T: 8064, Avg. loss: 9658202735245748224.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1294579359.89, NNZs: 2, Bias: -10422355944.214945, T: 8192, Avg. loss: 9381057389738254336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1294570395.99, NNZs: 2, Bias: -10422210633.961700, T: 8320, Avg. loss: 9370307134414110720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1294559838.62, NNZs: 2, Bias: -10422065632.975430, T: 8448, Avg. loss: 9363236173119918080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1294625206.60, NNZs: 2, Bias: -10421911077.356346, T: 8576, Avg. loss: 9368123804750991360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1294676338.36, NNZs: 2, Bias: -10421758718.160769, T: 8704, Avg. loss: 9339984376489156608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1294596489.74, NNZs: 2, Bias: -10421622066.219042, T: 8832, Avg. loss: 9381414433459648512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1294663675.40, NNZs: 2, Bias: -10421467610.412985, T: 8960, Avg. loss: 9346365637744852992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1294599778.68, NNZs: 2, Bias: -10421329265.578911, T: 9088, Avg. loss: 9361968123912443904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1294667675.42, NNZs: 2, Bias: -10421174743.210045, T: 9216, Avg. loss: 9345141580293763072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1294663849.76, NNZs: 2, Bias: -10421028741.201347, T: 9344, Avg. loss: 9372167645600313344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 73 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 403956408162.62, NNZs: 2, Bias: -27347492678.643372, T: 128, Avg. loss: 18407164492566474869157396480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 594739980101.35, NNZs: 2, Bias: 32652507321.356628, T: 256, Avg. loss: 19790022522141244189241769984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 568509992058.73, NNZs: 2, Bias: -80688360915.529175, T: 384, Avg. loss: 22222929326700834064785473536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1202839428436.55, NNZs: 2, Bias: -100688360915.529175, T: 512, Avg. loss: 22347244458557754388049297408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 207106305699.14, NNZs: 2, Bias: -100688360915.529175, T: 640, Avg. loss: 21483097370143652331997102080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2120254187162.69, NNZs: 2, Bias: -100753468061.222717, T: 768, Avg. loss: 18694012562713692831444107264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 230120601855.93, NNZs: 2, Bias: -82404955556.410004, T: 896, Avg. loss: 1852992037860317758251597824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 312152767911.83, NNZs: 2, Bias: -77391990780.804047, T: 1024, Avg. loss: 780032661809508282326319104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 331538699741.48, NNZs: 2, Bias: -69224795006.624176, T: 1152, Avg. loss: 876558986364806821717213184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 213913557728.08, NNZs: 2, Bias: -95902624427.313843, T: 1280, Avg. loss: 783038390038822520822431744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 278976532857.84, NNZs: 2, Bias: -92359108649.659897, T: 1408, Avg. loss: 744476475791586947791585280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 100118831218.97, NNZs: 2, Bias: -108731255862.040527, T: 1536, Avg. loss: 791461867263094998020653056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 214286954733.87, NNZs: 2, Bias: -106316176966.404205, T: 1664, Avg. loss: 835000026728341846251012096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 407832161549.60, NNZs: 2, Bias: -98531086423.639511, T: 1792, Avg. loss: 778633561883672682367549440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 136826776489.38, NNZs: 2, Bias: -91361193250.681702, T: 1920, Avg. loss: 844418526147258665031172096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 144083496477.74, NNZs: 2, Bias: -94792567798.451797, T: 2048, Avg. loss: 822465357099773856506183680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 53683249941.55, NNZs: 2, Bias: -93365550845.917801, T: 2176, Avg. loss: 29861945284768499815677952.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 54316430073.74, NNZs: 2, Bias: -96366784894.729889, T: 2304, Avg. loss: 27035568369953150636916736.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 3932023294.70, NNZs: 2, Bias: -96087673433.709152, T: 2432, Avg. loss: 27109684846928681244819456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 27576922323.39, NNZs: 2, Bias: -95297046800.519623, T: 2560, Avg. loss: 27795600361536209417142272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 32173455762.33, NNZs: 2, Bias: -95722292959.591110, T: 2688, Avg. loss: 26111184059526970290995200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 34398841911.52, NNZs: 2, Bias: -97601389360.002365, T: 2816, Avg. loss: 28479715759203924138000384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 19207418169.95, NNZs: 2, Bias: -97883623195.397278, T: 2944, Avg. loss: 27800185870236314991853568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 54679292086.35, NNZs: 2, Bias: -97268896293.109909, T: 3072, Avg. loss: 29096272783973752596594688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 26379179232.57, NNZs: 2, Bias: -97472091546.247696, T: 3200, Avg. loss: 33080028315898277877776384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 79870764013.92, NNZs: 2, Bias: -97047283057.172440, T: 3328, Avg. loss: 29957671694758998393749504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 16066824953.08, NNZs: 2, Bias: -97752073976.032730, T: 3456, Avg. loss: 2286766573636698463272960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3196421774.79, NNZs: 2, Bias: -97730553042.015350, T: 3584, Avg. loss: 437407249573812056883200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 6757222531.12, NNZs: 2, Bias: -97767822184.500778, T: 3712, Avg. loss: 548992079865506923806720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4147972724.46, NNZs: 2, Bias: -97647937448.269073, T: 3840, Avg. loss: 586146056732080317923328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5913789345.08, NNZs: 2, Bias: -97555203290.563873, T: 3968, Avg. loss: 445816284604278157344768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 3956908257.21, NNZs: 2, Bias: -97385183589.447586, T: 4096, Avg. loss: 417181646566849360429056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1732749348.53, NNZs: 2, Bias: -97261035437.366226, T: 4224, Avg. loss: 534776147429472522469376.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1821194502.89, NNZs: 2, Bias: -97239034805.889481, T: 4352, Avg. loss: 552332813369513131114496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 14157019930.65, NNZs: 2, Bias: -97077059734.035934, T: 4480, Avg. loss: 476061854354646480453632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1632709111.53, NNZs: 2, Bias: -97170916745.079544, T: 4608, Avg. loss: 575899666366016476151808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6133817636.91, NNZs: 2, Bias: -97078184748.907471, T: 4736, Avg. loss: 336115254704539172864000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1322170208.89, NNZs: 2, Bias: -97218977213.587631, T: 4864, Avg. loss: 456867622911398318702592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1498362117.75, NNZs: 2, Bias: -97024459231.711426, T: 4992, Avg. loss: 492577673346657653096448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 11268411311.49, NNZs: 2, Bias: -96925523081.375458, T: 5120, Avg. loss: 535803839339371243241472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 6069763864.96, NNZs: 2, Bias: -96911550867.409164, T: 5248, Avg. loss: 400182960099097789333504.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9291490247.05, NNZs: 2, Bias: -96998896787.962814, T: 5376, Avg. loss: 537664151102438022053888.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4121070888.20, NNZs: 2, Bias: -96894160877.084274, T: 5504, Avg. loss: 13313386729894293012480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1823300584.49, NNZs: 2, Bias: -96818420183.703323, T: 5632, Avg. loss: 4116037640056975392768.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1368906077.89, NNZs: 2, Bias: -96764561890.511200, T: 5760, Avg. loss: 1742346838938404257792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1612812059.81, NNZs: 2, Bias: -96721465798.211868, T: 5888, Avg. loss: 1089341498961262149632.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1793697163.62, NNZs: 2, Bias: -96684003138.702713, T: 6016, Avg. loss: 993068742227903905792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1884158078.47, NNZs: 2, Bias: -96649224312.325912, T: 6144, Avg. loss: 956703578053335842816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1962383390.62, NNZs: 2, Bias: -96615362599.296875, T: 6272, Avg. loss: 966760701572904124416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2006550962.32, NNZs: 2, Bias: -96583731342.116623, T: 6400, Avg. loss: 895670829662753783808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1977943676.76, NNZs: 2, Bias: -96551590136.210968, T: 6528, Avg. loss: 999060282004009254912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1952678382.08, NNZs: 2, Bias: -96518372842.548111, T: 6656, Avg. loss: 1009145164931335847936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1947420854.82, NNZs: 2, Bias: -96486578093.208389, T: 6784, Avg. loss: 993164022402750087168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2024423473.82, NNZs: 2, Bias: -96454731624.435944, T: 6912, Avg. loss: 868255466854919045120.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2035985712.35, NNZs: 2, Bias: -96422607924.193298, T: 7040, Avg. loss: 1003179509808068558848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1997992733.41, NNZs: 2, Bias: -96388696160.399597, T: 7168, Avg. loss: 1046185774877073080320.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2069301944.80, NNZs: 2, Bias: -96355048563.232681, T: 7296, Avg. loss: 977871505532019933184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2056305768.35, NNZs: 2, Bias: -96323508275.481964, T: 7424, Avg. loss: 917333123269399543808.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2062075977.43, NNZs: 2, Bias: -96288877794.819656, T: 7552, Avg. loss: 1025529496410186448896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2074238330.67, NNZs: 2, Bias: -96282256753.207977, T: 7680, Avg. loss: 773398524267547590656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2086387248.00, NNZs: 2, Bias: -96275734889.339005, T: 7808, Avg. loss: 760506506154725343232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2054768423.80, NNZs: 2, Bias: -96269779613.358276, T: 7936, Avg. loss: 809696945728444432384.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2054799914.14, NNZs: 2, Bias: -96263263419.121384, T: 8064, Avg. loss: 791955127846869139456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2031713725.09, NNZs: 2, Bias: -96257224178.968826, T: 8192, Avg. loss: 795155540783803662336.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 2033870539.93, NNZs: 2, Bias: -96250610065.442169, T: 8320, Avg. loss: 798810469050896089088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2015108274.16, NNZs: 2, Bias: -96244563506.092178, T: 8448, Avg. loss: 782882763545772687360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2027106769.73, NNZs: 2, Bias: -96242981858.147507, T: 8576, Avg. loss: 785866504783759409152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2029034015.14, NNZs: 2, Bias: -96241640525.737610, T: 8704, Avg. loss: 768998715365876957184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2031456871.73, NNZs: 2, Bias: -96240292746.695984, T: 8832, Avg. loss: 766500347984975364096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 2032153060.38, NNZs: 2, Bias: -96238981182.702667, T: 8960, Avg. loss: 766747495997847764992.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 2027242557.06, NNZs: 2, Bias: -96237790240.700211, T: 9088, Avg. loss: 765597958255470444544.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 71 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 664643143477.21, NNZs: 2, Bias: -42714438523.856598, T: 128, Avg. loss: 20893212663943806695443005440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1325492248162.36, NNZs: 2, Bias: -2714438523.856598, T: 256, Avg. loss: 21276043806503546578481971200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1031740414173.64, NNZs: 2, Bias: -86066449626.316925, T: 384, Avg. loss: 18976221908810068193831813120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 448763361747.71, NNZs: 2, Bias: -106066449626.316925, T: 512, Avg. loss: 18324477806892517186865201152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 448461184131.40, NNZs: 2, Bias: -126066449626.316925, T: 640, Avg. loss: 18913380381443777349455708160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1469029036616.86, NNZs: 2, Bias: -127185410299.321777, T: 768, Avg. loss: 20834065660236349569041956864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 467775114121.98, NNZs: 2, Bias: -182935947642.782990, T: 896, Avg. loss: 22010512376811490024265613312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151770234833.98, NNZs: 2, Bias: -167453172898.536407, T: 1024, Avg. loss: 19858246655916765373391699968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 126817500696.11, NNZs: 2, Bias: -175921691263.821045, T: 1152, Avg. loss: 21316581592169729586574131200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 60453045781.69, NNZs: 2, Bias: -166281888306.300415, T: 1280, Avg. loss: 858224962600928822698180608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 237331254465.78, NNZs: 2, Bias: -159930727084.273529, T: 1408, Avg. loss: 821931134060585875654311936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 393793584391.56, NNZs: 2, Bias: -165807361019.653534, T: 1536, Avg. loss: 843350299220349843773849600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 258812650866.37, NNZs: 2, Bias: -188372961807.878265, T: 1664, Avg. loss: 779384296297859347510198272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 228120441466.61, NNZs: 2, Bias: -178411972396.671600, T: 1792, Avg. loss: 788384555952669524534231040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 398185463596.51, NNZs: 2, Bias: -196313074280.313477, T: 1920, Avg. loss: 839751561178003559948484608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 347825573329.42, NNZs: 2, Bias: -189689137830.195435, T: 2048, Avg. loss: 805136623230583609002819584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 7984853457.29, NNZs: 2, Bias: -203687792794.995483, T: 2176, Avg. loss: 807024831053193342772838400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 255849482625.58, NNZs: 2, Bias: -210749143622.620972, T: 2304, Avg. loss: 808989967212786636292096000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 59038717370.90, NNZs: 2, Bias: -201291890795.134735, T: 2432, Avg. loss: 35914639517653868207931392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28642747257.11, NNZs: 2, Bias: -196120977180.056244, T: 2560, Avg. loss: 30387555098696762282475520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 34844387277.97, NNZs: 2, Bias: -190431752655.689453, T: 2688, Avg. loss: 30066713795603828693794816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10149756026.76, NNZs: 2, Bias: -191632799821.177063, T: 2816, Avg. loss: 31885707382285596945809408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10800569152.43, NNZs: 2, Bias: -191451643230.011810, T: 2944, Avg. loss: 31031750274883138829156352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 60935991127.07, NNZs: 2, Bias: -189770288908.376373, T: 3072, Avg. loss: 29880660407519811161030656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 18183169050.11, NNZs: 2, Bias: -190448448874.375122, T: 3200, Avg. loss: 30785846120869048243716096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 69636663954.13, NNZs: 2, Bias: -191301594994.704498, T: 3328, Avg. loss: 30599375011353389667713024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 22552299852.71, NNZs: 2, Bias: -190870914328.606445, T: 3456, Avg. loss: 28676202566089335885529088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 40626294690.18, NNZs: 2, Bias: -188169596958.205719, T: 3584, Avg. loss: 27178783356409452567724032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 103756912414.59, NNZs: 2, Bias: -188517495250.319946, T: 3712, Avg. loss: 30730077750835440783458304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 9899952650.62, NNZs: 2, Bias: -190097892540.097687, T: 3840, Avg. loss: 35688646296369245907320832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 18633802749.29, NNZs: 2, Bias: -188325130686.789276, T: 3968, Avg. loss: 29232710326981378248278016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 33190265377.42, NNZs: 2, Bias: -188976147294.144226, T: 4096, Avg. loss: 28246396154148620500729856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 65145966180.37, NNZs: 2, Bias: -188096531421.491943, T: 4224, Avg. loss: 31289916768135742056562688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7119589361.76, NNZs: 2, Bias: -186925917112.529510, T: 4352, Avg. loss: 1664765301503274013163520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 13231584499.33, NNZs: 2, Bias: -186833267096.043793, T: 4480, Avg. loss: 723031159593672353251328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2727468793.82, NNZs: 2, Bias: -186233866662.500244, T: 4608, Avg. loss: 539524293178605229309952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 10575384060.96, NNZs: 2, Bias: -185852957327.718292, T: 4736, Avg. loss: 594898859599313862918144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4003686943.67, NNZs: 2, Bias: -185727663010.449402, T: 4864, Avg. loss: 644365637430444608716800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 13126848265.87, NNZs: 2, Bias: -185142967976.052917, T: 4992, Avg. loss: 493305181049742556135424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3009421909.03, NNZs: 2, Bias: -185384678459.567596, T: 5120, Avg. loss: 640751531987384559206400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 7594916949.33, NNZs: 2, Bias: -185299103317.718018, T: 5248, Avg. loss: 636635085174109108174848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6414114012.74, NNZs: 2, Bias: -184762475936.268768, T: 5376, Avg. loss: 617324468778232822366208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 14119729657.88, NNZs: 2, Bias: -184140872957.424957, T: 5504, Avg. loss: 628648174834477978091520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 5484712239.81, NNZs: 2, Bias: -183975311959.195679, T: 5632, Avg. loss: 812107537378205849616384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4236527102.98, NNZs: 2, Bias: -183896428796.657593, T: 5760, Avg. loss: 6761319366682159874048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3890516459.49, NNZs: 2, Bias: -183846730179.258392, T: 5888, Avg. loss: 3285466727367354875904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3877084515.61, NNZs: 2, Bias: -183791820767.251038, T: 6016, Avg. loss: 3124162142241462681600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3898606686.87, NNZs: 2, Bias: -183738175334.554108, T: 6144, Avg. loss: 3030812194002209603584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 3654773071.09, NNZs: 2, Bias: -183685158319.897064, T: 6272, Avg. loss: 3350939993617657757696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3636985862.05, NNZs: 2, Bias: -183630422055.253632, T: 6400, Avg. loss: 2965181130236879175680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 3572360576.68, NNZs: 2, Bias: -183570919531.410553, T: 6528, Avg. loss: 3428538570011332575232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 3593120822.79, NNZs: 2, Bias: -183513858876.954437, T: 6656, Avg. loss: 3128523560254383325184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 3669824155.88, NNZs: 2, Bias: -183455131485.341888, T: 6784, Avg. loss: 3238069314754215149568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 3635919843.38, NNZs: 2, Bias: -183395104696.773010, T: 6912, Avg. loss: 3390510983993293799424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 3578743092.65, NNZs: 2, Bias: -183336027758.935760, T: 7040, Avg. loss: 3470329819349367914496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 3544244421.69, NNZs: 2, Bias: -183325333327.541840, T: 7168, Avg. loss: 2624273926484383498240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 3539779453.55, NNZs: 2, Bias: -183313909685.952148, T: 7296, Avg. loss: 2661551721816791187456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 3585142962.04, NNZs: 2, Bias: -183301385282.659271, T: 7424, Avg. loss: 2688122763611725103104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 3592140271.87, NNZs: 2, Bias: -183289764856.380981, T: 7552, Avg. loss: 2655403474707321716736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 3584498413.79, NNZs: 2, Bias: -183278453442.824738, T: 7680, Avg. loss: 2648187103991120789504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 3587118510.47, NNZs: 2, Bias: -183267174117.784821, T: 7808, Avg. loss: 2603409223007478480896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 3601050959.05, NNZs: 2, Bias: -183255484498.231506, T: 7936, Avg. loss: 2633451243742707580928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 3606533384.57, NNZs: 2, Bias: -183243901339.919830, T: 8064, Avg. loss: 2651777290290204770304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 3576264498.15, NNZs: 2, Bias: -183233062012.005554, T: 8192, Avg. loss: 2641843432536864194560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 3597914738.49, NNZs: 2, Bias: -183221116980.684601, T: 8320, Avg. loss: 2660547462382576205824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 3606019248.27, NNZs: 2, Bias: -183209337161.618011, T: 8448, Avg. loss: 2684189952378566344704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 3604431453.80, NNZs: 2, Bias: -183207078044.040039, T: 8576, Avg. loss: 2577384001905155375104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 3606794205.66, NNZs: 2, Bias: -183204741880.805817, T: 8704, Avg. loss: 2576179799684940300288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 3598480663.83, NNZs: 2, Bias: -183202611784.849670, T: 8832, Avg. loss: 2581262272778344595456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 3603517829.30, NNZs: 2, Bias: -183200221445.550018, T: 8960, Avg. loss: 2577649422254517256192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 3604742467.06, NNZs: 2, Bias: -183197903901.058502, T: 9088, Avg. loss: 2580251786476745392128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 3589215506.32, NNZs: 2, Bias: -183195944410.068787, T: 9216, Avg. loss: 2548503851788959481856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 3602780318.37, NNZs: 2, Bias: -183193385503.283966, T: 9344, Avg. loss: 2578589267408636608512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 3604129283.66, NNZs: 2, Bias: -183191067825.255585, T: 9472, Avg. loss: 2577633175580307357696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 3596440657.45, NNZs: 2, Bias: -183188932305.646881, T: 9600, Avg. loss: 2573176082262366093312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 3607580930.21, NNZs: 2, Bias: -183186431471.166656, T: 9728, Avg. loss: 2566330275577463308288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 3611147559.59, NNZs: 2, Bias: -183184070869.912201, T: 9856, Avg. loss: 2576574410943440617472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 77 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1263138288265.56, NNZs: 2, Bias: -4758134792.231201, T: 128, Avg. loss: 20891177378359497534855970816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1370257294220.24, NNZs: 2, Bias: -4758134792.231201, T: 256, Avg. loss: 24130866466353544926039375872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 499961406087.53, NNZs: 2, Bias: 67182143244.693695, T: 384, Avg. loss: 22301037194324049852505260032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2315042802333.69, NNZs: 2, Bias: 64513091161.850754, T: 512, Avg. loss: 22315361856706407222552297472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1783885658686.04, NNZs: 2, Bias: 64513091161.850754, T: 640, Avg. loss: 21800205230737261639988412416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1811655933120.61, NNZs: 2, Bias: -22225964380.752930, T: 768, Avg. loss: 21622255506566941671010861056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 265026597867.42, NNZs: 2, Bias: -7080882339.911747, T: 896, Avg. loss: 1342383651269075695053045760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151794448028.80, NNZs: 2, Bias: -719630906.102901, T: 1024, Avg. loss: 903977677445980800340197376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 187247162940.09, NNZs: 2, Bias: 5178003170.377895, T: 1152, Avg. loss: 814341164782451100221440000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 477590502499.70, NNZs: 2, Bias: 5617068980.594179, T: 1280, Avg. loss: 857781483549940269969309696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 145866372471.45, NNZs: 2, Bias: -4592454847.141748, T: 1408, Avg. loss: 949534915506726136405032960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 353565418921.15, NNZs: 2, Bias: -365797406.012601, T: 1536, Avg. loss: 848827642449665873344987136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 288551999843.20, NNZs: 2, Bias: 12423202164.093254, T: 1664, Avg. loss: 933940147041731541467136000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 482306411890.70, NNZs: 2, Bias: 21824724423.556709, T: 1792, Avg. loss: 890426568833857104746905600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 74094762631.12, NNZs: 2, Bias: 19188952274.866634, T: 1920, Avg. loss: 92766859953895740893298688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 56792486063.94, NNZs: 2, Bias: 15515822281.522091, T: 2048, Avg. loss: 32142431248616898795929600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 34025253045.46, NNZs: 2, Bias: 15277261244.790794, T: 2176, Avg. loss: 31338209962153213146693632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 36042523521.01, NNZs: 2, Bias: 13996166091.673729, T: 2304, Avg. loss: 33240244575521928248295424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 26914537944.07, NNZs: 2, Bias: 10625115955.960426, T: 2432, Avg. loss: 35684958594625778558697472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 7504707109.56, NNZs: 2, Bias: 11880244695.613331, T: 2560, Avg. loss: 37528003157449200111714304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 53205332525.22, NNZs: 2, Bias: 11345318242.429434, T: 2688, Avg. loss: 31074962728701941747023872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 14248684434.69, NNZs: 2, Bias: 9408183849.926250, T: 2816, Avg. loss: 33071220584302514978947072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 6550452558.58, NNZs: 2, Bias: 12917564435.114159, T: 2944, Avg. loss: 33606700883107817405284352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 78057395441.62, NNZs: 2, Bias: 13475303832.838789, T: 3072, Avg. loss: 31343847205523743106400256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 90407285182.78, NNZs: 2, Bias: 13709726810.633234, T: 3200, Avg. loss: 32714238054925791288885248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 12007068823.41, NNZs: 2, Bias: 13437937020.392809, T: 3328, Avg. loss: 33682432500437772532711424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10184172760.68, NNZs: 2, Bias: 13228912011.399471, T: 3456, Avg. loss: 638630159015679145017344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1967801951.03, NNZs: 2, Bias: 12929115655.227032, T: 3584, Avg. loss: 503424247850137882198016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2626079974.64, NNZs: 2, Bias: 12919734583.501692, T: 3712, Avg. loss: 555537227459892655161344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2373169259.74, NNZs: 2, Bias: 12769165779.812254, T: 3840, Avg. loss: 543162814841158040027136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 9790203637.45, NNZs: 2, Bias: 12401998716.447336, T: 3968, Avg. loss: 681838404847616724566016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9169726342.43, NNZs: 2, Bias: 12511602749.060795, T: 4096, Avg. loss: 600099901556723168575488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2162905474.45, NNZs: 2, Bias: 12819232840.121288, T: 4224, Avg. loss: 675348577107543444160512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1505588643.19, NNZs: 2, Bias: 12800498973.129715, T: 4352, Avg. loss: 452130279382228598784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1288597535.92, NNZs: 2, Bias: 12788335027.949137, T: 4480, Avg. loss: 144114739440643588096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1251547481.40, NNZs: 2, Bias: 12780310761.833897, T: 4608, Avg. loss: 42569044570897408000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1253277881.26, NNZs: 2, Bias: 12774071059.712494, T: 4736, Avg. loss: 22287171235471667200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1254847378.55, NNZs: 2, Bias: 12769084397.851604, T: 4864, Avg. loss: 17988194825155121152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1260522695.17, NNZs: 2, Bias: 12764093397.901894, T: 4992, Avg. loss: 16747035222955417600.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1263857138.20, NNZs: 2, Bias: 12759401856.324327, T: 5120, Avg. loss: 16769621714329929728.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1264048796.18, NNZs: 2, Bias: 12755143203.869825, T: 5248, Avg. loss: 16588247890851745792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1265346283.84, NNZs: 2, Bias: 12750867974.504972, T: 5376, Avg. loss: 16159341639264768000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1263944364.53, NNZs: 2, Bias: 12746528442.389591, T: 5504, Avg. loss: 18195172364669372416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1265453217.13, NNZs: 2, Bias: 12742078068.190556, T: 5632, Avg. loss: 16838587029622423552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1266736578.41, NNZs: 2, Bias: 12737812909.459887, T: 5760, Avg. loss: 16147634993260175360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1267595875.73, NNZs: 2, Bias: 12733582743.252054, T: 5888, Avg. loss: 15911347026359613440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1265984974.95, NNZs: 2, Bias: 12729633867.219450, T: 6016, Avg. loss: 15682734025521250304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1266994707.08, NNZs: 2, Bias: 12725629694.420580, T: 6144, Avg. loss: 15915760056268347392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1265352393.18, NNZs: 2, Bias: 12721607101.004683, T: 6272, Avg. loss: 16918412534380228608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1262874316.58, NNZs: 2, Bias: 12717524917.193644, T: 6400, Avg. loss: 17712724170520739840.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1264658623.74, NNZs: 2, Bias: 12713052085.533077, T: 6528, Avg. loss: 17816898195965231104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1265879419.41, NNZs: 2, Bias: 12708447894.387867, T: 6656, Avg. loss: 18061931244964456448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1264646503.07, NNZs: 2, Bias: 12707699761.325382, T: 6784, Avg. loss: 14038526656552710144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1265032062.71, NNZs: 2, Bias: 12706808806.720871, T: 6912, Avg. loss: 13683862373328918528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1265074322.48, NNZs: 2, Bias: 12705947500.450933, T: 7040, Avg. loss: 13756547587491135488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1265214250.01, NNZs: 2, Bias: 12705079981.336817, T: 7168, Avg. loss: 13694033096920463360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1265377616.45, NNZs: 2, Bias: 12704222201.938629, T: 7296, Avg. loss: 13517304731114917888.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1264870004.24, NNZs: 2, Bias: 12703417864.747442, T: 7424, Avg. loss: 13735202669776220160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1264870438.08, NNZs: 2, Bias: 12702562109.939175, T: 7552, Avg. loss: 13721041016316024832.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1265228971.39, NNZs: 2, Bias: 12701684015.698912, T: 7680, Avg. loss: 13511405871921092608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1264822378.04, NNZs: 2, Bias: 12700879911.614025, T: 7808, Avg. loss: 13564968863739836416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1264900636.66, NNZs: 2, Bias: 12700005496.313461, T: 7936, Avg. loss: 13903387538204694528.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1265389204.53, NNZs: 2, Bias: 12699112816.897718, T: 8064, Avg. loss: 13524240673039276032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1264723903.17, NNZs: 2, Bias: 12698320970.692198, T: 8192, Avg. loss: 13788059572476137472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1264704206.77, NNZs: 2, Bias: 12697472259.555944, T: 8320, Avg. loss: 13621310541041299456.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1264957477.18, NNZs: 2, Bias: 12697273821.624516, T: 8448, Avg. loss: 13503386842760701952.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1265019943.13, NNZs: 2, Bias: 12697097065.645842, T: 8576, Avg. loss: 13299672373957040128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1265041017.24, NNZs: 2, Bias: 12696924911.570217, T: 8704, Avg. loss: 13263530050481920000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1264903371.22, NNZs: 2, Bias: 12696768432.604773, T: 8832, Avg. loss: 13277163475782563840.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1265063724.79, NNZs: 2, Bias: 12696582039.644310, T: 8960, Avg. loss: 13288062071869390848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1265092388.09, NNZs: 2, Bias: 12696408955.508575, T: 9088, Avg. loss: 13275632043531001856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1265051544.97, NNZs: 2, Bias: 12696243097.154711, T: 9216, Avg. loss: 13257377739414183936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1265192518.71, NNZs: 2, Bias: 12696059975.287741, T: 9344, Avg. loss: 13181433330693410816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1264908942.87, NNZs: 2, Bias: 12695918605.434267, T: 9472, Avg. loss: 13238690402068172800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1264954722.78, NNZs: 2, Bias: 12695743562.919094, T: 9600, Avg. loss: 13294001417662222336.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1264954925.41, NNZs: 2, Bias: 12695572832.349308, T: 9728, Avg. loss: 13314148638813659136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1264799148.77, NNZs: 2, Bias: 12695420072.402098, T: 9856, Avg. loss: 13127205511332495360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1264977948.06, NNZs: 2, Bias: 12695231345.027761, T: 9984, Avg. loss: 13323029057886846976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1264883061.44, NNZs: 2, Bias: 12695070485.826532, T: 10112, Avg. loss: 13285741647627245568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1264973985.54, NNZs: 2, Bias: 12694890615.452829, T: 10240, Avg. loss: 13318533365010345984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1264988591.01, NNZs: 2, Bias: 12694718460.869230, T: 10368, Avg. loss: 13310361689747681280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1264986841.45, NNZs: 2, Bias: 12694548083.603014, T: 10496, Avg. loss: 13299190848163842048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 82 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 131061054474.62, NNZs: 2, Bias: -8728970643.681850, T: 128, Avg. loss: 48552376779187203828992704512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2310958459167.97, NNZs: 2, Bias: -8728970643.681850, T: 256, Avg. loss: 51077854672427189646221377536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1811222791376.04, NNZs: 2, Bias: -8728970643.681850, T: 384, Avg. loss: 50199960086442787649601142784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 396061863854.63, NNZs: 2, Bias: -8728970643.681850, T: 512, Avg. loss: 50908625270143182478279442432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1940742126095.07, NNZs: 2, Bias: -8728970643.681850, T: 640, Avg. loss: 49987168470132386132526104576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 425116454633.32, NNZs: 2, Bias: -8728970643.681850, T: 768, Avg. loss: 51223147075554401927657684992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 195140173969.52, NNZs: 2, Bias: -7684156477.450567, T: 896, Avg. loss: 1011582109060271339544248320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 250678622287.53, NNZs: 2, Bias: -15628244242.615612, T: 1024, Avg. loss: 949556082773440661465071616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 188258232894.27, NNZs: 2, Bias: -17936635722.818409, T: 1152, Avg. loss: 895167811835668568188387328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 165165049494.69, NNZs: 2, Bias: -25788581125.328884, T: 1280, Avg. loss: 1020093635742602664836333568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 269185352529.53, NNZs: 2, Bias: -25708823250.916374, T: 1408, Avg. loss: 889805531228195884409815040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 178468048980.09, NNZs: 2, Bias: -11963928918.780811, T: 1536, Avg. loss: 937366554412285598151737344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 222204892907.07, NNZs: 2, Bias: -12871267662.726795, T: 1664, Avg. loss: 991630432059687956868235264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 290579990430.20, NNZs: 2, Bias: 8075278365.292345, T: 1792, Avg. loss: 993056450500598219059232768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 42827323653.60, NNZs: 2, Bias: -10846575417.588253, T: 1920, Avg. loss: 1023073945517492501624127488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 77865821318.16, NNZs: 2, Bias: -957147625.381658, T: 2048, Avg. loss: 1010848046649783339972558848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 43010213188.54, NNZs: 2, Bias: 2002873917.293525, T: 2176, Avg. loss: 35215923007637617920442368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 26232920495.86, NNZs: 2, Bias: 331467567.825697, T: 2304, Avg. loss: 36336980757821636374167552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 32363512224.72, NNZs: 2, Bias: -402245321.416176, T: 2432, Avg. loss: 34653384948552257545175040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 97877482082.55, NNZs: 2, Bias: -1221286378.426369, T: 2560, Avg. loss: 32940340989051855435726848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 21595542322.20, NNZs: 2, Bias: -598114260.674150, T: 2688, Avg. loss: 36155401370254924404752384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 80211562996.44, NNZs: 2, Bias: -1976995177.374065, T: 2816, Avg. loss: 35236017550111912375615488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 100455581509.46, NNZs: 2, Bias: -3507044923.156220, T: 2944, Avg. loss: 35044393556021908122632192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 53092631451.11, NNZs: 2, Bias: -3614227830.062082, T: 3072, Avg. loss: 35198734625542564225220608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 45184977054.44, NNZs: 2, Bias: -1247904898.427568, T: 3200, Avg. loss: 36211361167092545080000512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 13382243363.79, NNZs: 2, Bias: -1579398899.475464, T: 3328, Avg. loss: 978636746106086663127040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 13400375995.64, NNZs: 2, Bias: -1428353323.953062, T: 3456, Avg. loss: 562178716629471179309056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 7339602583.64, NNZs: 2, Bias: -1803332109.318164, T: 3584, Avg. loss: 620993907004317622075392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 16560781058.22, NNZs: 2, Bias: -1742030721.063230, T: 3712, Avg. loss: 519803384626567834501120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 2068895495.38, NNZs: 2, Bias: -1713561722.013831, T: 3840, Avg. loss: 603027833256909436092416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5215100213.24, NNZs: 2, Bias: -1691887826.864703, T: 3968, Avg. loss: 710741134901941184233472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4555308019.13, NNZs: 2, Bias: -1486826788.523766, T: 4096, Avg. loss: 550574283708366315323392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 13415502696.71, NNZs: 2, Bias: -1705875791.348505, T: 4224, Avg. loss: 572890476472836166778880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 801951989.67, NNZs: 2, Bias: -1923613467.085751, T: 4352, Avg. loss: 709706035917232107683840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 226980713.61, NNZs: 2, Bias: -1920637302.918739, T: 4480, Avg. loss: 131277729110138208256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 87590379.16, NNZs: 2, Bias: -1918471247.564847, T: 4608, Avg. loss: 6718278874461845504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 30001208.18, NNZs: 2, Bias: -1917236701.037813, T: 4736, Avg. loss: 1525836596461746688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8009268.36, NNZs: 2, Bias: -1916372566.718818, T: 4864, Avg. loss: 567065357873538048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 15041283.93, NNZs: 2, Bias: -1915607218.567039, T: 4992, Avg. loss: 384461667680673280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 18770095.65, NNZs: 2, Bias: -1914936892.588963, T: 5120, Avg. loss: 332282981031276352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 19940063.88, NNZs: 2, Bias: -1914316771.538980, T: 5248, Avg. loss: 308103048038813120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 20108756.72, NNZs: 2, Bias: -1913685532.386147, T: 5376, Avg. loss: 336052953655291584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 22936514.50, NNZs: 2, Bias: -1913046883.869666, T: 5504, Avg. loss: 314155867296168064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 22969863.34, NNZs: 2, Bias: -1912444231.920721, T: 5632, Avg. loss: 306182324623425344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 21511597.95, NNZs: 2, Bias: -1911833744.438895, T: 5760, Avg. loss: 325363907781927680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 22677337.28, NNZs: 2, Bias: -1911197821.773697, T: 5888, Avg. loss: 325393091414179648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 19433649.10, NNZs: 2, Bias: -1910599000.274627, T: 6016, Avg. loss: 339798036830074304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 23121066.02, NNZs: 2, Bias: -1909925541.852123, T: 6144, Avg. loss: 328404863997862016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 23524773.20, NNZs: 2, Bias: -1909276547.695475, T: 6272, Avg. loss: 337888152970257472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 22592892.06, NNZs: 2, Bias: -1909161330.581686, T: 6400, Avg. loss: 277068409477177216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 22108914.40, NNZs: 2, Bias: -1909041296.815356, T: 6528, Avg. loss: 276182421953355808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 22284158.40, NNZs: 2, Bias: -1908915156.926856, T: 6656, Avg. loss: 270630935537631168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 22303746.44, NNZs: 2, Bias: -1908790810.539146, T: 6784, Avg. loss: 271490939180489504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 21771169.14, NNZs: 2, Bias: -1908673381.683633, T: 6912, Avg. loss: 270684480854021632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 22297557.56, NNZs: 2, Bias: -1908542171.779863, T: 7040, Avg. loss: 274026041029520352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 21889752.38, NNZs: 2, Bias: -1908422467.855983, T: 7168, Avg. loss: 272315746578541344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 22133401.41, NNZs: 2, Bias: -1908298777.826957, T: 7296, Avg. loss: 263369927454114112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 22248294.51, NNZs: 2, Bias: -1908171882.921199, T: 7424, Avg. loss: 275136553439262688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 22266946.76, NNZs: 2, Bias: -1908047874.854872, T: 7552, Avg. loss: 270368547995896800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 21816659.21, NNZs: 2, Bias: -1907928729.800341, T: 7680, Avg. loss: 272145243185944544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 22280528.66, NNZs: 2, Bias: -1907798208.863435, T: 7808, Avg. loss: 273718486253649440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 22340657.40, NNZs: 2, Bias: -1907673119.117334, T: 7936, Avg. loss: 271772212273490272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 22197265.44, NNZs: 2, Bias: -1907650060.372316, T: 8064, Avg. loss: 264321864475244800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 22283107.78, NNZs: 2, Bias: -1907624164.676529, T: 8192, Avg. loss: 266282947686477408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 22397042.23, NNZs: 2, Bias: -1907597993.526247, T: 8320, Avg. loss: 265596516848992576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 22439581.51, NNZs: 2, Bias: -1907572698.076678, T: 8448, Avg. loss: 265111621285697728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 22418282.40, NNZs: 2, Bias: -1907548104.023317, T: 8576, Avg. loss: 265610199487565088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 67 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1454969759135.91, NNZs: 2, Bias: -8637221861.160675, T: 128, Avg. loss: 40932844581439830252312330240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 425116454633.32, NNZs: 2, Bias: -8637221861.160675, T: 256, Avg. loss: 41829204711793453878216753152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1414847341588.48, NNZs: 2, Bias: -8637221861.160675, T: 384, Avg. loss: 41686283048721646920210055168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 251467691761.78, NNZs: 2, Bias: -8637221861.160675, T: 512, Avg. loss: 46576326928797191198115627008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 280743655315.66, NNZs: 2, Bias: -8637221861.160675, T: 640, Avg. loss: 40109524461106646881570652160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1498056407482.71, NNZs: 2, Bias: -10034849642.455069, T: 768, Avg. loss: 44102266084569481386339074048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1379095718215.38, NNZs: 2, Bias: -10034849642.455069, T: 896, Avg. loss: 45946108938125363502697676800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 359235298933.72, NNZs: 2, Bias: -10034849642.455069, T: 1024, Avg. loss: 44958644463562668031124439040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1570284687564.65, NNZs: 2, Bias: -10034849642.455069, T: 1152, Avg. loss: 35035975563337015136931020800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 222733024044.48, NNZs: 2, Bias: -10034849642.455069, T: 1280, Avg. loss: 47522338301282547874006040576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2841726939732.25, NNZs: 2, Bias: -10034849642.455069, T: 1408, Avg. loss: 46912532894536209742793015296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 466514737173.44, NNZs: 2, Bias: -10034849642.455069, T: 1536, Avg. loss: 46579316127100359282459148288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 911344062360.64, NNZs: 2, Bias: -10034849642.455069, T: 1664, Avg. loss: 39767533475604043595713085440.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1492263381578.47, NNZs: 2, Bias: -10034849642.455069, T: 1792, Avg. loss: 42713749313035833738992287744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 139203233838.03, NNZs: 2, Bias: -1844905654.949163, T: 1920, Avg. loss: 1380491347028447399040253952.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 108789665253.78, NNZs: 2, Bias: -4185415129.639077, T: 2048, Avg. loss: 836565883557386559992889344.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 202691990392.56, NNZs: 2, Bias: 1657475884.894416, T: 2176, Avg. loss: 825752566352162725723897856.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 348721541532.09, NNZs: 2, Bias: -2788774621.781045, T: 2304, Avg. loss: 967450264868307211286216704.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 376893984480.77, NNZs: 2, Bias: -9820931035.789667, T: 2432, Avg. loss: 907646055110429784651333632.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 294502633000.42, NNZs: 2, Bias: -16554469820.814854, T: 2560, Avg. loss: 905726771449246824706080768.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 141256914419.10, NNZs: 2, Bias: -10102713751.777851, T: 2688, Avg. loss: 842021394207207852097929216.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 268095248030.17, NNZs: 2, Bias: -36341506652.110832, T: 2816, Avg. loss: 785226021068710998647504896.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 147171634357.15, NNZs: 2, Bias: -29841438226.404770, T: 2944, Avg. loss: 861461885475127174851723264.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 268195405212.12, NNZs: 2, Bias: -30203598948.758884, T: 3072, Avg. loss: 840585951401414769504157696.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 380338568102.40, NNZs: 2, Bias: -19588652612.998104, T: 3200, Avg. loss: 896407529203602042755481600.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 149120735086.88, NNZs: 2, Bias: -6479797576.295750, T: 3328, Avg. loss: 881484136079347558452822016.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 496300347355.72, NNZs: 2, Bias: -9997392479.246862, T: 3456, Avg. loss: 779267932058923903955763200.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 51479674715.40, NNZs: 2, Bias: -30749219020.044403, T: 3584, Avg. loss: 866854761815958729177169920.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 258507230958.28, NNZs: 2, Bias: -25630270625.036686, T: 3712, Avg. loss: 940724759012987113217982464.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 178958506556.47, NNZs: 2, Bias: -21214917527.599422, T: 3840, Avg. loss: 859229159475368421966741504.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 177404945536.45, NNZs: 2, Bias: -13627175050.489941, T: 3968, Avg. loss: 939668663864789032360738816.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 85814915040.07, NNZs: 2, Bias: -14094041148.405344, T: 4096, Avg. loss: 873206333305147994987823104.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 27497042574.16, NNZs: 2, Bias: -14377418942.216986, T: 4224, Avg. loss: 33638092484628528685383680.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 46742127623.67, NNZs: 2, Bias: -17384423994.681648, T: 4352, Avg. loss: 32412553312210600190803968.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 49807818895.43, NNZs: 2, Bias: -14848204261.038006, T: 4480, Avg. loss: 31609890927840616534507520.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 25609719338.52, NNZs: 2, Bias: -16502401443.130072, T: 4608, Avg. loss: 30070555723170694882656256.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 10828501958.36, NNZs: 2, Bias: -17745866902.431553, T: 4736, Avg. loss: 32011402886236430116323328.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 85523885173.79, NNZs: 2, Bias: -21342014338.767666, T: 4864, Avg. loss: 27735233265608828460728320.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 12653052929.45, NNZs: 2, Bias: -23966144654.381844, T: 4992, Avg. loss: 32000445808456214993960960.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 22981238717.16, NNZs: 2, Bias: -23044152066.312923, T: 5120, Avg. loss: 29812367766893957130223616.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 34445096305.29, NNZs: 2, Bias: -18947811493.564671, T: 5248, Avg. loss: 30018201912579764919468032.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 16246320453.97, NNZs: 2, Bias: -21606108243.968067, T: 5376, Avg. loss: 32407662130463398621609984.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 14667567509.20, NNZs: 2, Bias: -19323999701.089741, T: 5504, Avg. loss: 30659501492908083994689536.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 3572522488.03, NNZs: 2, Bias: -19044004679.546032, T: 5632, Avg. loss: 513296021370266269515776.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4460322182.89, NNZs: 2, Bias: -18710868521.166702, T: 5760, Avg. loss: 540972877645036690341888.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 3494348624.76, NNZs: 2, Bias: -18924472677.755535, T: 5888, Avg. loss: 614189792584401726472192.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3606208079.89, NNZs: 2, Bias: -18930361495.831524, T: 6016, Avg. loss: 486330535287717015584768.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 3905843190.42, NNZs: 2, Bias: -18997430587.374001, T: 6144, Avg. loss: 363671110734481933205504.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 10363521339.58, NNZs: 2, Bias: -19298818927.524330, T: 6272, Avg. loss: 600099409826713427771392.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 10287854561.27, NNZs: 2, Bias: -19378498338.425446, T: 6400, Avg. loss: 459363924869689938804736.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 5681640181.68, NNZs: 2, Bias: -19506939984.498642, T: 6528, Avg. loss: 667732858644821188804608.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 19770133681.73, NNZs: 2, Bias: -19512302122.464672, T: 6656, Avg. loss: 423813157129925165056000.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9522479510.13, NNZs: 2, Bias: -19414899315.501007, T: 6784, Avg. loss: 565766567644669491019776.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2836218698.34, NNZs: 2, Bias: -19384044491.315205, T: 6912, Avg. loss: 16637708376907404279808.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1020182238.39, NNZs: 2, Bias: -19355504181.968613, T: 7040, Avg. loss: 1024603740168628338688.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 283805699.18, NNZs: 2, Bias: -19339439194.757648, T: 7168, Avg. loss: 222226267326041653248.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 90017186.93, NNZs: 2, Bias: -19328131477.424892, T: 7296, Avg. loss: 69530454733802356736.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 174636600.36, NNZs: 2, Bias: -19319124148.484348, T: 7424, Avg. loss: 44939127422854938624.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 233134395.11, NNZs: 2, Bias: -19310691753.002522, T: 7552, Avg. loss: 40541306480965664768.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 251058158.01, NNZs: 2, Bias: -19302964326.733936, T: 7680, Avg. loss: 39913362427417681920.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 249861040.62, NNZs: 2, Bias: -19295089537.805428, T: 7808, Avg. loss: 42304109356789219328.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 279295493.48, NNZs: 2, Bias: -19287259682.349918, T: 7936, Avg. loss: 37767890386653290496.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 254209449.54, NNZs: 2, Bias: -19279601511.433849, T: 8064, Avg. loss: 44325280119272939520.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 254060309.15, NNZs: 2, Bias: -19271980457.720715, T: 8192, Avg. loss: 38983370017942519808.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 235696456.59, NNZs: 2, Bias: -19264448213.286068, T: 8320, Avg. loss: 40503733879844618240.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 257921445.90, NNZs: 2, Bias: -19256452290.599293, T: 8448, Avg. loss: 39374500123563950080.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 245715540.41, NNZs: 2, Bias: -19248768978.382713, T: 8576, Avg. loss: 41525223151009832960.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 242997908.70, NNZs: 2, Bias: -19247306711.958710, T: 8704, Avg. loss: 32889842475165147136.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 248616859.52, NNZs: 2, Bias: -19245718964.756477, T: 8832, Avg. loss: 33476889502724530176.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 250688367.11, NNZs: 2, Bias: -19244174149.320492, T: 8960, Avg. loss: 33539682472076374016.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 243194380.78, NNZs: 2, Bias: -19242753211.586136, T: 9088, Avg. loss: 33476017544087822336.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 247742439.27, NNZs: 2, Bias: -19241171993.630039, T: 9216, Avg. loss: 33674925483558031360.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 249252687.98, NNZs: 2, Bias: -19239667566.989918, T: 9344, Avg. loss: 32640579125927751680.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 242914693.03, NNZs: 2, Bias: -19238221057.973923, T: 9472, Avg. loss: 33768437662974959616.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 245752674.89, NNZs: 2, Bias: -19236656459.408123, T: 9600, Avg. loss: 33839383112137641984.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 243608949.65, NNZs: 2, Bias: -19235175755.775051, T: 9728, Avg. loss: 33326789440123052032.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 239454237.72, NNZs: 2, Bias: -19233718702.827065, T: 9856, Avg. loss: 33320879568182751232.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 243177598.83, NNZs: 2, Bias: -19232154977.464474, T: 9984, Avg. loss: 33497207833766621184.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 242693789.29, NNZs: 2, Bias: -19231858956.532639, T: 10112, Avg. loss: 32654324053807521792.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 242908045.44, NNZs: 2, Bias: -19231553597.430710, T: 10240, Avg. loss: 32720211923642572800.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 242957399.89, NNZs: 2, Bias: -19231250813.206474, T: 10368, Avg. loss: 32657673653221703680.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 244449828.47, NNZs: 2, Bias: -19230930029.372452, T: 10496, Avg. loss: 32624112694765113344.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 243050461.80, NNZs: 2, Bias: -19230647118.686546, T: 10624, Avg. loss: 32465086995056263168.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 244028084.84, NNZs: 2, Bias: -19230332200.635334, T: 10752, Avg. loss: 32704086213415636992.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 243596706.24, NNZs: 2, Bias: -19230035163.173889, T: 10880, Avg. loss: 32693739510951714816.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 243630534.87, NNZs: 2, Bias: -19229732207.476055, T: 11008, Avg. loss: 32689158869712302080.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 244436043.23, NNZs: 2, Bias: -19229419806.476105, T: 11136, Avg. loss: 32652409927003447296.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 244483239.75, NNZs: 2, Bias: -19229116822.406452, T: 11264, Avg. loss: 32670883273982099456.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 88 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 88526832090.62, NNZs: 2, Bias: -8205031608.803167, T: 128, Avg. loss: 38844677703331388305017143296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1047551908021.75, NNZs: 2, Bias: -8205031608.803167, T: 256, Avg. loss: 42780933090296195986474663936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2811846724129.89, NNZs: 2, Bias: -8205031608.803167, T: 384, Avg. loss: 40050288289293834208459882496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1658223748473.05, NNZs: 2, Bias: -8205031608.803167, T: 512, Avg. loss: 44808805660833475045716131840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2229854031097.10, NNZs: 2, Bias: -8205031608.803167, T: 640, Avg. loss: 41412892139572184546015182848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1498056407482.71, NNZs: 2, Bias: -9606981292.699135, T: 768, Avg. loss: 40589557919956453401236078592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 186575427540.22, NNZs: 2, Bias: -6152766011.194609, T: 896, Avg. loss: 1286159639689765378871787520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 157035555155.86, NNZs: 2, Bias: -5073049849.181282, T: 1024, Avg. loss: 783600429231883150910554112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 22641531065.24, NNZs: 2, Bias: -1263607266.125277, T: 1152, Avg. loss: 915644033289814209474854912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 114330213617.65, NNZs: 2, Bias: 5211253213.638288, T: 1280, Avg. loss: 883419518496323524186079232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 135934986935.25, NNZs: 2, Bias: 2805927787.854404, T: 1408, Avg. loss: 807799928728019053626523648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 293301820474.76, NNZs: 2, Bias: 6171476405.890657, T: 1536, Avg. loss: 750060623724776065270284288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11929930200.39, NNZs: 2, Bias: 29458536538.031830, T: 1664, Avg. loss: 761318792844166562060435456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 529073595876.57, NNZs: 2, Bias: 5486241525.040800, T: 1792, Avg. loss: 764456803016705536893648896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 597900046847.53, NNZs: 2, Bias: 11657263458.380981, T: 1920, Avg. loss: 817958032779414471855570944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 45279187356.26, NNZs: 2, Bias: 18007145238.436687, T: 2048, Avg. loss: 937161206455959895748378624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 161224161302.69, NNZs: 2, Bias: 26051765291.221554, T: 2176, Avg. loss: 887702890632032108949798912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 25094287315.78, NNZs: 2, Bias: 30273681303.661022, T: 2304, Avg. loss: 35625663677895660458213376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 5602306863.50, NNZs: 2, Bias: 33669770857.172367, T: 2432, Avg. loss: 29762814997725411952033792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 24021171967.20, NNZs: 2, Bias: 32099491650.128326, T: 2560, Avg. loss: 32238227447056035414540288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 40486888262.75, NNZs: 2, Bias: 32339650335.527737, T: 2688, Avg. loss: 27778001172706432294846464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 53149570334.20, NNZs: 2, Bias: 31265433345.280674, T: 2816, Avg. loss: 30181018286574279541653504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 75263635548.10, NNZs: 2, Bias: 29719529360.450394, T: 2944, Avg. loss: 29477532188422973031448576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 64802000053.96, NNZs: 2, Bias: 30744446921.733349, T: 3072, Avg. loss: 32566228796782934889594880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 14925986876.54, NNZs: 2, Bias: 30207187813.249638, T: 3200, Avg. loss: 30410149851488223573835776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 29453983213.37, NNZs: 2, Bias: 32337162690.547947, T: 3328, Avg. loss: 28913480380873703608549376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 7969518565.85, NNZs: 2, Bias: 32545567895.865639, T: 3456, Avg. loss: 539633582080951603691520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1344476216.49, NNZs: 2, Bias: 32529890165.707172, T: 3584, Avg. loss: 283365049947640167399424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1333502271.10, NNZs: 2, Bias: 32550084325.516563, T: 3712, Avg. loss: 314180441614987030429696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 577440601.00, NNZs: 2, Bias: 32290604960.097618, T: 3840, Avg. loss: 347756190203211117756416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 8568384370.36, NNZs: 2, Bias: 32057229389.482147, T: 3968, Avg. loss: 401608584129960560558080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9914402914.44, NNZs: 2, Bias: 31974659202.629414, T: 4096, Avg. loss: 291549778982862755725312.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 394026939.78, NNZs: 2, Bias: 32188376203.701298, T: 4224, Avg. loss: 426761552536970459086848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 198902991.43, NNZs: 2, Bias: 32169616451.372051, T: 4352, Avg. loss: 189291533156083400704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 293645138.83, NNZs: 2, Bias: 32155204890.840694, T: 4480, Avg. loss: 124863549160456503296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 372829838.70, NNZs: 2, Bias: 32142380786.557518, T: 4608, Avg. loss: 104125630907312062464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 411623195.44, NNZs: 2, Bias: 32129940797.355255, T: 4736, Avg. loss: 105357458454663692288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 358608702.19, NNZs: 2, Bias: 32117795769.657829, T: 4864, Avg. loss: 119480511171360210944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 396662101.00, NNZs: 2, Bias: 32105095862.814423, T: 4992, Avg. loss: 111197683530658037760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 417708723.08, NNZs: 2, Bias: 32092427161.397442, T: 5120, Avg. loss: 110300495257852723200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 438086841.32, NNZs: 2, Bias: 32080017809.644337, T: 5248, Avg. loss: 103994692207098642432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 436178096.26, NNZs: 2, Bias: 32067838596.307285, T: 5376, Avg. loss: 104503837208047697920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 437557177.82, NNZs: 2, Bias: 32055941196.694359, T: 5504, Avg. loss: 105058332011779211264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 422051770.84, NNZs: 2, Bias: 32043991027.464447, T: 5632, Avg. loss: 103810262291748077568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 436820390.93, NNZs: 2, Bias: 32032017735.818172, T: 5760, Avg. loss: 104994753131150344192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 422250521.94, NNZs: 2, Bias: 32020781348.222179, T: 5888, Avg. loss: 100633095898162184192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 397065159.56, NNZs: 2, Bias: 32009131689.339832, T: 6016, Avg. loss: 103732949276616785920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 392013957.72, NNZs: 2, Bias: 31996798386.555466, T: 6144, Avg. loss: 107954962207664816128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 397545714.75, NNZs: 2, Bias: 31984094341.781967, T: 6272, Avg. loss: 110050944787297042432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 383036035.29, NNZs: 2, Bias: 31972284078.124844, T: 6400, Avg. loss: 104378478938300203008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 403325222.63, NNZs: 2, Bias: 31960189787.179787, T: 6528, Avg. loss: 99488936613701632000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 383015681.92, NNZs: 2, Bias: 31948565278.148197, T: 6656, Avg. loss: 102247988411804221440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 418141853.16, NNZs: 2, Bias: 31935969958.935608, T: 6784, Avg. loss: 107227313748147994624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 384962861.12, NNZs: 2, Bias: 31923858097.455643, T: 6912, Avg. loss: 110835625722403078144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 382395794.63, NNZs: 2, Bias: 31912242014.922653, T: 7040, Avg. loss: 102486554130028855296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 412746058.26, NNZs: 2, Bias: 31899715791.493103, T: 7168, Avg. loss: 104809140547315417088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 398964438.92, NNZs: 2, Bias: 31897486453.897926, T: 7296, Avg. loss: 88122659954709725184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 400425484.13, NNZs: 2, Bias: 31895030397.086098, T: 7424, Avg. loss: 89232546051160719360.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 400629050.81, NNZs: 2, Bias: 31892604837.649082, T: 7552, Avg. loss: 88619113639102201856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 403094103.32, NNZs: 2, Bias: 31890119975.885086, T: 7680, Avg. loss: 89911535624210923520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 410667942.03, NNZs: 2, Bias: 31887596836.199139, T: 7808, Avg. loss: 88750140900389421056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 405727707.60, NNZs: 2, Bias: 31885225231.297390, T: 7936, Avg. loss: 89335656960305463296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 403374136.35, NNZs: 2, Bias: 31884773136.879280, T: 8064, Avg. loss: 86075884605802758144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 404554214.04, NNZs: 2, Bias: 31884274371.833645, T: 8192, Avg. loss: 86454435875597860864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 403721958.63, NNZs: 2, Bias: 31883802695.406578, T: 8320, Avg. loss: 86118546621148708864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 404957056.70, NNZs: 2, Bias: 31883303067.321594, T: 8448, Avg. loss: 86480178019696214016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 403650774.67, NNZs: 2, Bias: 31882838426.685570, T: 8576, Avg. loss: 85872920577143668736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 404921103.75, NNZs: 2, Bias: 31882338281.115944, T: 8704, Avg. loss: 86480139942160891904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 406747659.10, NNZs: 2, Bias: 31881833261.179726, T: 8832, Avg. loss: 86035547883541086208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 405987878.05, NNZs: 2, Bias: 31881359133.637722, T: 8960, Avg. loss: 86392385215931990016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 406435225.48, NNZs: 2, Bias: 31880871838.621387, T: 9088, Avg. loss: 85957656065044938752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 406508127.51, NNZs: 2, Bias: 31880387280.012619, T: 9216, Avg. loss: 86395223367185743872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 72 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2927718907272.35, NNZs: 2, Bias: -8407909380.944422, T: 128, Avg. loss: 39277364664206877814616489984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2310958459167.97, NNZs: 2, Bias: -8407909380.944422, T: 256, Avg. loss: 46408100808433350528288686080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1758402115558.33, NNZs: 2, Bias: -8407909380.944422, T: 384, Avg. loss: 42777808746589242265010438144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1772441536412.41, NNZs: 2, Bias: -8407909380.944422, T: 512, Avg. loss: 38965554194710804430403403776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2546922260297.71, NNZs: 2, Bias: -8407909380.944422, T: 640, Avg. loss: 38786899421211403161517948928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2203811471065.53, NNZs: 2, Bias: -8407909380.944422, T: 768, Avg. loss: 40472592213924560970297901056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2844975395324.18, NNZs: 2, Bias: -8407909380.944422, T: 896, Avg. loss: 42516972068945733964498206720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1238244725407.70, NNZs: 2, Bias: -9807830287.040977, T: 1024, Avg. loss: 41695566499707515345393680384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1179103472982.76, NNZs: 2, Bias: -9807830287.040977, T: 1152, Avg. loss: 44107120068930610960881680384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 2201496082213.18, NNZs: 2, Bias: -9807830287.040977, T: 1280, Avg. loss: 39104973530575371340506726400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 253477189998.52, NNZs: 2, Bias: -4310026388.134239, T: 1408, Avg. loss: 1935229641883148929900478464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 392585455686.42, NNZs: 2, Bias: -32310026388.134239, T: 1536, Avg. loss: 873929082433575975559102464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 425631704790.89, NNZs: 2, Bias: -28964601136.687469, T: 1664, Avg. loss: 704233019248772306316558336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 319480096249.22, NNZs: 2, Bias: -26698426029.938805, T: 1792, Avg. loss: 806596609631633470956503040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 443051017435.19, NNZs: 2, Bias: -39390620683.720108, T: 1920, Avg. loss: 819419904718352605260021760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 338976426927.45, NNZs: 2, Bias: -30496502539.735336, T: 2048, Avg. loss: 860631442133021461042954240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 93870225219.81, NNZs: 2, Bias: -25797185880.706013, T: 2176, Avg. loss: 822211889950881871831236608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 370619340112.98, NNZs: 2, Bias: -34871872397.047272, T: 2304, Avg. loss: 884218762323764874915610624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 72002770123.06, NNZs: 2, Bias: -33408399496.161636, T: 2432, Avg. loss: 71436035581213173576892416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 105956494899.62, NNZs: 2, Bias: -34642278549.804359, T: 2560, Avg. loss: 31170492617050980526063616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 19403104639.50, NNZs: 2, Bias: -36754656041.096779, T: 2688, Avg. loss: 29239695174393528462606336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 18980405293.08, NNZs: 2, Bias: -35687874747.931160, T: 2816, Avg. loss: 28561400793519955455770624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 15437657713.00, NNZs: 2, Bias: -37980020840.289230, T: 2944, Avg. loss: 30982614298346508823560192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 6897595602.24, NNZs: 2, Bias: -36302264908.867424, T: 3072, Avg. loss: 28934958745856391688224768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 51957307218.38, NNZs: 2, Bias: -36283334653.610321, T: 3200, Avg. loss: 32885962188629248030277632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 109346690859.85, NNZs: 2, Bias: -37661397478.378082, T: 3328, Avg. loss: 28548341968702965060468736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 90562724601.68, NNZs: 2, Bias: -38365305611.380821, T: 3456, Avg. loss: 32992109750947457720647680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 79346256073.36, NNZs: 2, Bias: -32833477367.967392, T: 3584, Avg. loss: 32831088062710073054461952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 52159863046.98, NNZs: 2, Bias: -34415646896.944168, T: 3712, Avg. loss: 29729221905624225351204864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 55269990403.04, NNZs: 2, Bias: -30594386215.846512, T: 3840, Avg. loss: 27918782351334519762583552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 73492133836.40, NNZs: 2, Bias: -28911752667.413864, T: 3968, Avg. loss: 26038836431472319927418880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 57687123169.47, NNZs: 2, Bias: -31901351365.245895, T: 4096, Avg. loss: 31515736360651008300285952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98374198549.61, NNZs: 2, Bias: -28221776115.110340, T: 4224, Avg. loss: 29863982088965510926434304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 10199952366.41, NNZs: 2, Bias: -27444284347.999016, T: 4352, Avg. loss: 32457618261446167084662784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 27868159327.97, NNZs: 2, Bias: -29348847975.918243, T: 4480, Avg. loss: 30818696859112355418603520.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 53313802936.24, NNZs: 2, Bias: -29559171120.929039, T: 4608, Avg. loss: 30929878551353130049601536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2641141750.52, NNZs: 2, Bias: -29532514587.437199, T: 4736, Avg. loss: 1320682606305306822574080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 11352696019.81, NNZs: 2, Bias: -29607969187.773663, T: 4864, Avg. loss: 553653331711942664912896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2903393845.80, NNZs: 2, Bias: -29586923373.246342, T: 4992, Avg. loss: 512516691054150924894208.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 19226641540.59, NNZs: 2, Bias: -29521841501.555813, T: 5120, Avg. loss: 464341282136829858938880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4461737512.31, NNZs: 2, Bias: -29433676484.266090, T: 5248, Avg. loss: 660581529412378589921280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 3282219871.67, NNZs: 2, Bias: -29261926658.522755, T: 5376, Avg. loss: 554861369084553147187200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4402666027.64, NNZs: 2, Bias: -28852225887.162895, T: 5504, Avg. loss: 538108290239051516084224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 14890171809.94, NNZs: 2, Bias: -28617948197.940365, T: 5632, Avg. loss: 587411772455077134991360.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 3191687949.14, NNZs: 2, Bias: -28847311076.149113, T: 5760, Avg. loss: 436060802309533430972416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 5247275301.70, NNZs: 2, Bias: -28846920743.231087, T: 5888, Avg. loss: 596886153155536280879104.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 3345867362.65, NNZs: 2, Bias: -28994498934.734596, T: 6016, Avg. loss: 533742221363719870349312.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 8503689784.47, NNZs: 2, Bias: -29062040858.159424, T: 6144, Avg. loss: 482753753360262624182272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 6269319060.51, NNZs: 2, Bias: -28828669578.640968, T: 6272, Avg. loss: 653834270770167440998400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 3554733711.31, NNZs: 2, Bias: -28422082293.455879, T: 6400, Avg. loss: 684097172934394600488960.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1532396881.63, NNZs: 2, Bias: -28417133716.209526, T: 6528, Avg. loss: 1456128119271655211008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 895178405.17, NNZs: 2, Bias: -28415504192.227161, T: 6656, Avg. loss: 178115538099695976448.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 584249747.85, NNZs: 2, Bias: -28409802656.892696, T: 6784, Avg. loss: 90748959415789305856.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 460332741.11, NNZs: 2, Bias: -28401420828.306313, T: 6912, Avg. loss: 75741833886649679872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 422211248.90, NNZs: 2, Bias: -28391747907.187954, T: 7040, Avg. loss: 75949371830862348288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 408813841.62, NNZs: 2, Bias: -28381342034.983665, T: 7168, Avg. loss: 79579446472114651136.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 376161772.76, NNZs: 2, Bias: -28371574913.168514, T: 7296, Avg. loss: 77958989367295950848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 373386749.72, NNZs: 2, Bias: -28361099762.033146, T: 7424, Avg. loss: 80386473525204811776.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 369535235.03, NNZs: 2, Bias: -28350317994.039276, T: 7552, Avg. loss: 82807282740877950976.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 374915750.26, NNZs: 2, Bias: -28348223661.200886, T: 7680, Avg. loss: 64627346080954621952.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 380612283.40, NNZs: 2, Bias: -28346118452.120865, T: 7808, Avg. loss: 64810592785202659328.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 380775007.46, NNZs: 2, Bias: -28344065875.494812, T: 7936, Avg. loss: 65502330349742407680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 386130441.67, NNZs: 2, Bias: -28341969881.221844, T: 8064, Avg. loss: 64562271235490086912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 382032094.34, NNZs: 2, Bias: -28339978121.321629, T: 8192, Avg. loss: 65475225978979516416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 379709562.84, NNZs: 2, Bias: -28337971341.302914, T: 8320, Avg. loss: 65072938429123379200.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 376043699.63, NNZs: 2, Bias: -28335975027.836323, T: 8448, Avg. loss: 65289118272584384512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 378425762.45, NNZs: 2, Bias: -28333897439.267242, T: 8576, Avg. loss: 65400747242421346304.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 383171315.47, NNZs: 2, Bias: -28331761993.716949, T: 8704, Avg. loss: 66154696400989913088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 382996607.12, NNZs: 2, Bias: -28331356019.126904, T: 8832, Avg. loss: 63591216216096735232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 381712388.40, NNZs: 2, Bias: -28330965064.062519, T: 8960, Avg. loss: 63595951695093809152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 383894583.03, NNZs: 2, Bias: -28330526968.808189, T: 9088, Avg. loss: 63672166484673159168.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 383321153.06, NNZs: 2, Bias: -28330126602.429279, T: 9216, Avg. loss: 63559250177372061696.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 383321467.23, NNZs: 2, Bias: -28329717343.882534, T: 9344, Avg. loss: 63766710167374340096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 382319728.84, NNZs: 2, Bias: -28329322948.745041, T: 9472, Avg. loss: 63527891646440046592.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 382680515.95, NNZs: 2, Bias: -28328909028.391846, T: 9600, Avg. loss: 63723025689636995072.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 383115615.37, NNZs: 2, Bias: -28328493996.628410, T: 9728, Avg. loss: 63759458807442784256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 383587407.02, NNZs: 2, Bias: -28328078734.753315, T: 9856, Avg. loss: 63720109639866957824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 383074855.15, NNZs: 2, Bias: -28327677386.266109, T: 9984, Avg. loss: 63584141302250586112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 383796872.83, NNZs: 2, Bias: -28327258735.564938, T: 10112, Avg. loss: 63691469537312432128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 79 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1570284687564.65, NNZs: 2, Bias: -9739604623.779953, T: 128, Avg. loss: 37464366719318683580800958464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 753429492387.97, NNZs: 2, Bias: -9739604623.779953, T: 256, Avg. loss: 47966672352293971705167085568.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1772441536412.41, NNZs: 2, Bias: -9739604623.779953, T: 384, Avg. loss: 47878152666863249623896555520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 534000936328.77, NNZs: 2, Bias: -9739604623.779953, T: 512, Avg. loss: 47862976080872548411298021376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 809311435727.93, NNZs: 2, Bias: -9739604623.779953, T: 640, Avg. loss: 48572962306768318195969294336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1492263381578.47, NNZs: 2, Bias: -9739604623.779953, T: 768, Avg. loss: 48450281462369194521346965504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 239473423379.37, NNZs: 2, Bias: -3719733064.262764, T: 896, Avg. loss: 1375452012111503275203756032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 188078761734.34, NNZs: 2, Bias: -8915474142.071259, T: 1024, Avg. loss: 933048171129835665968070656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 366881878732.56, NNZs: 2, Bias: 1556312502.991898, T: 1152, Avg. loss: 964946173730742527168872448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 311821278234.82, NNZs: 2, Bias: -23298748688.979252, T: 1280, Avg. loss: 1014596340212405853879271424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 377091978156.31, NNZs: 2, Bias: -17605142370.354214, T: 1408, Avg. loss: 904629072653580825983451136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 38318790710.36, NNZs: 2, Bias: -22107855996.619118, T: 1536, Avg. loss: 960437258096328284678651904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 120886412704.39, NNZs: 2, Bias: -21262625623.980865, T: 1664, Avg. loss: 967055149833621754188136448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 232778705646.72, NNZs: 2, Bias: -14525906110.047392, T: 1792, Avg. loss: 1021117775684329398788423680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 308333730904.60, NNZs: 2, Bias: -13783725058.381302, T: 1920, Avg. loss: 985398121385592016101965824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 380455267400.13, NNZs: 2, Bias: -15550007648.000900, T: 2048, Avg. loss: 942550020875730174504599552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11303338885.11, NNZs: 2, Bias: -17274124222.440445, T: 2176, Avg. loss: 70553868709690786057289728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 47911335637.03, NNZs: 2, Bias: -17681081992.211010, T: 2304, Avg. loss: 33675620295973926653132800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 52421670087.58, NNZs: 2, Bias: -18874283751.450680, T: 2432, Avg. loss: 34325738988664085704343552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 17903183610.13, NNZs: 2, Bias: -20460709745.948952, T: 2560, Avg. loss: 33612794163433843000868864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 31539847028.77, NNZs: 2, Bias: -18586809225.064373, T: 2688, Avg. loss: 31438046216609037096583168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 87254866579.63, NNZs: 2, Bias: -18013306972.735298, T: 2816, Avg. loss: 33502958022038230040313856.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 34689717125.03, NNZs: 2, Bias: -18229470345.070469, T: 2944, Avg. loss: 32783976413346028119392256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 56648254127.90, NNZs: 2, Bias: -16957566514.039515, T: 3072, Avg. loss: 31729727006406601630285824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4804655216.54, NNZs: 2, Bias: -13626577483.128542, T: 3200, Avg. loss: 33424284282232234525589504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 67987689037.75, NNZs: 2, Bias: -10056654361.097916, T: 3328, Avg. loss: 33576634761305827294838784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2000912159.13, NNZs: 2, Bias: -10256620478.523825, T: 3456, Avg. loss: 1910779613237777000300544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 12055748562.79, NNZs: 2, Bias: -10137813197.244322, T: 3584, Avg. loss: 603226979155090526437376.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 10866452788.50, NNZs: 2, Bias: -10371702705.084425, T: 3712, Avg. loss: 692182198569266724208640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4424153886.06, NNZs: 2, Bias: -10456476198.159765, T: 3840, Avg. loss: 654339741436643811262464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1769288651.35, NNZs: 2, Bias: -10682973142.604996, T: 3968, Avg. loss: 558493689114683636711424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 6240271574.07, NNZs: 2, Bias: -10774615597.454485, T: 4096, Avg. loss: 506655072169633341505536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8429135961.77, NNZs: 2, Bias: -10725269347.549242, T: 4224, Avg. loss: 474562846034040136400896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 5475101536.50, NNZs: 2, Bias: -10419894376.170853, T: 4352, Avg. loss: 448059228756232393195520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3824719492.71, NNZs: 2, Bias: -10151811648.745653, T: 4480, Avg. loss: 585658878590297562939392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2089990068.07, NNZs: 2, Bias: -9921523277.051905, T: 4608, Avg. loss: 655949412154079795216384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 193783771.85, NNZs: 2, Bias: -9754119564.522482, T: 4736, Avg. loss: 471338205814871371546624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5488350155.63, NNZs: 2, Bias: -9544510920.850370, T: 4864, Avg. loss: 604842627742759118700544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 11944059436.92, NNZs: 2, Bias: -9494295821.999737, T: 4992, Avg. loss: 547272981331784700526592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 3795551020.11, NNZs: 2, Bias: -9493325223.098719, T: 5120, Avg. loss: 19960156922042780745728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1657791862.09, NNZs: 2, Bias: -9516038269.559212, T: 5248, Avg. loss: 1302005071012348297216.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 739711171.34, NNZs: 2, Bias: -9522441705.412132, T: 5376, Avg. loss: 245818366238756962304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 383336237.95, NNZs: 2, Bias: -9522267305.376961, T: 5504, Avg. loss: 49144670792697446400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 222761179.30, NNZs: 2, Bias: -9520747832.999825, T: 5632, Avg. loss: 15705456872774825984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 153589481.97, NNZs: 2, Bias: -9518204514.185617, T: 5760, Avg. loss: 9641564733058340864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 126412732.42, NNZs: 2, Bias: -9514950793.100628, T: 5888, Avg. loss: 9448606715675928576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 122461825.94, NNZs: 2, Bias: -9511513094.989834, T: 6016, Avg. loss: 9166226371099730944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 117196333.25, NNZs: 2, Bias: -9507953859.529724, T: 6144, Avg. loss: 9704980563430907904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 121224602.15, NNZs: 2, Bias: -9504444450.627611, T: 6272, Avg. loss: 9244324760400087040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 116926786.30, NNZs: 2, Bias: -9500994939.456390, T: 6400, Avg. loss: 8799647774860278784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 122740040.19, NNZs: 2, Bias: -9497515435.227049, T: 6528, Avg. loss: 8649888926794776576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 127298103.69, NNZs: 2, Bias: -9493949678.060957, T: 6656, Avg. loss: 8792856230252004352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 127979915.64, NNZs: 2, Bias: -9490401040.111032, T: 6784, Avg. loss: 9034265291861768192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 116131694.43, NNZs: 2, Bias: -9487081173.000530, T: 6912, Avg. loss: 9280052222237399040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 120409144.49, NNZs: 2, Bias: -9483447455.302717, T: 7040, Avg. loss: 9364176817562892288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 113011649.92, NNZs: 2, Bias: -9480031655.224802, T: 7168, Avg. loss: 8980855960205722624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 114468919.30, NNZs: 2, Bias: -9479293477.835821, T: 7296, Avg. loss: 7894127135040530432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 114350608.58, NNZs: 2, Bias: -9478583165.118376, T: 7424, Avg. loss: 7789313194340688896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 118405463.83, NNZs: 2, Bias: -9477823899.639500, T: 7552, Avg. loss: 7752041168773998592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 115832082.89, NNZs: 2, Bias: -9477142047.517277, T: 7680, Avg. loss: 7811231177911834624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 114428828.10, NNZs: 2, Bias: -9476444456.049604, T: 7808, Avg. loss: 7805365512037057536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 114053440.84, NNZs: 2, Bias: -9475741870.982391, T: 7936, Avg. loss: 7720392227591343104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 115583820.17, NNZs: 2, Bias: -9475010733.128099, T: 8064, Avg. loss: 7795025980612249600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 117701147.03, NNZs: 2, Bias: -9474271551.856625, T: 8192, Avg. loss: 7788103624371021824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 117247445.10, NNZs: 2, Bias: -9473566102.460106, T: 8320, Avg. loss: 7746268606438744064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 115817402.05, NNZs: 2, Bias: -9472865830.123299, T: 8448, Avg. loss: 7852701403263407104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 114895516.87, NNZs: 2, Bias: -9472162992.984522, T: 8576, Avg. loss: 7799372158226621440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 116232428.13, NNZs: 2, Bias: -9472003316.465582, T: 8704, Avg. loss: 7653896464503806976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 116873785.88, NNZs: 2, Bias: -9471853240.388529, T: 8832, Avg. loss: 7579529536655068160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 117246270.83, NNZs: 2, Bias: -9471706483.497004, T: 8960, Avg. loss: 7577134248771135488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 116844388.70, NNZs: 2, Bias: -9471569629.401684, T: 9088, Avg. loss: 7556871118761958400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 116273150.66, NNZs: 2, Bias: -9471435011.678394, T: 9216, Avg. loss: 7546146312527345664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 116159697.26, NNZs: 2, Bias: -9471294258.828314, T: 9344, Avg. loss: 7576692768017111040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 116604829.86, NNZs: 2, Bias: -9471146211.717424, T: 9472, Avg. loss: 7603023616957544448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 117135685.30, NNZs: 2, Bias: -9470997383.155285, T: 9600, Avg. loss: 7582592873741665280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 116789248.12, NNZs: 2, Bias: -9470859279.763309, T: 9728, Avg. loss: 7587771823691392000.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 116815306.44, NNZs: 2, Bias: -9470716475.848671, T: 9856, Avg. loss: 7593622657662229504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 77 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1678359217139.17, NNZs: 2, Bias: -8787090015.320244, T: 128, Avg. loss: 39258784434397944803896590336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1415083913061.55, NNZs: 2, Bias: -17340781862.830517, T: 256, Avg. loss: 43637046978771275074072739840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2481958476919.90, NNZs: 2, Bias: 2659218137.169483, T: 384, Avg. loss: 43045433695844638882818686976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1787926422398.46, NNZs: 2, Bias: 2659218137.169483, T: 512, Avg. loss: 40173797429565375271395131392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1366327741403.80, NNZs: 2, Bias: -44449168087.414139, T: 640, Avg. loss: 41884307751180166374151421952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2523010025576.45, NNZs: 2, Bias: 15241936931.753510, T: 768, Avg. loss: 41814173938757772067154690048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 156752934913.65, NNZs: 2, Bias: 10840128641.482290, T: 896, Avg. loss: 1380863522334377614896005120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 90162886650.94, NNZs: 2, Bias: 11158457941.573978, T: 1024, Avg. loss: 937587601235048391432470528.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 130798025418.20, NNZs: 2, Bias: 10840996996.754421, T: 1152, Avg. loss: 990443872380889729853292544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 166513439397.48, NNZs: 2, Bias: 1165336725.507511, T: 1280, Avg. loss: 993099557247150260354023424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 194156660790.63, NNZs: 2, Bias: 6299807015.934297, T: 1408, Avg. loss: 1013184578897555230231101440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 312053741333.49, NNZs: 2, Bias: 23307766761.889420, T: 1536, Avg. loss: 959294603066244926709694464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 79999596568.49, NNZs: 2, Bias: 31476267469.341389, T: 1664, Avg. loss: 1027580356796213209059033088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 28351966950.05, NNZs: 2, Bias: 27979272564.776802, T: 1792, Avg. loss: 39284595373881221472845824.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 102102695799.28, NNZs: 2, Bias: 27436795656.903576, T: 1920, Avg. loss: 35564794369393474138013696.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 35119210272.06, NNZs: 2, Bias: 28031950757.603642, T: 2048, Avg. loss: 36591163931938143634194432.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 27414385445.89, NNZs: 2, Bias: 29434987441.495453, T: 2176, Avg. loss: 37210975346234680798085120.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 64978112008.26, NNZs: 2, Bias: 29014222938.717979, T: 2304, Avg. loss: 32101561236043702663643136.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 38995919625.64, NNZs: 2, Bias: 28682760396.897209, T: 2432, Avg. loss: 33666507216832281047990272.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 25733098703.68, NNZs: 2, Bias: 28966280524.398258, T: 2560, Avg. loss: 35098931706817802972168192.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 48851668172.75, NNZs: 2, Bias: 27074275508.910446, T: 2688, Avg. loss: 34998162131491908969562112.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 41594628344.08, NNZs: 2, Bias: 23710043601.964645, T: 2816, Avg. loss: 31805051924853085169516544.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 61604463134.33, NNZs: 2, Bias: 21411256826.041035, T: 2944, Avg. loss: 32728148105525203327516672.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 43139397009.56, NNZs: 2, Bias: 22679763481.967815, T: 3072, Avg. loss: 37536528623102277644713984.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 21649384668.67, NNZs: 2, Bias: 20880745993.278358, T: 3200, Avg. loss: 36267438612914612673183744.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8482755734.23, NNZs: 2, Bias: 21772431245.672848, T: 3328, Avg. loss: 34596930433065264250617856.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 71594132840.49, NNZs: 2, Bias: 21752687299.708988, T: 3456, Avg. loss: 34313080574025970191695872.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 10507465404.69, NNZs: 2, Bias: 22473176785.089874, T: 3584, Avg. loss: 2370011800887152022126592.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 2771929390.40, NNZs: 2, Bias: 22354476498.435951, T: 3712, Avg. loss: 677492469076194448375808.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 5332653801.75, NNZs: 2, Bias: 22230055225.926235, T: 3840, Avg. loss: 700245238771116268322816.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 7203789407.69, NNZs: 2, Bias: 22143445401.185905, T: 3968, Avg. loss: 689761692549165969571840.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1151226788.45, NNZs: 2, Bias: 21803878355.909481, T: 4096, Avg. loss: 606690735438487300866048.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6066143187.89, NNZs: 2, Bias: 21652407576.324749, T: 4224, Avg. loss: 705508235933493101592576.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 3653353722.18, NNZs: 2, Bias: 21524195042.565372, T: 4352, Avg. loss: 547249752860127813173248.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2269324379.04, NNZs: 2, Bias: 21290805225.634644, T: 4480, Avg. loss: 732410655520764255535104.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 15606545490.36, NNZs: 2, Bias: 21278769940.600414, T: 4608, Avg. loss: 778598052801515284856832.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 10556931755.47, NNZs: 2, Bias: 21290093778.783661, T: 4736, Avg. loss: 698913147197822135697408.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2240369168.98, NNZs: 2, Bias: 21115512212.046700, T: 4864, Avg. loss: 726211073031893524938752.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 13065525946.72, NNZs: 2, Bias: 21239534046.181568, T: 4992, Avg. loss: 589286487995077326012416.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 761389416.44, NNZs: 2, Bias: 21146539366.282410, T: 5120, Avg. loss: 50259865720432527147008.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 255733496.94, NNZs: 2, Bias: 21133257586.056816, T: 5248, Avg. loss: 146778869923665559552.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 80541855.32, NNZs: 2, Bias: 21123924469.522453, T: 5376, Avg. loss: 65172910154052984832.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 169522514.83, NNZs: 2, Bias: 21115777568.461617, T: 5504, Avg. loss: 45300569747198705664.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 200598809.35, NNZs: 2, Bias: 21108598628.988262, T: 5632, Avg. loss: 41654453811716669440.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 223984873.11, NNZs: 2, Bias: 21101541225.180305, T: 5760, Avg. loss: 38873738504198209536.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 252003678.54, NNZs: 2, Bias: 21094543632.266800, T: 5888, Avg. loss: 38955078930283749376.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 265106560.84, NNZs: 2, Bias: 21087249332.392914, T: 6016, Avg. loss: 41825698883841859584.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 258345152.60, NNZs: 2, Bias: 21080669867.731262, T: 6144, Avg. loss: 39070895368759853056.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 240493108.98, NNZs: 2, Bias: 21073785911.338917, T: 6272, Avg. loss: 41380624596970602496.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 257547266.89, NNZs: 2, Bias: 21067034571.689449, T: 6400, Avg. loss: 37787116354243829760.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 241376523.04, NNZs: 2, Bias: 21060101073.807495, T: 6528, Avg. loss: 42086304308929331200.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 261953613.61, NNZs: 2, Bias: 21052874054.986786, T: 6656, Avg. loss: 39747047473651261440.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 252291799.93, NNZs: 2, Bias: 21046293482.005142, T: 6784, Avg. loss: 38243138523016241152.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 226311320.73, NNZs: 2, Bias: 21040017435.061031, T: 6912, Avg. loss: 39652069942452420608.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 236441089.76, NNZs: 2, Bias: 21033090357.991840, T: 7040, Avg. loss: 39299298561610670080.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 240241767.46, NNZs: 2, Bias: 21031701947.045212, T: 7168, Avg. loss: 32904009384062447616.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 240609555.00, NNZs: 2, Bias: 21030330570.195972, T: 7296, Avg. loss: 33545056014338494464.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 247608991.68, NNZs: 2, Bias: 21028918602.626129, T: 7424, Avg. loss: 32494844630815305728.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 245356356.89, NNZs: 2, Bias: 21027584538.800644, T: 7552, Avg. loss: 33249508458197188608.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 246960554.49, NNZs: 2, Bias: 21026213129.185875, T: 7680, Avg. loss: 33021640472029536256.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 246074924.71, NNZs: 2, Bias: 21024860524.955677, T: 7808, Avg. loss: 33353366984936673280.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 245774478.35, NNZs: 2, Bias: 21023508975.659370, T: 7936, Avg. loss: 33096667398961795072.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 245646013.69, NNZs: 2, Bias: 21022154126.194923, T: 8064, Avg. loss: 33103301047023382528.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 246816017.15, NNZs: 2, Bias: 21021869699.638317, T: 8192, Avg. loss: 32286849888281575424.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 249651152.11, NNZs: 2, Bias: 21021567251.845192, T: 8320, Avg. loss: 32057746753215881216.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 249044928.49, NNZs: 2, Bias: 21021303882.287258, T: 8448, Avg. loss: 32258802312059613184.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 249447549.28, NNZs: 2, Bias: 21021029159.122932, T: 8576, Avg. loss: 32174557703743143936.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 249143356.46, NNZs: 2, Bias: 21020762422.810745, T: 8704, Avg. loss: 32223085243568771072.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 247488531.71, NNZs: 2, Bias: 21020512619.376980, T: 8832, Avg. loss: 32091278456171331584.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 248580558.42, NNZs: 2, Bias: 21020229051.731667, T: 8960, Avg. loss: 32265726089878736896.000000\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 70 epochs took 0.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1850949621082.44, NNZs: 2, Bias: 20488269755.192513, T: 128, Avg. loss: 33594516450367511922875564032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 510199221151.44, NNZs: 2, Bias: 20196184505.897614, T: 256, Avg. loss: 36335861389056513792081395712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2659519520874.17, NNZs: 2, Bias: -58816717593.635300, T: 384, Avg. loss: 35021393338392611654838779904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 812114947664.18, NNZs: 2, Bias: -80221722130.851349, T: 512, Avg. loss: 36492364832690077160236384256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 83881486429.08, NNZs: 2, Bias: -65281821057.545700, T: 640, Avg. loss: 37214044981999355031285923840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 798178417411.05, NNZs: 2, Bias: -99609653357.423218, T: 768, Avg. loss: 37595614059761868003950460928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 432919042185.81, NNZs: 2, Bias: -90536417010.009033, T: 896, Avg. loss: 953020287730348836092116992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 161935764560.34, NNZs: 2, Bias: -87907059559.562927, T: 1024, Avg. loss: 900221678136742238792712192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 294037862395.71, NNZs: 2, Bias: -93074493885.119247, T: 1152, Avg. loss: 910554927767662177017659392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 464144253143.58, NNZs: 2, Bias: -87233387654.823151, T: 1280, Avg. loss: 796498732669202916066721792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 103892538902.36, NNZs: 2, Bias: -90244378430.066544, T: 1408, Avg. loss: 890926481529224588104302592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 135078203255.63, NNZs: 2, Bias: -80335899526.160736, T: 1536, Avg. loss: 843314067569241251406413824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 177835292445.24, NNZs: 2, Bias: -78387378882.713638, T: 1664, Avg. loss: 958808348989583422891491328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 387253938577.98, NNZs: 2, Bias: -66498263710.365448, T: 1792, Avg. loss: 844060562865454376573468672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 299200779810.30, NNZs: 2, Bias: -60087841424.978851, T: 1920, Avg. loss: 783025763828361107869794304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 57338304553.26, NNZs: 2, Bias: -77953896008.157623, T: 2048, Avg. loss: 954788312047149329556701184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 553424488478.35, NNZs: 2, Bias: -79003263171.545395, T: 2176, Avg. loss: 824328326402025935729590272.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 276095293354.66, NNZs: 2, Bias: -79687603820.649628, T: 2304, Avg. loss: 849978025142796689873043456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 385032734577.23, NNZs: 2, Bias: -81672297405.044876, T: 2432, Avg. loss: 914048922208689319443431424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 469623141521.42, NNZs: 2, Bias: -83897616774.441650, T: 2560, Avg. loss: 862496986878273025501822976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 36666759001.36, NNZs: 2, Bias: -84925092731.799881, T: 2688, Avg. loss: 108345010750894108154265600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 29271417523.82, NNZs: 2, Bias: -82930604107.341782, T: 2816, Avg. loss: 26307590750201619289210880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 62796785914.09, NNZs: 2, Bias: -80736548753.540466, T: 2944, Avg. loss: 32675197779104168662794240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 86502998813.62, NNZs: 2, Bias: -78121047285.617767, T: 3072, Avg. loss: 31218251959613757438558208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 56650337794.48, NNZs: 2, Bias: -78766995106.193512, T: 3200, Avg. loss: 31071276614346870529982464.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 28266289526.82, NNZs: 2, Bias: -79541057893.500702, T: 3328, Avg. loss: 31025378745196263161987072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 41463952788.65, NNZs: 2, Bias: -76413659063.052963, T: 3456, Avg. loss: 29699196389843906747957248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3896546419.01, NNZs: 2, Bias: -76678173775.736908, T: 3584, Avg. loss: 783854961741242633814016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1333886963.99, NNZs: 2, Bias: -76646103756.926987, T: 3712, Avg. loss: 610647145767599316402176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3043433234.41, NNZs: 2, Bias: -76222194267.257431, T: 3840, Avg. loss: 567149341144090348093440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2681554198.81, NNZs: 2, Bias: -76143277179.613205, T: 3968, Avg. loss: 719871439156857289048064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4435945569.59, NNZs: 2, Bias: -76148801780.579041, T: 4096, Avg. loss: 513953375449501535305728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7001272660.45, NNZs: 2, Bias: -76168273458.312836, T: 4224, Avg. loss: 558035743663326635229184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 10698871108.31, NNZs: 2, Bias: -76236602690.223511, T: 4352, Avg. loss: 445991587619020291964928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3122584924.67, NNZs: 2, Bias: -76154657585.250519, T: 4480, Avg. loss: 728522473863846173868032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2768389954.12, NNZs: 2, Bias: -75930216013.676590, T: 4608, Avg. loss: 672795791770857896935424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2165098525.77, NNZs: 2, Bias: -75883212578.724304, T: 4736, Avg. loss: 503705445224677728321536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 5278310565.74, NNZs: 2, Bias: -75707789064.613297, T: 4864, Avg. loss: 488324564733827829727232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1381104160.78, NNZs: 2, Bias: -75464327118.544617, T: 4992, Avg. loss: 653266037235668400209920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1162295145.55, NNZs: 2, Bias: -75437667102.205276, T: 5120, Avg. loss: 633271144194233204736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1024523159.43, NNZs: 2, Bias: -75411096515.293839, T: 5248, Avg. loss: 584613968687523692544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 994601195.05, NNZs: 2, Bias: -75380655506.514160, T: 5376, Avg. loss: 656853744262004080640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1016029670.40, NNZs: 2, Bias: -75350243133.001648, T: 5504, Avg. loss: 641582073035021615104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1009006329.81, NNZs: 2, Bias: -75320716894.300842, T: 5632, Avg. loss: 597141087910582288384.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 981805469.37, NNZs: 2, Bias: -75292215993.490051, T: 5760, Avg. loss: 581967068565025259520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 994075294.13, NNZs: 2, Bias: -75263470848.320221, T: 5888, Avg. loss: 573946031156187103232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 955018998.70, NNZs: 2, Bias: -75234400330.839447, T: 6016, Avg. loss: 620953191410624888832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 965934578.83, NNZs: 2, Bias: -75204287741.479248, T: 6144, Avg. loss: 630149750906495434752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1028505969.47, NNZs: 2, Bias: -75173560366.013336, T: 6272, Avg. loss: 631021419153764122624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1047080325.76, NNZs: 2, Bias: -75145462955.339081, T: 6400, Avg. loss: 585505607814532104192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 959702213.87, NNZs: 2, Bias: -75119047545.544830, T: 6528, Avg. loss: 556787365010776522752.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 975170897.89, NNZs: 2, Bias: -75089050127.962219, T: 6656, Avg. loss: 599331878162396741632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 956303404.85, NNZs: 2, Bias: -75059166433.441544, T: 6784, Avg. loss: 623250332020671381504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1041481768.58, NNZs: 2, Bias: -75028669561.316055, T: 6912, Avg. loss: 582392316204612780032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1013250037.24, NNZs: 2, Bias: -75001226164.848083, T: 7040, Avg. loss: 554760039269459886080.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 966176168.97, NNZs: 2, Bias: -74972359020.176651, T: 7168, Avg. loss: 619108632512063078400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 993974938.28, NNZs: 2, Bias: -74943647010.318359, T: 7296, Avg. loss: 559545568709473796096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 922425243.70, NNZs: 2, Bias: -74913582621.043869, T: 7424, Avg. loss: 646300103622036422656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 962534567.12, NNZs: 2, Bias: -74884747163.438446, T: 7552, Avg. loss: 582993440024768937984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1066767262.96, NNZs: 2, Bias: -74853020347.972885, T: 7680, Avg. loss: 612538897500570517504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1039571014.29, NNZs: 2, Bias: -74847638214.670593, T: 7808, Avg. loss: 493419628877419315200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1017468335.52, NNZs: 2, Bias: -74842161826.567444, T: 7936, Avg. loss: 496150368979144409088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1012578831.15, NNZs: 2, Bias: -74836392081.708038, T: 8064, Avg. loss: 502851884563253886976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1025155933.03, NNZs: 2, Bias: -74830444042.412384, T: 8192, Avg. loss: 495111066954033594368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 989496879.14, NNZs: 2, Bias: -74825094077.755981, T: 8320, Avg. loss: 503334112355757326336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 991857512.28, NNZs: 2, Bias: -74819230536.974380, T: 8448, Avg. loss: 502443739196165718016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1011137240.63, NNZs: 2, Bias: -74817802035.710358, T: 8576, Avg. loss: 494003691384336875520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1004957280.18, NNZs: 2, Bias: -74816727956.871918, T: 8704, Avg. loss: 487845488393110028288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1009525315.73, NNZs: 2, Bias: -74815510525.454529, T: 8832, Avg. loss: 487207428485981667328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1007051882.42, NNZs: 2, Bias: -74814383436.196411, T: 8960, Avg. loss: 489240661136120020992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1007971563.44, NNZs: 2, Bias: -74813212270.845291, T: 9088, Avg. loss: 488632923075801907200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1004326817.79, NNZs: 2, Bias: -74812099739.033524, T: 9216, Avg. loss: 490038473251134046208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1007528217.26, NNZs: 2, Bias: -74810896210.433258, T: 9344, Avg. loss: 489641722874603765760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1002600719.21, NNZs: 2, Bias: -74809801761.000687, T: 9472, Avg. loss: 489629007613334585344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 74 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1142404097585.47, NNZs: 2, Bias: 37126836627.602272, T: 128, Avg. loss: 33090839958145936883277889536.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1575865467746.75, NNZs: 2, Bias: 49956329998.104942, T: 256, Avg. loss: 32546086062564763693582647296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 197247792402.09, NNZs: 2, Bias: 64717921225.413788, T: 384, Avg. loss: 34589402052244927176572403712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 849264156647.17, NNZs: 2, Bias: 29044481723.686462, T: 512, Avg. loss: 31454428018956196619646664704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1073222086063.71, NNZs: 2, Bias: 53892596756.661270, T: 640, Avg. loss: 33157829339835928736513916928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1903576770888.84, NNZs: 2, Bias: 43152566978.258049, T: 768, Avg. loss: 29282720275528706588997058560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 858413998917.29, NNZs: 2, Bias: 17671565632.172707, T: 896, Avg. loss: 31485222176652117407594184704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 556521348526.24, NNZs: 2, Bias: 45415644867.284515, T: 1024, Avg. loss: 37388843895186224697325912064.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 2740315880547.31, NNZs: 2, Bias: 28926412470.516754, T: 1152, Avg. loss: 34320044902229828570001178624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 360851863116.47, NNZs: 2, Bias: 26121303887.859436, T: 1280, Avg. loss: 29620581531517356373058781184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 2175274004353.71, NNZs: 2, Bias: 61672998894.956696, T: 1408, Avg. loss: 29910991729275526442456711168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 167155709447.61, NNZs: 2, Bias: 55150238484.072479, T: 1536, Avg. loss: 1338776150754720404725563392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 133623685563.30, NNZs: 2, Bias: 58440633078.079277, T: 1664, Avg. loss: 811539907699733413998100480.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 53254694800.11, NNZs: 2, Bias: 61059346993.262245, T: 1792, Avg. loss: 911208933030479811470950400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 339653017645.57, NNZs: 2, Bias: 59811890025.546219, T: 1920, Avg. loss: 827362758811332904858157056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 184752270251.02, NNZs: 2, Bias: 57030798376.644249, T: 2048, Avg. loss: 838528154183512979417333760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 158757596027.68, NNZs: 2, Bias: 46212128141.409119, T: 2176, Avg. loss: 791789900936992762170966016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 116540049856.21, NNZs: 2, Bias: 39295751560.619728, T: 2304, Avg. loss: 831880637058739817817309184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 99731024728.91, NNZs: 2, Bias: 34294661786.947800, T: 2432, Avg. loss: 852020566480732161937768448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 336188305589.05, NNZs: 2, Bias: 52339890460.701660, T: 2560, Avg. loss: 800155253462974860017795072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 209898343284.54, NNZs: 2, Bias: 63475663976.307625, T: 2688, Avg. loss: 773285531321135511344513024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 171708616806.91, NNZs: 2, Bias: 49869600853.190628, T: 2816, Avg. loss: 809373335984981998923939840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 326101843397.25, NNZs: 2, Bias: 43669947058.862976, T: 2944, Avg. loss: 772566148479927958571581440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 87254509378.50, NNZs: 2, Bias: 47519883846.884674, T: 3072, Avg. loss: 861140571113395509241315328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 415003961769.93, NNZs: 2, Bias: 51498627055.574661, T: 3200, Avg. loss: 794145362581932458396090368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 202316358810.32, NNZs: 2, Bias: 51999227832.301132, T: 3328, Avg. loss: 794252414020816687717154816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 442627420739.42, NNZs: 2, Bias: 40202693952.457916, T: 3456, Avg. loss: 795017322941937526985719808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 219694495545.85, NNZs: 2, Bias: 41562815615.779396, T: 3584, Avg. loss: 817294337549616193772453888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 70692301050.24, NNZs: 2, Bias: 35967967351.028030, T: 3712, Avg. loss: 39402030532730319854895104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 20302571936.15, NNZs: 2, Bias: 35607874374.476288, T: 3840, Avg. loss: 30022762892001686260285440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 34646844033.88, NNZs: 2, Bias: 39004627021.996025, T: 3968, Avg. loss: 28019595855646583666245632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 17482673600.51, NNZs: 2, Bias: 37109030092.621391, T: 4096, Avg. loss: 31974283629370997479571456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 23126631231.60, NNZs: 2, Bias: 39247656075.331085, T: 4224, Avg. loss: 28577527097024127369740288.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 60034105461.53, NNZs: 2, Bias: 36816949248.987366, T: 4352, Avg. loss: 28411389989729414485639168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 45411467631.64, NNZs: 2, Bias: 35209975814.218216, T: 4480, Avg. loss: 28478516015683886167097344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 38522939115.53, NNZs: 2, Bias: 36534307461.510132, T: 4608, Avg. loss: 31068556880298119702511616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4682347450.96, NNZs: 2, Bias: 36183024356.010841, T: 4736, Avg. loss: 608605368174760865824768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7329743516.68, NNZs: 2, Bias: 36129081498.047729, T: 4864, Avg. loss: 305572111043804268593152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9035357039.80, NNZs: 2, Bias: 36039294171.860382, T: 4992, Avg. loss: 435906240843455477579776.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 958786992.98, NNZs: 2, Bias: 36201509894.281700, T: 5120, Avg. loss: 674779646921780588707840.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 7216470266.48, NNZs: 2, Bias: 36210468354.093666, T: 5248, Avg. loss: 394354887763680580075520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6719763134.32, NNZs: 2, Bias: 36211043228.407104, T: 5376, Avg. loss: 405982595280433814962176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 5838720995.03, NNZs: 2, Bias: 36122476296.285065, T: 5504, Avg. loss: 401738727319947437932544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2070089793.36, NNZs: 2, Bias: 36052607355.276176, T: 5632, Avg. loss: 4722994510883673079808.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 560059971.64, NNZs: 2, Bias: 36023301831.574974, T: 5760, Avg. loss: 812129122736278732800.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 174915156.70, NNZs: 2, Bias: 36002336709.360512, T: 5888, Avg. loss: 249334019497956081664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 322536072.22, NNZs: 2, Bias: 35985172824.601173, T: 6016, Avg. loss: 165535665298969755648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 447610373.25, NNZs: 2, Bias: 35970301214.959023, T: 6144, Avg. loss: 133336908314610712576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 478494277.63, NNZs: 2, Bias: 35956294719.816818, T: 6272, Avg. loss: 136595676041490825216.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 472150503.54, NNZs: 2, Bias: 35942329194.330086, T: 6400, Avg. loss: 141143975161943605248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 467134725.92, NNZs: 2, Bias: 35928873009.822113, T: 6528, Avg. loss: 144829067610223345664.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 470062729.27, NNZs: 2, Bias: 35915435163.861176, T: 6656, Avg. loss: 137298765994058858496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 431605622.31, NNZs: 2, Bias: 35903132778.494400, T: 6784, Avg. loss: 131489824144987144192.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 463153815.74, NNZs: 2, Bias: 35888529148.059761, T: 6912, Avg. loss: 142624440249430999040.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 511232736.65, NNZs: 2, Bias: 35874832838.630287, T: 7040, Avg. loss: 131283788549386764288.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 470945765.73, NNZs: 2, Bias: 35861584119.393272, T: 7168, Avg. loss: 140376391756477104128.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 492824143.16, NNZs: 2, Bias: 35847402298.548264, T: 7296, Avg. loss: 135134671255567499264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 531124183.67, NNZs: 2, Bias: 35833216270.059395, T: 7424, Avg. loss: 136422062076087795712.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 502698924.42, NNZs: 2, Bias: 35819801555.394440, T: 7552, Avg. loss: 142666848808894513152.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 460257873.04, NNZs: 2, Bias: 35806702111.069298, T: 7680, Avg. loss: 141159785838883012608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 467786731.28, NNZs: 2, Bias: 35803941479.779671, T: 7808, Avg. loss: 110435523317567684608.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 466439416.28, NNZs: 2, Bias: 35801252251.176140, T: 7936, Avg. loss: 112480369895655505920.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 465074121.99, NNZs: 2, Bias: 35798607399.442894, T: 8064, Avg. loss: 110406452818372526080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 466190867.56, NNZs: 2, Bias: 35795896234.701378, T: 8192, Avg. loss: 111957386872932892672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 470834512.92, NNZs: 2, Bias: 35793149839.161308, T: 8320, Avg. loss: 111056831362553970688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 476845129.69, NNZs: 2, Bias: 35790386595.335220, T: 8448, Avg. loss: 110843165291200856064.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 481851906.73, NNZs: 2, Bias: 35787655334.757996, T: 8576, Avg. loss: 109956168705342160896.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 469762785.98, NNZs: 2, Bias: 35785116468.181870, T: 8704, Avg. loss: 112252423038100602880.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 468637861.90, NNZs: 2, Bias: 35782463390.896255, T: 8832, Avg. loss: 110346113802935812096.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 480105987.88, NNZs: 2, Bias: 35779646481.315430, T: 8960, Avg. loss: 110072888647151452160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 465547450.12, NNZs: 2, Bias: 35777200900.193642, T: 9088, Avg. loss: 108952469644482740224.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 476335061.13, NNZs: 2, Bias: 35774337476.601715, T: 9216, Avg. loss: 112937102988442959872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 481725563.85, NNZs: 2, Bias: 35771604945.989815, T: 9344, Avg. loss: 110024672987564572672.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 480028463.36, NNZs: 2, Bias: 35768937304.449287, T: 9472, Avg. loss: 111500689040118022144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 469491934.93, NNZs: 2, Bias: 35766382309.189095, T: 9600, Avg. loss: 111610608361885335552.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 479236700.57, NNZs: 2, Bias: 35763599079.656166, T: 9728, Avg. loss: 109760593727463014400.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 474196680.05, NNZs: 2, Bias: 35763126262.316811, T: 9856, Avg. loss: 109029005277131194368.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 472156078.22, NNZs: 2, Bias: 35762617592.033234, T: 9984, Avg. loss: 108100458317680754688.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 471036907.46, NNZs: 2, Bias: 35762098060.717606, T: 10112, Avg. loss: 107780710452982218752.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 471007982.11, NNZs: 2, Bias: 35761563231.094894, T: 10240, Avg. loss: 108000018735167913984.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 471269534.12, NNZs: 2, Bias: 35761025404.099167, T: 10368, Avg. loss: 107786957884224651264.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 473290690.71, NNZs: 2, Bias: 35760464038.366638, T: 10496, Avg. loss: 107878772686922776576.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 471794380.85, NNZs: 2, Bias: 35759949273.584251, T: 10624, Avg. loss: 107812502033178689536.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 470821183.30, NNZs: 2, Bias: 35759428163.090073, T: 10752, Avg. loss: 107655773795802333184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 473718012.12, NNZs: 2, Bias: 35758857115.294670, T: 10880, Avg. loss: 107442721801524297728.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 472340549.44, NNZs: 2, Bias: 35758340329.599464, T: 11008, Avg. loss: 107920801125682593792.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 472021673.58, NNZs: 2, Bias: 35757810330.926323, T: 11136, Avg. loss: 107728832323538141184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 470379452.73, NNZs: 2, Bias: 35757298136.168564, T: 11264, Avg. loss: 107648529464776949760.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 471507163.17, NNZs: 2, Bias: 35756747970.023537, T: 11392, Avg. loss: 107990652917900115968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 472510536.05, NNZs: 2, Bias: 35756199501.582573, T: 11520, Avg. loss: 107948863987104710656.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 90 epochs took 0.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 496742349562.95, NNZs: 2, Bias: 14563327105.443008, T: 128, Avg. loss: 35186735931586348185240469504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 777659487269.27, NNZs: 2, Bias: -12094700408.142708, T: 256, Avg. loss: 28800363555274842382956232704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 938598583482.36, NNZs: 2, Bias: 65717240601.788719, T: 384, Avg. loss: 36721627744120678471511834624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 379793515441.14, NNZs: 2, Bias: 108465271927.395218, T: 512, Avg. loss: 33569021789569141359578710016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2387991443053.92, NNZs: 2, Bias: 104721264300.567917, T: 640, Avg. loss: 36603085231881378305543241728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 872684829925.88, NNZs: 2, Bias: 144721264300.567932, T: 768, Avg. loss: 36056111298317316340387414016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 677296609838.21, NNZs: 2, Bias: 130388908640.487000, T: 896, Avg. loss: 37811571791845635439420506112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 262117470417.53, NNZs: 2, Bias: 135965276767.065460, T: 1024, Avg. loss: 886353850178605197186564096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 157912457103.31, NNZs: 2, Bias: 126551995446.017075, T: 1152, Avg. loss: 840938368266088021793701888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 101358341713.32, NNZs: 2, Bias: 135166288046.988007, T: 1280, Avg. loss: 815194298112066936167727104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 166119331658.99, NNZs: 2, Bias: 137216576778.947021, T: 1408, Avg. loss: 775414419239147028613169152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 307868240257.61, NNZs: 2, Bias: 138782677126.684753, T: 1536, Avg. loss: 821500163561940121882198016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 60815078684.26, NNZs: 2, Bias: 129511347370.963593, T: 1664, Avg. loss: 863896909483006085170200576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 234952191635.67, NNZs: 2, Bias: 112022920007.178375, T: 1792, Avg. loss: 887272862607657732526833664.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 197421760193.20, NNZs: 2, Bias: 112532726667.070648, T: 1920, Avg. loss: 934912599416400999931183104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 140627384841.43, NNZs: 2, Bias: 120660885730.160980, T: 2048, Avg. loss: 816745421022543457242054656.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 18714977508.91, NNZs: 2, Bias: 118915812827.428207, T: 2176, Avg. loss: 31468600832433309268049920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 108079067845.16, NNZs: 2, Bias: 118377313763.646622, T: 2304, Avg. loss: 29041363665219213938655232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 78183676120.40, NNZs: 2, Bias: 118840807615.561066, T: 2432, Avg. loss: 31423794906203995175387136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 18257037200.53, NNZs: 2, Bias: 119693389167.221375, T: 2560, Avg. loss: 32270474165127006212063232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 62344086724.85, NNZs: 2, Bias: 119672629028.120712, T: 2688, Avg. loss: 31110593359098384937385984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 62930524550.45, NNZs: 2, Bias: 120930968027.103119, T: 2816, Avg. loss: 32855691938975557888245760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 35612920394.31, NNZs: 2, Bias: 123578383455.120041, T: 2944, Avg. loss: 28982827619175446163226624.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 86204787955.18, NNZs: 2, Bias: 123782782632.787720, T: 3072, Avg. loss: 28868148196485548732317696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 111512698788.26, NNZs: 2, Bias: 124959872826.791290, T: 3200, Avg. loss: 29802597793822664657207296.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 48742939141.39, NNZs: 2, Bias: 127271433511.449783, T: 3328, Avg. loss: 31159565180345422482243584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 94470071353.89, NNZs: 2, Bias: 130103211926.238724, T: 3456, Avg. loss: 28998276377565979517911040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 39863517311.12, NNZs: 2, Bias: 128026821719.518738, T: 3584, Avg. loss: 30809868073019838700716032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 88887246570.83, NNZs: 2, Bias: 129969814260.967484, T: 3712, Avg. loss: 26246538425252477010968576.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 24060737783.60, NNZs: 2, Bias: 128326167713.274170, T: 3840, Avg. loss: 30415073844589794617720832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 71868801867.91, NNZs: 2, Bias: 125668179444.781738, T: 3968, Avg. loss: 31656724000430916756307968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 10273121739.98, NNZs: 2, Bias: 125398101197.931335, T: 4096, Avg. loss: 30001230567044894955667456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 97340491086.76, NNZs: 2, Bias: 125042165995.481140, T: 4224, Avg. loss: 29258755754714714387513344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 29597076323.75, NNZs: 2, Bias: 121108607401.453094, T: 4352, Avg. loss: 32188129371694196594835456.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9989775067.83, NNZs: 2, Bias: 120911335382.983536, T: 4480, Avg. loss: 614523300336901300420608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 10351028309.64, NNZs: 2, Bias: 120611875818.132004, T: 4608, Avg. loss: 543316882274489804521472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 3342726325.32, NNZs: 2, Bias: 120191566328.523071, T: 4736, Avg. loss: 657883370140203881594880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 3980742901.59, NNZs: 2, Bias: 119904054176.456619, T: 4864, Avg. loss: 581188422978442174136320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2155239768.18, NNZs: 2, Bias: 119936826413.302856, T: 4992, Avg. loss: 510609253577186095398912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7491041453.67, NNZs: 2, Bias: 119552005152.833603, T: 5120, Avg. loss: 484363512728800546783232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9296836733.59, NNZs: 2, Bias: 119515261948.648010, T: 5248, Avg. loss: 504319521528610069413888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9686451856.64, NNZs: 2, Bias: 119648832437.225418, T: 5376, Avg. loss: 652502865562639905325056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 5789060920.86, NNZs: 2, Bias: 119452290658.072342, T: 5504, Avg. loss: 739596305600276756168704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 8229218602.97, NNZs: 2, Bias: 119320984667.797485, T: 5632, Avg. loss: 556932238228951819878400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2797931897.14, NNZs: 2, Bias: 119230194176.485870, T: 5760, Avg. loss: 611680776182833482825728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 541982193.15, NNZs: 2, Bias: 119158067734.671295, T: 5888, Avg. loss: 3460615075523402399744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1027699181.25, NNZs: 2, Bias: 119102213245.014420, T: 6016, Avg. loss: 1756314704268072583168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1323002888.00, NNZs: 2, Bias: 119055778313.565460, T: 6144, Avg. loss: 1416341252401864376320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1515559341.70, NNZs: 2, Bias: 119009702826.363480, T: 6272, Avg. loss: 1413601625567328993280.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1443479399.21, NNZs: 2, Bias: 118968245993.976273, T: 6400, Avg. loss: 1341743304167892713472.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1450655529.66, NNZs: 2, Bias: 118925661560.794373, T: 6528, Avg. loss: 1372942973751122722816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1576568018.44, NNZs: 2, Bias: 118881574542.054138, T: 6656, Avg. loss: 1353422232310467264512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1723266518.07, NNZs: 2, Bias: 118837057172.673218, T: 6784, Avg. loss: 1354978109376419594240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1624633855.95, NNZs: 2, Bias: 118796485542.530441, T: 6912, Avg. loss: 1361490539182098481152.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1745022330.20, NNZs: 2, Bias: 118751846074.756500, T: 7040, Avg. loss: 1368340537377225703424.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1704999849.75, NNZs: 2, Bias: 118743945712.526871, T: 7168, Avg. loss: 1138593204019891666944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1723469347.30, NNZs: 2, Bias: 118735368094.372330, T: 7296, Avg. loss: 1109799044557410795520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1721420453.85, NNZs: 2, Bias: 118726921486.206970, T: 7424, Avg. loss: 1140421573398809280512.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1703803064.09, NNZs: 2, Bias: 118718680098.389679, T: 7552, Avg. loss: 1142526314526347624448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1700325095.35, NNZs: 2, Bias: 118710298313.467804, T: 7680, Avg. loss: 1133560241749325905920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1676871712.36, NNZs: 2, Bias: 118702171555.209686, T: 7808, Avg. loss: 1139334703054598963200.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1679843919.67, NNZs: 2, Bias: 118693622532.684219, T: 7936, Avg. loss: 1143459481947821572096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1672399908.05, NNZs: 2, Bias: 118692040938.763535, T: 8064, Avg. loss: 1108755188269603880960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1670547175.92, NNZs: 2, Bias: 118690382061.198822, T: 8192, Avg. loss: 1107384749227619385344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1672089316.02, NNZs: 2, Bias: 118688676426.040939, T: 8320, Avg. loss: 1107098848531776274432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1671620613.53, NNZs: 2, Bias: 118686996553.790039, T: 8448, Avg. loss: 1109094655307493801984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1665652935.81, NNZs: 2, Bias: 118685397134.725555, T: 8576, Avg. loss: 1106359644353986035712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 1674557378.70, NNZs: 2, Bias: 118683587092.438629, T: 8704, Avg. loss: 1107672115245283540992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 1667939194.96, NNZs: 2, Bias: 118681994934.373550, T: 8832, Avg. loss: 1107694936110044545024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1669364712.55, NNZs: 2, Bias: 118680289807.957184, T: 8960, Avg. loss: 1108327290897244487680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1665067180.43, NNZs: 2, Bias: 118678666056.805267, T: 9088, Avg. loss: 1107457484412166471680.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1674242774.87, NNZs: 2, Bias: 118676852778.844727, T: 9216, Avg. loss: 1107829261997607747584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 72 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2569377746906.06, NNZs: 2, Bias: 10499513488.096680, T: 128, Avg. loss: 37917645036851043111001915392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1882203956687.40, NNZs: 2, Bias: 30499513488.096680, T: 256, Avg. loss: 35400699502101833260577325056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2691570125252.66, NNZs: 2, Bias: -9500486511.903320, T: 384, Avg. loss: 39249035192987694370765406208.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2383912422570.45, NNZs: 2, Bias: 17063992231.185707, T: 512, Avg. loss: 39019602803555073336159502336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 608767934790.05, NNZs: 2, Bias: 17063992231.185707, T: 640, Avg. loss: 41045282916473680258029060096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 535436806538.74, NNZs: 2, Bias: 57063992231.185707, T: 768, Avg. loss: 36851428434997646407491387392.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1473369276747.75, NNZs: 2, Bias: 15413073002.686104, T: 896, Avg. loss: 34844259468653717782836281344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 878460755458.93, NNZs: 2, Bias: 35413073002.686104, T: 1024, Avg. loss: 44452685140763401109203058688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1414431977112.98, NNZs: 2, Bias: 29334511020.769249, T: 1152, Avg. loss: 37485279735332317000951136256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1919124326704.65, NNZs: 2, Bias: 37982154101.421364, T: 1280, Avg. loss: 36237674332272436441845334016.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1784466250202.18, NNZs: 2, Bias: 56922784294.684410, T: 1408, Avg. loss: 38301901775646258055279017984.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 2731925603309.46, NNZs: 2, Bias: 78897912813.245850, T: 1536, Avg. loss: 38002611803293811848949792768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 485109179406.95, NNZs: 2, Bias: 85020394938.061035, T: 1664, Avg. loss: 1895748960892582865227743232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 428691755186.08, NNZs: 2, Bias: 97184227928.679581, T: 1792, Avg. loss: 965278968549080367586344960.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 80028534844.66, NNZs: 2, Bias: 117508370291.611984, T: 1920, Avg. loss: 947349563353260148689731584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 484158933784.43, NNZs: 2, Bias: 124599258575.943390, T: 2048, Avg. loss: 977588183422975614434410496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 272360939312.34, NNZs: 2, Bias: 137639412749.873627, T: 2176, Avg. loss: 1001533976721227739358560256.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 332485401459.81, NNZs: 2, Bias: 133694539439.772812, T: 2304, Avg. loss: 795765636564319459115794432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 170916375247.66, NNZs: 2, Bias: 133931875960.885422, T: 2432, Avg. loss: 879396384253958619039531008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 156845012815.56, NNZs: 2, Bias: 129197079408.238937, T: 2560, Avg. loss: 877255246956696147664568320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 200783707091.30, NNZs: 2, Bias: 137141097577.064636, T: 2688, Avg. loss: 835404132005564792512184320.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 27436295146.96, NNZs: 2, Bias: 135539373379.003235, T: 2816, Avg. loss: 890688890572375534136721408.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 140460133094.03, NNZs: 2, Bias: 135440470403.664124, T: 2944, Avg. loss: 868989150312887718827261952.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 33478280922.32, NNZs: 2, Bias: 135642831027.592026, T: 3072, Avg. loss: 36667980809157796276731904.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 53023813773.49, NNZs: 2, Bias: 136075622643.711014, T: 3200, Avg. loss: 33904424136194876942319616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 19587469015.59, NNZs: 2, Bias: 135660230988.437103, T: 3328, Avg. loss: 35134023800365362112888832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 63911579286.47, NNZs: 2, Bias: 135888243798.141586, T: 3456, Avg. loss: 33108950531513374734286848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 43322757297.88, NNZs: 2, Bias: 135001545970.748932, T: 3584, Avg. loss: 32181354768789121540292608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 65317331951.88, NNZs: 2, Bias: 132377149430.315872, T: 3712, Avg. loss: 33846927395957671018364928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10015311510.30, NNZs: 2, Bias: 131436211270.652710, T: 3840, Avg. loss: 32324855087672141159596032.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 48055997716.86, NNZs: 2, Bias: 131632812691.712509, T: 3968, Avg. loss: 35004942795409816587075584.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 98836844074.34, NNZs: 2, Bias: 130974299175.060837, T: 4096, Avg. loss: 34880430483686341335842816.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 11759612800.08, NNZs: 2, Bias: 132391466216.947357, T: 4224, Avg. loss: 32354149001219605784428544.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1069498962.15, NNZs: 2, Bias: 131981164269.882629, T: 4352, Avg. loss: 695851177062430117199872.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 17904125781.68, NNZs: 2, Bias: 131875488642.319046, T: 4480, Avg. loss: 425491423150825285877760.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2208996712.84, NNZs: 2, Bias: 131627313423.653290, T: 4608, Avg. loss: 619523041649279836880896.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 13952903232.63, NNZs: 2, Bias: 131216293343.835403, T: 4736, Avg. loss: 567824491817095063928832.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4113972662.16, NNZs: 2, Bias: 131018502234.739426, T: 4864, Avg. loss: 872276204121248151633920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1952363180.04, NNZs: 2, Bias: 130436097692.878326, T: 4992, Avg. loss: 729484368704444764782592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 1614080532.83, NNZs: 2, Bias: 130297552290.170441, T: 5120, Avg. loss: 648471676096636862332928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 1267728346.08, NNZs: 2, Bias: 130246507719.243393, T: 5248, Avg. loss: 2185186357145348079616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 1415088141.83, NNZs: 2, Bias: 130195094393.849182, T: 5376, Avg. loss: 1816742695020135710720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 1638412016.49, NNZs: 2, Bias: 130141957672.302139, T: 5504, Avg. loss: 1865155910915456499712.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 1604750303.47, NNZs: 2, Bias: 130092798774.984100, T: 5632, Avg. loss: 1868267014765084934144.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 1665015379.32, NNZs: 2, Bias: 130042169413.251831, T: 5760, Avg. loss: 1895568603267134128128.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 1655833862.06, NNZs: 2, Bias: 129993319343.905014, T: 5888, Avg. loss: 1750320569234420924416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 1597329584.91, NNZs: 2, Bias: 129946872077.622803, T: 6016, Avg. loss: 1654675697933129089024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 1816421683.32, NNZs: 2, Bias: 129897505822.435532, T: 6144, Avg. loss: 1660401514133320892416.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 1795911370.73, NNZs: 2, Bias: 129850490965.914764, T: 6272, Avg. loss: 1744385757166023213056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 1700137990.28, NNZs: 2, Bias: 129804525640.241745, T: 6400, Avg. loss: 1787942459321345638400.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 1559846176.70, NNZs: 2, Bias: 129757687942.056458, T: 6528, Avg. loss: 1718171279311969189888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 1615913657.74, NNZs: 2, Bias: 129707064056.292374, T: 6656, Avg. loss: 1815144444175550251008.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 1639426999.91, NNZs: 2, Bias: 129697051072.887329, T: 6784, Avg. loss: 1469983664729548914688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 1643770345.31, NNZs: 2, Bias: 129687398388.365524, T: 6912, Avg. loss: 1449313380081093050368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 1626528042.88, NNZs: 2, Bias: 129677901166.247208, T: 7040, Avg. loss: 1467771053177519734784.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 1623268467.47, NNZs: 2, Bias: 129668388305.516800, T: 7168, Avg. loss: 1439385873920640679936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 1657398335.06, NNZs: 2, Bias: 129658379350.857880, T: 7296, Avg. loss: 1441715039299627646976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 1631504645.72, NNZs: 2, Bias: 129649067074.317490, T: 7424, Avg. loss: 1453402452310177349632.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 1633410030.49, NNZs: 2, Bias: 129639334171.886276, T: 7552, Avg. loss: 1467410522106556055552.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 1637786848.89, NNZs: 2, Bias: 129629544851.911987, T: 7680, Avg. loss: 1470764222735182987264.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 1640961411.98, NNZs: 2, Bias: 129619845900.790848, T: 7808, Avg. loss: 1456919524375876075520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 1638426249.53, NNZs: 2, Bias: 129617961025.907608, T: 7936, Avg. loss: 1408673188131341860864.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 1646043039.03, NNZs: 2, Bias: 129615937449.783066, T: 8064, Avg. loss: 1417079112765113106432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 1652368316.73, NNZs: 2, Bias: 129613939999.583771, T: 8192, Avg. loss: 1408931056839954268160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 1648102065.58, NNZs: 2, Bias: 129612070664.774536, T: 8320, Avg. loss: 1414008977449000370176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 1647744178.02, NNZs: 2, Bias: 129610154562.329056, T: 8448, Avg. loss: 1412100532436624474112.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 1652004268.40, NNZs: 2, Bias: 129608178400.704849, T: 8576, Avg. loss: 1412368270863117320192.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 67 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 919083238885.36, NNZs: 2, Bias: -5204257128.401099, T: 160, Avg. loss: 42690963164631123085857128448.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1886855850349.99, NNZs: 2, Bias: -5204257128.401099, T: 320, Avg. loss: 47667337297692698680596889600.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2014377571360.44, NNZs: 2, Bias: -5204257128.401099, T: 480, Avg. loss: 47807542913564326634566189056.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1217875198860.70, NNZs: 2, Bias: -5204257128.401099, T: 640, Avg. loss: 43251646055368062477034061824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 809311435727.93, NNZs: 2, Bias: -5204257128.401099, T: 800, Avg. loss: 45910176442290427616347291648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2402109489594.51, NNZs: 2, Bias: -5204257128.401099, T: 960, Avg. loss: 46122434190168428714177593344.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 251745696815.97, NNZs: 2, Bias: -10047999925.521950, T: 1120, Avg. loss: 2545857278695625429042069504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 281021341411.71, NNZs: 2, Bias: 10389146427.667542, T: 1280, Avg. loss: 852978271793155018506371072.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 215153914303.90, NNZs: 2, Bias: 17424428434.144768, T: 1440, Avg. loss: 872641863331569000800845824.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 46580229640.58, NNZs: 2, Bias: 27819893892.602467, T: 1600, Avg. loss: 943508972606631104875593728.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 258321845784.56, NNZs: 2, Bias: 26586289230.208298, T: 1760, Avg. loss: 912840699306954259855048704.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 115707366078.01, NNZs: 2, Bias: 34942285473.213730, T: 1920, Avg. loss: 892182220793200138923278336.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 126815044063.32, NNZs: 2, Bias: 32399737153.832092, T: 2080, Avg. loss: 862522273889744387504603136.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 65661352425.73, NNZs: 2, Bias: 28291359388.318878, T: 2240, Avg. loss: 32039401921562099346046976.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 18711406630.33, NNZs: 2, Bias: 27362925834.524296, T: 2400, Avg. loss: 32337791390868865760100352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 61472263361.95, NNZs: 2, Bias: 29455488471.260468, T: 2560, Avg. loss: 34210340720494819955179520.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 16053091767.24, NNZs: 2, Bias: 31994963459.320305, T: 2720, Avg. loss: 33013714712542535099613184.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 52172330459.75, NNZs: 2, Bias: 33507106069.481030, T: 2880, Avg. loss: 31432669975421756437954560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 17444958926.82, NNZs: 2, Bias: 31682078538.609108, T: 3040, Avg. loss: 34306072632086980143874048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 37543059300.05, NNZs: 2, Bias: 31121521851.976128, T: 3200, Avg. loss: 28603493543964495648391168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8495885397.35, NNZs: 2, Bias: 27067781647.110123, T: 3360, Avg. loss: 31790682767478888318631936.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 65842960673.00, NNZs: 2, Bias: 26635288127.879967, T: 3520, Avg. loss: 32667488747490214401802240.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 58438063099.93, NNZs: 2, Bias: 26128767261.115467, T: 3680, Avg. loss: 31413037737363009695645696.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 87385547076.92, NNZs: 2, Bias: 21522349591.919670, T: 3840, Avg. loss: 34998131188255095561125888.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10726892585.14, NNZs: 2, Bias: 22138642588.847534, T: 4000, Avg. loss: 35776126814564916337311744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 6892215675.57, NNZs: 2, Bias: 22352118601.354145, T: 4160, Avg. loss: 610992335193305396543488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4467390753.87, NNZs: 2, Bias: 22603849405.348473, T: 4320, Avg. loss: 680814273185237633597440.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1035302350.14, NNZs: 2, Bias: 22622796160.422375, T: 4480, Avg. loss: 522815536395996970876928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 741661144.43, NNZs: 2, Bias: 22311729178.170395, T: 4640, Avg. loss: 528054215911945107668992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3197291719.29, NNZs: 2, Bias: 22239873959.189957, T: 4800, Avg. loss: 528149593844210936578048.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 5673545957.63, NNZs: 2, Bias: 22120502424.154472, T: 4960, Avg. loss: 522209315976754698911744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11021280083.13, NNZs: 2, Bias: 22152556422.815884, T: 5120, Avg. loss: 644413658849833685876736.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 517441864.27, NNZs: 2, Bias: 22029798790.768898, T: 5280, Avg. loss: 551602696124161276772352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 10859048186.42, NNZs: 2, Bias: 22440323659.295929, T: 5440, Avg. loss: 608573550245285963235328.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 3490720464.64, NNZs: 2, Bias: 22330209402.602215, T: 5600, Avg. loss: 559289892105222690439168.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2648055633.64, NNZs: 2, Bias: 21721261826.727421, T: 5760, Avg. loss: 719586543373524727234560.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 629399090.77, NNZs: 2, Bias: 21730138318.979305, T: 5920, Avg. loss: 820085594847913967616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 379211545.09, NNZs: 2, Bias: 21722484606.237095, T: 6080, Avg. loss: 58993974811162042368.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 309579364.70, NNZs: 2, Bias: 21713270242.947746, T: 6240, Avg. loss: 48296819353137348608.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 279769236.96, NNZs: 2, Bias: 21704096105.093285, T: 6400, Avg. loss: 44260342219063164928.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 282234970.22, NNZs: 2, Bias: 21694185567.456818, T: 6560, Avg. loss: 46742283911497711616.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 282900700.66, NNZs: 2, Bias: 21684215059.487328, T: 6720, Avg. loss: 47269423429559762944.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 292779500.71, NNZs: 2, Bias: 21673917066.692379, T: 6880, Avg. loss: 47530901247436316672.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 278782632.00, NNZs: 2, Bias: 21663844126.834324, T: 7040, Avg. loss: 49268362840795521024.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 255666458.18, NNZs: 2, Bias: 21654187175.054100, T: 7200, Avg. loss: 48218725434415210496.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 255399091.54, NNZs: 2, Bias: 21652190619.050457, T: 7360, Avg. loss: 39918014185293938688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 260323614.91, NNZs: 2, Bias: 21650123305.372810, T: 7520, Avg. loss: 40077393829297184768.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 268463009.40, NNZs: 2, Bias: 21648022921.458820, T: 7680, Avg. loss: 39828635158241583104.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 264602268.13, NNZs: 2, Bias: 21646093801.052441, T: 7840, Avg. loss: 39382630812680863744.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 269393294.15, NNZs: 2, Bias: 21644034043.208969, T: 8000, Avg. loss: 39839725101277298688.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 274638422.89, NNZs: 2, Bias: 21641990527.636337, T: 8160, Avg. loss: 39203570838350970880.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 268848278.19, NNZs: 2, Bias: 21640063864.266541, T: 8320, Avg. loss: 39682335682379726848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 275111790.22, NNZs: 2, Bias: 21637979962.819096, T: 8480, Avg. loss: 39749900963544481792.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 277964986.03, NNZs: 2, Bias: 21635974991.959522, T: 8640, Avg. loss: 38895260052716830720.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 274526380.80, NNZs: 2, Bias: 21634028739.479210, T: 8800, Avg. loss: 39451828367253585920.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 272503252.98, NNZs: 2, Bias: 21632056972.136650, T: 8960, Avg. loss: 39574374557194452992.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 267560215.20, NNZs: 2, Bias: 21630168068.095169, T: 9120, Avg. loss: 38504740169291120640.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 271477533.12, NNZs: 2, Bias: 21628103685.457870, T: 9280, Avg. loss: 39878732826465239040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 274137074.76, NNZs: 2, Bias: 21626081720.577583, T: 9440, Avg. loss: 39358585049928114176.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 277110966.79, NNZs: 2, Bias: 21624050796.375801, T: 9600, Avg. loss: 39447552427807342592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 273236083.45, NNZs: 2, Bias: 21622136316.426189, T: 9760, Avg. loss: 38741137558845284352.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 268368310.87, NNZs: 2, Bias: 21620220147.695965, T: 9920, Avg. loss: 39139843329255260160.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 270372957.38, NNZs: 2, Bias: 21619797282.653530, T: 10080, Avg. loss: 38553103244960530432.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 271057471.47, NNZs: 2, Bias: 21619391229.615265, T: 10240, Avg. loss: 38496165944157077504.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 269905309.61, NNZs: 2, Bias: 21619008449.203293, T: 10400, Avg. loss: 38449954112807477248.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 270271435.46, NNZs: 2, Bias: 21618606283.342838, T: 10560, Avg. loss: 38510353475256418304.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 270202092.70, NNZs: 2, Bias: 21618209704.797512, T: 10720, Avg. loss: 38468820404083539968.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 270608114.83, NNZs: 2, Bias: 21617806921.676292, T: 10880, Avg. loss: 38516390915782811648.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 270054773.69, NNZs: 2, Bias: 21617416581.743580, T: 11040, Avg. loss: 38455566126334156800.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 270970959.63, NNZs: 2, Bias: 21617007595.271713, T: 11200, Avg. loss: 38500736713916735488.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 70 epochs took 0.00 seconds\n",
      "MSE: 9.029858046590142e+19\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6d2e3e5",
   "metadata": {},
   "source": [
    "<h1 style=\"color:orange;\">Phase Four - Part 5/ The amount of prediction error according to the formula : Error = Ypred - Ytest </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6e379e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7.042950e+08</td>\n",
       "      <td>16.9</td>\n",
       "      <td>7.042950e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-5.973064e+09</td>\n",
       "      <td>22.4</td>\n",
       "      <td>-5.973064e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-8.526966e+09</td>\n",
       "      <td>21.4</td>\n",
       "      <td>-8.526966e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.112889e+10</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1.112889e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-8.248641e+09</td>\n",
       "      <td>24.7</td>\n",
       "      <td>-8.248641e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.687116e+09</td>\n",
       "      <td>12.6</td>\n",
       "      <td>6.687116e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-6.652500e+09</td>\n",
       "      <td>22.3</td>\n",
       "      <td>-6.652500e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.471433e+10</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.471433e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3.423409e+09</td>\n",
       "      <td>11.5</td>\n",
       "      <td>3.423409e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2.147720e+09</td>\n",
       "      <td>14.9</td>\n",
       "      <td>2.147720e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.278017e+10</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.278017e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.576308e+10</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1.576308e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2.481572e+09</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.481572e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.343612e+10</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.343612e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.021358e+10</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.021358e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>6.344520e+09</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6.344520e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.375542e+10</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.375542e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1.887289e+08</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1.887289e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1.048694e+10</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.048694e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-3.999328e+09</td>\n",
       "      <td>18.9</td>\n",
       "      <td>-3.999328e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-4.630253e+09</td>\n",
       "      <td>19.7</td>\n",
       "      <td>-4.630253e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.840051e+09</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.840051e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>8.199280e+09</td>\n",
       "      <td>10.9</td>\n",
       "      <td>8.199280e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-7.386094e+09</td>\n",
       "      <td>22.2</td>\n",
       "      <td>-7.386094e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.383238e+10</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.383238e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.693358e+10</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.693358e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-6.162040e+09</td>\n",
       "      <td>21.7</td>\n",
       "      <td>-6.162040e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>7.010718e+09</td>\n",
       "      <td>13.4</td>\n",
       "      <td>7.010718e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.176685e+10</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1.176685e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.390339e+10</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.390339e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.390184e+09</td>\n",
       "      <td>10.6</td>\n",
       "      <td>5.390184e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.090984e+10</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.090984e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-6.686732e+09</td>\n",
       "      <td>23.7</td>\n",
       "      <td>-6.686732e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>8.959186e+09</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.959186e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-3.839816e+09</td>\n",
       "      <td>16.1</td>\n",
       "      <td>-3.839816e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-5.826543e+09</td>\n",
       "      <td>20.7</td>\n",
       "      <td>-5.826543e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>5.658562e+09</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.658562e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>-7.188211e+09</td>\n",
       "      <td>20.8</td>\n",
       "      <td>-7.188211e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>8.679023e+09</td>\n",
       "      <td>11.9</td>\n",
       "      <td>8.679023e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.906119e+10</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.906119e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predicted  Actual         error\n",
       "95   7.042950e+08    16.9  7.042950e+08\n",
       "15  -5.973064e+09    22.4 -5.973064e+09\n",
       "30  -8.526966e+09    21.4 -8.526966e+09\n",
       "158  1.112889e+10     7.3  1.112889e+10\n",
       "128 -8.248641e+09    24.7 -8.248641e+09\n",
       "115  6.687116e+09    12.6  6.687116e+09\n",
       "69  -6.652500e+09    22.3 -6.652500e+09\n",
       "170  1.471433e+10     8.4  1.471433e+10\n",
       "174  3.423409e+09    11.5  3.423409e+09\n",
       "45   2.147720e+09    14.9  2.147720e+09\n",
       "66   1.278017e+10     9.5  1.278017e+10\n",
       "182  1.576308e+10     8.7  1.576308e+10\n",
       "165  2.481572e+09    11.9  2.481572e+09\n",
       "78   1.343612e+10     5.3  1.343612e+10\n",
       "186  1.021358e+10    10.3  1.021358e+10\n",
       "177  6.344520e+09    11.7  6.344520e+09\n",
       "56   1.375542e+10     5.5  1.375542e+10\n",
       "152  1.887289e+08    16.6  1.887289e+08\n",
       "82   1.048694e+10    11.3  1.048694e+10\n",
       "68  -3.999328e+09    18.9 -3.999328e+09\n",
       "124 -4.630253e+09    19.7 -4.630253e+09\n",
       "16   6.840051e+09    12.5  6.840051e+09\n",
       "148  8.199280e+09    10.9  8.199280e+09\n",
       "93  -7.386094e+09    22.2 -7.386094e+09\n",
       "65   1.383238e+10     9.3  1.383238e+10\n",
       "60   1.693358e+10     8.1  1.693358e+10\n",
       "84  -6.162040e+09    21.7 -6.162040e+09\n",
       "67   7.010718e+09    13.4  7.010718e+09\n",
       "125  1.176685e+10    10.6  1.176685e+10\n",
       "132  1.390339e+10     5.7  1.390339e+10\n",
       "9    5.390184e+09    10.6  5.390184e+09\n",
       "18   1.090984e+10    11.3  1.090984e+10\n",
       "55  -6.686732e+09    23.7 -6.686732e+09\n",
       "75   8.959186e+09     8.7  8.959186e+09\n",
       "150 -3.839816e+09    16.1 -3.839816e+09\n",
       "104 -5.826543e+09    20.7 -5.826543e+09\n",
       "135  5.658562e+09    11.6  5.658562e+09\n",
       "137 -7.188211e+09    20.8 -7.188211e+09\n",
       "164  8.679023e+09    11.9  8.679023e+09\n",
       "76   1.906119e+10     6.9  1.906119e+10"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Predicted\":y_pred, \"Actual\":y_test})\n",
    "\n",
    "# Calculate the error\n",
    "df['error'] = df['Predicted'] - df['Actual']\n",
    "\n",
    "# Show the dataframe\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
